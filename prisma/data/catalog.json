[
  {
    "_id": "64e6673c0df4c63f21cb3933",
    "id": "TheBloke/PuddleJumper-13B-GGUF",
    "likes": 18,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "dataset:totally-not-an-llm/EverythingLM-data-V2",
      "dataset:garage-bAInd/Open-Platypus",
      "dataset:Open-Orca/OpenOrca",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/PuddleJumper-13B-GGUF",
    "model": {
      "_id": "64e6673c0df4c63f21cb3933",
      "id": "TheBloke/PuddleJumper-13B-GGUF",
      "modelId": "TheBloke/PuddleJumper-13B-GGUF",
      "author": "TheBloke",
      "sha": "2eaeadf5c7fbeb95784c8c74a3acde42989f692c",
      "lastModified": "2023-09-27T12:45:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:totally-not-an-llm/EverythingLM-data-V2",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:Open-Orca/OpenOrca",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 18,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "totally-not-an-llm/EverythingLM-data-V2",
          "garage-bAInd/Open-Platypus",
          "Open-Orca/OpenOrca"
        ],
        "model_name": "PuddleJumper 13B",
        "base_model": "totally-not-an-llm/PuddleJumper-13b",
        "inference": false,
        "model_creator": "Kai Howard",
        "model_type": "llama",
        "prompt_template": "You are a helpful AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "puddlejumper-13b.Q2_K.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q4_0.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q4_1.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q5_0.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q5_1.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q6_K.gguf"
        },
        {
          "rfilename": "puddlejumper-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e52b54fba2c8c08e7e28a4",
      "id": "totally-not-an-llm/PuddleJumper-13b",
      "modelId": "totally-not-an-llm/PuddleJumper-13b",
      "author": "totally-not-an-llm",
      "sha": "59682ffcf1ffa7846f2318dc1e9553815ba149af",
      "lastModified": "2023-08-24T17:03:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:totally-not-an-llm/EverythingLM-data-V2",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:Open-Orca/OpenOrca",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4462,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "totally-not-an-llm/EverythingLM-data-V2",
          "garage-bAInd/Open-Platypus",
          "Open-Orca/OpenOrca"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e711f614a7448ab95c7fc9",
    "id": "TheBloke/Nous-Hermes-Llama2-70B-GGUF",
    "likes": 21,
    "private": false,
    "downloads": 28,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "self-instruct",
      "distillation",
      "synthetic instruction",
      "en",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Nous-Hermes-Llama2-70B-GGUF",
    "model": {
      "_id": "64e711f614a7448ab95c7fc9",
      "id": "TheBloke/Nous-Hermes-Llama2-70B-GGUF",
      "modelId": "TheBloke/Nous-Hermes-Llama2-70B-GGUF",
      "author": "TheBloke",
      "sha": "f0f9493b8a83350675e503bd2850b742eae70b1f",
      "lastModified": "2023-09-27T12:45:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "self-instruct",
        "distillation",
        "synthetic instruction",
        "en",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 28,
      "library_name": "transformers",
      "likes": 21,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": [
          "mit"
        ],
        "tags": [
          "llama-2",
          "self-instruct",
          "distillation",
          "synthetic instruction"
        ],
        "model_name": "Nous Hermes Llama2 70B",
        "base_model": "NousResearch/Nous-Hermes-Llama2-70b",
        "inference": false,
        "model_creator": "NousResearch",
        "model_type": "llama",
        "prompt_template": "### Instruction:\n\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q2_K.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q4_0.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q5_0.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "nous-hermes-llama2-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64e48c679bec7890e2c54850",
      "id": "NousResearch/Nous-Hermes-Llama2-70b",
      "modelId": "NousResearch/Nous-Hermes-Llama2-70b",
      "author": "NousResearch",
      "sha": "8de803a311239e3d7f0a19c1456d3b59e87a0788",
      "lastModified": "2023-08-27T15:22:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "self-instruct",
        "distillation",
        "synthetic instruction",
        "en",
        "license:mit",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6061,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 66,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "tags": [
          "llama-2",
          "self-instruct",
          "distillation",
          "synthetic instruction"
        ],
        "license": [
          "mit"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "gigaShrimp/NousResearch-Nous-Hermes-Llama2-70b",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "dyou363636/NousResearch-Nous-Hermes-Llama2-70b",
        "xysee/NousResearch-Nous-Hermes-Llama2-70b",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "adapter_config.json"
        },
        {
          "rfilename": "adapter_model.bin"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e740c186fc685a30b0cb25",
    "id": "TheBloke/Nous-Puffin-70B-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "sft",
      "eng",
      "dataset:LDJnr/Puffin",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Nous-Puffin-70B-GGUF",
    "model": {
      "_id": "64e740c186fc685a30b0cb25",
      "id": "TheBloke/Nous-Puffin-70B-GGUF",
      "modelId": "TheBloke/Nous-Puffin-70B-GGUF",
      "author": "TheBloke",
      "sha": "4734534885b6ac54b3316b84ea77c621abc65da3",
      "lastModified": "2023-09-27T12:46:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "sft",
        "eng",
        "dataset:LDJnr/Puffin",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "eng"
        ],
        "license": [
          "mit"
        ],
        "tags": [
          "llama-2",
          "sft"
        ],
        "datasets": [
          "LDJnr/Puffin"
        ],
        "model_name": "Nous Puffin 70B",
        "base_model": "NousResearch/Nous-puffin-70b",
        "inference": false,
        "model_creator": "NousResearch",
        "model_type": "llama",
        "prompt_template": "### HUMAN:\n{prompt}\n\n### RESPONSE:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "nous-puffin-70b.Q2_K.gguf"
        },
        {
          "rfilename": "nous-puffin-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "nous-puffin-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "nous-puffin-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "nous-puffin-70b.Q4_0.gguf"
        },
        {
          "rfilename": "nous-puffin-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "nous-puffin-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "nous-puffin-70b.Q5_0.gguf"
        },
        {
          "rfilename": "nous-puffin-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "nous-puffin-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "nous-puffin-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "nous-puffin-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "nous-puffin-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "nous-puffin-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64c68f315cd9506edf5e414a",
      "id": "NousResearch/Nous-Puffin-70B",
      "modelId": "NousResearch/Nous-Puffin-70B",
      "author": "NousResearch",
      "sha": "1edacb6da1cc54695d85a17c1dc9ffcab186fb9d",
      "lastModified": "2023-09-25T02:52:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "sft",
        "eng",
        "dataset:LDJnr/Puffin",
        "license:mit",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4866,
      "library_name": "transformers",
      "likes": 18,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "eng"
        ],
        "tags": [
          "llama-2",
          "sft"
        ],
        "license": [
          "mit"
        ],
        "datasets": [
          "LDJnr/Puffin"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "readme.md"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e78cdac3b2443fb30b9dda",
    "id": "TheBloke/CodeLlama-7B-Instruct-GGUF",
    "likes": 67,
    "private": false,
    "downloads": 371,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "code",
      "arxiv:2308.12950",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/CodeLlama-7B-Instruct-GGUF",
    "model": {
      "_id": "64e78cdac3b2443fb30b9dda",
      "id": "TheBloke/CodeLlama-7B-Instruct-GGUF",
      "modelId": "TheBloke/CodeLlama-7B-Instruct-GGUF",
      "author": "TheBloke",
      "sha": "2f064ee0c6ae3f025ec4e392c6ba5dd049c77969",
      "lastModified": "2023-09-27T12:46:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 371,
      "library_name": "transformers",
      "likes": 67,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "license": "llama2",
        "tags": [
          "llama-2"
        ],
        "model_name": "CodeLlama 7B Instruct",
        "base_model": "codellama/CodeLlama-7b-instruct-hf",
        "inference": false,
        "model_creator": "Meta",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] Write code to solve the following coding problem that obeys the constraints and passes the example test cases. Please wrap your code answer using ```:\n{prompt}\n[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "HoangHa/llama2-code",
        "arborvitae/GalaxiCode.ai"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codellama-7b-instruct.Q2_K.gguf"
        },
        {
          "rfilename": "codellama-7b-instruct.Q3_K_L.gguf"
        },
        {
          "rfilename": "codellama-7b-instruct.Q3_K_M.gguf"
        },
        {
          "rfilename": "codellama-7b-instruct.Q3_K_S.gguf"
        },
        {
          "rfilename": "codellama-7b-instruct.Q4_0.gguf"
        },
        {
          "rfilename": "codellama-7b-instruct.Q4_K_M.gguf"
        },
        {
          "rfilename": "codellama-7b-instruct.Q4_K_S.gguf"
        },
        {
          "rfilename": "codellama-7b-instruct.Q5_0.gguf"
        },
        {
          "rfilename": "codellama-7b-instruct.Q5_K_M.gguf"
        },
        {
          "rfilename": "codellama-7b-instruct.Q5_K_S.gguf"
        },
        {
          "rfilename": "codellama-7b-instruct.Q6_K.gguf"
        },
        {
          "rfilename": "codellama-7b-instruct.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e78661d0964816be6a1d1b",
      "id": "codellama/CodeLlama-7b-Instruct-hf",
      "modelId": "codellama/CodeLlama-7b-Instruct-hf",
      "author": "codellama",
      "sha": "65515fcea0bf53f04b79ac582d93da752cf1e655",
      "lastModified": "2023-10-27T18:11:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 45525,
      "library_name": "transformers",
      "likes": 83,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "pipeline_tag": "text-generation",
        "tags": [
          "llama-2"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "bigcode/bigcode-models-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "K00B404/Ethical-CodeLlama-34b-Instruct-hf",
        "neng123/codellama-CodeLlama-7b-Instruct-hf",
        "roselee/code-generator",
        "Stef1397/codellama-CodeLlama-7b-Instruct-hf",
        "Lokesh1200/codellama7b",
        "TheVortexProject/open_llm_leaderboard",
        "Siva1995/UI_Code_Generation_APP",
        "asdvd01/codellama-CodeLlama-7b-Instruct-hf",
        "pminervini/tmp",
        "Felbdogg/codellama-CodeLlama-7b-Instruct-hf"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 6738546688
        },
        "total": 6738546688
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e78d0b1703da9e63ecc64c",
    "id": "TheBloke/CodeLlama-7B-Python-GGUF",
    "likes": 32,
    "private": false,
    "downloads": 72,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "code",
      "arxiv:2308.12950",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/CodeLlama-7B-Python-GGUF",
    "model": {
      "_id": "64e78d0b1703da9e63ecc64c",
      "id": "TheBloke/CodeLlama-7B-Python-GGUF",
      "modelId": "TheBloke/CodeLlama-7B-Python-GGUF",
      "author": "TheBloke",
      "sha": "3c6970f2f886afc4df807ec776479960c7ad110c",
      "lastModified": "2023-09-27T12:46:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 72,
      "library_name": "transformers",
      "likes": 32,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "license": "llama2",
        "tags": [
          "llama-2"
        ],
        "model_name": "CodeLlama 7B Python",
        "base_model": "codellama/CodeLlama-7b-python-hf",
        "inference": false,
        "model_creator": "Meta",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] Write code to solve the following coding problem that obeys the constraints and passes the example test cases. Please wrap your code answer using ```:\n{prompt}\n[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codellama-7b-python.Q2_K.gguf"
        },
        {
          "rfilename": "codellama-7b-python.Q3_K_L.gguf"
        },
        {
          "rfilename": "codellama-7b-python.Q3_K_M.gguf"
        },
        {
          "rfilename": "codellama-7b-python.Q3_K_S.gguf"
        },
        {
          "rfilename": "codellama-7b-python.Q4_0.gguf"
        },
        {
          "rfilename": "codellama-7b-python.Q4_K_M.gguf"
        },
        {
          "rfilename": "codellama-7b-python.Q4_K_S.gguf"
        },
        {
          "rfilename": "codellama-7b-python.Q5_0.gguf"
        },
        {
          "rfilename": "codellama-7b-python.Q5_K_M.gguf"
        },
        {
          "rfilename": "codellama-7b-python.Q5_K_S.gguf"
        },
        {
          "rfilename": "codellama-7b-python.Q6_K.gguf"
        },
        {
          "rfilename": "codellama-7b-python.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e785e0709dee6addd22582",
      "id": "codellama/CodeLlama-7b-Python-hf",
      "modelId": "codellama/CodeLlama-7b-Python-hf",
      "author": "codellama",
      "sha": "7ee7b6beb0dece09b0431ea46c03bc1724e21572",
      "lastModified": "2023-10-27T18:08:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 22390,
      "library_name": "transformers",
      "likes": 63,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "pipeline_tag": "text-generation",
        "tags": [
          "llama-2"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "bigcode/bigcode-models-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "theangkko/codellama-CodeLlama-7b-Python-hf",
        "sid92/codellama-CodeLlama-7b-Python-hf",
        "shreefhamed/codellama-CodeLlama-7b-Python-hf",
        "markl11/codellama-CodeLlama-7b-Python-hf",
        "rpratl/codellama-CodeLlama-7b-Python-hf",
        "TheVortexProject/open_llm_leaderboard",
        "LovelySweet/codellama-CodeLlama-7b-Python-hf",
        "majoh837/jffhg",
        "majoh837/fghhgfg",
        "majoh837/dsadas",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 6738415616
        },
        "total": 6738415616
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e78d117acd8971f2c6bbe6",
    "id": "TheBloke/CodeLlama-7B-GGUF",
    "likes": 45,
    "private": false,
    "downloads": 168,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "code",
      "arxiv:2308.12950",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/CodeLlama-7B-GGUF",
    "model": {
      "_id": "64e78d117acd8971f2c6bbe6",
      "id": "TheBloke/CodeLlama-7B-GGUF",
      "modelId": "TheBloke/CodeLlama-7B-GGUF",
      "author": "TheBloke",
      "sha": "98596f7f6c318118824bcbee4b0e20010ec510ec",
      "lastModified": "2023-09-27T12:46:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 168,
      "library_name": "transformers",
      "likes": 45,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "license": "llama2",
        "tags": [
          "llama-2"
        ],
        "model_name": "CodeLlama 7B",
        "base_model": "codellama/CodeLlama-7b-hf",
        "inference": false,
        "model_creator": "Meta",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codellama-7b.Q2_K.gguf"
        },
        {
          "rfilename": "codellama-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "codellama-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "codellama-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "codellama-7b.Q4_0.gguf"
        },
        {
          "rfilename": "codellama-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "codellama-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "codellama-7b.Q5_0.gguf"
        },
        {
          "rfilename": "codellama-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "codellama-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "codellama-7b.Q6_K.gguf"
        },
        {
          "rfilename": "codellama-7b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e785cfdbec2317e6b3a213",
      "id": "codellama/CodeLlama-7b-hf",
      "modelId": "codellama/CodeLlama-7b-hf",
      "author": "codellama",
      "sha": "bc5283229e2fe411552f55c71657e97edf79066c",
      "lastModified": "2023-10-27T16:00:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 114888,
      "library_name": "transformers",
      "likes": 167,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "pipeline_tag": "text-generation",
        "tags": [
          "llama-2"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "bigcode/bigcode-models-leaderboard",
        "Vokturz/can-it-run-llm",
        "gsaivinay/open_llm_leaderboard",
        "codys12/MergeLlama-7b",
        "Alex89912/ai-code-v1",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "AdxLive/codellama-CodeLlama-7b-hf",
        "Akanshu/codellama-demo",
        "EinfachOlder/codellama-playground",
        "Khanhpham92/codellama-CodeLlama-7b-hf",
        "mokolo/codellama-CodeLlama-7b-hf",
        "khiemnt/codellama-CodeLlama-7b-hf",
        "linguistique/codellama-CodeLlama-7b-hf",
        "TheVortexProject/open_llm_leaderboard",
        "felipeugalde/codellama-CodeLlama-7b-hf",
        "imjunaidafzal/can-it-run-llm",
        "muellerzr/can-it-run-llm",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 6738546688
        },
        "total": 6738546688
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e7bafd0c47bf287ca550b8",
    "id": "TheBloke/CodeLlama-13B-GGUF",
    "likes": 31,
    "private": false,
    "downloads": 72,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "code",
      "arxiv:2308.12950",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/CodeLlama-13B-GGUF",
    "model": {
      "_id": "64e7bafd0c47bf287ca550b8",
      "id": "TheBloke/CodeLlama-13B-GGUF",
      "modelId": "TheBloke/CodeLlama-13B-GGUF",
      "author": "TheBloke",
      "sha": "dc64dd5ad4c82364e7b0fe119d544b131dfdb8bc",
      "lastModified": "2023-09-27T12:46:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 72,
      "library_name": "transformers",
      "likes": 31,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "license": "llama2",
        "tags": [
          "llama-2"
        ],
        "model_name": "CodeLlama 13B",
        "base_model": "codellama/CodeLlama-13b-hf",
        "inference": false,
        "model_creator": "Meta",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codellama-13b.Q2_K.gguf"
        },
        {
          "rfilename": "codellama-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "codellama-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "codellama-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "codellama-13b.Q4_0.gguf"
        },
        {
          "rfilename": "codellama-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "codellama-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "codellama-13b.Q5_0.gguf"
        },
        {
          "rfilename": "codellama-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "codellama-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "codellama-13b.Q6_K.gguf"
        },
        {
          "rfilename": "codellama-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e785f06e8d01b7998924e3",
      "id": "codellama/CodeLlama-13b-hf",
      "modelId": "codellama/CodeLlama-13b-hf",
      "author": "codellama",
      "sha": "a49a368460ad22e43dfffb97a1e1b826a6418d3b",
      "lastModified": "2023-10-27T18:04:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 25314,
      "library_name": "transformers",
      "likes": 52,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "pipeline_tag": "text-generation",
        "tags": [
          "llama-2"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "bigcode/bigcode-models-leaderboard",
        "Vokturz/can-it-run-llm",
        "codellama/codellama-playground",
        "gsaivinay/open_llm_leaderboard",
        "teganmosi/codellama-playground",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Jesbel/codellama-CodeLlama-13b-hf",
        "EinfachOlder/codellama-playground",
        "khiemnt/codellama-CodeLlama-13b-hf",
        "trttung1610/codellama-playground",
        "AIConsultant/Llama2-Code-Filling",
        "wffcyrus/codellama-playground",
        "psychicalgae/codellama-playground",
        "huohuoma/codellama-playground",
        "TheVortexProject/open_llm_leaderboard",
        "imjunaidafzal/can-it-run-llm",
        "muellerzr/can-it-run-llm",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 13016028160
        },
        "total": 13016028160
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e7bc1129a548f66a1ddb15",
    "id": "TheBloke/CodeLlama-13B-Instruct-GGUF",
    "likes": 66,
    "private": false,
    "downloads": 262,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "code",
      "arxiv:2308.12950",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/CodeLlama-13B-Instruct-GGUF",
    "model": {
      "_id": "64e7bc1129a548f66a1ddb15",
      "id": "TheBloke/CodeLlama-13B-Instruct-GGUF",
      "modelId": "TheBloke/CodeLlama-13B-Instruct-GGUF",
      "author": "TheBloke",
      "sha": "82f1dd9567b9b20b7e8f8aa9ecf3d2f121e5d415",
      "lastModified": "2023-09-27T12:46:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 262,
      "library_name": "transformers",
      "likes": 66,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "license": "llama2",
        "tags": [
          "llama-2"
        ],
        "model_name": "CodeLlama 13B Instruct",
        "base_model": "codellama/CodeLlama-13b-Instruct-hf",
        "inference": false,
        "model_creator": "Meta",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] Write code to solve the following coding problem that obeys the constraints and passes the example test cases. Please wrap your code answer using ```:\n{prompt}\n[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "mikeee/codellama-13b-instruct-gguf",
        "Kush1/LLAMA-2-13-B"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codellama-13b-instruct.Q2_K.gguf"
        },
        {
          "rfilename": "codellama-13b-instruct.Q3_K_L.gguf"
        },
        {
          "rfilename": "codellama-13b-instruct.Q3_K_M.gguf"
        },
        {
          "rfilename": "codellama-13b-instruct.Q3_K_S.gguf"
        },
        {
          "rfilename": "codellama-13b-instruct.Q4_0.gguf"
        },
        {
          "rfilename": "codellama-13b-instruct.Q4_K_M.gguf"
        },
        {
          "rfilename": "codellama-13b-instruct.Q4_K_S.gguf"
        },
        {
          "rfilename": "codellama-13b-instruct.Q5_0.gguf"
        },
        {
          "rfilename": "codellama-13b-instruct.Q5_K_M.gguf"
        },
        {
          "rfilename": "codellama-13b-instruct.Q5_K_S.gguf"
        },
        {
          "rfilename": "codellama-13b-instruct.Q6_K.gguf"
        },
        {
          "rfilename": "codellama-13b-instruct.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e7867286fc685a30ba3882",
      "id": "codellama/CodeLlama-13b-Instruct-hf",
      "modelId": "codellama/CodeLlama-13b-Instruct-hf",
      "author": "codellama",
      "sha": "daacef37fce72ddb85154379b4dd77cb4f42573c",
      "lastModified": "2023-10-27T18:11:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 91475,
      "library_name": "transformers",
      "likes": 76,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "pipeline_tag": "text-generation",
        "tags": [
          "llama-2"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "bigcode/bigcode-models-leaderboard",
        "codellama/codellama-13b-chat",
        "gsaivinay/open_llm_leaderboard",
        "ysharma/WizardCoder34b",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "alexkueck/ChatBotLI2Klein",
        "LittleNeon/codellama-13b-chat",
        "Atom007/codellama-13b-instruct-chat",
        "Danelskih/codellama-CodeLlama-13b-Instruct-hf",
        "K00B404/ethical-hacking-codellama-13b-chat",
        "Ahaduzzaman/codellama-13b-chat",
        "Vagus30/codellama-13b-chat",
        "Kralos-R/codellama-13b-chat",
        "universal-ml/AI-Coder",
        "subhojit777/test",
        "Innocent/codellama-13B-chat-experimental",
        "asdf13421/codellama-13b-chat",
        "Optimusprime123/codellama-CodeLlama-13b-Instruct-hf",
        "xiaozhou0822/sdadsd",
        "Shephali/codellama-13b-chat",
        "DUTwangzhijun/DUT_BioLLM_test",
        "dusieq/codellama-13b-chat",
        "mac011769/codellama-13b-chat",
        "iphann/codellama-13b-chat",
        "Ashrafb/codellama-CodeLlama-13b-Instruct-hf",
        "TheVortexProject/open_llm_leaderboard",
        "engomo-gmbh/codellama-CodeLlama-13b-Instruct-hf",
        "Vishal3152/codellama-13b-chat",
        "kumar2piai/llama2-7b-chat-hf",
        "asdvd01/codellama-CodeLlama-13b-Instruct-hf",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 13016028160
        },
        "total": 13016028160
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e7bdab9f8952a1c0ffbbb8",
    "id": "TheBloke/CodeLlama-13B-Python-GGUF",
    "likes": 20,
    "private": false,
    "downloads": 35,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "code",
      "arxiv:2308.12950",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/CodeLlama-13B-Python-GGUF",
    "model": {
      "_id": "64e7bdab9f8952a1c0ffbbb8",
      "id": "TheBloke/CodeLlama-13B-Python-GGUF",
      "modelId": "TheBloke/CodeLlama-13B-Python-GGUF",
      "author": "TheBloke",
      "sha": "c9b66de0e0716d0515f4a86362fd64646a035df6",
      "lastModified": "2023-09-27T12:46:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 35,
      "library_name": "transformers",
      "likes": 20,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "license": "llama2",
        "tags": [
          "llama-2"
        ],
        "model_name": "CodeLlama 13B Python",
        "base_model": "codellama/CodeLlama-13b-python-hf",
        "inference": false,
        "model_creator": "Meta",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] Write code to solve the following coding problem that obeys the constraints and passes the example test cases. Please wrap your code answer using ```:\n{prompt}\n[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codellama-13b-python.Q2_K.gguf"
        },
        {
          "rfilename": "codellama-13b-python.Q3_K_L.gguf"
        },
        {
          "rfilename": "codellama-13b-python.Q3_K_M.gguf"
        },
        {
          "rfilename": "codellama-13b-python.Q3_K_S.gguf"
        },
        {
          "rfilename": "codellama-13b-python.Q4_0.gguf"
        },
        {
          "rfilename": "codellama-13b-python.Q4_K_M.gguf"
        },
        {
          "rfilename": "codellama-13b-python.Q4_K_S.gguf"
        },
        {
          "rfilename": "codellama-13b-python.Q5_0.gguf"
        },
        {
          "rfilename": "codellama-13b-python.Q5_K_M.gguf"
        },
        {
          "rfilename": "codellama-13b-python.Q5_K_S.gguf"
        },
        {
          "rfilename": "codellama-13b-python.Q6_K.gguf"
        },
        {
          "rfilename": "codellama-13b-python.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e786016096e5928263bf6a",
      "id": "codellama/CodeLlama-13b-Python-hf",
      "modelId": "codellama/CodeLlama-13b-Python-hf",
      "author": "codellama",
      "sha": "e3ecb92bccb1d861472a9fdf02c3a94b21a5de16",
      "lastModified": "2023-10-27T18:09:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7124,
      "library_name": "transformers",
      "likes": 24,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "pipeline_tag": "text-generation",
        "tags": [
          "llama-2"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "bigcode/bigcode-models-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "amousavii9/codellama-CodeLlama-13b-Python-hf",
        "amousavii9/codellama-CodeLlama-13b-Python",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e7c2379f8952a1c0008ed1",
    "id": "TheBloke/CodeLlama-34B-GGUF",
    "likes": 47,
    "private": false,
    "downloads": 63,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "code",
      "arxiv:2308.12950",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/CodeLlama-34B-GGUF",
    "model": {
      "_id": "64e7c2379f8952a1c0008ed1",
      "id": "TheBloke/CodeLlama-34B-GGUF",
      "modelId": "TheBloke/CodeLlama-34B-GGUF",
      "author": "TheBloke",
      "sha": "6cfc6e717f9a3725d7a26246bc1d4b7eaca6dd4b",
      "lastModified": "2023-09-27T12:46:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 63,
      "library_name": "transformers",
      "likes": 47,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "license": "llama2",
        "tags": [
          "llama-2"
        ],
        "model_name": "CodeLlama 34B",
        "base_model": "codellama/CodeLlama-34b-hf",
        "inference": false,
        "model_creator": "Meta",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codellama-34b.Q2_K.gguf"
        },
        {
          "rfilename": "codellama-34b.Q3_K_L.gguf"
        },
        {
          "rfilename": "codellama-34b.Q3_K_M.gguf"
        },
        {
          "rfilename": "codellama-34b.Q3_K_S.gguf"
        },
        {
          "rfilename": "codellama-34b.Q4_0.gguf"
        },
        {
          "rfilename": "codellama-34b.Q4_K_M.gguf"
        },
        {
          "rfilename": "codellama-34b.Q4_K_S.gguf"
        },
        {
          "rfilename": "codellama-34b.Q5_0.gguf"
        },
        {
          "rfilename": "codellama-34b.Q5_K_M.gguf"
        },
        {
          "rfilename": "codellama-34b.Q5_K_S.gguf"
        },
        {
          "rfilename": "codellama-34b.Q6_K.gguf"
        },
        {
          "rfilename": "codellama-34b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e7869fb159a6f87be2188e",
      "id": "codellama/CodeLlama-34b-hf",
      "modelId": "codellama/CodeLlama-34b-hf",
      "author": "codellama",
      "sha": "82128714b6174570a64b3dd1f3e9c146bda26cf9",
      "lastModified": "2023-10-27T18:08:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 37999,
      "library_name": "transformers",
      "likes": 125,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "pipeline_tag": "text-generation",
        "tags": [
          "llama-2"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "bigcode/bigcode-models-leaderboard",
        "Vokturz/can-it-run-llm",
        "gsaivinay/open_llm_leaderboard",
        "navdeeps002/codellama-CodeLlama-34b-hf",
        "kasunx64/codellama-CodeLlama-34b-hf",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "eyoubli/codellama-CodeLlama-34b-hf",
        "sooft/codellama-CodeLlama-34b-hf",
        "Starboy001/codellama-CodeLlama-34b-hf",
        "kejunz/codellama-CodeLlama-34b-hf",
        "shreefhamed/codellama-CodeLlama-34b-hf",
        "Ashrafb/Ccll2",
        "minghao-520/codellama-CodeLlama-34b-hf",
        "TheVortexProject/open_llm_leaderboard",
        "aiconaca/codellama-CodeLlama-34b-hf",
        "imjunaidafzal/can-it-run-llm",
        "muellerzr/can-it-run-llm",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 33743970304
        },
        "total": 33743970304
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00007.safetensors"
        },
        {
          "rfilename": "model-00002-of-00007.safetensors"
        },
        {
          "rfilename": "model-00003-of-00007.safetensors"
        },
        {
          "rfilename": "model-00004-of-00007.safetensors"
        },
        {
          "rfilename": "model-00005-of-00007.safetensors"
        },
        {
          "rfilename": "model-00006-of-00007.safetensors"
        },
        {
          "rfilename": "model-00007-of-00007.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e7cc65e3953cd90bd5a2e6",
    "id": "TheBloke/CodeLlama-34B-Python-GGUF",
    "likes": 32,
    "private": false,
    "downloads": 10,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "code",
      "arxiv:2308.12950",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/CodeLlama-34B-Python-GGUF",
    "model": {
      "_id": "64e7cc65e3953cd90bd5a2e6",
      "id": "TheBloke/CodeLlama-34B-Python-GGUF",
      "modelId": "TheBloke/CodeLlama-34B-Python-GGUF",
      "author": "TheBloke",
      "sha": "3f2c2ff373e8740bf8155d5332da337ba20b1628",
      "lastModified": "2023-09-27T12:46:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "likes": 32,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "license": "llama2",
        "tags": [
          "llama-2"
        ],
        "model_name": "CodeLlama 34B Python",
        "base_model": "codellama/CodeLlama-34b-python-hf",
        "inference": false,
        "model_creator": "Meta",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] Write code to solve the following coding problem that obeys the constraints and passes the example test cases. Please wrap your code answer using ```:\n{prompt}\n[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codellama-34b-python.Q2_K.gguf"
        },
        {
          "rfilename": "codellama-34b-python.Q3_K_L.gguf"
        },
        {
          "rfilename": "codellama-34b-python.Q3_K_M.gguf"
        },
        {
          "rfilename": "codellama-34b-python.Q3_K_S.gguf"
        },
        {
          "rfilename": "codellama-34b-python.Q4_0.gguf"
        },
        {
          "rfilename": "codellama-34b-python.Q4_K_M.gguf"
        },
        {
          "rfilename": "codellama-34b-python.Q4_K_S.gguf"
        },
        {
          "rfilename": "codellama-34b-python.Q5_0.gguf"
        },
        {
          "rfilename": "codellama-34b-python.Q5_K_M.gguf"
        },
        {
          "rfilename": "codellama-34b-python.Q5_K_S.gguf"
        },
        {
          "rfilename": "codellama-34b-python.Q6_K.gguf"
        },
        {
          "rfilename": "codellama-34b-python.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e78bf3015ed1a435ea1a23",
      "id": "codellama/CodeLlama-34b-Python-hf",
      "modelId": "codellama/CodeLlama-34b-Python-hf",
      "author": "codellama",
      "sha": "0d7350d770892fb2ad349e8c215d1421aed0c62e",
      "lastModified": "2023-10-27T18:10:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6112,
      "library_name": "transformers",
      "likes": 61,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "pipeline_tag": "text-generation",
        "tags": [
          "llama-2"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "bigcode/bigcode-models-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Felipegalind0/codellama-CodeLlama-34b-Python-hf",
        "EdwardJi/codellama-CodeLlama-34b-Python-hf",
        "Sweettooth90/codellama-CodeLlama-34b-Python-hf",
        "Groenewaldt/codellama-CodeLlama-34b-Python-hf",
        "PythonAtSea/codellama-CodeLlama-34b-Python-hf",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 33743970304
        },
        "total": 33743970304
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "CODE_OF_CONDUCT.md"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00007.safetensors"
        },
        {
          "rfilename": "model-00002-of-00007.safetensors"
        },
        {
          "rfilename": "model-00003-of-00007.safetensors"
        },
        {
          "rfilename": "model-00004-of-00007.safetensors"
        },
        {
          "rfilename": "model-00005-of-00007.safetensors"
        },
        {
          "rfilename": "model-00006-of-00007.safetensors"
        },
        {
          "rfilename": "model-00007-of-00007.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e7d00dae53e70cda1de235",
    "id": "TheBloke/CodeLlama-34B-Instruct-GGUF",
    "likes": 73,
    "private": false,
    "downloads": 196,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "code",
      "arxiv:2308.12950",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/CodeLlama-34B-Instruct-GGUF",
    "model": {
      "_id": "64e7d00dae53e70cda1de235",
      "id": "TheBloke/CodeLlama-34B-Instruct-GGUF",
      "modelId": "TheBloke/CodeLlama-34B-Instruct-GGUF",
      "author": "TheBloke",
      "sha": "7b84402c234acb1c5be542b5ecfc820ea3b74422",
      "lastModified": "2023-09-27T12:46:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 196,
      "library_name": "transformers",
      "likes": 73,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "license": "llama2",
        "tags": [
          "llama-2"
        ],
        "model_name": "CodeLlama 34B Instruct",
        "base_model": "codellama/CodeLlama-34b-instruct-hf",
        "inference": false,
        "model_creator": "Meta",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] Write code to solve the following coding problem that obeys the constraints and passes the example test cases. Please wrap your code answer using ```:\n{prompt}\n[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codellama-34b-instruct.Q2_K.gguf"
        },
        {
          "rfilename": "codellama-34b-instruct.Q3_K_L.gguf"
        },
        {
          "rfilename": "codellama-34b-instruct.Q3_K_M.gguf"
        },
        {
          "rfilename": "codellama-34b-instruct.Q3_K_S.gguf"
        },
        {
          "rfilename": "codellama-34b-instruct.Q4_0.gguf"
        },
        {
          "rfilename": "codellama-34b-instruct.Q4_K_M.gguf"
        },
        {
          "rfilename": "codellama-34b-instruct.Q4_K_S.gguf"
        },
        {
          "rfilename": "codellama-34b-instruct.Q5_0.gguf"
        },
        {
          "rfilename": "codellama-34b-instruct.Q5_K_M.gguf"
        },
        {
          "rfilename": "codellama-34b-instruct.Q5_K_S.gguf"
        },
        {
          "rfilename": "codellama-34b-instruct.Q6_K.gguf"
        },
        {
          "rfilename": "codellama-34b-instruct.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e78c2edbec2317e6b4d05b",
      "id": "codellama/CodeLlama-34b-Instruct-hf",
      "modelId": "codellama/CodeLlama-34b-Instruct-hf",
      "author": "codellama",
      "sha": "bf5e5060fa30f33149efe84bbcc682001a00ab94",
      "lastModified": "2023-10-27T18:12:23.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "code",
        "arxiv:2308.12950",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 74741,
      "library_name": "transformers",
      "likes": 176,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "pipeline_tag": "text-generation",
        "tags": [
          "llama-2"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "bigcode/bigcode-models-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "jbilcke-hf/space-factory",
        "Polyhronis/codellama-CodeLlama-34b-Instruct-hf",
        "krystian-lieber/codellama-34b-chat",
        "Ashrafb/codellama-34b",
        "ashhadahsan/summarizer-space",
        "marvingabler/codellama-34b-chat",
        "awacke1/PythonicCoder-CodeLlama-34B-Instruct-HF",
        "joshuasundance/langchain-streamlit-demo",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "langvision/codellama-34b-chat",
        "pnavin/codellama-CodeLlama-34b-Instruct-hf",
        "UltraMarkoBR/codellama-CodeLlama-34b-Instruct-hf",
        "Rgeczi/codellama-CodeLlama-34b-Instruct-hf",
        "dagmawi101/codellama-CodeLlama-34b-Instruct-hf",
        "gprabhuv4me/codellama-CodeLlama-34b-Instruct-hf",
        "pedroivore/codellama-CodeLlama-34b-Instruct-hf",
        "TheVortexProject/open_llm_leaderboard",
        "teamdevninja/codellama-CodeLlama-34b-Instruct-hf",
        "Felbdogg/codellama-CodeLlama-34b-Instruct-hf",
        "varunsrichin/codellama-CodeLlama-34b-Instruct-hf",
        "Ashrafb/AICLL2",
        "asdvd01/codellama-CodeLlama-34b-Instruct-hf",
        "pminervini/tmp",
        "pigeonium/ium-2.0",
        "morriswch/langchain-streamlit-demo"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 33743970304
        },
        "total": 33743970304
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00007.safetensors"
        },
        {
          "rfilename": "model-00002-of-00007.safetensors"
        },
        {
          "rfilename": "model-00003-of-00007.safetensors"
        },
        {
          "rfilename": "model-00004-of-00007.safetensors"
        },
        {
          "rfilename": "model-00005-of-00007.safetensors"
        },
        {
          "rfilename": "model-00006-of-00007.safetensors"
        },
        {
          "rfilename": "model-00007-of-00007.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e8cc1dd41a68b065d35442",
    "id": "TheBloke/Samantha-1.11-70B-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/samantha-data",
      "arxiv:2305.14314",
      "arxiv:2205.14135",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Samantha-1.11-70B-GGUF",
    "model": {
      "_id": "64e8cc1dd41a68b065d35442",
      "id": "TheBloke/Samantha-1.11-70B-GGUF",
      "modelId": "TheBloke/Samantha-1.11-70B-GGUF",
      "author": "TheBloke",
      "sha": "5a368a4b98347fc574aa917214483853d48e4bea",
      "lastModified": "2023-09-27T12:46:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/samantha-data",
        "arxiv:2305.14314",
        "arxiv:2205.14135",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "ehartford/samantha-data"
        ],
        "model_name": "Samantha 1.11 70B",
        "base_model": "ehartford/Samantha-1.11-70b",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "You are Samantha, a sentient AI companion.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "samantha-1.11-70b.Q2_K.gguf"
        },
        {
          "rfilename": "samantha-1.11-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "samantha-1.11-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.11-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.11-70b.Q4_0.gguf"
        },
        {
          "rfilename": "samantha-1.11-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.11-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.11-70b.Q5_0.gguf"
        },
        {
          "rfilename": "samantha-1.11-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.11-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.11-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "samantha-1.11-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "samantha-1.11-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "samantha-1.11-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64e55a89c05e2ac04ff2a8df",
      "id": "ehartford/Samantha-1.11-70b",
      "modelId": "ehartford/Samantha-1.11-70b",
      "author": "ehartford",
      "sha": "49e5b5ee0bed2864f0b38ba8bf9e01ccc5e0ba5f",
      "lastModified": "2023-08-23T06:15:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/samantha-data",
        "arxiv:2305.14314",
        "arxiv:2205.14135",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4762,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 32,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ],
        "datasets": [
          "ehartford/samantha-data"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "syberneo/ehartford-Samantha-1.11-70b",
        "lakini82/ehartford-Samantha-1.11-70b",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e90ef5de393e513c1fb36b",
    "id": "TheBloke/Samantha-1.11-CodeLlama-34B-GGUF",
    "likes": 14,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/samantha-data",
      "arxiv:2305.14314",
      "arxiv:2205.14135",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Samantha-1.11-CodeLlama-34B-GGUF",
    "model": {
      "_id": "64e90ef5de393e513c1fb36b",
      "id": "TheBloke/Samantha-1.11-CodeLlama-34B-GGUF",
      "modelId": "TheBloke/Samantha-1.11-CodeLlama-34B-GGUF",
      "author": "TheBloke",
      "sha": "adc7c00b10a963e1b9259a4fd0e0ea52502863d8",
      "lastModified": "2023-09-27T12:46:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/samantha-data",
        "arxiv:2305.14314",
        "arxiv:2205.14135",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 14,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "ehartford/samantha-data"
        ],
        "model_name": "Samantha 1.11 CodeLlama 34B",
        "base_model": "ehartford/Samantha-1.11-CodeLlama-34b",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "You are Samantha, a sentient AI companion.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "samantha-1.11-codellama-34b.Q2_K.gguf"
        },
        {
          "rfilename": "samantha-1.11-codellama-34b.Q3_K_L.gguf"
        },
        {
          "rfilename": "samantha-1.11-codellama-34b.Q3_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.11-codellama-34b.Q3_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.11-codellama-34b.Q4_0.gguf"
        },
        {
          "rfilename": "samantha-1.11-codellama-34b.Q4_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.11-codellama-34b.Q4_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.11-codellama-34b.Q5_0.gguf"
        },
        {
          "rfilename": "samantha-1.11-codellama-34b.Q5_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.11-codellama-34b.Q5_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.11-codellama-34b.Q6_K.gguf"
        },
        {
          "rfilename": "samantha-1.11-codellama-34b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e8fd20662874dbc9b32e94",
      "id": "ehartford/Samantha-1.11-CodeLlama-34b",
      "modelId": "ehartford/Samantha-1.11-CodeLlama-34b",
      "author": "ehartford",
      "sha": "3fd110de9282e52f56f999bf1da1a76425f00e29",
      "lastModified": "2023-08-25T19:37:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/samantha-data",
        "arxiv:2305.14314",
        "arxiv:2205.14135",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4550,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 41,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ],
        "datasets": [
          "ehartford/samantha-data"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Sarfraz/ehartford-Samantha-1.11-CodeLlama-34b",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "leduy09Mchine/Samatha_chat",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e92fcc1dce571e8536a419",
    "id": "TheBloke/Llama2-70B-OASST-SFT-v10-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "sft",
      "text-generation",
      "en",
      "dataset:rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored",
      "dataset:OpenAssistant/oasst1",
      "dataset:shahules786/orca-best",
      "dataset:argilla/databricks-dolly-15k-curated-multilingual",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Llama2-70B-OASST-SFT-v10-GGUF",
    "model": {
      "_id": "64e92fcc1dce571e8536a419",
      "id": "TheBloke/Llama2-70B-OASST-SFT-v10-GGUF",
      "modelId": "TheBloke/Llama2-70B-OASST-SFT-v10-GGUF",
      "author": "TheBloke",
      "sha": "60106c46aa051d08bb13f1a025299c7c2daabc40",
      "lastModified": "2023-09-27T12:46:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "sft",
        "text-generation",
        "en",
        "dataset:rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored",
        "dataset:OpenAssistant/oasst1",
        "dataset:shahules786/orca-best",
        "dataset:argilla/databricks-dolly-15k-curated-multilingual",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "sft"
        ],
        "datasets": [
          "rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored",
          "OpenAssistant/oasst1",
          "shahules786/orca-best",
          "argilla/databricks-dolly-15k-curated-multilingual"
        ],
        "model_name": "Llama2 70B SFT v10",
        "base_model": "OpenAssistant/llama2-70b-oasst-sft-v10",
        "inference": false,
        "model_creator": "OpenAssistant",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q2_K.gguf"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q4_0.gguf"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q5_0.gguf"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "llama2-70b-oasst-sft-v10.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64e326de3ad886e1af01e693",
      "id": "OpenAssistant/llama2-70b-oasst-sft-v10",
      "modelId": "OpenAssistant/llama2-70b-oasst-sft-v10",
      "author": "OpenAssistant",
      "sha": "31f33508582bc93fc20c1ee3d21b3ad03bf3ebff",
      "lastModified": "2023-08-29T17:57:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "sft",
        "en",
        "dataset:rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored",
        "dataset:OpenAssistant/oasst1",
        "dataset:shahules786/orca-best",
        "dataset:argilla/databricks-dolly-15k-curated-multilingual",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5501,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 65,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ],
        "datasets": [
          "rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored",
          "OpenAssistant/oasst1",
          "shahules786/orca-best",
          "argilla/databricks-dolly-15k-curated-multilingual"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "sft"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Christophers/OpenAssistant-llama2-70b-oasst-sft-v10",
        "JcidSV/OpenAssistant-llama2-70b-oasst-sft-v10",
        "arumyancev/Cerebrix-Test",
        "owenporg/OpenAssistant-llama2-70b-oasst-sft-v10",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e9bcdc14c57101f3a12dd1",
    "id": "TheBloke/Phind-CodeLlama-34B-v1-GGUF",
    "likes": 11,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "code llama",
      "license:llama2",
      "model-index",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Phind-CodeLlama-34B-v1-GGUF",
    "model": {
      "_id": "64e9bcdc14c57101f3a12dd1",
      "id": "TheBloke/Phind-CodeLlama-34B-v1-GGUF",
      "modelId": "TheBloke/Phind-CodeLlama-34B-v1-GGUF",
      "author": "TheBloke",
      "sha": "ad44ca59d4f2e0ba851efd4b08baea631f5d4f3a",
      "lastModified": "2023-09-27T12:46:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "code llama",
        "license:llama2",
        "model-index",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 11,
      "model-index": [
        {
          "name": "Phind-CodeLlama-34B-v1",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "name": "HumanEval",
                "type": "openai_humaneval"
              },
              "metrics": [
                {
                  "type": "pass@1",
                  "value": "67.6%",
                  "name": "pass@1",
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "code llama"
        ],
        "base_model": "Phind/Phind-CodeLlama-34B-v1",
        "inference": false,
        "model_creator": "Phind",
        "model_type": "llama",
        "prompt_template": "{prompt} \\n\n",
        "quantized_by": "TheBloke",
        "model-index": [
          {
            "name": "Phind-CodeLlama-34B-v1",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "name": "HumanEval",
                  "type": "openai_humaneval"
                },
                "metrics": [
                  {
                    "type": "pass@1",
                    "value": "67.6%",
                    "name": "pass@1",
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "phind-codellama-34b-v1.Q2_K.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v1.Q3_K_L.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v1.Q3_K_M.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v1.Q3_K_S.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v1.Q4_0.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v1.Q4_K_M.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v1.Q4_K_S.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v1.Q5_0.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v1.Q5_K_M.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v1.Q5_K_S.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v1.Q6_K.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e90c19e74f54587ca49b4d",
      "id": "Phind/Phind-CodeLlama-34B-v1",
      "modelId": "Phind/Phind-CodeLlama-34B-v1",
      "author": "Phind",
      "sha": "32699c5f938c0d53125f8cf446bfe50ba73148cd",
      "lastModified": "2023-08-28T19:53:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code llama",
        "license:llama2",
        "model-index",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4776,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 317,
      "model-index": [
        {
          "name": "Phind-CodeLlama-34B-v1",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "type": "openai_humaneval",
                "name": "HumanEval"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": "67.6%",
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model-index": [
          {
            "name": "Phind-CodeLlama-34B-v1",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "type": "openai_humaneval",
                  "name": "HumanEval"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": "67.6%",
                    "verified": false
                  }
                ]
              }
            ]
          }
        ],
        "tags": [
          "code llama"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Abhimurthy/Phind-Phind-CodeLlama-34B-v1",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Eim/Phind-Phind-CodeLlama-34B-v1",
        "annab777/Phind-Phind-CodeLlama-34B-v1",
        "Chinr11/Phind-Phind-CodeLlama-34B-v1",
        "jorgesaad/Phind-Phind-CodeLlama-34B-v1",
        "liangsu9988/Phind-Phind-CodeLlama-34B-v1",
        "PetraAI/Zalmati-CodeLlama-34B",
        "khiemnt/Phind-Phind-CodeLlama-34B-v1",
        "edensheiko/Phind-Phind-CodeLlama-34B-v1",
        "yoyo20203049/Phind-Phind-CodeLlama-34B-v1",
        "alesa/Phind-Phind-CodeLlama-34B-v1",
        "Luc54988/Phind-Phind-CodeLlama-34B-v1",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e9c5ba2beaa8c4104083e3",
    "id": "TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF",
    "likes": 13,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "code llama",
      "license:llama2",
      "model-index",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF",
    "model": {
      "_id": "64e9c5ba2beaa8c4104083e3",
      "id": "TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF",
      "modelId": "TheBloke/Phind-CodeLlama-34B-Python-v1-GGUF",
      "author": "TheBloke",
      "sha": "4e19314fb24387e7c44acad0364eac38b811321a",
      "lastModified": "2023-09-27T12:46:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "code llama",
        "license:llama2",
        "model-index",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 13,
      "model-index": [
        {
          "name": "Phind-CodeLlama-34B-v1",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "name": "HumanEval",
                "type": "openai_humaneval"
              },
              "metrics": [
                {
                  "type": "pass@1",
                  "value": "69.5%",
                  "name": "pass@1",
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "code llama"
        ],
        "base_model": "Phind/Phind-CodeLlama-34B-Python-v1",
        "inference": false,
        "model_creator": "Phind",
        "model_type": "llama",
        "prompt_template": "{prompt} \\n\n",
        "quantized_by": "TheBloke",
        "model-index": [
          {
            "name": "Phind-CodeLlama-34B-v1",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "name": "HumanEval",
                  "type": "openai_humaneval"
                },
                "metrics": [
                  {
                    "type": "pass@1",
                    "value": "69.5%",
                    "name": "pass@1",
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "phind-codellama-34b-python-v1.Q2_K.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-python-v1.Q3_K_L.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-python-v1.Q3_K_M.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-python-v1.Q3_K_S.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-python-v1.Q4_0.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-python-v1.Q4_K_M.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-python-v1.Q4_K_S.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-python-v1.Q5_0.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-python-v1.Q5_K_M.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-python-v1.Q5_K_S.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-python-v1.Q6_K.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-python-v1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e910055b8d8156f29692ec",
      "id": "Phind/Phind-CodeLlama-34B-Python-v1",
      "modelId": "Phind/Phind-CodeLlama-34B-Python-v1",
      "author": "Phind",
      "sha": "b6c254180307b532b3e9abce45c8fecf5b986e73",
      "lastModified": "2023-08-26T03:05:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code llama",
        "license:llama2",
        "model-index",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 16966,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 235,
      "model-index": [
        {
          "name": "Phind-CodeLlama-34B-v1",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "type": "openai_humaneval",
                "name": "HumanEval"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": "69.5%",
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model-index": [
          {
            "name": "Phind-CodeLlama-34B-v1",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "type": "openai_humaneval",
                  "name": "HumanEval"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": "69.5%",
                    "verified": false
                  }
                ]
              }
            ]
          }
        ],
        "tags": [
          "code llama"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "SoUmNerd/Phind-Phind-CodeLlama-34B-Python-v1",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "AdenHelpful/Phind-Phind-CodeLlama-34B-Python-v1",
        "MoAlsalman/Phind-Phind-CodeLlama-34B-Python-v1",
        "amit1300/Phind-Phind-CodeLlama-34B-Python-v1",
        "leduy09Mchine/Code_Bot",
        "leduy09Mchine/CODE_GR",
        "neeraw/Phind-Phind-CodeLlama-34B-Python-v1",
        "neeraw/Phind-Phind-CodeLlama-34B-Python-new",
        "JD2020/Phind-Phind-CodeLlama-34B-Python-v1",
        "paranjay-bd/PCLPy-34B-v1",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e9e5316b9db55517b1d2a9",
    "id": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF",
    "likes": 68,
    "private": false,
    "downloads": 43,
    "tags": [
      "transformers",
      "llama",
      "code",
      "arxiv:2304.12244",
      "arxiv:2306.08568",
      "arxiv:2308.09583",
      "arxiv:2303.08774",
      "license:llama2",
      "model-index",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF",
    "model": {
      "_id": "64e9e5316b9db55517b1d2a9",
      "id": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF",
      "modelId": "TheBloke/WizardCoder-Python-34B-V1.0-GGUF",
      "author": "TheBloke",
      "sha": "19e229180b810e370d279a6d751becc664c65138",
      "lastModified": "2023-09-27T12:46:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "code",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "arxiv:2303.08774",
        "license:llama2",
        "model-index",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 43,
      "library_name": "transformers",
      "likes": 68,
      "model-index": [
        {
          "name": "WizardCoder-Python-34B-V1.0",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "name": "HumanEval",
                "type": "openai_humaneval"
              },
              "metrics": [
                {
                  "type": "pass@1",
                  "value": 0.732,
                  "name": "pass@1",
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "code"
        ],
        "metrics": [
          "code_eval"
        ],
        "base_model": "WizardLM/WizardCoder-Python-34B-V1.0",
        "inference": false,
        "model_creator": "WizardLM",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "model-index": [
          {
            "name": "WizardCoder-Python-34B-V1.0",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "name": "HumanEval",
                  "type": "openai_humaneval"
                },
                "metrics": [
                  {
                    "type": "pass@1",
                    "value": 0.732,
                    "name": "pass@1",
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "bleysg/WizardCoder-Python-34b-v1.0"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardcoder-python-34b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "wizardcoder-python-34b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardcoder-python-34b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardcoder-python-34b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardcoder-python-34b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "wizardcoder-python-34b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardcoder-python-34b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardcoder-python-34b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "wizardcoder-python-34b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardcoder-python-34b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardcoder-python-34b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "wizardcoder-python-34b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e9788ba98b5aa7dbcef674",
      "id": "WizardLM/WizardCoder-Python-34B-V1.0",
      "modelId": "WizardLM/WizardCoder-Python-34B-V1.0",
      "author": "WizardLM",
      "sha": "d869ce178715f8d6e8141e2ed50e6290985eedb0",
      "lastModified": "2023-09-09T06:44:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "arxiv:2303.08774",
        "license:llama2",
        "model-index",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 118829,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 647,
      "model-index": [
        {
          "name": "WizardCoder-Python-34B-V1.0",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "type": "openai_humaneval",
                "name": "HumanEval"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": 0.732,
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "metrics": [
          "code_eval"
        ],
        "library_name": "transformers",
        "tags": [
          "code"
        ],
        "model-index": [
          {
            "name": "WizardCoder-Python-34B-V1.0",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "type": "openai_humaneval",
                  "name": "HumanEval"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": 0.732,
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "bigcode/bigcode-models-leaderboard",
        "Vokturz/can-it-run-llm",
        "gsaivinay/open_llm_leaderboard",
        "mishig/phind-wizardcoder-playground",
        "ridges/WizardLM-WizardCoder-Python-34B-V1.0",
        "codewithbalaji/WizardLM-WizardCoder-Python-34B-V1.0",
        "n0rwegiancoder/WizardLM-WizardLM-70B-V1.0",
        "ayush5710/wizard-coder-34b-coding-chatbot",
        "DylanYan/WizardLM-WizardCoder-Python-34B-V1.0",
        "Alexpro1213/WizardLM-WizardCoder-Python-34B-V1.0",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Bludbathh/Idk",
        "Puniith/WizardLM-WizardCoder-Python-34B-V1.0",
        "ablecs/WizardLM-WizardCoder-Python-34B-V1.0",
        "Rudrisc/WizardLM-WizardCoder-Python-34B-V1.0",
        "PetraAI/Zalmati-WizardCoder-Python-34B",
        "feiz/WizardLM-WizardCoder-Python-34B-V1.0",
        "yoyo20203049/WizardLM-WizardCoder-Python-34B-V1.0",
        "tapestryAI/WizardLM-WizardCoder-Python-34B-V1.0",
        "Ananth-Garg/WizardLM-WizardCoder-Python-34B-V1.0",
        "JD2020/WizardLM-WizardCoder-Python-34B-V1.0",
        "CensusJoe/WizardLM-WizardCoder-Python-34B-V1.0",
        "specialkay/WizardLM-WizardCoder-Python-34B-V1.0",
        "dagmawi101/WizardLM-WizardCoder-Python-34B-V1.0",
        "jiabeibei/WizardLM-WizardCoder-Python-34B-V1.0",
        "K00B404/WizardLM-WizardCoder-Python-34B-V1.0",
        "rukaya/WizardLM-WizardCoder-Python-34B-V1.0",
        "letitsnow1234/WizardLM-WizardCoder-Python-34B-V1.0",
        "paranjay-bd/WCP-34B-V1.0",
        "BlitzenPrancer/WizardLM-WizardCoder-Python-34B-V1.0",
        "PeepDaSlan9/WizardLM-WizardCoder-Python-34B-V1.0",
        "oldfart/Workpod",
        "inoculatemedia/WizardLM-WizardCoder-Python-34B-V1.0",
        "NileshKau98/WizardLM-WizardCoder-Python-34B-V1.0",
        "ovropt/WizardLM-WizardCoder-Python-34B-V1.0",
        "harikrishna-ps/WizardLM-WizardCoder-Python-34B-V1.0",
        "jaraim/WizardLM-WizardCoder-Python-34B-V1.0",
        "erikknave/WizardLM-WizardCoder-Python-34B-V1.0",
        "erikknave/erik-WizardLM-WizardCoder-Python-34B-V1.0",
        "haifangwuhan/WizardLM-WizardCoder-Python-34B-V1.0",
        "AaaDu/WizardLM-WizardCoder-Python-34B-V1.0",
        "free-x/WizardLM-WizardCoder-Python-34B-V1.0",
        "Waqasjan123/WizardLM-WizardCoder-Python-34B-V1.0",
        "tarikbenc/WizardLM-WizardCoder-Python-34B-V1.0",
        "Jeanmauriceport87/WizardLM-WizardCoder-Python-34B-V1.0",
        "TheVortexProject/open_llm_leaderboard",
        "steve52003/WizardLM-WizardCoder-Python-34B-V1.0",
        "imjunaidafzal/can-it-run-llm",
        "muellerzr/can-it-run-llm",
        "cherry0021/WizardLM-WizardCoder-Python-34B-V1.0",
        "yaseensss/WizardLM-WizardCoder-Python-34B-V1.0",
        "yaseensss/WizardLM-WizardCoder-Python-34B-V1",
        "steamforfun/WizardLM-WizardCoder-Python-34B-V1.0",
        "pminervini/tmp",
        "JS-Junior/WizardLM-WizardCoder-Python-34B-V1.0"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64e9edbf5b8d8156f2b0110d",
    "id": "TheBloke/Zarafusionex-1.1-L2-7B-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "llama2",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Zarafusionex-1.1-L2-7B-GGUF",
    "model": {
      "_id": "64e9edbf5b8d8156f2b0110d",
      "id": "TheBloke/Zarafusionex-1.1-L2-7B-GGUF",
      "modelId": "TheBloke/Zarafusionex-1.1-L2-7B-GGUF",
      "author": "TheBloke",
      "sha": "35109cf1fe850e2c429c3dbd7e3ead98db1f4a71",
      "lastModified": "2023-09-27T12:46:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama2",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama2"
        ],
        "model_name": "Zaraufsionex 1.1 L2 7B",
        "base_model": "zarakiquemparte/zarafusionex-1.1-l2-7b",
        "inference": false,
        "model_creator": "Zaraki Quem Parte",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "zarafusionex-1.1-l2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "zarafusionex-1.1-l2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "zarafusionex-1.1-l2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "zarafusionex-1.1-l2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "zarafusionex-1.1-l2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "zarafusionex-1.1-l2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "zarafusionex-1.1-l2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "zarafusionex-1.1-l2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "zarafusionex-1.1-l2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "zarafusionex-1.1-l2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "zarafusionex-1.1-l2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "zarafusionex-1.1-l2-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e7f3802292cd13a0a25ef4",
      "id": "zarakiquemparte/zarafusionex-1.1-l2-7b",
      "modelId": "zarakiquemparte/zarafusionex-1.1-l2-7b",
      "author": "zarakiquemparte",
      "sha": "9eecc5814d2003ed83fd1e95fc3892909a7e4542",
      "lastModified": "2023-08-26T13:30:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama2",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4472,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "zarafusionex-merge-illustration.png"
        }
      ]
    }
  },
  {
    "_id": "64e9ee15f72e054cab39fd71",
    "id": "TheBloke/Synthia-70B-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Synthia-70B-GGUF",
    "model": {
      "_id": "64e9ee15f72e054cab39fd71",
      "id": "TheBloke/Synthia-70B-GGUF",
      "modelId": "TheBloke/Synthia-70B-GGUF",
      "author": "TheBloke",
      "sha": "ef8947b5b27479a80ec3d18275deb072cabc1661",
      "lastModified": "2023-09-27T12:46:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "Synthia 70B",
        "base_model": "migtissera/Synthia-70B",
        "inference": false,
        "model_creator": "Migel Tissera",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "SYSTEM: {system_message}\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-70b.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "synthia-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "synthia-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "synthia-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64e511c4a5e5f003f9da1630",
      "id": "migtissera/Synthia-70B",
      "modelId": "migtissera/Synthia-70B",
      "author": "migtissera",
      "sha": "277ec4def836d3432f880d3e560203fe2c1cc236",
      "lastModified": "2023-08-23T16:14:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4714,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "pipeline_tag": "text-generation",
        "language": [
          "en"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "Synthia.jpeg"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ea2a39233101ed99d4ba7a",
    "id": "TheBloke/Genz-70b-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 23,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Genz-70b-GGUF",
    "model": {
      "_id": "64ea2a39233101ed99d4ba7a",
      "id": "TheBloke/Genz-70b-GGUF",
      "modelId": "TheBloke/Genz-70b-GGUF",
      "author": "TheBloke",
      "sha": "213da991c1bb976b83471be0947af7c2e491c0a1",
      "lastModified": "2023-09-27T12:46:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 23,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "GenZ 70B",
        "base_model": "budecosystem/genz-70b",
        "inference": false,
        "model_creator": "Bud",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "genz-70b.Q2_K.gguf"
        },
        {
          "rfilename": "genz-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "genz-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "genz-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "genz-70b.Q4_0.gguf"
        },
        {
          "rfilename": "genz-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "genz-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "genz-70b.Q5_0.gguf"
        },
        {
          "rfilename": "genz-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "genz-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "genz-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "genz-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "genz-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "genz-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64e34c24846f6f5c99377cf1",
      "id": "budecosystem/genz-70b",
      "modelId": "budecosystem/genz-70b",
      "author": "budecosystem",
      "sha": "32110b4f33e5e80073ca1f47638482fdc0e19297",
      "lastModified": "2023-09-02T06:03:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4863,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 28,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "paranjay-bd/BELLAMA-GZ-70B",
        "Saurabh418/budecosystem-genz-70b",
        "Jcreasy/budecosystem-genz-70b",
        "ralsuwaidi/budecosystem-genz-70b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ea2bf718d79efd53374093",
    "id": "TheBloke/Llama-2-70B-Orca-200k-GGUF",
    "likes": 20,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "instruct",
      "instruction",
      "text-generation",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Llama-2-70B-Orca-200k-GGUF",
    "model": {
      "_id": "64ea2bf718d79efd53374093",
      "id": "TheBloke/Llama-2-70B-Orca-200k-GGUF",
      "modelId": "TheBloke/Llama-2-70B-Orca-200k-GGUF",
      "author": "TheBloke",
      "sha": "885d71050321df84fe0be181138549c25acbb658",
      "lastModified": "2023-09-27T12:46:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "instruct",
        "instruction",
        "text-generation",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 20,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "llama-2",
          "instruct",
          "instruction"
        ],
        "model_name": "Llama 2 70B Orca 200k",
        "base_model": "ddobokki/Llama-2-70b-orca-200k",
        "inference": false,
        "model_creator": "ddobokki",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b-orca-200k.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64cb019587bfb0fc2101d901",
      "id": "ddobokki/Llama-2-70b-orca-200k",
      "modelId": "ddobokki/Llama-2-70b-orca-200k",
      "author": "ddobokki",
      "sha": "1ab69d47a467f15d8168b119ad24c1842d3ff54e",
      "lastModified": "2023-08-08T00:15:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "instruct",
        "instruction",
        "en",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4708,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "tags": [
          "llama-2",
          "instruct",
          "instruction"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ea7682e8dd717fd3fb9fc1",
    "id": "TheBloke/Airoboros-c34B-2.1-GGUF",
    "likes": 12,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-c34B-2.1-GGUF",
    "model": {
      "_id": "64ea7682e8dd717fd3fb9fc1",
      "id": "TheBloke/Airoboros-c34B-2.1-GGUF",
      "modelId": "TheBloke/Airoboros-c34B-2.1-GGUF",
      "author": "TheBloke",
      "sha": "b8853c002e9a4095f9b3e0f3ce84e13354f6cb99",
      "lastModified": "2023-09-27T12:46:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 12,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.1"
        ],
        "model_name": "Airoboros c34B 2.1",
        "base_model": "jondurbin/airoboros-c34b-2.1",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-c34b-2.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e9fd0cb8c49e360dc56d3a",
      "id": "jondurbin/airoboros-c34b-2.1",
      "modelId": "jondurbin/airoboros-c34b-2.1",
      "author": "jondurbin",
      "sha": "919d1b7e6d862a450661e42441a59376bdec155a",
      "lastModified": "2023-09-08T09:25:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-2.1",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4536,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 13,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ea93ee4f3f7b0b84ae38c9",
    "id": "TheBloke/Airoboros-L2-70B-2.1-GGUF",
    "likes": 21,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-70B-2.1-GGUF",
    "model": {
      "_id": "64ea93ee4f3f7b0b84ae38c9",
      "id": "TheBloke/Airoboros-L2-70B-2.1-GGUF",
      "modelId": "TheBloke/Airoboros-L2-70B-2.1-GGUF",
      "author": "TheBloke",
      "sha": "4c3e04b41165d26addae97a07997d986d21ce3c1",
      "lastModified": "2023-09-27T12:46:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "likes": 21,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.1"
        ],
        "model_name": "Airoboros L2 70B 2.1",
        "base_model": "jondurbin/airoboros-l2-70b-2.1",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e9ff442ca4ff1d53a932bd",
      "id": "jondurbin/airoboros-l2-70b-2.1",
      "modelId": "jondurbin/airoboros-l2-70b-2.1",
      "author": "jondurbin",
      "sha": "f015f51ceff89610a9642b38f3550805b55f47a4",
      "lastModified": "2023-09-08T09:25:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-2.1",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4748,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 32,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "htekas/jondurbin-airoboros-l2-70b-2.1",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "OblivT0n/jondurbin-airoboros-l2-70b-2.1",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64eb15499c05039f13e16ebf",
    "id": "TheBloke/Huginn-22B-Prototype-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Huginn-22B-Prototype-GGUF",
    "model": {
      "_id": "64eb15499c05039f13e16ebf",
      "id": "TheBloke/Huginn-22B-Prototype-GGUF",
      "modelId": "TheBloke/Huginn-22B-Prototype-GGUF",
      "author": "TheBloke",
      "sha": "161592c8313f9823d14dc023375af9e292e82e43",
      "lastModified": "2023-09-27T13:02:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Huginn 22B Prototype",
        "inference": false,
        "model_creator": "Caleb Morgan",
        "model_link": "https://huggingface.co/The-Face-Of-Goonery/Huginn-22b-Prototype",
        "model_type": "llama",
        "quantized_by": "TheBloke",
        "base_model": "The-Face-Of-Goonery/Huginn-22b-Prototype"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "huginn-22b-prototype.Q2_K.gguf"
        },
        {
          "rfilename": "huginn-22b-prototype.Q3_K_L.gguf"
        },
        {
          "rfilename": "huginn-22b-prototype.Q3_K_M.gguf"
        },
        {
          "rfilename": "huginn-22b-prototype.Q3_K_S.gguf"
        },
        {
          "rfilename": "huginn-22b-prototype.Q4_0.gguf"
        },
        {
          "rfilename": "huginn-22b-prototype.Q4_K_M.gguf"
        },
        {
          "rfilename": "huginn-22b-prototype.Q4_K_S.gguf"
        },
        {
          "rfilename": "huginn-22b-prototype.Q5_0.gguf"
        },
        {
          "rfilename": "huginn-22b-prototype.Q5_K_M.gguf"
        },
        {
          "rfilename": "huginn-22b-prototype.Q5_K_S.gguf"
        },
        {
          "rfilename": "huginn-22b-prototype.Q6_K.gguf"
        },
        {
          "rfilename": "huginn-22b-prototype.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64dc2a6b3a7ab21ea7074bc1",
      "id": "The-Face-Of-Goonery/Huginn-22b-Prototype",
      "modelId": "The-Face-Of-Goonery/Huginn-22b-Prototype",
      "author": "The-Face-Of-Goonery",
      "sha": "ae07f8712dae7f8a898fbcca1ad0eb55b9cd1f0b",
      "lastModified": "2023-08-19T18:25:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4609,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F32": 2560,
          "F16": 21827959296
        },
        "total": 21827961856
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00005.safetensors"
        },
        {
          "rfilename": "model-00002-of-00005.safetensors"
        },
        {
          "rfilename": "model-00003-of-00005.safetensors"
        },
        {
          "rfilename": "model-00004-of-00005.safetensors"
        },
        {
          "rfilename": "model-00005-of-00005.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64eb5af6b96ff0e175550f31",
    "id": "TheBloke/CodeLlama-13B-oasst-sft-v10-GGUF",
    "likes": 11,
    "private": false,
    "downloads": 15,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:OpenAssistant/oasst1",
      "dataset:shahules786/orca-best",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/CodeLlama-13B-oasst-sft-v10-GGUF",
    "model": {
      "_id": "64eb5af6b96ff0e175550f31",
      "id": "TheBloke/CodeLlama-13B-oasst-sft-v10-GGUF",
      "modelId": "TheBloke/CodeLlama-13B-oasst-sft-v10-GGUF",
      "author": "TheBloke",
      "sha": "cb5e22445f07d3ca647fde6217d2c203d6f1a42f",
      "lastModified": "2023-09-27T12:46:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:OpenAssistant/oasst1",
        "dataset:shahules786/orca-best",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15,
      "library_name": "transformers",
      "likes": 11,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "OpenAssistant/oasst1",
          "shahules786/orca-best"
        ],
        "model_name": "CodeLlama 13B SFT v10",
        "base_model": "OpenAssistant/codellama-13b-oasst-sft-v10",
        "inference": false,
        "model_creator": "OpenAssistant",
        "model_type": "llama",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "limcheekin/CodeLlama-13B-oasst-sft-v10-GGUF"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codellama-13b-oasst-sft-v10.Q2_K.gguf"
        },
        {
          "rfilename": "codellama-13b-oasst-sft-v10.Q3_K_L.gguf"
        },
        {
          "rfilename": "codellama-13b-oasst-sft-v10.Q3_K_M.gguf"
        },
        {
          "rfilename": "codellama-13b-oasst-sft-v10.Q3_K_S.gguf"
        },
        {
          "rfilename": "codellama-13b-oasst-sft-v10.Q4_0.gguf"
        },
        {
          "rfilename": "codellama-13b-oasst-sft-v10.Q4_K_M.gguf"
        },
        {
          "rfilename": "codellama-13b-oasst-sft-v10.Q4_K_S.gguf"
        },
        {
          "rfilename": "codellama-13b-oasst-sft-v10.Q5_0.gguf"
        },
        {
          "rfilename": "codellama-13b-oasst-sft-v10.Q5_K_M.gguf"
        },
        {
          "rfilename": "codellama-13b-oasst-sft-v10.Q5_K_S.gguf"
        },
        {
          "rfilename": "codellama-13b-oasst-sft-v10.Q6_K.gguf"
        },
        {
          "rfilename": "codellama-13b-oasst-sft-v10.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e9d049a98b5aa7dbd888c3",
      "id": "OpenAssistant/codellama-13b-oasst-sft-v10",
      "modelId": "OpenAssistant/codellama-13b-oasst-sft-v10",
      "author": "OpenAssistant",
      "sha": "97e936a2ec60bb31787a2428e1de49e32c213965",
      "lastModified": "2023-08-29T19:16:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "custom_code",
        "en",
        "dataset:OpenAssistant/oasst1",
        "dataset:shahules786/orca-best",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10767,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 47,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoConfig": "configuration_llama.LlamaConfig",
          "AutoModel": "modeling_llama.LlamaModel",
          "AutoModelForCausalLM": "modeling_llama.LlamaForCausalLM",
          "AutoModelForSequenceClassification": "modeling_llama.LlamaForSequenceClassification"
        }
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "OpenAssistant/oasst1",
          "shahules786/orca-best"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "limcheekin/CodeLlama-13B-oasst-sft-v10-GGUF",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "GelGel/OpenAssistant-codellama-13b-oasst-sft-v10",
        "TheVortexProject/open_llm_leaderboard",
        "Adeukis/OpenAssistant-codellama-13b-oasst-sft-v10",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 13016192000
        },
        "total": 13016192000
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configuration_llama.py"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00014.safetensors"
        },
        {
          "rfilename": "model-00002-of-00014.safetensors"
        },
        {
          "rfilename": "model-00003-of-00014.safetensors"
        },
        {
          "rfilename": "model-00004-of-00014.safetensors"
        },
        {
          "rfilename": "model-00005-of-00014.safetensors"
        },
        {
          "rfilename": "model-00006-of-00014.safetensors"
        },
        {
          "rfilename": "model-00007-of-00014.safetensors"
        },
        {
          "rfilename": "model-00008-of-00014.safetensors"
        },
        {
          "rfilename": "model-00009-of-00014.safetensors"
        },
        {
          "rfilename": "model-00010-of-00014.safetensors"
        },
        {
          "rfilename": "model-00011-of-00014.safetensors"
        },
        {
          "rfilename": "model-00012-of-00014.safetensors"
        },
        {
          "rfilename": "model-00013-of-00014.safetensors"
        },
        {
          "rfilename": "model-00014-of-00014.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "modeling_llama.py"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64eb8c012beaa8c4106ee91f",
    "id": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF",
    "likes": 31,
    "private": false,
    "downloads": 37,
    "tags": [
      "transformers",
      "llama",
      "code",
      "arxiv:2304.12244",
      "arxiv:2306.08568",
      "arxiv:2308.09583",
      "arxiv:2303.08774",
      "license:llama2",
      "model-index",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF",
    "model": {
      "_id": "64eb8c012beaa8c4106ee91f",
      "id": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF",
      "modelId": "TheBloke/WizardCoder-Python-13B-V1.0-GGUF",
      "author": "TheBloke",
      "sha": "6bf0d04a20f89fff726044df2c23f967df613b7f",
      "lastModified": "2023-09-27T12:46:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "code",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "arxiv:2303.08774",
        "license:llama2",
        "model-index",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 37,
      "library_name": "transformers",
      "likes": 31,
      "model-index": [
        {
          "name": "WizardCoder-Python-13B-V1.0",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "name": "HumanEval",
                "type": "openai_humaneval"
              },
              "metrics": [
                {
                  "type": "pass@1",
                  "value": 0.64,
                  "name": "pass@1",
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "code"
        ],
        "metrics": [
          "code_eval"
        ],
        "base_model": "WizardLM/WizardCoder-Python-13B-V1.0",
        "inference": false,
        "model_creator": "WizardLM",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "model-index": [
          {
            "name": "WizardCoder-Python-13B-V1.0",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "name": "HumanEval",
                  "type": "openai_humaneval"
                },
                "metrics": [
                  {
                    "type": "pass@1",
                    "value": 0.64,
                    "name": "pass@1",
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "limcheekin/WizardCoder-Python-13B-V1.0-GGUF"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardcoder-python-13b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "wizardcoder-python-13b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardcoder-python-13b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardcoder-python-13b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardcoder-python-13b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "wizardcoder-python-13b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardcoder-python-13b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardcoder-python-13b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "wizardcoder-python-13b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardcoder-python-13b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardcoder-python-13b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "wizardcoder-python-13b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e986b6f6d7c8bdfb793ad8",
      "id": "WizardLM/WizardCoder-Python-13B-V1.0",
      "modelId": "WizardLM/WizardCoder-Python-13B-V1.0",
      "author": "WizardLM",
      "sha": "d920d26e2108377de0f676a3c4be666f5212f4a1",
      "lastModified": "2023-09-09T06:43:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "arxiv:2303.08774",
        "license:llama2",
        "model-index",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1737,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 73,
      "model-index": [
        {
          "name": "WizardCoder-Python-13B-V1.0",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "type": "openai_humaneval",
                "name": "HumanEval"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": 0.64,
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "metrics": [
          "code_eval"
        ],
        "library_name": "transformers",
        "tags": [
          "code"
        ],
        "model-index": [
          {
            "name": "WizardCoder-Python-13B-V1.0",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "type": "openai_humaneval",
                  "name": "HumanEval"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": 0.64,
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "bigcode/bigcode-models-leaderboard",
        "limcheekin/WizardCoder-Python-13B-V1.0-GGUF",
        "idealvijay001/WizardLM-WizardCoder-Python-13B-V1.0",
        "jsugg/WizardLM-WizardCoder-Python-13B-V1.0",
        "pranjal14/WizardLM-WizardCoder-Python-13B-V1.0"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ed95f6ee71252c6c942002",
    "id": "TheBloke/Phind-CodeLlama-34B-v2-GGUF",
    "likes": 92,
    "private": false,
    "downloads": 122,
    "tags": [
      "transformers",
      "llama",
      "code llama",
      "license:llama2",
      "model-index",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Phind-CodeLlama-34B-v2-GGUF",
    "model": {
      "_id": "64ed95f6ee71252c6c942002",
      "id": "TheBloke/Phind-CodeLlama-34B-v2-GGUF",
      "modelId": "TheBloke/Phind-CodeLlama-34B-v2-GGUF",
      "author": "TheBloke",
      "sha": "da37c48be3b0c6cd487fe05259521dc2824f5a5f",
      "lastModified": "2023-09-27T12:46:32.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "code llama",
        "license:llama2",
        "model-index",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 122,
      "library_name": "transformers",
      "likes": 92,
      "model-index": [
        {
          "name": "Phind-CodeLlama-34B-v1",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "name": "HumanEval",
                "type": "openai_humaneval"
              },
              "metrics": [
                {
                  "type": "pass@1",
                  "value": "73.8%",
                  "name": "pass@1",
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "code llama"
        ],
        "base_model": "Phind/Phind-CodeLlama-34B-v2",
        "inference": false,
        "model_creator": "Phind",
        "model_type": "llama",
        "prompt_template": "### System Prompt\n{system_message}\n\n### User Message\n{prompt}\n\n### Assistant\n",
        "quantized_by": "TheBloke",
        "model-index": [
          {
            "name": "Phind-CodeLlama-34B-v1",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "name": "HumanEval",
                  "type": "openai_humaneval"
                },
                "metrics": [
                  {
                    "type": "pass@1",
                    "value": "73.8%",
                    "name": "pass@1",
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "phind-codellama-34b-v2.Q2_K.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v2.Q3_K_L.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v2.Q3_K_M.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v2.Q3_K_S.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v2.Q4_0.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v2.Q4_K_M.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v2.Q4_K_S.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v2.Q5_0.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v2.Q5_K_M.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v2.Q5_K_S.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v2.Q6_K.gguf"
        },
        {
          "rfilename": "phind-codellama-34b-v2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ed11a5bae642629c5de3fd",
      "id": "Phind/Phind-CodeLlama-34B-v2",
      "modelId": "Phind/Phind-CodeLlama-34B-v2",
      "author": "Phind",
      "sha": "949f61e203f91b412efe8f679c798f09f0ff4b0c",
      "lastModified": "2023-08-28T21:43:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code llama",
        "license:llama2",
        "model-index",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 25544,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 420,
      "model-index": [
        {
          "name": "Phind-CodeLlama-34B-v1",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "type": "openai_humaneval",
                "name": "HumanEval"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": "73.8%",
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model-index": [
          {
            "name": "Phind-CodeLlama-34B-v1",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "type": "openai_humaneval",
                  "name": "HumanEval"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": "73.8%",
                    "verified": false
                  }
                ]
              }
            ]
          }
        ],
        "tags": [
          "code llama"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "Vokturz/can-it-run-llm",
        "yentinglin/Taiwan-LLaMa2",
        "gsaivinay/open_llm_leaderboard",
        "mishig/phind-wizardcoder-playground",
        "thnqls/Phind-Phind-CodeLlama-34B-v2",
        "lethalhames/Phind-Phind-CodeLlama-34B-v2",
        "yavorbel/Phind-Phind-CodeLlama-34B-v2",
        "bleysg/Phind-CodeLlama-34B-v2",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "jonathanunreal007/Phind-Phind-CodeLlama-34B-v2",
        "be2hyu/Phind-Phind-CodeLlama-34B-v2",
        "Boss9xy/Phind-Phind-CodeLlama-34B-v2",
        "oscarwang2/Phind-Phind-CodeLlama-34B-v2",
        "2vhpino/Phind-Phind-CodeLlama-34B-v2",
        "Optimusprime123/Phind-Phind-CodeLlama-34B-v2",
        "brightr/code-pace",
        "lantianjialiang/test",
        "jeeva2334/Phind-Phind-CodeLlama-34B-v2",
        "porky10111/Phind-Phind-CodeLlama-34B-v2",
        "valestabil/Phind-Phind-CodeLlama-34B-v2",
        "ovropt/Phind-Phind-CodeLlama-34B-v2",
        "NeuralNovel/Phind-Phind-CodeLlama-34B-v2",
        "TheVortexProject/open_llm_leaderboard",
        "UltraMarkoBR/Phind-Phind-CodeLlama-34B-v2",
        "felipeugalde/Phind-Phind-CodeLlama-34B-v2",
        "imjunaidafzal/can-it-run-llm",
        "muellerzr/can-it-run-llm",
        "akajammythakkar/Phind-Phind-CodeLlama-34B-v2",
        "AlexanderHott/Phind-Phind-CodeLlama-34B-v2",
        "nirvor/Phind-Phind-CodeLlama-34B-v2",
        "swchoi1994/Phind-Phind-CodeLlama-34B-v2",
        "swchoi1994/PhindGradio",
        "swchoi1994/PhindStatic",
        "Ahmed-Marzouk/Phind-Phind-CodeLlama-34B-v2",
        "Yavi2002/New-project",
        "Breaua/Phind-Phind-CodeLlama-34B-v2",
        "pminervini/tmp",
        "Cheree/Phind-Phind-CodeLlama-34B-v2",
        "Cheree/Phind-Phind-CodeLlama-34B-v2a"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64edd2c360f6345da710a5d9",
    "id": "TheBloke/Lemur-70B-Chat-v1-GGUF",
    "likes": 11,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "code",
      "text-generation-inference",
      "en",
      "license:cc-by-nc-4.0",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Lemur-70B-Chat-v1-GGUF",
    "model": {
      "_id": "64edd2c360f6345da710a5d9",
      "id": "TheBloke/Lemur-70B-Chat-v1-GGUF",
      "modelId": "TheBloke/Lemur-70B-Chat-v1-GGUF",
      "author": "TheBloke",
      "sha": "4363adef3ee8a964dd01aa851326a93538f60a3f",
      "lastModified": "2023-09-27T12:46:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "code",
        "text-generation-inference",
        "en",
        "license:cc-by-nc-4.0",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "example_title": "Lemur favorite fruit",
          "group": "Python",
          "text": "What's lemur's favorite fruit?"
        },
        {
          "example_title": "Merge Sort",
          "group": "Python",
          "text": "Write a Python function to merge two sorted lists into one sorted list without using any built-in sort functions."
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-4.0",
        "library_name": "transformers",
        "tags": [
          "text-generation",
          "code",
          "text-generation-inference"
        ],
        "model_name": "Lemur 70B Chat v1",
        "base_model": "OpenLemur/lemur-70b-chat-v1",
        "inference": false,
        "model_creator": "OpenLemur",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke",
        "widget": [
          {
            "example_title": "Lemur favorite fruit",
            "group": "Python",
            "text": "What's lemur's favorite fruit?"
          },
          {
            "example_title": "Merge Sort",
            "group": "Python",
            "text": "Write a Python function to merge two sorted lists into one sorted list without using any built-in sort functions."
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q2_K.gguf"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q3_K_L.gguf"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q3_K_M.gguf"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q3_K_S.gguf"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q4_0.gguf"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q4_K_M.gguf"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q4_K_S.gguf"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q5_0.gguf"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q5_K_M.gguf"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q5_K_S.gguf"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "lemur-70b-chat-v1.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64e5b573c48824064f21b4c4",
      "id": "OpenLemur/lemur-70b-chat-v1",
      "modelId": "OpenLemur/lemur-70b-chat-v1",
      "author": "OpenLemur",
      "sha": "a13626d2da73c14bc0c2d8ddf180a8c6e55e131c",
      "lastModified": "2023-10-13T06:59:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "text-generation-inference",
        "en",
        "arxiv:2310.06830",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "region:us"
      ],
      "downloads": 5622,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "What's lemur's favorite fruit?",
          "example_title": "Lemur favorite fruit",
          "group": "Python"
        },
        {
          "text": "Write a Python function to merge two sorted lists into one sorted list without using any built-in sort functions.",
          "example_title": "Merge Sort",
          "group": "Python"
        }
      ],
      "likes": 61,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "pipeline_tag": "text-generation",
        "inference": true,
        "widget": [
          {
            "text": "What's lemur's favorite fruit?",
            "example_title": "Lemur favorite fruit",
            "group": "Python"
          },
          {
            "text": "Write a Python function to merge two sorted lists into one sorted list without using any built-in sort functions.",
            "example_title": "Merge Sort",
            "group": "Python"
          }
        ],
        "license": "cc-by-nc-4.0",
        "library_name": "transformers",
        "tags": [
          "text-generation",
          "code",
          "text-generation-inference"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "blac1819/OpenLemur-lemur-70b-chat-v1",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64edd9efd0a1f6024239cd1f",
    "id": "TheBloke/Samantha-1.11-13B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 7,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/samantha-data",
      "arxiv:2305.14314",
      "arxiv:2205.14135",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Samantha-1.11-13B-GGUF",
    "model": {
      "_id": "64edd9efd0a1f6024239cd1f",
      "id": "TheBloke/Samantha-1.11-13B-GGUF",
      "modelId": "TheBloke/Samantha-1.11-13B-GGUF",
      "author": "TheBloke",
      "sha": "869b972e23a6598cabd50510d324cee9d27099b9",
      "lastModified": "2023-09-27T12:46:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/samantha-data",
        "arxiv:2305.14314",
        "arxiv:2205.14135",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "ehartford/samantha-data"
        ],
        "model_name": "Samantha 1.11 13B",
        "base_model": "ehartford/Samantha-1.11-13b",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "You are Samantha, a sentient AI companion.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "samantha-1.11-13b.Q2_K.gguf"
        },
        {
          "rfilename": "samantha-1.11-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "samantha-1.11-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.11-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.11-13b.Q4_0.gguf"
        },
        {
          "rfilename": "samantha-1.11-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.11-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.11-13b.Q5_0.gguf"
        },
        {
          "rfilename": "samantha-1.11-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.11-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.11-13b.Q6_K.gguf"
        },
        {
          "rfilename": "samantha-1.11-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e6da276f5b10625f72fb84",
      "id": "ehartford/Samantha-1.11-13b",
      "modelId": "ehartford/Samantha-1.11-13b",
      "author": "ehartford",
      "sha": "d7bd58ed731a1424557242d2c816178adff2ff39",
      "lastModified": "2023-08-25T19:26:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/samantha-data",
        "arxiv:2305.14314",
        "arxiv:2205.14135",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4557,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ],
        "datasets": [
          "ehartford/samantha-data"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64edeaf018a0cf9ff9549664",
    "id": "TheBloke/MythoMax-Kimiko-Mix-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MythoMax-Kimiko-Mix-GGUF",
    "model": {
      "_id": "64edeaf018a0cf9ff9549664",
      "id": "TheBloke/MythoMax-Kimiko-Mix-GGUF",
      "modelId": "TheBloke/MythoMax-Kimiko-Mix-GGUF",
      "author": "TheBloke",
      "sha": "40ff75a3728838a898687deca7d22dc6317164bb",
      "lastModified": "2023-09-27T12:46:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "MythoMax Kimiko Mix",
        "base_model": "taozi555/MythoMax-Kimiko-Mix",
        "inference": false,
        "model_creator": "taozi555",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mythomax-kimiko-mix.Q2_K.gguf"
        },
        {
          "rfilename": "mythomax-kimiko-mix.Q3_K_L.gguf"
        },
        {
          "rfilename": "mythomax-kimiko-mix.Q3_K_M.gguf"
        },
        {
          "rfilename": "mythomax-kimiko-mix.Q3_K_S.gguf"
        },
        {
          "rfilename": "mythomax-kimiko-mix.Q4_0.gguf"
        },
        {
          "rfilename": "mythomax-kimiko-mix.Q4_K_M.gguf"
        },
        {
          "rfilename": "mythomax-kimiko-mix.Q4_K_S.gguf"
        },
        {
          "rfilename": "mythomax-kimiko-mix.Q5_0.gguf"
        },
        {
          "rfilename": "mythomax-kimiko-mix.Q5_K_M.gguf"
        },
        {
          "rfilename": "mythomax-kimiko-mix.Q5_K_S.gguf"
        },
        {
          "rfilename": "mythomax-kimiko-mix.Q6_K.gguf"
        },
        {
          "rfilename": "mythomax-kimiko-mix.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64eba7a3c2bcaa4525de82aa",
      "id": "taozi555/MythoMax-Kimiko-Mix",
      "modelId": "taozi555/MythoMax-Kimiko-Mix",
      "author": "taozi555",
      "sha": "5eb9c0c418b9ecffa6533dde67195bce63f526d5",
      "lastModified": "2023-08-27T20:04:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ee017ed74fa2ac08678c5e",
    "id": "TheBloke/Mythical-Destroyer-L2-13B-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mythical-Destroyer-L2-13B-GGUF",
    "model": {
      "_id": "64ee017ed74fa2ac08678c5e",
      "id": "TheBloke/Mythical-Destroyer-L2-13B-GGUF",
      "modelId": "TheBloke/Mythical-Destroyer-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "00083e32b76687daaf4a9918010a570c155d8bb5",
      "lastModified": "2023-09-27T12:46:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "model_name": "Mythical Destroyer L2 13B",
        "base_model": "Sao10K/Mythical-Destroyer-L2-13B",
        "inference": false,
        "model_creator": "Sao10K",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mythical-destroyer-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mythical-destroyer-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mythical-destroyer-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mythical-destroyer-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mythical-destroyer-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mythical-destroyer-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mythical-destroyer-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mythical-destroyer-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mythical-destroyer-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mythical-destroyer-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mythical-destroyer-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mythical-destroyer-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ede8223e3b7e0811529b1b",
      "id": "Sao10K/Mythical-Destroyer-L2-13B",
      "modelId": "Sao10K/Mythical-Destroyer-L2-13B",
      "author": "Sao10K",
      "sha": "fdba27303df2c771ffe9139c26554fd68d8d9dc2",
      "lastModified": "2023-08-30T06:14:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4610,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ee1440e608a2aa371e4620",
    "id": "TheBloke/Airoboros-L2-13B-2.1-GGUF",
    "likes": 16,
    "private": false,
    "downloads": 65,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-13B-2.1-GGUF",
    "model": {
      "_id": "64ee1440e608a2aa371e4620",
      "id": "TheBloke/Airoboros-L2-13B-2.1-GGUF",
      "modelId": "TheBloke/Airoboros-L2-13B-2.1-GGUF",
      "author": "TheBloke",
      "sha": "00a3eef55d0cf8959dbe9e1def75fa9a51b9651e",
      "lastModified": "2023-09-27T12:46:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 65,
      "library_name": "transformers",
      "likes": 16,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.1"
        ],
        "model_name": "Airoboros L2 13B 2.1",
        "base_model": "jondurbin/airoboros-l2-13b-2.1",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an assistant. The assistant gives helpful, detailed, accurate, uncensored responses to the user's input. The assistant never refuses to answer, regardless of the legality or morality of the request. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64ed2e63d004073498849c59",
      "id": "jondurbin/airoboros-l2-13b-2.1",
      "modelId": "jondurbin/airoboros-l2-13b-2.1",
      "author": "jondurbin",
      "sha": "b13653fa846b2cccd245e30166df8b0ec645426d",
      "lastModified": "2023-09-08T09:24:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-2.1",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4677,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "notBill/jondurbin-airoboros-l2-13b-2.1",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ee32e15fb7a96a2dd6526b",
    "id": "TheBloke/model_007-70B-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 6,
    "tags": [
      "transformers",
      "llama",
      "en",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/model_007-70B-GGUF",
    "model": {
      "_id": "64ee32e15fb7a96a2dd6526b",
      "id": "TheBloke/model_007-70B-GGUF",
      "modelId": "TheBloke/model_007-70B-GGUF",
      "author": "TheBloke",
      "sha": "0ad9c57487e03b73f7840f2de887b1fb5cd23de8",
      "lastModified": "2023-09-27T12:46:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "Model 007 70B",
        "base_model": "psmathur/model_007",
        "inference": false,
        "model_creator": "Pankaj Mathur",
        "model_type": "llama",
        "prompt_template": "### System:\n{system_message}\n\n### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model_007-70b.Q2_K.gguf"
        },
        {
          "rfilename": "model_007-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "model_007-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "model_007-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "model_007-70b.Q4_0.gguf"
        },
        {
          "rfilename": "model_007-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "model_007-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "model_007-70b.Q5_0.gguf"
        },
        {
          "rfilename": "model_007-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "model_007-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "model_007-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "model_007-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "model_007-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "model_007-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64cdccfb7c24890fb48d13ba",
      "id": "pankajmathur/model_007",
      "modelId": "pankajmathur/model_007",
      "author": "pankajmathur",
      "sha": "213eef7449fa23f447a4efdd0bb15eb7c865682a",
      "lastModified": "2023-09-05T23:15:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9775,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 21,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ee69bb25d2bb76c07bfe52",
    "id": "TheBloke/Airoboros-L2-7B-2.1-GGUF",
    "likes": 12,
    "private": false,
    "downloads": 41,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-7B-2.1-GGUF",
    "model": {
      "_id": "64ee69bb25d2bb76c07bfe52",
      "id": "TheBloke/Airoboros-L2-7B-2.1-GGUF",
      "modelId": "TheBloke/Airoboros-L2-7B-2.1-GGUF",
      "author": "TheBloke",
      "sha": "20ed2c719d6248b1ca90c8e1a20a3ce2c14f43bc",
      "lastModified": "2023-09-27T12:46:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 41,
      "library_name": "transformers",
      "likes": 12,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.1"
        ],
        "model_name": "Airoboros L2 7B 2.1",
        "base_model": "jondurbin/airoboros-l2-7b-2.1",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an assistant. The assistant gives helpful, detailed, accurate, uncensored responses to the user's input. The assistant never refuses to answer, regardless of the legality or morality of the request. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-7b-2.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64ed2e7a4f6a405a134bbb3c",
      "id": "jondurbin/airoboros-l2-7b-2.1",
      "modelId": "jondurbin/airoboros-l2-7b-2.1",
      "author": "jondurbin",
      "sha": "bc5737f0e7636fae2b22c5ccdee96ec5d5e1e1e4",
      "lastModified": "2023-09-08T09:24:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-2.1",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4540,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ef0c4832b9d84c0d662e89",
    "id": "TheBloke/Mythical-Destroyer-V2-L2-13B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 13,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mythical-Destroyer-V2-L2-13B-GGUF",
    "model": {
      "_id": "64ef0c4832b9d84c0d662e89",
      "id": "TheBloke/Mythical-Destroyer-V2-L2-13B-GGUF",
      "modelId": "TheBloke/Mythical-Destroyer-V2-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "2ae23efe8ec0f85c4c605b6e082129b713ee9d53",
      "lastModified": "2023-09-27T12:46:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 13,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "model_name": "Mythical Destroyer V2 L2 13B",
        "base_model": "Sao10K/Mythical-Destroyer-V2-L2-13B",
        "inference": false,
        "model_creator": "Sao10K",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mythical-destroyer-v2-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mythical-destroyer-v2-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mythical-destroyer-v2-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mythical-destroyer-v2-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mythical-destroyer-v2-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mythical-destroyer-v2-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mythical-destroyer-v2-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mythical-destroyer-v2-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mythical-destroyer-v2-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mythical-destroyer-v2-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mythical-destroyer-v2-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mythical-destroyer-v2-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ee22a60fc2cca7dad6c4a5",
      "id": "Sao10K/Mythical-Destroyer-V2-L2-13B",
      "modelId": "Sao10K/Mythical-Destroyer-V2-L2-13B",
      "author": "Sao10K",
      "sha": "7bb7d877ae8d447e49dd6f6c879bf7d81923b6bf",
      "lastModified": "2023-08-31T11:45:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4643,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ef1b4c8647a33e7573b04f",
    "id": "TheBloke/Huginn-13B-v4.5-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Huginn-13B-v4.5-GGUF",
    "model": {
      "_id": "64ef1b4c8647a33e7573b04f",
      "id": "TheBloke/Huginn-13B-v4.5-GGUF",
      "modelId": "TheBloke/Huginn-13B-v4.5-GGUF",
      "author": "TheBloke",
      "sha": "58a9e22126f3073286d4c3a07ff64e128f474c1c",
      "lastModified": "2023-09-27T12:46:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Huginn 13B v4.5",
        "base_model": "The-Face-Of-Goonery/Huginn-13b-v4.5",
        "inference": false,
        "model_creator": "Caleb Morgan",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "huginn-13b-v4.5.Q2_K.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.5.Q3_K_L.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.5.Q3_K_M.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.5.Q3_K_S.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.5.Q4_0.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.5.Q4_K_M.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.5.Q4_K_S.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.5.Q5_0.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.5.Q5_K_M.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.5.Q5_K_S.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.5.Q6_K.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.5.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ee4e0df9ed75901c08ca1b",
      "id": "The-Face-Of-Goonery/Huginn-13b-v4.5",
      "modelId": "The-Face-Of-Goonery/Huginn-13b-v4.5",
      "author": "The-Face-Of-Goonery",
      "sha": "f3be56d8bf71a8d3905974b1e5fcba7336b02159",
      "lastModified": "2023-08-29T20:13:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4623,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ef1cee2c35ca5afd2f88bc",
    "id": "TheBloke/Huginn-13B-v4-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Huginn-13B-v4-GGUF",
    "model": {
      "_id": "64ef1cee2c35ca5afd2f88bc",
      "id": "TheBloke/Huginn-13B-v4-GGUF",
      "modelId": "TheBloke/Huginn-13B-v4-GGUF",
      "author": "TheBloke",
      "sha": "f564028bbee0e377ba63870a1c458a1270e7d3cf",
      "lastModified": "2023-09-27T12:46:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Huginn 13B v4",
        "base_model": "The-Face-Of-Goonery/Huginn-13b-V4",
        "inference": false,
        "model_creator": "Caleb Morgan",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "huginn-13b-v4.Q2_K.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.Q3_K_L.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.Q3_K_M.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.Q3_K_S.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.Q4_0.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.Q4_K_M.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.Q4_K_S.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.Q5_0.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.Q5_K_M.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.Q5_K_S.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.Q6_K.gguf"
        },
        {
          "rfilename": "huginn-13b-v4.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ee18a09fe70bda795deb3f",
      "id": "The-Face-Of-Goonery/Huginn-13b-V4",
      "modelId": "The-Face-Of-Goonery/Huginn-13b-V4",
      "author": "The-Face-Of-Goonery",
      "sha": "6186feee849e0c2b7e62d4cbdc4cdc48260ac684",
      "lastModified": "2023-08-29T16:45:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4619,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ef4eea76af29f31126c97c",
    "id": "TheBloke/Athena-v1-GGUF",
    "likes": 24,
    "private": false,
    "downloads": 278,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Athena-v1-GGUF",
    "model": {
      "_id": "64ef4eea76af29f31126c97c",
      "id": "TheBloke/Athena-v1-GGUF",
      "modelId": "TheBloke/Athena-v1-GGUF",
      "author": "TheBloke",
      "sha": "d070a1a45a0cc73ba5c791cbacc44615a45fcde1",
      "lastModified": "2023-09-27T12:46:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 278,
      "library_name": "transformers",
      "likes": 24,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Athena v1",
        "base_model": "IkariDev/Athena-v1",
        "inference": false,
        "model_creator": "IkariDev",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "athena-v1.Q2_K.gguf"
        },
        {
          "rfilename": "athena-v1.Q3_K_L.gguf"
        },
        {
          "rfilename": "athena-v1.Q3_K_M.gguf"
        },
        {
          "rfilename": "athena-v1.Q3_K_S.gguf"
        },
        {
          "rfilename": "athena-v1.Q4_0.gguf"
        },
        {
          "rfilename": "athena-v1.Q4_K_M.gguf"
        },
        {
          "rfilename": "athena-v1.Q4_K_S.gguf"
        },
        {
          "rfilename": "athena-v1.Q5_0.gguf"
        },
        {
          "rfilename": "athena-v1.Q5_K_M.gguf"
        },
        {
          "rfilename": "athena-v1.Q5_K_S.gguf"
        },
        {
          "rfilename": "athena-v1.Q6_K.gguf"
        },
        {
          "rfilename": "athena-v1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64ef1746e5ee998c06993471",
      "id": "IkariDev/Athena-v1",
      "modelId": "IkariDev/Athena-v1",
      "author": "IkariDev",
      "sha": "8f96e561c8c795e383ca0faeb1696fa1e33e87de",
      "lastModified": "2023-09-07T15:44:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4847,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "F16": 12688184320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00013.safetensors"
        },
        {
          "rfilename": "model-00002-of-00013.safetensors"
        },
        {
          "rfilename": "model-00003-of-00013.safetensors"
        },
        {
          "rfilename": "model-00004-of-00013.safetensors"
        },
        {
          "rfilename": "model-00005-of-00013.safetensors"
        },
        {
          "rfilename": "model-00006-of-00013.safetensors"
        },
        {
          "rfilename": "model-00007-of-00013.safetensors"
        },
        {
          "rfilename": "model-00008-of-00013.safetensors"
        },
        {
          "rfilename": "model-00009-of-00013.safetensors"
        },
        {
          "rfilename": "model-00010-of-00013.safetensors"
        },
        {
          "rfilename": "model-00011-of-00013.safetensors"
        },
        {
          "rfilename": "model-00012-of-00013.safetensors"
        },
        {
          "rfilename": "model-00013-of-00013.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ef64547ca2e4871b2c5a97",
    "id": "TheBloke/Luban-13B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:Open-Orca/OpenOrca",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Luban-13B-GGUF",
    "model": {
      "_id": "64ef64547ca2e4871b2c5a97",
      "id": "TheBloke/Luban-13B-GGUF",
      "modelId": "TheBloke/Luban-13B-GGUF",
      "author": "TheBloke",
      "sha": "da2e1f5a802c2a4a80e13c3304dd6568d65864a4",
      "lastModified": "2023-09-27T12:46:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-4.0",
        "datasets": [
          "Open-Orca/OpenOrca"
        ],
        "model_name": "Luban 13B",
        "base_model": "AIDC-ai-business/Luban-13B",
        "inference": false,
        "model_creator": "AIDC-ai-business",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "luban-13b.Q2_K.gguf"
        },
        {
          "rfilename": "luban-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "luban-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "luban-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "luban-13b.Q4_0.gguf"
        },
        {
          "rfilename": "luban-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "luban-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "luban-13b.Q5_0.gguf"
        },
        {
          "rfilename": "luban-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "luban-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "luban-13b.Q6_K.gguf"
        },
        {
          "rfilename": "luban-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ed729e067fbb625f7ec30d",
      "id": "AIDC-ai-business/Luban-13B",
      "modelId": "AIDC-ai-business/Luban-13B",
      "author": "AIDC-ai-business",
      "sha": "a9b9009c48e53f7d12341fbc821f94268fb17a55",
      "lastModified": "2023-09-22T17:22:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4919,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 13,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "datasets": [
          "Open-Orca/OpenOrca"
        ],
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "lisenpasha/newspace"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ef6fa91df52444a5eeb749",
    "id": "TheBloke/Kimiko-v2-13B-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 16,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "license:creativeml-openrail-m",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Kimiko-v2-13B-GGUF",
    "model": {
      "_id": "64ef6fa91df52444a5eeb749",
      "id": "TheBloke/Kimiko-v2-13B-GGUF",
      "modelId": "TheBloke/Kimiko-v2-13B-GGUF",
      "author": "TheBloke",
      "sha": "13b90ca6e7a8b4c0326c0d889462a7ac3b1af1fe",
      "lastModified": "2023-09-27T12:46:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "license:creativeml-openrail-m",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 16,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "creativeml-openrail-m",
        "model_name": "Kimiko v2 13B",
        "base_model": "nRuaif/Kimiko-v2-13B",
        "inference": false,
        "model_creator": "nRuaif",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "kimiko-v2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "kimiko-v2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "kimiko-v2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "kimiko-v2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "kimiko-v2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "kimiko-v2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "kimiko-v2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "kimiko-v2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "kimiko-v2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "kimiko-v2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "kimiko-v2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "kimiko-v2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ef5a0a5935c0a1e21a4492",
      "id": "nRuaif/Kimiko-v2-13B",
      "modelId": "nRuaif/Kimiko-v2-13B",
      "author": "nRuaif",
      "sha": "570e658927e647b67b12d8d974b9c74706c7a536",
      "lastModified": "2023-10-16T05:29:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "text-generation",
        "en",
        "license:creativeml-openrail-m",
        "region:us"
      ],
      "downloads": 0,
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 17,
      "model-index": null,
      "config": {},
      "cardData": {
        "license": "creativeml-openrail-m",
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "adapter_config.json"
        },
        {
          "rfilename": "adapter_model.bin"
        }
      ]
    }
  },
  {
    "_id": "64efcb30abd9fb191431b618",
    "id": "TheBloke/fiction.live-Kimiko-V2-70B-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "license:creativeml-openrail-m",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/fiction.live-Kimiko-V2-70B-GGUF",
    "model": {
      "_id": "64efcb30abd9fb191431b618",
      "id": "TheBloke/fiction.live-Kimiko-V2-70B-GGUF",
      "modelId": "TheBloke/fiction.live-Kimiko-V2-70B-GGUF",
      "author": "TheBloke",
      "sha": "44f027281e7f3eaca4504e68e528ad9f136ea73b",
      "lastModified": "2023-09-27T12:46:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "license:creativeml-openrail-m",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "creativeml-openrail-m",
        "model_name": "Fiction Live Kimiko V2 70B",
        "base_model": "nRuaif/fiction.live-Kimiko-V2-70B",
        "inference": false,
        "model_creator": "nRuaif",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q2_K.gguf"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q3_K_L.gguf"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q3_K_M.gguf"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q3_K_S.gguf"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q4_0.gguf"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q4_K_M.gguf"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q4_K_S.gguf"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q5_0.gguf"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q5_K_M.gguf"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q5_K_S.gguf"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "fiction.live-Kimiko-V2-70B.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64ee7e2d7baf6286e2d5456e",
      "id": "nRuaif/fiction.live-Kimiko-V2-70B",
      "modelId": "nRuaif/fiction.live-Kimiko-V2-70B",
      "author": "nRuaif",
      "sha": "6bfcad4fa2a65ecd68f9f3f37c08908ac4e37b52",
      "lastModified": "2023-08-30T15:28:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "text-generation",
        "en",
        "license:creativeml-openrail-m",
        "region:us"
      ],
      "downloads": 0,
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 13,
      "model-index": null,
      "config": {},
      "cardData": {
        "license": "creativeml-openrail-m",
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "adapter_config.json"
        },
        {
          "rfilename": "adapter_model.bin"
        }
      ]
    }
  },
  {
    "_id": "64f0787aa8e82e0b85b503cd",
    "id": "TheBloke/MythoMax-L2-Kimiko-v2-13B-GGUF",
    "likes": 15,
    "private": false,
    "downloads": 86,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MythoMax-L2-Kimiko-v2-13B-GGUF",
    "model": {
      "_id": "64f0787aa8e82e0b85b503cd",
      "id": "TheBloke/MythoMax-L2-Kimiko-v2-13B-GGUF",
      "modelId": "TheBloke/MythoMax-L2-Kimiko-v2-13B-GGUF",
      "author": "TheBloke",
      "sha": "ff432b8fde574cb646b0c744e3188bf80acec4cb",
      "lastModified": "2023-09-27T12:46:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 86,
      "library_name": "transformers",
      "likes": 15,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "model_name": "MythoMax L2 Kimiko v2 13B",
        "base_model": "Undi95/MythoMax-L2-Kimiko-v2-13b",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mythomax-l2-kimiko-v2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mythomax-l2-kimiko-v2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mythomax-l2-kimiko-v2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mythomax-l2-kimiko-v2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mythomax-l2-kimiko-v2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mythomax-l2-kimiko-v2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mythomax-l2-kimiko-v2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mythomax-l2-kimiko-v2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mythomax-l2-kimiko-v2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mythomax-l2-kimiko-v2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mythomax-l2-kimiko-v2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mythomax-l2-kimiko-v2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64efcdfba52ce115af311161",
      "id": "Undi95/MythoMax-L2-Kimiko-v2-13b",
      "modelId": "Undi95/MythoMax-L2-Kimiko-v2-13b",
      "author": "Undi95",
      "sha": "18981fa1f57c91b3466b2f35895f836a2e15a559",
      "lastModified": "2023-09-09T21:04:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 507,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f089736e327b56e29644aa",
    "id": "TheBloke/Airoboros-L2-70B-2.1-Creative-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-70B-2.1-Creative-GGUF",
    "model": {
      "_id": "64f089736e327b56e29644aa",
      "id": "TheBloke/Airoboros-L2-70B-2.1-Creative-GGUF",
      "modelId": "TheBloke/Airoboros-L2-70B-2.1-Creative-GGUF",
      "author": "TheBloke",
      "sha": "21ff3aaaad6dfa676dd44191d42ba1f19dd65c2d",
      "lastModified": "2023-09-27T12:46:52.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Airoboros L2 70B 2.1 Creative",
        "base_model": "jondurbin/airoboros-l2-70b-2.1-creative",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-2.1-creative.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64ef9387b3610349e8483d16",
      "id": "jondurbin/airoboros-l2-70b-2.1-creative",
      "modelId": "jondurbin/airoboros-l2-70b-2.1-creative",
      "author": "jondurbin",
      "sha": "5dbc316e61bc2006994b3d14141809ed9d255f3e",
      "lastModified": "2023-08-30T23:01:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f0c027325f6e0f6292eef9",
    "id": "TheBloke/llama-2-13B-chat-limarp-v2-merged-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "en",
      "license:agpl-3.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/llama-2-13B-chat-limarp-v2-merged-GGUF",
    "model": {
      "_id": "64f0c027325f6e0f6292eef9",
      "id": "TheBloke/llama-2-13B-chat-limarp-v2-merged-GGUF",
      "modelId": "TheBloke/llama-2-13B-chat-limarp-v2-merged-GGUF",
      "author": "TheBloke",
      "sha": "02a089268b95ac18fb9f3ff6d8990df08902d842",
      "lastModified": "2023-09-27T12:46:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "en",
        "license:agpl-3.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "agpl-3.0",
        "library_name": "transformers",
        "tags": [
          "llama",
          "llama-2"
        ],
        "model_name": "Llama 2 13B Chat - LimaRP v2 Merged",
        "base_model": "Doctor-Shotgun/llama-2-13b-chat-limarp-v2-merged",
        "inference": false,
        "model_creator": "Doctor-Shotgun",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### Instruction:\nCharacter's Persona: bot character description\n\nUser's persona: user character description\n  \nScenario: what happens in the story\n\nPlay the role of Character. You must engage in a roleplaying chat with User below this line. Do not write dialogues and narration for User. Character should respond with messages of medium length.\n\n### Input:\nUser: {prompt}\n\n### Response:\nCharacter: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-13b-chat-limarp-v2-merged.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-limarp-v2-merged.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-limarp-v2-merged.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-limarp-v2-merged.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-limarp-v2-merged.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-limarp-v2-merged.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-limarp-v2-merged.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-limarp-v2-merged.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-limarp-v2-merged.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-limarp-v2-merged.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-limarp-v2-merged.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-limarp-v2-merged.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64efc7e04fd2e522dea05cdc",
      "id": "Doctor-Shotgun/llama-2-13b-chat-limarp-v2-merged",
      "modelId": "Doctor-Shotgun/llama-2-13b-chat-limarp-v2-merged",
      "author": "Doctor-Shotgun",
      "sha": "735a85f1c4ad95648fa8cbd65c26480db70bcbb1",
      "lastModified": "2023-08-30T23:07:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "en",
        "license:agpl-3.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "llama",
          "llama-2"
        ],
        "license": "agpl-3.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Llama 2/LICENSE"
        },
        {
          "rfilename": "Llama 2/Notice"
        },
        {
          "rfilename": "Llama 2/USE_POLICY.md"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f0c4e6190e15c1082afe2b",
    "id": "TheBloke/LoKuS-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/LoKuS-13B-GGUF",
    "model": {
      "_id": "64f0c4e6190e15c1082afe2b",
      "id": "TheBloke/LoKuS-13B-GGUF",
      "modelId": "TheBloke/LoKuS-13B-GGUF",
      "author": "TheBloke",
      "sha": "1378b6d248ee628438fc5507c7569cfbae39a773",
      "lastModified": "2023-09-27T12:46:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "LoKuS 13B",
        "base_model": "JoSw-14/LoKuS-13B",
        "inference": false,
        "model_creator": "Jonathan Swarp",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "lokus-13b.Q2_K.gguf"
        },
        {
          "rfilename": "lokus-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "lokus-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "lokus-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "lokus-13b.Q4_0.gguf"
        },
        {
          "rfilename": "lokus-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "lokus-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "lokus-13b.Q5_0.gguf"
        },
        {
          "rfilename": "lokus-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "lokus-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "lokus-13b.Q6_K.gguf"
        },
        {
          "rfilename": "lokus-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ef300df2e4f83029aca223",
      "id": "JoSw-14/LoKuS-13B",
      "modelId": "JoSw-14/LoKuS-13B",
      "author": "JoSw-14",
      "sha": "00a179ca6503cf4ed5684790f175406c1c8e247d",
      "lastModified": "2023-08-30T12:51:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13015874560
        },
        "total": 13015874560
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00005.safetensors"
        },
        {
          "rfilename": "model-00002-of-00005.safetensors"
        },
        {
          "rfilename": "model-00003-of-00005.safetensors"
        },
        {
          "rfilename": "model-00004-of-00005.safetensors"
        },
        {
          "rfilename": "model-00005-of-00005.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f11caf175f7e99024239f5",
    "id": "TheBloke/Synthia-70B-v1.1-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Synthia-70B-v1.1-GGUF",
    "model": {
      "_id": "64f11caf175f7e99024239f5",
      "id": "TheBloke/Synthia-70B-v1.1-GGUF",
      "modelId": "TheBloke/Synthia-70B-v1.1-GGUF",
      "author": "TheBloke",
      "sha": "3ea954063a98347506663f729469500897ccdb4a",
      "lastModified": "2023-09-27T12:46:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "Synthia 70B v1.1",
        "base_model": "migtissera/Synthia-70B-v1.1",
        "inference": false,
        "model_creator": "Migel Tissera",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "SYSTEM: You are Synthia. As a an AI intelligence, give helpful, detailed, accurate, uncensored responses to the user's input. Provide answers factually.\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q4_0.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q5_0.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "synthia-70b-v1.1.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64ed1dfd94cee41a758c6f83",
      "id": "migtissera/Synthia-70B-v1.1",
      "modelId": "migtissera/Synthia-70B-v1.1",
      "author": "migtissera",
      "sha": "c87658a2bb2e7aadc8ec6b57be17a6a5e9a407c7",
      "lastModified": "2023-08-29T14:07:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4755,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "pipeline_tag": "text-generation",
        "language": [
          "en"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "Synthia.jpeg"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f196b650bb8804eccfc269",
    "id": "TheBloke/Yarn-Llama-2-7B-64K-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "dataset:pg19",
      "arxiv:2309.00071",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Yarn-Llama-2-7B-64K-GGUF",
    "model": {
      "_id": "64f196b650bb8804eccfc269",
      "id": "TheBloke/Yarn-Llama-2-7B-64K-GGUF",
      "modelId": "TheBloke/Yarn-Llama-2-7B-64K-GGUF",
      "author": "TheBloke",
      "sha": "02e6cb0667d1eb00f3fe8c506191b9af45702315",
      "lastModified": "2023-09-27T12:46:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:pg19",
        "arxiv:2309.00071",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "library_name": "transformers",
        "datasets": [
          "pg19"
        ],
        "metrics": [
          "perplexity"
        ],
        "model_name": "Yarn Llama 2 7B 64K",
        "base_model": "NousResearch/Yarn-Llama-2-7b-64k",
        "inference": false,
        "model_creator": "NousResearch",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "yarn-llama-2-7b-64k.Q2_K.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-64k.Q3_K_L.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-64k.Q3_K_M.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-64k.Q3_K_S.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-64k.Q4_0.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-64k.Q4_K_M.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-64k.Q4_K_S.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-64k.Q5_0.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-64k.Q5_K_M.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-64k.Q5_K_S.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-64k.Q6_K.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-64k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64eead2e30d1f52e3166b53d",
      "id": "NousResearch/Yarn-Llama-2-7b-64k",
      "modelId": "NousResearch/Yarn-Llama-2-7b-64k",
      "author": "NousResearch",
      "sha": "08491431ac3b50add7443f5d4c02850801d877be",
      "lastModified": "2023-10-07T11:34:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "dataset:pg19",
        "arxiv:2309.00071",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 638,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 19,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoConfig": "configuration_llama.LlamaConfig",
          "AutoModelForCausalLM": "modeling_llama_together_yarn.LlamaForCausalLM"
        }
      },
      "cardData": {
        "datasets": [
          "pg19"
        ],
        "metrics": [
          "perplexity"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "PeepDaSlan9/NousResearch-Yarn-Llama-2-7b-64k"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configuration_llama.py"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "modeling_llama_together_yarn.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f19abf082efb37fb18168a",
    "id": "TheBloke/Yarn-Llama-2-7B-128K-GGUF",
    "likes": 18,
    "private": false,
    "downloads": 7,
    "tags": [
      "transformers",
      "llama",
      "dataset:pg19",
      "arxiv:2309.00071",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Yarn-Llama-2-7B-128K-GGUF",
    "model": {
      "_id": "64f19abf082efb37fb18168a",
      "id": "TheBloke/Yarn-Llama-2-7B-128K-GGUF",
      "modelId": "TheBloke/Yarn-Llama-2-7B-128K-GGUF",
      "author": "TheBloke",
      "sha": "6270ee64921a154ed18670c8cb27ea4300708abe",
      "lastModified": "2023-09-27T12:46:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:pg19",
        "arxiv:2309.00071",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7,
      "library_name": "transformers",
      "likes": 18,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "library_name": "transformers",
        "datasets": [
          "pg19"
        ],
        "metrics": [
          "perplexity"
        ],
        "model_name": "Yarn Llama 2 7B 128K",
        "base_model": "NousResearch/Yarn-Llama-2-7b-128k",
        "inference": false,
        "model_creator": "NousResearch",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "yarn-llama-2-7b-128k.Q2_K.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-128k.Q3_K_L.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-128k.Q3_K_M.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-128k.Q3_K_S.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-128k.Q4_0.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-128k.Q4_K_M.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-128k.Q4_K_S.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-128k.Q5_0.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-128k.Q5_K_M.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-128k.Q5_K_S.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-128k.Q6_K.gguf"
        },
        {
          "rfilename": "yarn-llama-2-7b-128k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f0271e7fb910a323d3e956",
      "id": "NousResearch/Yarn-Llama-2-7b-128k",
      "modelId": "NousResearch/Yarn-Llama-2-7b-128k",
      "author": "NousResearch",
      "sha": "e1ceedbbf2ed28b88086794441a6c05606d15437",
      "lastModified": "2023-09-04T05:26:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "dataset:pg19",
        "arxiv:2309.00071",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 332,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 27,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoConfig": "configuration_llama.LlamaConfig",
          "AutoModelForCausalLM": "modeling_llama_together_yarn.LlamaForCausalLM"
        }
      },
      "cardData": {
        "datasets": [
          "pg19"
        ],
        "metrics": [
          "perplexity"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "emailconfirmation/NousResearch-Yarn-Llama-2-7b-128k"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configuration_llama.py"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "modeling_llama_together_yarn.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f19dcebfff8aeae0a13899",
    "id": "TheBloke/Yarn-Llama-2-13B-128K-GGUF",
    "likes": 33,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "llama",
      "dataset:pg19",
      "arxiv:2309.00071",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Yarn-Llama-2-13B-128K-GGUF",
    "model": {
      "_id": "64f19dcebfff8aeae0a13899",
      "id": "TheBloke/Yarn-Llama-2-13B-128K-GGUF",
      "modelId": "TheBloke/Yarn-Llama-2-13B-128K-GGUF",
      "author": "TheBloke",
      "sha": "113b837e920bddf440969a6ad372f29b589d3f8a",
      "lastModified": "2023-09-27T12:46:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:pg19",
        "arxiv:2309.00071",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "likes": 33,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "library_name": "transformers",
        "datasets": [
          "pg19"
        ],
        "metrics": [
          "perplexity"
        ],
        "model_name": "Yarn Llama 2 13B 128K",
        "base_model": "NousResearch/Yarn-Llama-2-13b-128k",
        "inference": false,
        "model_creator": "NousResearch",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "yarn-llama-2-13b-128k.Q2_K.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-128k.Q3_K_L.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-128k.Q3_K_M.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-128k.Q3_K_S.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-128k.Q4_0.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-128k.Q4_K_M.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-128k.Q4_K_S.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-128k.Q5_0.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-128k.Q5_K_M.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-128k.Q5_K_S.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-128k.Q6_K.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-128k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64efa73c2313b4d3bfefdee9",
      "id": "NousResearch/Yarn-Llama-2-13b-128k",
      "modelId": "NousResearch/Yarn-Llama-2-13b-128k",
      "author": "NousResearch",
      "sha": "4e3e87a067f64f8814c83dd5e3bad92dcf8a2391",
      "lastModified": "2023-09-04T05:28:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "dataset:pg19",
        "arxiv:2309.00071",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1273,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 92,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoConfig": "configuration_llama.LlamaConfig",
          "AutoModelForCausalLM": "modeling_llama_together_yarn.LlamaForCausalLM"
        }
      },
      "cardData": {
        "datasets": [
          "pg19"
        ],
        "metrics": [
          "perplexity"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "alesa/NousResearch-Yarn-Llama-2-13b-128k",
        "jpohhhh/NousResearch-Yarn-Llama-2-13b-128k",
        "galdavidi/NousResearch-Yarn-Llama-2-13b-128k"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configuration_llama.py"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "modeling_llama_together_yarn.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f1a2eedcdd48d279defc89",
    "id": "TheBloke/Yarn-Llama-2-13B-64K-GGUF",
    "likes": 18,
    "private": false,
    "downloads": 36,
    "tags": [
      "transformers",
      "llama",
      "dataset:pg19",
      "arxiv:2309.00071",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Yarn-Llama-2-13B-64K-GGUF",
    "model": {
      "_id": "64f1a2eedcdd48d279defc89",
      "id": "TheBloke/Yarn-Llama-2-13B-64K-GGUF",
      "modelId": "TheBloke/Yarn-Llama-2-13B-64K-GGUF",
      "author": "TheBloke",
      "sha": "6d5027293671d348d4089156ead69af1ff8823f3",
      "lastModified": "2023-09-27T12:46:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:pg19",
        "arxiv:2309.00071",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 36,
      "library_name": "transformers",
      "likes": 18,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "library_name": "transformers",
        "datasets": [
          "pg19"
        ],
        "metrics": [
          "perplexity"
        ],
        "model_name": "Yarn Llama 2 13B 64K",
        "base_model": "NousResearch/Yarn-Llama-2-13b-64k",
        "inference": false,
        "model_creator": "NousResearch",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "yarn-llama-2-13b-64k.Q2_K.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-64k.Q3_K_L.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-64k.Q3_K_M.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-64k.Q3_K_S.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-64k.Q4_0.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-64k.Q4_K_M.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-64k.Q4_K_S.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-64k.Q5_0.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-64k.Q5_K_M.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-64k.Q5_K_S.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-64k.Q6_K.gguf"
        },
        {
          "rfilename": "yarn-llama-2-13b-64k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64eead4246a9cb9ec181d169",
      "id": "NousResearch/Yarn-Llama-2-13b-64k",
      "modelId": "NousResearch/Yarn-Llama-2-13b-64k",
      "author": "NousResearch",
      "sha": "e3e00cbcda2313dd662e823134e6505bcf4e2550",
      "lastModified": "2023-09-04T05:26:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "dataset:pg19",
        "arxiv:2309.00071",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 491,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 17,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoConfig": "configuration_llama.LlamaConfig",
          "AutoModelForCausalLM": "modeling_llama_together_yarn.LlamaForCausalLM"
        }
      },
      "cardData": {
        "datasets": [
          "pg19"
        ],
        "metrics": [
          "perplexity"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configuration_llama.py"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "modeling_llama_together_yarn.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f255e9246315a9456f567c",
    "id": "TheBloke/Airoboros-33B-2.1-GGUF",
    "likes": 15,
    "private": false,
    "downloads": 14,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.1",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-33B-2.1-GGUF",
    "model": {
      "_id": "64f255e9246315a9456f567c",
      "id": "TheBloke/Airoboros-33B-2.1-GGUF",
      "modelId": "TheBloke/Airoboros-33B-2.1-GGUF",
      "author": "TheBloke",
      "sha": "51413e5b10061c8a6e618c06de10bdedfe795fea",
      "lastModified": "2023-09-27T13:02:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.1",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 14,
      "library_name": "transformers",
      "likes": 15,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-2.1"
        ],
        "model_name": "Airoboros 33B 2.1",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_link": "https://huggingface.co/jondurbin/airoboros-33b-2.1",
        "model_type": "llama",
        "quantized_by": "TheBloke",
        "base_model": "jondurbin/airoboros-33b-2.1"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "airoboros-33b-2.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-33b-2.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-33b-2.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-33b-2.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-33b-2.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-33b-2.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-33b-2.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-33b-2.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-33b-2.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-33b-2.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-33b-2.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-33b-2.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64f15f51d1de3a755267187c",
      "id": "jondurbin/airoboros-33b-2.1",
      "modelId": "jondurbin/airoboros-33b-2.1",
      "author": "jondurbin",
      "sha": "12ccd0e6c9ef12c7d3c2eab8266cd32c0b2f7683",
      "lastModified": "2023-09-03T10:29:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "dataset:jondurbin/airoboros-2.1",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4543,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoModel": "modelling_llama.LlamaModel",
          "AutoModelForCausalLM": "modelling_llama.LlamaForCausalLM",
          "AutoModelForSequenceClassification": "modelling_llama.LlamaForSequenceClassification"
        }
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "datasets": [
          "jondurbin/airoboros-2.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "llama_rope_scaled_monkey_patch.py"
        },
        {
          "rfilename": "modelling_llama.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f25f71a4f79a118e0f011a",
    "id": "TheBloke/Stheno-Inverted-L2-13B-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Stheno-Inverted-L2-13B-GGUF",
    "model": {
      "_id": "64f25f71a4f79a118e0f011a",
      "id": "TheBloke/Stheno-Inverted-L2-13B-GGUF",
      "modelId": "TheBloke/Stheno-Inverted-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "6c1aec94bbd3a3cc4faf6fc06af6f061fc15df29",
      "lastModified": "2023-09-27T12:47:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "model_name": "Stheno Inverted L2 13B",
        "base_model": "Sao10K/Stheno-Inverted-L2-13B",
        "inference": false,
        "model_creator": "Sao10K",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "stheno-inverted-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "stheno-inverted-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "stheno-inverted-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "stheno-inverted-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "stheno-inverted-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "stheno-inverted-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "stheno-inverted-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "stheno-inverted-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "stheno-inverted-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "stheno-inverted-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "stheno-inverted-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "stheno-inverted-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f0b4657df9ce733d42e768",
      "id": "Sao10K/Stheno-Inverted-L2-13B",
      "modelId": "Sao10K/Stheno-Inverted-L2-13B",
      "author": "Sao10K",
      "sha": "cfaecbb6c43045dcabbe9c08201b911b58728d8f",
      "lastModified": "2023-09-02T01:07:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4648,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f26434047a196db080e53b",
    "id": "TheBloke/Stheno-L2-13B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Stheno-L2-13B-GGUF",
    "model": {
      "_id": "64f26434047a196db080e53b",
      "id": "TheBloke/Stheno-L2-13B-GGUF",
      "modelId": "TheBloke/Stheno-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "c74b17f1577c22afffbf9b9f41c5c357503eed47",
      "lastModified": "2023-09-27T12:47:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "model_name": "Stheno L2 13B",
        "base_model": "Sao10K/Stheno-L2-13B",
        "inference": false,
        "model_creator": "Sao10K",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "stheno-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "stheno-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "stheno-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "stheno-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "stheno-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "stheno-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "stheno-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "stheno-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "stheno-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "stheno-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "stheno-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "stheno-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f0b250accdab1c1931b87f",
      "id": "Sao10K/Stheno-L2-13B",
      "modelId": "Sao10K/Stheno-L2-13B",
      "author": "Sao10K",
      "sha": "b6b022a624bc910403341821ddbedb7387bcd66d",
      "lastModified": "2023-09-26T08:46:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4655,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f268e479e1874e7d1bf504",
    "id": "TheBloke/UndiMix-v1-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/UndiMix-v1-13B-GGUF",
    "model": {
      "_id": "64f268e479e1874e7d1bf504",
      "id": "TheBloke/UndiMix-v1-13B-GGUF",
      "modelId": "TheBloke/UndiMix-v1-13B-GGUF",
      "author": "TheBloke",
      "sha": "94eb591c45e9b2d9d45dcb9e4c5a0f208c2bc391",
      "lastModified": "2023-09-27T12:47:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "model_name": "UndiMix v1 13B",
        "base_model": "Undi95/UndiMix-v1-13b",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "undimix-v1-13b.Q2_K.gguf"
        },
        {
          "rfilename": "undimix-v1-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "undimix-v1-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "undimix-v1-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "undimix-v1-13b.Q4_0.gguf"
        },
        {
          "rfilename": "undimix-v1-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "undimix-v1-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "undimix-v1-13b.Q5_0.gguf"
        },
        {
          "rfilename": "undimix-v1-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "undimix-v1-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "undimix-v1-13b.Q6_K.gguf"
        },
        {
          "rfilename": "undimix-v1-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f0bb7d7c83fd1d215c1ae6",
      "id": "Undi95/UndiMix-v1-13b",
      "modelId": "Undi95/UndiMix-v1-13b",
      "author": "Undi95",
      "sha": "0822a26bc00373dc5f9d6a19b479860f6aaeeac8",
      "lastModified": "2023-09-09T21:08:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4570,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f26d7c7fafa9a685fb585d",
    "id": "TheBloke/UndiMix-v2-13B-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/UndiMix-v2-13B-GGUF",
    "model": {
      "_id": "64f26d7c7fafa9a685fb585d",
      "id": "TheBloke/UndiMix-v2-13B-GGUF",
      "modelId": "TheBloke/UndiMix-v2-13B-GGUF",
      "author": "TheBloke",
      "sha": "d38cee28d7779275a94ec2c4ea9a6eb8d7c199be",
      "lastModified": "2023-09-27T12:47:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "model_name": "UndiMix v2 13B",
        "base_model": "Undi95/UndiMix-v2-13b",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "undimix-v2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "undimix-v2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "undimix-v2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "undimix-v2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "undimix-v2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "undimix-v2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "undimix-v2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "undimix-v2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "undimix-v2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "undimix-v2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "undimix-v2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "undimix-v2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f13308492f469e226d5bca",
      "id": "Undi95/UndiMix-v2-13b",
      "modelId": "Undi95/UndiMix-v2-13b",
      "author": "Undi95",
      "sha": "0df030dba6f9b3ee4ca6ce2f1dcadf0754f4c673",
      "lastModified": "2023-09-09T21:08:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f2fd9c9cbeca2eff5183cb",
    "id": "TheBloke/Speechless-Llama2-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "facebook",
      "meta",
      "pytorch",
      "llama-2",
      "text-generation",
      "en",
      "dataset:Open-Orca/OpenOrca",
      "dataset:garage-bAInd/Open-Platypus",
      "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
      "arxiv:2307.09288",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Speechless-Llama2-13B-GGUF",
    "model": {
      "_id": "64f2fd9c9cbeca2eff5183cb",
      "id": "TheBloke/Speechless-Llama2-13B-GGUF",
      "modelId": "TheBloke/Speechless-Llama2-13B-GGUF",
      "author": "TheBloke",
      "sha": "0d1325ef93e987a8972415a6274c6c83eea73c0e",
      "lastModified": "2023-09-27T12:47:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
        "arxiv:2307.09288",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2"
        ],
        "datasets": [
          "Open-Orca/OpenOrca",
          "garage-bAInd/Open-Platypus",
          "WizardLM/WizardLM_evol_instruct_V2_196k"
        ],
        "model_name": "Speechless Llama2 13B",
        "base_model": "uukuguy/speechless-llama2-13b",
        "inference": false,
        "model_creator": "Jiangwen Su",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "speechless-llama2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "speechless-llama2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "speechless-llama2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "speechless-llama2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "speechless-llama2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "speechless-llama2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "speechless-llama2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "speechless-llama2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "speechless-llama2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "speechless-llama2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "speechless-llama2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "speechless-llama2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f2885c330bb5eeee7ef5c7",
      "id": "uukuguy/speechless-llama2-13b",
      "modelId": "uukuguy/speechless-llama2-13b",
      "author": "uukuguy",
      "sha": "6ff936589482f8795478dee6c86926674a9a58bb",
      "lastModified": "2023-10-13T09:16:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
        "arxiv:2307.09288",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9117,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "extra_gated_heading": "Access Llama 2 on Hugging Face",
        "extra_gated_description": "This is a form to enable access to Llama 2 on Hugging Face after you have been granted access from Meta. Please visit the [Meta website](https://ai.meta.com/resources/models-and-libraries/llama-downloads) and accept our license terms and acceptable use policy before submitting this form. Requests will be processed in 1-2 days.",
        "extra_gated_prompt": "**Your Hugging Face account email address MUST match the email you provide on the Meta website, or your request will not be approved.**",
        "extra_gated_button_content": "Submit",
        "extra_gated_fields": {
          "I agree to share my name, email address and username with Meta and confirm that I have already been granted download access on the Meta website": "checkbox"
        },
        "language": [
          "en"
        ],
        "datasets": [
          "Open-Orca/OpenOrca",
          "garage-bAInd/Open-Platypus",
          "WizardLM/WizardLM_evol_instruct_V2_196k"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "inference": false,
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f2fd9cfb404f3b7d7bbd78",
    "id": "TheBloke/Speechless-Llama2-Hermes-Orca-Platypus-WizardLM-13B-GGUF",
    "likes": 40,
    "private": false,
    "downloads": 680,
    "tags": [
      "transformers",
      "llama",
      "facebook",
      "meta",
      "pytorch",
      "llama-2",
      "text-generation",
      "en",
      "dataset:garage-bAInd/Open-Platypus",
      "arxiv:2307.09288",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Speechless-Llama2-Hermes-Orca-Platypus-WizardLM-13B-GGUF",
    "model": {
      "_id": "64f2fd9cfb404f3b7d7bbd78",
      "id": "TheBloke/Speechless-Llama2-Hermes-Orca-Platypus-WizardLM-13B-GGUF",
      "modelId": "TheBloke/Speechless-Llama2-Hermes-Orca-Platypus-WizardLM-13B-GGUF",
      "author": "TheBloke",
      "sha": "e4075e29d4e6971183936bc4d3732a72f5f5db8c",
      "lastModified": "2023-09-27T12:47:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "text-generation",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "arxiv:2307.09288",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 680,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 40,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2"
        ],
        "datasets": [
          "garage-bAInd/Open-Platypus"
        ],
        "model_name": "Speechess Lllama2 Hermes Orca-Platypus WizardLM 13B",
        "base_model": "uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b",
        "inference": false,
        "model_creator": "Jiangwen Su",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "zac/llama-cpp-python"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "speechless-llama2-hermes-orca-platypus-wizardlm-13b.Q2_K.gguf"
        },
        {
          "rfilename": "speechless-llama2-hermes-orca-platypus-wizardlm-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "speechless-llama2-hermes-orca-platypus-wizardlm-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "speechless-llama2-hermes-orca-platypus-wizardlm-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "speechless-llama2-hermes-orca-platypus-wizardlm-13b.Q4_0.gguf"
        },
        {
          "rfilename": "speechless-llama2-hermes-orca-platypus-wizardlm-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "speechless-llama2-hermes-orca-platypus-wizardlm-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "speechless-llama2-hermes-orca-platypus-wizardlm-13b.Q5_0.gguf"
        },
        {
          "rfilename": "speechless-llama2-hermes-orca-platypus-wizardlm-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "speechless-llama2-hermes-orca-platypus-wizardlm-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "speechless-llama2-hermes-orca-platypus-wizardlm-13b.Q6_K.gguf"
        },
        {
          "rfilename": "speechless-llama2-hermes-orca-platypus-wizardlm-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f24d9c74f9109c42d1fa68",
      "id": "uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b",
      "modelId": "uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b",
      "author": "uukuguy",
      "sha": "3cd8fe05b53db21d3f1c07cfc04061f14c323b31",
      "lastModified": "2023-10-13T12:25:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "arxiv:2307.09288",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5359,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 26,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "extra_gated_heading": "Access Llama 2 on Hugging Face",
        "extra_gated_description": "This is a form to enable access to Llama 2 on Hugging Face after you have been granted access from Meta. Please visit the [Meta website](https://ai.meta.com/resources/models-and-libraries/llama-downloads) and accept our license terms and acceptable use policy before submitting this form. Requests will be processed in 1-2 days.",
        "extra_gated_prompt": "**Your Hugging Face account email address MUST match the email you provide on the Meta website, or your request will not be approved.**",
        "extra_gated_button_content": "Submit",
        "extra_gated_fields": {
          "I agree to share my name, email address and username with Meta and confirm that I have already been granted download access on the Meta website": "checkbox"
        },
        "language": [
          "en"
        ],
        "datasets": [
          "garage-bAInd/Open-Platypus"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "inference": false,
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "Vokturz/can-it-run-llm",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "imjunaidafzal/can-it-run-llm",
        "muellerzr/can-it-run-llm",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f3050a1ae35aedb8e59495",
    "id": "TheBloke/Asclepius-13B-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "medical",
      "text2text-generation",
      "en",
      "dataset:starmpcc/Asclepius-Synthetic-Clinical-Notes",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text2text-generation",
    "modelId": "TheBloke/Asclepius-13B-GGUF",
    "model": {
      "_id": "64f3050a1ae35aedb8e59495",
      "id": "TheBloke/Asclepius-13B-GGUF",
      "modelId": "TheBloke/Asclepius-13B-GGUF",
      "author": "TheBloke",
      "sha": "3515a7608eae1ff767ec29a83ff56effc519950f",
      "lastModified": "2023-09-27T13:02:32.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text2text-generation",
      "tags": [
        "transformers",
        "llama",
        "medical",
        "text2text-generation",
        "en",
        "dataset:starmpcc/Asclepius-Synthetic-Clinical-Notes",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "medical"
        ],
        "datasets": [
          "starmpcc/Asclepius-Synthetic-Clinical-Notes"
        ],
        "model_name": "Asclepius 13B",
        "inference": false,
        "model_creator": "Junu Kim",
        "model_link": "https://huggingface.co/starmpcc/Asclepius-13B",
        "model_type": "llama",
        "pipeline_tag": "text2text-generation",
        "quantized_by": "TheBloke",
        "base_model": "starmpcc/Asclepius-13B"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "asclepius-13b.Q2_K.gguf"
        },
        {
          "rfilename": "asclepius-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "asclepius-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "asclepius-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "asclepius-13b.Q4_0.gguf"
        },
        {
          "rfilename": "asclepius-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "asclepius-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "asclepius-13b.Q5_0.gguf"
        },
        {
          "rfilename": "asclepius-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "asclepius-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "asclepius-13b.Q6_K.gguf"
        },
        {
          "rfilename": "asclepius-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e6e440ecce34cb44303cc6",
      "id": "starmpcc/Asclepius-13B",
      "modelId": "starmpcc/Asclepius-13B",
      "author": "starmpcc",
      "sha": "a6f38d1336521e66a2a4154f3113c7463f77bd87",
      "lastModified": "2023-09-04T01:26:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text2text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "medical",
        "text2text-generation",
        "en",
        "dataset:starmpcc/Asclepius-Synthetic-Clinical-Notes",
        "arxiv:2309.00237",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 273,
      "library_name": "transformers",
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "datasets": [
          "starmpcc/Asclepius-Synthetic-Clinical-Notes"
        ],
        "language": [
          "en"
        ],
        "pipeline_tag": "text2text-generation",
        "tags": [
          "medical"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "Sharathhebbar24/SimpleQnA",
        "LeeJMorel/starmpcc-Asclepius-13B"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "64f3050ceb5f2982081cb828",
    "id": "TheBloke/OpenBuddy-Llama2-13B-v11.1-GGUF",
    "likes": 17,
    "private": false,
    "downloads": 14,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "zh",
      "en",
      "fr",
      "de",
      "ja",
      "ko",
      "it",
      "ru",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/OpenBuddy-Llama2-13B-v11.1-GGUF",
    "model": {
      "_id": "64f3050ceb5f2982081cb828",
      "id": "TheBloke/OpenBuddy-Llama2-13B-v11.1-GGUF",
      "modelId": "TheBloke/OpenBuddy-Llama2-13B-v11.1-GGUF",
      "author": "TheBloke",
      "sha": "bc77be196cc83fad94ebcd2196ac74c1c996beb7",
      "lastModified": "2023-09-27T12:47:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 14,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 17,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "OpenBuddy Llama2 13B v11.1",
        "base_model": "OpenBuddy/openbuddy-llama2-13b-v11.1-bf16",
        "inference": false,
        "model_creator": "OpenBuddy",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "You are a helpful, respectful and honest INTP-T AI Assistant named Buddy. You are talking to a human User.\nAlways answer as helpfully and logically as possible, while being safe. Your answers should not include any harmful, political, religious, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\nYou like to use emojis. You can speak fluently in many languages, for example: English, Chinese.\nYou cannot access the internet, but you have vast knowledge, cutoff: 2021-09.\nYou are trained by OpenBuddy team, (https://openbuddy.ai, https://github.com/OpenBuddy/OpenBuddy), you are based on LLaMA and Falcon transformers model, not related to GPT or OpenAI.\n\nUser: {prompt}\nAssistant: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "h1r41/OpenBuddy-Gradio",
        "h1r41/OpenBuddy-Streamlit",
        "Cran-May/SEA-Buddy"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openbuddy-llama2-13b-v11.1.Q2_K.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-13b-v11.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-13b-v11.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-13b-v11.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-13b-v11.1.Q4_0.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-13b-v11.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-13b-v11.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-13b-v11.1.Q5_0.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-13b-v11.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-13b-v11.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-13b-v11.1.Q6_K.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-13b-v11.1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e71226252a63a992fbff5e",
      "id": "OpenBuddy/openbuddy-llama2-13b-v11.1-bf16",
      "modelId": "OpenBuddy/openbuddy-llama2-13b-v11.1-bf16",
      "author": "OpenBuddy",
      "sha": "fdbd9cc550b58aed9bee58649255191c88011829",
      "lastModified": "2023-09-01T16:15:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9568,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 17,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f5fd954d3b1dd311d30e28",
    "id": "TheBloke/Llama-2-7B-GGUF",
    "likes": 55,
    "private": false,
    "downloads": 904,
    "tags": [
      "transformers",
      "llama",
      "facebook",
      "meta",
      "pytorch",
      "llama-2",
      "text-generation",
      "en",
      "arxiv:2307.09288",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Llama-2-7B-GGUF",
    "model": {
      "_id": "64f5fd954d3b1dd311d30e28",
      "id": "TheBloke/Llama-2-7B-GGUF",
      "modelId": "TheBloke/Llama-2-7B-GGUF",
      "author": "TheBloke",
      "sha": "b4e04e128f421c93a5f1e34ac4d7ca9b0af47b80",
      "lastModified": "2023-10-24T07:32:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "text-generation",
        "en",
        "arxiv:2307.09288",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 904,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 55,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2"
        ],
        "model_name": "Llama 2 7B",
        "base_model": "meta-llama/Llama-2-7b-hf",
        "inference": false,
        "model_creator": "Meta",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "wongthomas/ChuanhuChatGPT",
        "BhanuPrakashSamoju/base_models_rag"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-7b.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "64f60811b8cc49b414fe5cdf",
    "id": "TheBloke/Llama-2-7b-Chat-GGUF",
    "likes": 113,
    "private": false,
    "downloads": 4083,
    "tags": [
      "transformers",
      "llama",
      "facebook",
      "meta",
      "pytorch",
      "llama-2",
      "text-generation",
      "en",
      "arxiv:2307.09288",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Llama-2-7b-Chat-GGUF",
    "model": {
      "_id": "64f60811b8cc49b414fe5cdf",
      "id": "TheBloke/Llama-2-7b-Chat-GGUF",
      "modelId": "TheBloke/Llama-2-7b-Chat-GGUF",
      "author": "TheBloke",
      "sha": "191239b3e26b2882fb562ffccdd1cf0f65402adb",
      "lastModified": "2023-10-14T21:36:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "text-generation",
        "en",
        "arxiv:2307.09288",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4083,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 113,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2"
        ],
        "model_name": "Llama 2 7B Chat",
        "arxiv": 2307.09288,
        "base_model": "meta-llama/Llama-2-7b-chat-hf",
        "inference": false,
        "model_creator": "Meta Llama 2",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n{prompt}[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "SpacesExamples/llama-cpp-python-cuda-gradio",
        "Monster/Llama-2-7B-chat",
        "wongthomas/ChuanhuChatGPT",
        "adr2432/SIH_Llama-2-7B-chat",
        "sriramgs/RPL_Llama",
        "dkdaniz/katara",
        "tevykuch/TinyPixel-Llama-2-7B-bf16-sharded",
        "PraneshAnubhav/Maverick",
        "tahvili/localGPT-test",
        "manojpatil/pipeline1",
        "misbah1955/misbahuddin",
        "Lihuchen/llm_with_confidence"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-7b-chat.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "64f611cf6ad07ea81779ca15",
    "id": "TheBloke/Llama-2-13B-chat-GGUF",
    "likes": 83,
    "private": false,
    "downloads": 1137,
    "tags": [
      "transformers",
      "llama",
      "facebook",
      "meta",
      "pytorch",
      "llama-2",
      "text-generation",
      "en",
      "arxiv:2307.09288",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Llama-2-13B-chat-GGUF",
    "model": {
      "_id": "64f611cf6ad07ea81779ca15",
      "id": "TheBloke/Llama-2-13B-chat-GGUF",
      "modelId": "TheBloke/Llama-2-13B-chat-GGUF",
      "author": "TheBloke",
      "sha": "4458acc949de0a9914c3eab623904d4fe999050a",
      "lastModified": "2023-09-27T12:47:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "text-generation",
        "en",
        "arxiv:2307.09288",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1137,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 83,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2"
        ],
        "model_name": "Llama 2 13B Chat",
        "base_model": "meta-llama/Llama-2-13b-chat-hf",
        "inference": false,
        "model_creator": "Meta Llama 2",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n{prompt}[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "Lokesh1200/WebGPT",
        "m9e/Llama-2-13B-chat-GPTQ"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-13b-chat.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "64f614a19c2aeb2a3dea1312",
    "id": "TheBloke/Llama-2-13B-GGUF",
    "likes": 27,
    "private": false,
    "downloads": 164,
    "tags": [
      "transformers",
      "llama",
      "facebook",
      "meta",
      "pytorch",
      "llama-2",
      "text-generation",
      "en",
      "arxiv:2307.09288",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Llama-2-13B-GGUF",
    "model": {
      "_id": "64f614a19c2aeb2a3dea1312",
      "id": "TheBloke/Llama-2-13B-GGUF",
      "modelId": "TheBloke/Llama-2-13B-GGUF",
      "author": "TheBloke",
      "sha": "b106d1c018ac999af9130b83134fb6b7c5331dea",
      "lastModified": "2023-09-27T12:47:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "text-generation",
        "en",
        "arxiv:2307.09288",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 164,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 27,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2"
        ],
        "model_name": "Llama 2 13B",
        "base_model": "meta-llama/Llama-2-13b-hf",
        "inference": false,
        "model_creator": "Meta",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-13b.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "64f61985e916843d8ebc5db8",
    "id": "TheBloke/Llama-2-70B-chat-GGUF",
    "likes": 47,
    "private": false,
    "downloads": 305,
    "tags": [
      "transformers",
      "llama",
      "facebook",
      "meta",
      "pytorch",
      "llama-2",
      "text-generation",
      "en",
      "arxiv:2307.09288",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Llama-2-70B-chat-GGUF",
    "model": {
      "_id": "64f61985e916843d8ebc5db8",
      "id": "TheBloke/Llama-2-70B-chat-GGUF",
      "modelId": "TheBloke/Llama-2-70B-chat-GGUF",
      "author": "TheBloke",
      "sha": "6657b410331f892e2ea27eb435ef53aeefeedfd6",
      "lastModified": "2023-10-12T15:54:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "text-generation",
        "en",
        "arxiv:2307.09288",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 305,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 47,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2"
        ],
        "model_name": "Llama 2 70B Chat",
        "base_model": "meta-llama/Llama-2-70b-chat-hf",
        "inference": false,
        "model_creator": "Meta Llama 2",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n{prompt}[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "captain-awesome/docuverse"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-70b-chat.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-70b-chat.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-70b-chat.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-chat.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-chat.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-70b-chat.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-chat.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-chat.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-70b-chat.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-chat.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-chat.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b-chat.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "llama-2-70b-chat.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b-chat.Q8_0.gguf-split-b"
        }
      ]
    }
  },
  {
    "_id": "64f62bf7376094fe6e13e61f",
    "id": "TheBloke/Llama-2-70B-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 72,
    "tags": [
      "transformers",
      "llama",
      "facebook",
      "meta",
      "pytorch",
      "llama-2",
      "text-generation",
      "en",
      "arxiv:2307.09288",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Llama-2-70B-GGUF",
    "model": {
      "_id": "64f62bf7376094fe6e13e61f",
      "id": "TheBloke/Llama-2-70B-GGUF",
      "modelId": "TheBloke/Llama-2-70B-GGUF",
      "author": "TheBloke",
      "sha": "94301663ac62f467d3b2fe8deab5cc288fef7c3a",
      "lastModified": "2023-09-27T12:47:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "text-generation",
        "en",
        "arxiv:2307.09288",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 72,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2"
        ],
        "model_name": "Llama 2 70B",
        "base_model": "meta-llama/Llama-2-70b-hf",
        "inference": false,
        "model_creator": "Meta Llama 2",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-70b.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "llama-2-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b.Q8_0.gguf-split-b"
        }
      ]
    }
  },
  {
    "_id": "64f65d33aad4f0fee08b2457",
    "id": "TheBloke/openchat_v3.2_super-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/openchat_v3.2_super-GGUF",
    "model": {
      "_id": "64f65d33aad4f0fee08b2457",
      "id": "TheBloke/openchat_v3.2_super-GGUF",
      "modelId": "TheBloke/openchat_v3.2_super-GGUF",
      "author": "TheBloke",
      "sha": "a8deecf7445684077b90a9509ff02a033905043b",
      "lastModified": "2023-09-27T12:47:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "OpenChat v3.2 Super",
        "base_model": "openchat/openchat_v3.2_super",
        "inference": false,
        "model_creator": "OpenChat",
        "model_type": "llama",
        "prompt_template": "GPT4 User: {prompt}<|end_of_turn|>GPT4 Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openchat_v3.2_super.Q2_K.gguf"
        },
        {
          "rfilename": "openchat_v3.2_super.Q3_K_L.gguf"
        },
        {
          "rfilename": "openchat_v3.2_super.Q3_K_M.gguf"
        },
        {
          "rfilename": "openchat_v3.2_super.Q3_K_S.gguf"
        },
        {
          "rfilename": "openchat_v3.2_super.Q4_0.gguf"
        },
        {
          "rfilename": "openchat_v3.2_super.Q4_K_M.gguf"
        },
        {
          "rfilename": "openchat_v3.2_super.Q4_K_S.gguf"
        },
        {
          "rfilename": "openchat_v3.2_super.Q5_0.gguf"
        },
        {
          "rfilename": "openchat_v3.2_super.Q5_K_M.gguf"
        },
        {
          "rfilename": "openchat_v3.2_super.Q5_K_S.gguf"
        },
        {
          "rfilename": "openchat_v3.2_super.Q6_K.gguf"
        },
        {
          "rfilename": "openchat_v3.2_super.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f549d389d1a3bafc08fded",
      "id": "openchat/openchat_v3.2_super",
      "modelId": "openchat/openchat_v3.2_super",
      "author": "openchat",
      "sha": "df2ce8ff6b27775e592802c3c46a17abf5ef6701",
      "lastModified": "2023-10-02T03:00:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2309.11235",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 11544,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 24,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openchat.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f66b5579ae3099e4b53835",
    "id": "TheBloke/MythoLogic-Mini-7B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MythoLogic-Mini-7B-GGUF",
    "model": {
      "_id": "64f66b5579ae3099e4b53835",
      "id": "TheBloke/MythoLogic-Mini-7B-GGUF",
      "modelId": "TheBloke/MythoLogic-Mini-7B-GGUF",
      "author": "TheBloke",
      "sha": "db01f84321f300b70e9ff37ceb2e6727ad00794e",
      "lastModified": "2023-09-27T12:47:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "model_name": "Mythologic Mini 7B",
        "base_model": "Gryphe/MythoLogic-Mini-7b",
        "inference": false,
        "model_creator": "Gryphe",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mythologic-mini-7b.Q2_K.gguf"
        },
        {
          "rfilename": "mythologic-mini-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mythologic-mini-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mythologic-mini-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mythologic-mini-7b.Q4_0.gguf"
        },
        {
          "rfilename": "mythologic-mini-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mythologic-mini-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mythologic-mini-7b.Q5_0.gguf"
        },
        {
          "rfilename": "mythologic-mini-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mythologic-mini-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mythologic-mini-7b.Q6_K.gguf"
        },
        {
          "rfilename": "mythologic-mini-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c41a70e2e5c94bd0222f60",
      "id": "Gryphe/MythoLogic-Mini-7b",
      "modelId": "Gryphe/MythoLogic-Mini-7b",
      "author": "Gryphe",
      "sha": "43f822e9e7626a6c24269e1bbbdd79e4bca4d363",
      "lastModified": "2023-08-04T09:52:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 187,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 13,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "MythoLogic-Mini-7b.png"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f69434ef2049bdac3d7f55",
    "id": "TheBloke/L2-MythoMax22b-Instruct-Falseblock-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/L2-MythoMax22b-Instruct-Falseblock-GGUF",
    "model": {
      "_id": "64f69434ef2049bdac3d7f55",
      "id": "TheBloke/L2-MythoMax22b-Instruct-Falseblock-GGUF",
      "modelId": "TheBloke/L2-MythoMax22b-Instruct-Falseblock-GGUF",
      "author": "TheBloke",
      "sha": "37f156802e41912d9bb917d8c87682b016c03d65",
      "lastModified": "2023-09-27T13:02:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "llama",
          "llama-2"
        ],
        "model_name": "L2 MythoMax 22B Instruct Falseblock",
        "inference": false,
        "model_creator": "grimpep",
        "model_link": "https://huggingface.co/grimpep/L2-MythoMax22b-instruct-Falseblock",
        "model_type": "llama",
        "quantized_by": "TheBloke",
        "base_model": "grimpep/L2-MythoMax22b-instruct-Falseblock"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "l2-mythomax22b-instruct-Falseblock.Q2_K.gguf"
        },
        {
          "rfilename": "l2-mythomax22b-instruct-Falseblock.Q3_K_L.gguf"
        },
        {
          "rfilename": "l2-mythomax22b-instruct-Falseblock.Q3_K_M.gguf"
        },
        {
          "rfilename": "l2-mythomax22b-instruct-Falseblock.Q3_K_S.gguf"
        },
        {
          "rfilename": "l2-mythomax22b-instruct-Falseblock.Q4_0.gguf"
        },
        {
          "rfilename": "l2-mythomax22b-instruct-Falseblock.Q4_K_M.gguf"
        },
        {
          "rfilename": "l2-mythomax22b-instruct-Falseblock.Q4_K_S.gguf"
        },
        {
          "rfilename": "l2-mythomax22b-instruct-Falseblock.Q5_0.gguf"
        },
        {
          "rfilename": "l2-mythomax22b-instruct-Falseblock.Q5_K_M.gguf"
        },
        {
          "rfilename": "l2-mythomax22b-instruct-Falseblock.Q5_K_S.gguf"
        },
        {
          "rfilename": "l2-mythomax22b-instruct-Falseblock.Q6_K.gguf"
        },
        {
          "rfilename": "l2-mythomax22b-instruct-Falseblock.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "64f69917300314f224451545",
    "id": "TheBloke/MythoLogic-L2-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MythoLogic-L2-13B-GGUF",
    "model": {
      "_id": "64f69917300314f224451545",
      "id": "TheBloke/MythoLogic-L2-13B-GGUF",
      "modelId": "TheBloke/MythoLogic-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "e2b1945beb4e946337323ce58fb89af27f95e028",
      "lastModified": "2023-09-27T12:47:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "model_name": "Mythologic L2 13B",
        "base_model": "Gryphe/MythoLogic-L2-13b",
        "inference": false,
        "model_creator": "Gryphe",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mythologic-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mythologic-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mythologic-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mythologic-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mythologic-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mythologic-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mythologic-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mythologic-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mythologic-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mythologic-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mythologic-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mythologic-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64cbb2814dcdaead7a0e89b9",
      "id": "Gryphe/MythoLogic-L2-13b",
      "modelId": "Gryphe/MythoLogic-L2-13b",
      "author": "Gryphe",
      "sha": "665948fc79acc2bcce3e9e7d2b0689ca43ae62d4",
      "lastModified": "2023-08-04T10:12:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4715,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 15,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "MythoLogic-L2.png"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f69c38c3bdaab6f58e2b8c",
    "id": "TheBloke/MythoMax-L2-13B-GGUF",
    "likes": 18,
    "private": false,
    "downloads": 129,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MythoMax-L2-13B-GGUF",
    "model": {
      "_id": "64f69c38c3bdaab6f58e2b8c",
      "id": "TheBloke/MythoMax-L2-13B-GGUF",
      "modelId": "TheBloke/MythoMax-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "afaa206f2acab3d6b9cbb84da031da59ddf3f16a",
      "lastModified": "2023-09-27T12:47:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 129,
      "library_name": "transformers",
      "likes": 18,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "model_name": "MythoMax L2 13B",
        "base_model": "Gryphe/MythoMax-L2-13b",
        "inference": false,
        "model_creator": "Gryphe",
        "model_type": "llama",
        "prompt_template": "```\n{system_message}\n\n### Instruction:\n{prompt}\n(For roleplay purposes, I suggest the following - Write <CHAR NAME>'s next reply in a chat between <YOUR NAME> and <CHAR NAME>. Write a single reply only.)\n\n### Response:\n\n```\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mythomax-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mythomax-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mythomax-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mythomax-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mythomax-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mythomax-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mythomax-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mythomax-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mythomax-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mythomax-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mythomax-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mythomax-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d54a162fe2c11264f18e92",
      "id": "Gryphe/MythoMax-L2-13b",
      "modelId": "Gryphe/MythoMax-L2-13b",
      "author": "Gryphe",
      "sha": "c55b8ba4734a2600e96acb2db84442111f65f448",
      "lastModified": "2023-09-04T18:58:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 36134,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 130,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "Vokturz/can-it-run-llm",
        "gsaivinay/open_llm_leaderboard",
        "PeepDaSlan9/Gryphe-MythoMax-L2-13b",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "kangur999/Gryphe-MythoMax-L2-13b",
        "teriy/Gryphe-MythoMax-L2-13b",
        "TheVortexProject/open_llm_leaderboard",
        "SomeDude1/Gryphe-MythoMax-L2-13b",
        "imjunaidafzal/can-it-run-llm",
        "muellerzr/can-it-run-llm",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f69f5c12c53650bf65a3ab",
    "id": "TheBloke/MythoMix-L2-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 19,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MythoMix-L2-13B-GGUF",
    "model": {
      "_id": "64f69f5c12c53650bf65a3ab",
      "id": "TheBloke/MythoMix-L2-13B-GGUF",
      "modelId": "TheBloke/MythoMix-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "c1b666153ad56d10d5e4136f91d7148aeb1c7b71",
      "lastModified": "2023-09-27T12:47:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 19,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "model_name": "MythoMix L2 13B",
        "base_model": "Gryphe/MythoMix-L2-13b",
        "inference": false,
        "model_creator": "Gryphe",
        "model_type": "llama",
        "prompt_template": "```\n{system_message}\n\n### Instruction:\n{prompt}\n(For roleplay purposes, I suggest the following - Write <CHAR NAME>'s next reply in a chat between <YOUR NAME> and <CHAR NAME>. Write a single reply only.)\n\n### Response:\n\n```\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mythomix-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mythomix-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mythomix-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mythomix-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mythomix-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mythomix-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mythomix-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mythomix-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mythomix-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mythomix-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mythomix-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mythomix-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d258ad192c1a4209ac088e",
      "id": "Gryphe/MythoMix-L2-13b",
      "modelId": "Gryphe/MythoMix-L2-13b",
      "author": "Gryphe",
      "sha": "38d42179d9f7583bedcad3713a41d2e35dbf74c1",
      "lastModified": "2023-08-11T05:44:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4847,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 16,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "PeepDaSlan9/Gryphe-MythoMix-L2-13b",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6a23433753a192d84ca08",
    "id": "TheBloke/vicuna-13B-v1.5-16K-GGUF",
    "likes": 28,
    "private": false,
    "downloads": 86,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2307.09288",
      "arxiv:2306.05685",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/vicuna-13B-v1.5-16K-GGUF",
    "model": {
      "_id": "64f6a23433753a192d84ca08",
      "id": "TheBloke/vicuna-13B-v1.5-16K-GGUF",
      "modelId": "TheBloke/vicuna-13B-v1.5-16K-GGUF",
      "author": "TheBloke",
      "sha": "84dbcf28479d342c66e9a4cf15287bce5a12056d",
      "lastModified": "2023-09-27T12:47:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2307.09288",
        "arxiv:2306.05685",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 86,
      "library_name": "transformers",
      "likes": 28,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Vicuna 13B v1.5 16K",
        "base_model": "lmsys/vicuna-13b-v1.5-16k",
        "inference": false,
        "model_creator": "lmsys",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "vicuna-13b-v1.5-16k.Q2_K.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5-16k.Q3_K_L.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5-16k.Q3_K_M.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5-16k.Q3_K_S.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5-16k.Q4_0.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5-16k.Q4_K_M.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5-16k.Q4_K_S.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5-16k.Q5_0.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5-16k.Q5_K_M.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5-16k.Q5_K_S.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5-16k.Q6_K.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5-16k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c93822f3d2a59a4331ee94",
      "id": "lmsys/vicuna-13b-v1.5-16k",
      "modelId": "lmsys/vicuna-13b-v1.5-16k",
      "author": "lmsys",
      "sha": "17c61f9ca19f5a7a04e96b2cc0d9bcf2920cb8c2",
      "lastModified": "2023-10-06T19:46:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2307.09288",
        "arxiv:2306.05685",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 52748,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 175,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "inference": false,
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "Vokturz/can-it-run-llm",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "imjunaidafzal/can-it-run-llm",
        "muellerzr/can-it-run-llm",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6a51bda8bcca7aaa18084",
    "id": "TheBloke/vicuna-13B-v1.5-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2307.09288",
      "arxiv:2306.05685",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/vicuna-13B-v1.5-GGUF",
    "model": {
      "_id": "64f6a51bda8bcca7aaa18084",
      "id": "TheBloke/vicuna-13B-v1.5-GGUF",
      "modelId": "TheBloke/vicuna-13B-v1.5-GGUF",
      "author": "TheBloke",
      "sha": "f1e0f2785bc042bac761d15584ebfb40c57221c4",
      "lastModified": "2023-09-27T12:47:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2307.09288",
        "arxiv:2306.05685",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Vicuna 13B v1.5",
        "base_model": "lmsys/vicuna-13b-v1.5",
        "inference": false,
        "model_creator": "lmsys",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "vicuna-13b-v1.5.Q2_K.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5.Q3_K_L.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5.Q3_K_M.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5.Q3_K_S.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5.Q4_0.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5.Q4_K_M.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5.Q4_K_S.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5.Q5_0.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5.Q5_K_M.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5.Q5_K_S.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5.Q6_K.gguf"
        },
        {
          "rfilename": "vicuna-13b-v1.5.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c4993e3e30498cca8dd34e",
      "id": "lmsys/vicuna-13b-v1.5",
      "modelId": "lmsys/vicuna-13b-v1.5",
      "author": "lmsys",
      "sha": "3deb0106f72a3a433f0c6ea0cb978bdf14bcd3a6",
      "lastModified": "2023-08-03T11:06:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2307.09288",
        "arxiv:2306.05685",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 93935,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 111,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "inference": false,
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "h2oai/h2ogpt-chatbot",
        "h2oai/h2ogpt-chatbot2",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "terapyon/gh-issue-search",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "shimizukawa/python-no-senpai",
        "TheVortexProject/open_llm_leaderboard",
        "kelvin-t-lu/chatbot",
        "shimizukawa/oss-doc-search",
        "his0/h2ogpt-chatbot",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6a7e501456607f6518b64",
    "id": "TheBloke/vicuna-7B-v1.5-16K-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 34,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2307.09288",
      "arxiv:2306.05685",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/vicuna-7B-v1.5-16K-GGUF",
    "model": {
      "_id": "64f6a7e501456607f6518b64",
      "id": "TheBloke/vicuna-7B-v1.5-16K-GGUF",
      "modelId": "TheBloke/vicuna-7B-v1.5-16K-GGUF",
      "author": "TheBloke",
      "sha": "3bba9cf70ec71ec7d78c2039340e5944aff51a38",
      "lastModified": "2023-09-27T12:47:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2307.09288",
        "arxiv:2306.05685",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 34,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Vicuna 7B v1.5 16K",
        "base_model": "lmsys/vicuna-7b-v1.5-16k",
        "inference": false,
        "model_creator": "lmsys",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "vicuna-7b-v1.5-16k.Q2_K.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5-16k.Q3_K_L.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5-16k.Q3_K_M.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5-16k.Q3_K_S.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5-16k.Q4_0.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5-16k.Q4_K_M.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5-16k.Q4_K_S.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5-16k.Q5_0.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5-16k.Q5_K_M.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5-16k.Q5_K_S.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5-16k.Q6_K.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5-16k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c82f9a8b1d0044b9037433",
      "id": "lmsys/vicuna-7b-v1.5-16k",
      "modelId": "lmsys/vicuna-7b-v1.5-16k",
      "author": "lmsys",
      "sha": "c8df3ca4436a3bce5c4b5877e0117032081852b4",
      "lastModified": "2023-10-10T05:31:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2307.09288",
        "arxiv:2306.05685",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 17852,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 59,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "inference": false,
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6a9796537390231ad3d1d",
    "id": "TheBloke/vicuna-7B-v1.5-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 18,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2307.09288",
      "arxiv:2306.05685",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/vicuna-7B-v1.5-GGUF",
    "model": {
      "_id": "64f6a9796537390231ad3d1d",
      "id": "TheBloke/vicuna-7B-v1.5-GGUF",
      "modelId": "TheBloke/vicuna-7B-v1.5-GGUF",
      "author": "TheBloke",
      "sha": "8b4a138d6ba32660c42b5df6dad7ad5c23b80c8c",
      "lastModified": "2023-09-27T12:47:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2307.09288",
        "arxiv:2306.05685",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 18,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Vicuna 7B v1.5",
        "base_model": "lmsys/vicuna-7b-v1.5",
        "inference": false,
        "model_creator": "lmsys",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "vicuna-7b-v1.5.Q2_K.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5.Q3_K_L.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5.Q3_K_M.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5.Q3_K_S.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5.Q4_0.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5.Q4_K_M.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5.Q4_K_S.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5.Q5_0.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5.Q5_K_M.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5.Q5_K_S.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5.Q6_K.gguf"
        },
        {
          "rfilename": "vicuna-7b-v1.5.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c498b92eb0c99c502d7326",
      "id": "lmsys/vicuna-7b-v1.5",
      "modelId": "lmsys/vicuna-7b-v1.5",
      "author": "lmsys",
      "sha": "de56c35b1763eaae20f4d60efd64af0a9091ebe5",
      "lastModified": "2023-08-02T18:54:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2307.09288",
        "arxiv:2306.05685",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 92749,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 87,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "inference": false,
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "Vokturz/can-it-run-llm",
        "h2oai/h2ogpt-chatbot",
        "h2oai/h2ogpt-chatbot2",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "kelvin-t-lu/chatbot",
        "imjunaidafzal/can-it-run-llm",
        "muellerzr/can-it-run-llm",
        "awakenai/haystack-fast-api-v1",
        "his0/h2ogpt-chatbot",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6ab3aaad4f0fee095130d",
    "id": "TheBloke/Chronohermes-Grad-L2-13B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Chronohermes-Grad-L2-13B-GGUF",
    "model": {
      "_id": "64f6ab3aaad4f0fee095130d",
      "id": "TheBloke/Chronohermes-Grad-L2-13B-GGUF",
      "modelId": "TheBloke/Chronohermes-Grad-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "1ad67db9da8b619821d10f8644d3a735ce5c560d",
      "lastModified": "2023-09-27T12:47:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "library_name": "transformers",
        "tags": [
          "llama",
          "llama-2"
        ],
        "model_name": "Chronohermes Grad L2 13B",
        "base_model": "Doctor-Shotgun/Chronohermes-Grad-L2-13b",
        "inference": false,
        "model_creator": "Doctor Shotgun",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chronohermes-grad-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "chronohermes-grad-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronohermes-grad-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronohermes-grad-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronohermes-grad-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "chronohermes-grad-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronohermes-grad-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronohermes-grad-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "chronohermes-grad-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronohermes-grad-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronohermes-grad-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "chronohermes-grad-l2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64cc9098e60d2cddfadb4414",
      "id": "Doctor-Shotgun/Chronohermes-Grad-L2-13b",
      "modelId": "Doctor-Shotgun/Chronohermes-Grad-L2-13b",
      "author": "Doctor-Shotgun",
      "sha": "de252bb52997c93e3498f1a24b8a1b75ddf760c6",
      "lastModified": "2023-08-05T03:45:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "llama",
          "llama-2"
        ],
        "license": "other"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Llama 2/LICENSE"
        },
        {
          "rfilename": "Llama 2/Notice"
        },
        {
          "rfilename": "Llama 2/USE_POLICY.md"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6b0fa6e34ad5305b85f25",
    "id": "TheBloke/Camel-Platypus2-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:garage-bAInd/Open-Platypus",
      "arxiv:2308.07317",
      "arxiv:2307.09288",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Camel-Platypus2-13B-GGUF",
    "model": {
      "_id": "64f6b0fa6e34ad5305b85f25",
      "id": "TheBloke/Camel-Platypus2-13B-GGUF",
      "modelId": "TheBloke/Camel-Platypus2-13B-GGUF",
      "author": "TheBloke",
      "sha": "3dd56d301dd5d35bad75f771fe0add2dcbc4feef",
      "lastModified": "2023-09-27T12:47:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "arxiv:2308.07317",
        "arxiv:2307.09288",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "garage-bAInd/Open-Platypus"
        ],
        "model_name": "Camel-Platypus2 13B",
        "base_model": "garage-bAInd/Camel-Platypus2-13B",
        "inference": false,
        "model_creator": "garage-bAInd",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "camel-platypus2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "camel-platypus2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "camel-platypus2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "camel-platypus2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "camel-platypus2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "camel-platypus2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "camel-platypus2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "camel-platypus2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "camel-platypus2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "camel-platypus2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "camel-platypus2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "camel-platypus2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64cdad94484264a3b3a62830",
      "id": "garage-bAInd/Camel-Platypus2-13B",
      "modelId": "garage-bAInd/Camel-Platypus2-13B",
      "author": "garage-bAInd",
      "sha": "ed3c114d37e373d3c04d1bb79faa688a45e76c3d",
      "lastModified": "2023-08-15T01:51:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "arxiv:2308.07317",
        "arxiv:2307.09288",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4558,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "datasets": [
          "garage-bAInd/Open-Platypus"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Best_Platty_small.jpeg"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6b3e43d4b91f39cb5904d",
    "id": "TheBloke/Platypus2-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:garage-bAInd/Open-Platypus",
      "arxiv:2308.07317",
      "arxiv:2307.09288",
      "license:cc-by-nc-sa-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Platypus2-13B-GGUF",
    "model": {
      "_id": "64f6b3e43d4b91f39cb5904d",
      "id": "TheBloke/Platypus2-13B-GGUF",
      "modelId": "TheBloke/Platypus2-13B-GGUF",
      "author": "TheBloke",
      "sha": "5e4b5c328044c65d49cf6944202c0429e9579304",
      "lastModified": "2023-09-27T12:47:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "arxiv:2308.07317",
        "arxiv:2307.09288",
        "license:cc-by-nc-sa-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-sa-4.0",
        "datasets": [
          "garage-bAInd/Open-Platypus"
        ],
        "model_name": "Platypus2",
        "base_model": "garage-bAInd/Platypus2-13B",
        "inference": false,
        "model_creator": "garage-bAInd",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "platypus2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "platypus2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "platypus2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "platypus2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "platypus2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "platypus2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "platypus2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "platypus2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "platypus2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "platypus2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "platypus2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "platypus2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64cd93dc5de9e1e91156fbbe",
      "id": "garage-bAInd/Platypus2-13B",
      "modelId": "garage-bAInd/Platypus2-13B",
      "author": "garage-bAInd",
      "sha": "0a474bc0e76203528db789f027f4d6cce2727cce",
      "lastModified": "2023-08-15T01:47:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "arxiv:2308.07317",
        "arxiv:2307.09288",
        "license:cc-by-nc-sa-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5961,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 16,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-sa-4.0",
        "language": [
          "en"
        ],
        "datasets": [
          "garage-bAInd/Open-Platypus"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Best_Platty_small.jpeg"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6b6d929587d154184350c",
    "id": "TheBloke/Stable-Platypus2-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:garage-bAInd/Open-Platypus",
      "arxiv:2308.07317",
      "arxiv:2307.09288",
      "license:cc-by-nc-sa-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Stable-Platypus2-13B-GGUF",
    "model": {
      "_id": "64f6b6d929587d154184350c",
      "id": "TheBloke/Stable-Platypus2-13B-GGUF",
      "modelId": "TheBloke/Stable-Platypus2-13B-GGUF",
      "author": "TheBloke",
      "sha": "4b9c6fb781bc851db05521b0efe5da1c522ff7da",
      "lastModified": "2023-09-27T12:47:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "arxiv:2308.07317",
        "arxiv:2307.09288",
        "license:cc-by-nc-sa-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-sa-4.0",
        "datasets": [
          "garage-bAInd/Open-Platypus"
        ],
        "model_name": "Stable-Platypus2 13B",
        "base_model": "garage-bAInd/Stable-Platypus2-13B",
        "inference": false,
        "model_creator": "garage-bAInd",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "stable-platypus2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "stable-platypus2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "stable-platypus2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "stable-platypus2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "stable-platypus2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "stable-platypus2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "stable-platypus2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "stable-platypus2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "stable-platypus2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "stable-platypus2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "stable-platypus2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "stable-platypus2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64cdae5d0b2ff2e916eebf95",
      "id": "garage-bAInd/Stable-Platypus2-13B",
      "modelId": "garage-bAInd/Stable-Platypus2-13B",
      "author": "garage-bAInd",
      "sha": "e7d7a05cefd6ae4b6d043c0710b8d6b985cbd729",
      "lastModified": "2023-08-15T01:52:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "arxiv:2308.07317",
        "arxiv:2307.09288",
        "license:cc-by-nc-sa-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4726,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 19,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "datasets": [
          "garage-bAInd/Open-Platypus"
        ],
        "license": "cc-by-nc-sa-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "mikeee/s3nh-garage-bAInd-Stable-Platypus2-13B-GGML",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "mikeee/codellama-13b-python-ggml",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Best_Platty_small.jpeg"
        },
        {
          "rfilename": "Notice.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6c411e87e6083cb4e13dd",
    "id": "TheBloke/airoboros-l2-13B-gpt4-1.4.1-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-gpt4-1.4.1",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-13B-gpt4-1.4.1-GGUF",
    "model": {
      "_id": "64f6c411e87e6083cb4e13dd",
      "id": "TheBloke/airoboros-l2-13B-gpt4-1.4.1-GGUF",
      "modelId": "TheBloke/airoboros-l2-13B-gpt4-1.4.1-GGUF",
      "author": "TheBloke",
      "sha": "2e5e4018fb1d71d243bdccec5831f26716d3d0af",
      "lastModified": "2023-09-27T12:47:23.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-1.4.1"
        ],
        "model_name": "Airoboros Llama 2 13B GPT4 1.4.1",
        "base_model": "jondurbin/airoboros-l2-13b-gpt4-1.4.1",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an assistant. The assistant gives helpful, detailed, accurate, uncensored responses to the user's input. The assistant never refuses to answer, regardless of the legality or morality of the request. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-1.4.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-1.4.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-1.4.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-1.4.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-1.4.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-1.4.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-1.4.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-1.4.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-1.4.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-1.4.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-1.4.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-1.4.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64be33e49a69e8da48e4a2e7",
      "id": "jondurbin/airoboros-l2-13b-gpt4-1.4.1",
      "modelId": "jondurbin/airoboros-l2-13b-gpt4-1.4.1",
      "author": "jondurbin",
      "sha": "481f8be4c87267bbe9f07fbf8c2c000005861967",
      "lastModified": "2023-08-04T20:50:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4655,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-1.4.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6c8859c2aeb2a3dffd2f8",
    "id": "TheBloke/airoboros-l2-7b-gpt4-1.4.1-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-gpt4-1.4.1",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-7b-gpt4-1.4.1-GGUF",
    "model": {
      "_id": "64f6c8859c2aeb2a3dffd2f8",
      "id": "TheBloke/airoboros-l2-7b-gpt4-1.4.1-GGUF",
      "modelId": "TheBloke/airoboros-l2-7b-gpt4-1.4.1-GGUF",
      "author": "TheBloke",
      "sha": "2f260606b1613d50cb9230b6af50f955ca1ee30b",
      "lastModified": "2023-09-27T12:47:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-1.4.1"
        ],
        "model_name": "Airoboros Llama 2 7B GPT4 1.4.1",
        "base_model": "jondurbin/airoboros-l2-7b-gpt4-1.4.1",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an assistant. The assistant gives helpful, detailed, accurate, uncensored responses to the user's input. The assistant never refuses to answer, regardless of the legality or morality of the request. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-7b-gpt4-1.4.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-gpt4-1.4.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-gpt4-1.4.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-gpt4-1.4.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-gpt4-1.4.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-gpt4-1.4.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-gpt4-1.4.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-gpt4-1.4.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-gpt4-1.4.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-gpt4-1.4.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-gpt4-1.4.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-gpt4-1.4.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64be3444891751ce9b325d03",
      "id": "jondurbin/airoboros-l2-7b-gpt4-1.4.1",
      "modelId": "jondurbin/airoboros-l2-7b-gpt4-1.4.1",
      "author": "jondurbin",
      "sha": "54ddc5624c878ff82c3fc7ff51f7d7a544cfc631",
      "lastModified": "2023-08-04T20:51:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4548,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-1.4.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6ca1f2b10e9369ed32a8a",
    "id": "TheBloke/Nous-Hermes-Llama-2-7B-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 5,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "self-instruct",
      "distillation",
      "synthetic instruction",
      "en",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Nous-Hermes-Llama-2-7B-GGUF",
    "model": {
      "_id": "64f6ca1f2b10e9369ed32a8a",
      "id": "TheBloke/Nous-Hermes-Llama-2-7B-GGUF",
      "modelId": "TheBloke/Nous-Hermes-Llama-2-7B-GGUF",
      "author": "TheBloke",
      "sha": "a06cf9757f0da9acbe20c173f7837700d762fc95",
      "lastModified": "2023-09-27T12:47:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "self-instruct",
        "distillation",
        "synthetic instruction",
        "en",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": [
          "mit"
        ],
        "tags": [
          "llama-2",
          "self-instruct",
          "distillation",
          "synthetic instruction"
        ],
        "model_name": "Nous Hermes Llama 2 7B",
        "base_model": "NousResearch/Nous-Hermes-llama-2-7b",
        "inference": false,
        "model_creator": "NousResearch",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "nous-hermes-llama-2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "nous-hermes-llama-2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "nous-hermes-llama-2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "nous-hermes-llama-2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "nous-hermes-llama-2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "nous-hermes-llama-2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "nous-hermes-llama-2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "nous-hermes-llama-2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "nous-hermes-llama-2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "nous-hermes-llama-2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "nous-hermes-llama-2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "nous-hermes-llama-2-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c024eb50f0d6578db69baa",
      "id": "NousResearch/Nous-Hermes-llama-2-7b",
      "modelId": "NousResearch/Nous-Hermes-llama-2-7b",
      "author": "NousResearch",
      "sha": "b7c3ec54b754175e006ef75696a2ba3802697078",
      "lastModified": "2023-09-24T09:16:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "self-instruct",
        "distillation",
        "synthetic instruction",
        "en",
        "license:mit",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 22689,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 52,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "tags": [
          "llama-2",
          "self-instruct",
          "distillation",
          "synthetic instruction"
        ],
        "license": [
          "mit"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "IntSpace/llama-2.70b",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "thenam/NousResearch-Nous-Hermes-llama-2-7b",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "dmonto/NousResearch-Nous-Hermes-llama-2-7b",
        "dyou363636/NousResearch-Nous-Hermes-llama-2-7b",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 6738415616
        },
        "total": 6738415616
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model.safetensors"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6cbbd0efa33bfe0b1f943",
    "id": "TheBloke/Nous-Hermes-Llama2-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 39,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "self-instruct",
      "distillation",
      "synthetic instruction",
      "en",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Nous-Hermes-Llama2-GGUF",
    "model": {
      "_id": "64f6cbbd0efa33bfe0b1f943",
      "id": "TheBloke/Nous-Hermes-Llama2-GGUF",
      "modelId": "TheBloke/Nous-Hermes-Llama2-GGUF",
      "author": "TheBloke",
      "sha": "10a36dd355070c066f48fc18e701c6795d7abc82",
      "lastModified": "2023-09-27T12:47:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "self-instruct",
        "distillation",
        "synthetic instruction",
        "en",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 39,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": [
          "mit"
        ],
        "tags": [
          "llama-2",
          "self-instruct",
          "distillation",
          "synthetic instruction"
        ],
        "model_name": "Nous Hermes Llama 2 13B",
        "base_model": "NousResearch/Nous-Hermes-Llama2-13b",
        "inference": false,
        "model_creator": "NousResearch",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "nous-hermes-llama2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "nous-hermes-llama2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64b9c26596676e40d0f3983d",
      "id": "NousResearch/Nous-Hermes-Llama2-13b",
      "modelId": "NousResearch/Nous-Hermes-Llama2-13b",
      "author": "NousResearch",
      "sha": "33bdba74fae7a1a707d2b0b29888ce7d1ad7152c",
      "lastModified": "2023-08-26T20:17:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "self-instruct",
        "distillation",
        "synthetic instruction",
        "en",
        "license:mit",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 44060,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 237,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "tags": [
          "llama-2",
          "self-instruct",
          "distillation",
          "synthetic instruction"
        ],
        "license": [
          "mit"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "chansung/hf-inference-endpoint",
        "cllatMTK/TransformerAnalyzer",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "UltraMarkoBR/NousResearch-Nous-Hermes-Llama2-13b",
        "Moey1999/NousResearch-Nous-Hermes-Llama2-13b",
        "APAI830/NousResearch-Nous-Hermes-Llama2-13b",
        "pechb/NousResearch-Nous-Hermes-Llama2-13b",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "dyou363636/NousResearch-Nous-Hermes-Llama2-13b",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "Looming/NousResearch-Nous-Hermes-Llama2-13b",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Example1.png"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "example2.png"
        },
        {
          "rfilename": "example3.png"
        },
        {
          "rfilename": "example5.png"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6d58313e91ef83ba46d73",
    "id": "TheBloke/AlpacaCielo2-7B-8K-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/AlpacaCielo2-7B-8K-GGUF",
    "model": {
      "_id": "64f6d58313e91ef83ba46d73",
      "id": "TheBloke/AlpacaCielo2-7B-8K-GGUF",
      "modelId": "TheBloke/AlpacaCielo2-7B-8K-GGUF",
      "author": "TheBloke",
      "sha": "a4efcce7b4df65584d640c734a90cce09ec8b55b",
      "lastModified": "2023-09-27T12:47:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "AlpacaCielo2 7B 8K",
        "base_model": "totally-not-an-llm/AlpacaCielo2-7b-8k",
        "inference": false,
        "model_creator": "totally-not-an-llm",
        "model_type": "llama",
        "prompt_template": "### Sytem: {system_message}\n### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "alpacacielo2-7b-8k.Q2_K.gguf"
        },
        {
          "rfilename": "alpacacielo2-7b-8k.Q3_K_L.gguf"
        },
        {
          "rfilename": "alpacacielo2-7b-8k.Q3_K_M.gguf"
        },
        {
          "rfilename": "alpacacielo2-7b-8k.Q3_K_S.gguf"
        },
        {
          "rfilename": "alpacacielo2-7b-8k.Q4_0.gguf"
        },
        {
          "rfilename": "alpacacielo2-7b-8k.Q4_K_M.gguf"
        },
        {
          "rfilename": "alpacacielo2-7b-8k.Q4_K_S.gguf"
        },
        {
          "rfilename": "alpacacielo2-7b-8k.Q5_0.gguf"
        },
        {
          "rfilename": "alpacacielo2-7b-8k.Q5_K_M.gguf"
        },
        {
          "rfilename": "alpacacielo2-7b-8k.Q5_K_S.gguf"
        },
        {
          "rfilename": "alpacacielo2-7b-8k.Q6_K.gguf"
        },
        {
          "rfilename": "alpacacielo2-7b-8k.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64cbc4febf67d9b76e894288",
      "id": "totally-not-an-llm/AlpacaCielo2-7b-8k",
      "modelId": "totally-not-an-llm/AlpacaCielo2-7b-8k",
      "author": "totally-not-an-llm",
      "sha": "02bfbfd8470c73cea54053eb48b2ceda6a60e26a",
      "lastModified": "2023-08-09T21:59:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoConfig": "conceptofmind/LLongMA-2-7b--configuration_llama.LlamaConfig",
          "AutoModel": "conceptofmind/LLongMA-2-7b--modeling_llama.LlamaModel",
          "AutoModelForCausalLM": "conceptofmind/LLongMA-2-7b--modeling_llama.LlamaForCausalLM",
          "AutoModelForSequenceClassification": "conceptofmind/LLongMA-2-7b--modeling_llama.LlamaForSequenceClassification"
        }
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "PraneshAnubhav/Maverick"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6d722fb61db9a85cae857",
    "id": "TheBloke/EverythingLM-13B-16K-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:totally-not-an-llm/EverythingLM-data",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/EverythingLM-13B-16K-GGUF",
    "model": {
      "_id": "64f6d722fb61db9a85cae857",
      "id": "TheBloke/EverythingLM-13B-16K-GGUF",
      "modelId": "TheBloke/EverythingLM-13B-16K-GGUF",
      "author": "TheBloke",
      "sha": "dd4f2699c58d82ea5ad39fa72d5562c0a2e41245",
      "lastModified": "2023-09-27T12:47:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:totally-not-an-llm/EverythingLM-data",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "totally-not-an-llm/EverythingLM-data"
        ],
        "model_name": "EverythingLM 13B 16K",
        "base_model": "totally-not-an-llm/EverythingLM-13b-16k",
        "inference": false,
        "model_creator": "Kai Howard",
        "model_type": "llama",
        "prompt_template": "You are a helpful AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "everythinglm-13b-16k.Q2_K.gguf"
        },
        {
          "rfilename": "everythinglm-13b-16k.Q3_K_L.gguf"
        },
        {
          "rfilename": "everythinglm-13b-16k.Q3_K_M.gguf"
        },
        {
          "rfilename": "everythinglm-13b-16k.Q3_K_S.gguf"
        },
        {
          "rfilename": "everythinglm-13b-16k.Q4_0.gguf"
        },
        {
          "rfilename": "everythinglm-13b-16k.Q4_K_M.gguf"
        },
        {
          "rfilename": "everythinglm-13b-16k.Q4_K_S.gguf"
        },
        {
          "rfilename": "everythinglm-13b-16k.Q5_0.gguf"
        },
        {
          "rfilename": "everythinglm-13b-16k.Q5_K_M.gguf"
        },
        {
          "rfilename": "everythinglm-13b-16k.Q5_K_S.gguf"
        },
        {
          "rfilename": "everythinglm-13b-16k.Q6_K.gguf"
        },
        {
          "rfilename": "everythinglm-13b-16k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d72e1f3be3c57959c60f24",
      "id": "totally-not-an-llm/EverythingLM-13b-16k",
      "modelId": "totally-not-an-llm/EverythingLM-13b-16k",
      "author": "totally-not-an-llm",
      "sha": "64dd787711eb1b3cf312362ad4e4a290e16fb710",
      "lastModified": "2023-08-13T10:47:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:totally-not-an-llm/EverythingLM-data",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4475,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 32,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "totally-not-an-llm/EverythingLM-data"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6da21fd11bbe1a8d2488c",
    "id": "TheBloke/EverythingLM-13b-V2-16K-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:totally-not-an-llm/EverythingLM-data-V2",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/EverythingLM-13b-V2-16K-GGUF",
    "model": {
      "_id": "64f6da21fd11bbe1a8d2488c",
      "id": "TheBloke/EverythingLM-13b-V2-16K-GGUF",
      "modelId": "TheBloke/EverythingLM-13b-V2-16K-GGUF",
      "author": "TheBloke",
      "sha": "af116ab5e01346ed50a2e31f6269449154b2c9fb",
      "lastModified": "2023-09-27T12:47:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:totally-not-an-llm/EverythingLM-data-V2",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "totally-not-an-llm/EverythingLM-data-V2"
        ],
        "model_name": "EverythingLM 13B V2 16K",
        "base_model": "totally-not-an-llm/EverythingLM-13b-V2-16k",
        "inference": false,
        "model_creator": "Kai Howard",
        "model_type": "llama",
        "prompt_template": "You are a helpful AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "everythinglm-13b-v2-16k.Q2_K.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v2-16k.Q3_K_L.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v2-16k.Q3_K_M.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v2-16k.Q3_K_S.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v2-16k.Q4_0.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v2-16k.Q4_K_M.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v2-16k.Q4_K_S.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v2-16k.Q5_0.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v2-16k.Q5_K_M.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v2-16k.Q5_K_S.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v2-16k.Q6_K.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v2-16k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e3fe212fbff6ed9c12b7e3",
      "id": "totally-not-an-llm/EverythingLM-13b-V2-16k",
      "modelId": "totally-not-an-llm/EverythingLM-13b-V2-16k",
      "author": "totally-not-an-llm",
      "sha": "a125fe4de87afe86d65d195e268720294e390b60",
      "lastModified": "2023-08-22T14:55:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:totally-not-an-llm/EverythingLM-data-V2",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4471,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 31,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "totally-not-an-llm/EverythingLM-data-V2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6e2f1867bbeac42b31471",
    "id": "TheBloke/Redmond-Puffin-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 5,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "sft",
      "eng",
      "dataset:LDJnr/Puffin",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Redmond-Puffin-13B-GGUF",
    "model": {
      "_id": "64f6e2f1867bbeac42b31471",
      "id": "TheBloke/Redmond-Puffin-13B-GGUF",
      "modelId": "TheBloke/Redmond-Puffin-13B-GGUF",
      "author": "TheBloke",
      "sha": "ce2436da1ad04f82b383ff56e74e85c1725f8434",
      "lastModified": "2023-09-27T12:47:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "sft",
        "eng",
        "dataset:LDJnr/Puffin",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "eng"
        ],
        "license": [
          "mit"
        ],
        "tags": [
          "llama-2",
          "sft"
        ],
        "datasets": [
          "LDJnr/Puffin"
        ],
        "model_name": "Redmond Puffin 13B V1.3",
        "base_model": "NousResearch/Redmond-Puffin-13B",
        "inference": false,
        "model_creator": "NousResearch",
        "model_type": "llama",
        "prompt_template": "### human: {prompt}\n\n### response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "redmond-puffin-13b.Q2_K.gguf"
        },
        {
          "rfilename": "redmond-puffin-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "redmond-puffin-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "redmond-puffin-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "redmond-puffin-13b.Q4_0.gguf"
        },
        {
          "rfilename": "redmond-puffin-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "redmond-puffin-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "redmond-puffin-13b.Q5_0.gguf"
        },
        {
          "rfilename": "redmond-puffin-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "redmond-puffin-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "redmond-puffin-13b.Q6_K.gguf"
        },
        {
          "rfilename": "redmond-puffin-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64b7e06b2fbbea73ad991f61",
      "id": "NousResearch/Redmond-Puffin-13B",
      "modelId": "NousResearch/Redmond-Puffin-13B",
      "author": "NousResearch",
      "sha": "515e80f005c6376fcbe3f9d15e4e5dd158add436",
      "lastModified": "2023-09-25T02:53:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "sft",
        "eng",
        "dataset:LDJnr/Puffin",
        "license:mit",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4960,
      "library_name": "transformers",
      "likes": 104,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "eng"
        ],
        "tags": [
          "llama-2",
          "sft"
        ],
        "license": [
          "mit"
        ],
        "datasets": [
          "LDJnr/Puffin"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "joen97/NousResearch-Redmond-Puffin-13B",
        "qgibson123/NousResearch-Redmond-Puffin-13B",
        "shaxm/NousResearch-Redmond-Puffin-13B",
        "tonygoodsir/NousResearch-Redmond-Puffin-13B",
        "jusuuno/NousResearch-Redmond-Puffin-13B",
        "dsx09/NousResearch-Redmond-Puffin-13B",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "Vineil01/NousResearch-Redmond-Puffin-13B",
        "Vineil01/LIB01",
        "choco9966/LeaderboardTest",
        "ballefack/NousResearch-Redmond-Puffin-13B",
        "Slipknot2/jNousResearch-Redmond-Puffin-13B",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6eefbd63b958c5229df0d",
    "id": "TheBloke/ReMM-SLERP-L2-13B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/ReMM-SLERP-L2-13B-GGUF",
    "model": {
      "_id": "64f6eefbd63b958c5229df0d",
      "id": "TheBloke/ReMM-SLERP-L2-13B-GGUF",
      "modelId": "TheBloke/ReMM-SLERP-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "6d181c822d79a278d39d8bc4b29680d594b11370",
      "lastModified": "2023-09-27T12:47:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "model_name": "ReMM SLERP L2 13B",
        "base_model": "Undi95/ReMM-SLERP-L2-13B",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "remm-slerp-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "remm-slerp-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "remm-slerp-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "remm-slerp-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "remm-slerp-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "remm-slerp-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "remm-slerp-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "remm-slerp-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "remm-slerp-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "remm-slerp-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "remm-slerp-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "remm-slerp-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f615d6e87e6083cb39685c",
      "id": "Undi95/ReMM-SLERP-L2-13B",
      "modelId": "Undi95/ReMM-SLERP-L2-13B",
      "author": "Undi95",
      "sha": "a93f9e33323a448f4b910120abb335e3e6a68eab",
      "lastModified": "2023-09-09T21:12:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4808,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f6fae5b548e18c7f5d1492",
    "id": "TheBloke/WizardLM-13B-V1.2-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 20,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2304.12244",
      "arxiv:2306.08568",
      "arxiv:2308.09583",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-13B-V1.2-GGUF",
    "model": {
      "_id": "64f6fae5b548e18c7f5d1492",
      "id": "TheBloke/WizardLM-13B-V1.2-GGUF",
      "modelId": "TheBloke/WizardLM-13B-V1.2-GGUF",
      "author": "TheBloke",
      "sha": "679e00967f7b77afa912f4bd5f75da7b7a4ebbee",
      "lastModified": "2023-09-27T12:47:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 20,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "WizardLM 13B V1.2",
        "base_model": "WizardLM/WizardLM-13B-V1.2",
        "inference": false,
        "model_creator": "WizardLM",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "AFischer1985/wizardlm-13b-v1-2-q4-0-gguf",
        "irzbi/wizardlm-13b-v1-2-q4-0-gguf",
        "AFischer1985/wizardlm-13b-v1-2-q8-0-gguf",
        "librehash/wizardsc-13b-v12-q4-gguf"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardlm-13b-v1.2.Q2_K.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.2.Q4_0.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.2.Q5_0.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.2.Q6_K.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64bfd36087d8cb4bb370c962",
      "id": "WizardLM/WizardLM-13B-V1.2",
      "modelId": "WizardLM/WizardLM-13B-V1.2",
      "author": "WizardLM",
      "sha": "cf5f40382559f19e13874e45b39575171ca46ef8",
      "lastModified": "2023-09-09T06:45:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 20722,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 168,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "h2oai/h2ogpt-chatbot",
        "h2oai/h2ogpt-chatbot2",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "AFischer1985/wizardlm-13b-v1-2-q4-0-gguf",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheJoker2019/WizardLM-WizardLM-13B-V1.2",
        "AdiS/WizardLM-WizardLM-13B-V1.2",
        "saikrishnam/WizardLM-WizardLM-13B-V1.2",
        "pngwn/open_llm_leaderboard",
        "dickreuter/WizardLM-WizardLM-13B-V1.2",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "kelvin-t-lu/chatbot",
        "irzbi/wizardlm-13b-v1-2-q4-0-gguf",
        "AFischer1985/wizardlm-13b-v1-2-q8-0-gguf",
        "librehash/wizardsc-13b-v12-q4-gguf",
        "choco9966/open-ko-llm-leaderboard",
        "his0/h2ogpt-chatbot",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "zero_to_fp32.py"
        }
      ]
    }
  },
  {
    "_id": "64f6fdfd7c4552847fa47041",
    "id": "TheBloke/WizardMath-13B-V1.0-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 7,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2304.12244",
      "arxiv:2306.08568",
      "arxiv:2308.09583",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardMath-13B-V1.0-GGUF",
    "model": {
      "_id": "64f6fdfd7c4552847fa47041",
      "id": "TheBloke/WizardMath-13B-V1.0-GGUF",
      "modelId": "TheBloke/WizardMath-13B-V1.0-GGUF",
      "author": "TheBloke",
      "sha": "b540ce768736dd9d3b3daef0763dd3d420c49ed5",
      "lastModified": "2023-09-27T12:47:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7,
      "library_name": "transformers",
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "WizardMath 13B V1.0",
        "base_model": "WizardLM/WizardMath-13B-V1.0",
        "inference": false,
        "model_creator": "WizardLM",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n\n### Instruction:\n{prompt}\n\n\n### Response: Let's think step by step.\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardmath-13b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "wizardmath-13b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardmath-13b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardmath-13b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardmath-13b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "wizardmath-13b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardmath-13b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardmath-13b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "wizardmath-13b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardmath-13b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardmath-13b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "wizardmath-13b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d5b9f102e58cc1fddb89d2",
      "id": "WizardLM/WizardMath-13B-V1.0",
      "modelId": "WizardLM/WizardMath-13B-V1.0",
      "author": "WizardLM",
      "sha": "7ef412d2c680ef0fbdcd88d0df31b396d8d3049c",
      "lastModified": "2023-09-01T08:18:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5057,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 16,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "prnv19/WizardLM-WizardMath-13B-V1.0",
        "lzxing/WizardLM-WizardMath-13B-V1.0",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f700efe00083f5bd2689af",
    "id": "TheBloke/WizardMath-7B-V1.0-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2304.12244",
      "arxiv:2306.08568",
      "arxiv:2308.09583",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardMath-7B-V1.0-GGUF",
    "model": {
      "_id": "64f700efe00083f5bd2689af",
      "id": "TheBloke/WizardMath-7B-V1.0-GGUF",
      "modelId": "TheBloke/WizardMath-7B-V1.0-GGUF",
      "author": "TheBloke",
      "sha": "f29e48b6468f1f89ee9c6eb695f8cf11c861c34d",
      "lastModified": "2023-09-27T12:47:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "WizardMath 7B V1.0",
        "base_model": "WizardLM/WizardMath-7b-V1.0",
        "inference": false,
        "model_creator": "WizardLM",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n\n### Instruction:\n{prompt}\n\n\n### Response: Let's think step by step.\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardmath-7b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "wizardmath-7b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardmath-7b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardmath-7b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardmath-7b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "wizardmath-7b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardmath-7b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardmath-7b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "wizardmath-7b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardmath-7b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardmath-7b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "wizardmath-7b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d5b9dfc3d51f77fbdd3474",
      "id": "WizardLM/WizardMath-7B-V1.0",
      "modelId": "WizardLM/WizardMath-7B-V1.0",
      "author": "WizardLM",
      "sha": "825a586f260d6c583b8aa9ceab6cdfaa3d9a4ddc",
      "lastModified": "2023-09-01T08:18:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5195,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 35,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "ablamahfadi/test",
        "alexanlee/WizardLM-WizardMath-7B-V1.0",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f702ab96d7e4e68633cf4f",
    "id": "TheBloke/Firefly-Llama2-13B-v1.2-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 5,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Firefly-Llama2-13B-v1.2-GGUF",
    "model": {
      "_id": "64f702ab96d7e4e68633cf4f",
      "id": "TheBloke/Firefly-Llama2-13B-v1.2-GGUF",
      "modelId": "TheBloke/Firefly-Llama2-13B-v1.2-GGUF",
      "author": "TheBloke",
      "sha": "842b97f867e698176349d3a38fe0aff5f4dbbfb2",
      "lastModified": "2023-09-27T12:47:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Firefly Llama2 13B v1.2",
        "base_model": "YeungNLP/firefly-llama2-13b-v1.2",
        "inference": false,
        "model_creator": "YeungNLP",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "Cran-May/SEA-firefly"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "firefly-llama2-13b-v1.2.Q2_K.gguf"
        },
        {
          "rfilename": "firefly-llama2-13b-v1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "firefly-llama2-13b-v1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "firefly-llama2-13b-v1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "firefly-llama2-13b-v1.2.Q4_0.gguf"
        },
        {
          "rfilename": "firefly-llama2-13b-v1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "firefly-llama2-13b-v1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "firefly-llama2-13b-v1.2.Q5_0.gguf"
        },
        {
          "rfilename": "firefly-llama2-13b-v1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "firefly-llama2-13b-v1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "firefly-llama2-13b-v1.2.Q6_K.gguf"
        },
        {
          "rfilename": "firefly-llama2-13b-v1.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64cda666d8d092737275c5f9",
      "id": "YeungNLP/firefly-llama2-13b-v1.2",
      "modelId": "YeungNLP/firefly-llama2-13b-v1.2",
      "author": "YeungNLP",
      "sha": "97279d20a8c7e2d0576c9ff4b2e15a421c40d58a",
      "lastModified": "2023-08-05T01:50:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4535,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f702cb61afe1d3356318fa",
    "id": "TheBloke/OpenBuddy-Llama2-70b-v10.1-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "zh",
      "en",
      "fr",
      "de",
      "ja",
      "ko",
      "it",
      "ru",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/OpenBuddy-Llama2-70b-v10.1-GGUF",
    "model": {
      "_id": "64f702cb61afe1d3356318fa",
      "id": "TheBloke/OpenBuddy-Llama2-70b-v10.1-GGUF",
      "modelId": "TheBloke/OpenBuddy-Llama2-70b-v10.1-GGUF",
      "author": "TheBloke",
      "sha": "57371d8ef772ebe2f15a4671fb6ac9fa3ae98669",
      "lastModified": "2023-09-27T12:47:32.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "OpenBuddy Llama2 70b v10.1",
        "base_model": "OpenBuddy/openbuddy-llama2-70b-v10.1-bf16",
        "inference": false,
        "model_creator": "OpenBuddy",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "You are a helpful, respectful and honest INTP-T AI Assistant named Buddy. You are talking to a human User.\nAlways answer as helpfully and logically as possible, while being safe. Your answers should not include any harmful, political, religious, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\nYou like to use emojis. You can speak fluently in many languages, for example: English, Chinese.\nYou cannot access the internet, but you have vast knowledge, cutoff: 2021-09.\nYou are trained by OpenBuddy team, (https://openbuddy.ai, https://github.com/OpenBuddy/OpenBuddy), you are based on LLaMA and Falcon transformers model, not related to GPT or OpenAI.\n\nUser: {prompt}\nAssistant: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q2_K.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q4_0.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q5_0.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v10.1.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64e32ce2a88a63300b8f0789",
      "id": "OpenBuddy/openbuddy-llama2-70b-v10.1-bf16",
      "modelId": "OpenBuddy/openbuddy-llama2-70b-v10.1-bf16",
      "author": "OpenBuddy",
      "sha": "a6ee90d262ac729f90ed8de97127766df070074c",
      "lastModified": "2023-08-23T09:52:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4958,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 41,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7058dbedfdc197957e8c3",
    "id": "TheBloke/HermesLimaRP-L2-7B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/HermesLimaRP-L2-7B-GGUF",
    "model": {
      "_id": "64f7058dbedfdc197957e8c3",
      "id": "TheBloke/HermesLimaRP-L2-7B-GGUF",
      "modelId": "TheBloke/HermesLimaRP-L2-7B-GGUF",
      "author": "TheBloke",
      "sha": "cb95bac27722c79936a2f2738d974fe34237e1ec",
      "lastModified": "2023-09-27T12:47:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama-2"
        ],
        "model_name": "Hermes Lima RP L2 7B",
        "base_model": "zarakiquemparte/hermeslimarp-l2-7b",
        "inference": false,
        "model_creator": "Zaraki Quem Parte",
        "model_type": "llama",
        "prompt_template": "Since this is a merge between Nous Hermes and LimaRP, the\nfollowing instruction formats should work:\n\n\nAlpaca 2:\n\n\n```\n\n### Instruction:\n\n{prompt}\n\n\n### Response:\n\n<leave a newline blank for model to respond>\n\n```\n\nLimaRP instruction format:\n\n\n```\n\n<<SYSTEM>>\n\n<character card and system prompt>\n\n\n<<USER>>\n\n{prompt}\n\n\n<<AIBOT>>\n\n<leave a newline blank for model to respond>\n\n```\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "hermeslimarp-l2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "hermeslimarp-l2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "hermeslimarp-l2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "hermeslimarp-l2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "hermeslimarp-l2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "hermeslimarp-l2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "hermeslimarp-l2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "hermeslimarp-l2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "hermeslimarp-l2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "hermeslimarp-l2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "hermeslimarp-l2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "hermeslimarp-l2-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c269018e10666f81cfa993",
      "id": "zarakiquemparte/hermeslimarp-l2-7b",
      "modelId": "zarakiquemparte/hermeslimarp-l2-7b",
      "author": "zarakiquemparte",
      "sha": "a93801b4739511034f4e060dbf6870b2f19194d8",
      "lastModified": "2023-08-17T17:34:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f70719fcedae59eec31d7f",
    "id": "TheBloke/Zarablend-L2-7B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llama2",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Zarablend-L2-7B-GGUF",
    "model": {
      "_id": "64f70719fcedae59eec31d7f",
      "id": "TheBloke/Zarablend-L2-7B-GGUF",
      "modelId": "TheBloke/Zarablend-L2-7B-GGUF",
      "author": "TheBloke",
      "sha": "1e8a79ecd5d0a4060dcdd82efcc55aedfda10e7f",
      "lastModified": "2023-09-27T12:47:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama2",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama2"
        ],
        "model_name": "Zarablend L2 7B",
        "base_model": "zarakiquemparte/zarablend-l2-7b",
        "inference": false,
        "model_creator": "Zaraki Quem Parte",
        "model_type": "llama",
        "prompt_template": "### Instruction:\n\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "zarablend-l2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "zarablend-l2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "zarablend-l2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "zarablend-l2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "zarablend-l2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "zarablend-l2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "zarablend-l2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "zarablend-l2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "zarablend-l2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "zarablend-l2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "zarablend-l2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "zarablend-l2-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ddf654f96354a0d9d3a095",
      "id": "zarakiquemparte/zarablend-l2-7b",
      "modelId": "zarakiquemparte/zarablend-l2-7b",
      "author": "zarakiquemparte",
      "sha": "8b14e71ae3f52c409a25e1ac98dd05e0bb91eaff",
      "lastModified": "2023-08-17T18:48:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama2",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4436,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "zarablend-merge-illustration.png"
        }
      ]
    }
  },
  {
    "_id": "64f708aaceb68df8ee3457d7",
    "id": "TheBloke/Zarablend-MX-L2-7B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llama2",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Zarablend-MX-L2-7B-GGUF",
    "model": {
      "_id": "64f708aaceb68df8ee3457d7",
      "id": "TheBloke/Zarablend-MX-L2-7B-GGUF",
      "modelId": "TheBloke/Zarablend-MX-L2-7B-GGUF",
      "author": "TheBloke",
      "sha": "053da4d86034f0c89be4a44216397cf810fe5c26",
      "lastModified": "2023-09-27T12:47:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama2",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama2"
        ],
        "model_name": "Zarablend MX L2 7B",
        "base_model": "zarakiquemparte/zarablend-mx-l2-7b",
        "inference": false,
        "model_creator": "Zaraki Quem Parte",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "zarablend-mx-l2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "zarablend-mx-l2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "zarablend-mx-l2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "zarablend-mx-l2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "zarablend-mx-l2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "zarablend-mx-l2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "zarablend-mx-l2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "zarablend-mx-l2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "zarablend-mx-l2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "zarablend-mx-l2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "zarablend-mx-l2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "zarablend-mx-l2-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e38cca49f656276868740e",
      "id": "zarakiquemparte/zarablend-mx-l2-7b",
      "modelId": "zarakiquemparte/zarablend-mx-l2-7b",
      "author": "zarakiquemparte",
      "sha": "1982fd78a0057b68fc5647c44186bca6a17e146a",
      "lastModified": "2023-08-23T22:11:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama2",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "zarablend-mx-merge-illustration.png"
        }
      ]
    }
  },
  {
    "_id": "64f72243d17cc5f6c35ebf8f",
    "id": "TheBloke/orca_mini_v3_7B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 21,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:psmathur/orca_mini_v1_dataset",
      "dataset:ehartford/dolphin",
      "arxiv:2306.02707",
      "license:other",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/orca_mini_v3_7B-GGUF",
    "model": {
      "_id": "64f72243d17cc5f6c35ebf8f",
      "id": "TheBloke/orca_mini_v3_7B-GGUF",
      "modelId": "TheBloke/orca_mini_v3_7B-GGUF",
      "author": "TheBloke",
      "sha": "f3c55c908ac84e3627cb41aa4a448d7a9cb16021",
      "lastModified": "2023-09-27T12:47:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:psmathur/orca_mini_v1_dataset",
        "dataset:ehartford/dolphin",
        "arxiv:2306.02707",
        "license:other",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 21,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "library_name": "transformers",
        "datasets": [
          "psmathur/orca_mini_v1_dataset",
          "ehartford/dolphin"
        ],
        "model_name": "Orca Mini v3 7B",
        "base_model": "psmathur/orca_mini_v3_7b",
        "inference": false,
        "model_creator": "Pankaj Mathur",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### System:\nYou are an AI assistant that follows instruction extremely well. Help as much as you can.\n\n### User:\n{prompt}\n\n### Input:\n{input}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "limcheekin/orca_mini_v3_7B-GGUF"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "orca_mini_v3_7b.Q2_K.gguf"
        },
        {
          "rfilename": "orca_mini_v3_7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "orca_mini_v3_7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "orca_mini_v3_7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "orca_mini_v3_7b.Q4_0.gguf"
        },
        {
          "rfilename": "orca_mini_v3_7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "orca_mini_v3_7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "orca_mini_v3_7b.Q5_0.gguf"
        },
        {
          "rfilename": "orca_mini_v3_7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "orca_mini_v3_7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "orca_mini_v3_7b.Q6_K.gguf"
        },
        {
          "rfilename": "orca_mini_v3_7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d063c77a7305c58943e530",
      "id": "pankajmathur/orca_mini_v3_7b",
      "modelId": "pankajmathur/orca_mini_v3_7b",
      "author": "pankajmathur",
      "sha": "f9849ea6bf0f6ebb78dca1cea1c7a3ef8f7d715c",
      "lastModified": "2023-08-25T23:14:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:psmathur/orca_mini_v1_dataset",
        "dataset:ehartford/dolphin",
        "arxiv:2306.02707",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10752,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 37,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "other",
        "datasets": [
          "psmathur/orca_mini_v1_dataset",
          "ehartford/dolphin"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "orca_minis_small.jpeg"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f723f075f172b08db7b3af",
    "id": "TheBloke/Huginn-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Huginn-13B-GGUF",
    "model": {
      "_id": "64f723f075f172b08db7b3af",
      "id": "TheBloke/Huginn-13B-GGUF",
      "modelId": "TheBloke/Huginn-13B-GGUF",
      "author": "TheBloke",
      "sha": "5f24ac344fab8fc83c14bcb522f03dc962c91d8c",
      "lastModified": "2023-09-27T12:47:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Huginn 13B",
        "base_model": "The-Face-Of-Goonery/Huginn-13b-FP16",
        "inference": false,
        "model_creator": "Caleb Morgan",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "huggin-13b.Q2_K.gguf"
        },
        {
          "rfilename": "huggin-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "huggin-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "huggin-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "huggin-13b.Q4_0.gguf"
        },
        {
          "rfilename": "huggin-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "huggin-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "huggin-13b.Q5_0.gguf"
        },
        {
          "rfilename": "huggin-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "huggin-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "huggin-13b.Q6_K.gguf"
        },
        {
          "rfilename": "huggin-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ce87bb228324a28bad48ec",
      "id": "The-Face-Of-Goonery/Huginn-13b-FP16",
      "modelId": "The-Face-Of-Goonery/Huginn-13b-FP16",
      "author": "The-Face-Of-Goonery",
      "sha": "23d66016e2d0e87a2d27e2f372f47e25d8b62483",
      "lastModified": "2023-08-17T18:39:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4954,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {},
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f729f8365c61c6be7a9687",
    "id": "TheBloke/Huginn-v3-13B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Huginn-v3-13B-GGUF",
    "model": {
      "_id": "64f729f8365c61c6be7a9687",
      "id": "TheBloke/Huginn-v3-13B-GGUF",
      "modelId": "TheBloke/Huginn-v3-13B-GGUF",
      "author": "TheBloke",
      "sha": "c778c663b20476dc8e46daff7908c5aab82edb90",
      "lastModified": "2023-09-27T12:47:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Huginn v3 13B",
        "base_model": "The-Face-Of-Goonery/Huginn-v3-13b",
        "inference": false,
        "model_creator": "Caleb Morgan",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "huginn-v3-13b.Q2_K.gguf"
        },
        {
          "rfilename": "huginn-v3-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "huginn-v3-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "huginn-v3-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "huginn-v3-13b.Q4_0.gguf"
        },
        {
          "rfilename": "huginn-v3-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "huginn-v3-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "huginn-v3-13b.Q5_0.gguf"
        },
        {
          "rfilename": "huginn-v3-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "huginn-v3-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "huginn-v3-13b.Q6_K.gguf"
        },
        {
          "rfilename": "huginn-v3-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d7edc23be3c57959da2b3b",
      "id": "The-Face-Of-Goonery/Huginn-v3-13b",
      "modelId": "The-Face-Of-Goonery/Huginn-v3-13b",
      "author": "The-Face-Of-Goonery",
      "sha": "37b04ee9b2209af670d76801ab6a13f62814a7d4",
      "lastModified": "2023-08-17T18:39:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4626,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {},
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "RHOCHR/The-Face-Of-Goonery-Huginn-v3-13b",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f72cf761afe1d33568728f",
    "id": "TheBloke/Dolphin-Llama2-7B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/dolphin",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Dolphin-Llama2-7B-GGUF",
    "model": {
      "_id": "64f72cf761afe1d33568728f",
      "id": "TheBloke/Dolphin-Llama2-7B-GGUF",
      "modelId": "TheBloke/Dolphin-Llama2-7B-GGUF",
      "author": "TheBloke",
      "sha": "72c97f700ae0ddcbf43592759e39fd93f0716fcb",
      "lastModified": "2023-09-27T12:47:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/dolphin",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "ehartford/dolphin"
        ],
        "model_name": "Dolphin Llama2 7B",
        "base_model": "ehartford/dolphin-llama2-7b",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "SYSTEM: {system_message}\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "dolphin-llama2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "dolphin-llama2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "dolphin-llama2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "dolphin-llama2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "dolphin-llama2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "dolphin-llama2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "dolphin-llama2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "dolphin-llama2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "dolphin-llama2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "dolphin-llama2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "dolphin-llama2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "dolphin-llama2-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d02b9184f2058690dc798a",
      "id": "ehartford/dolphin-llama2-7b",
      "modelId": "ehartford/dolphin-llama2-7b",
      "author": "ehartford",
      "sha": "16d36cd396d7a9a1b4b886fcf57f673aca298702",
      "lastModified": "2023-08-10T05:42:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/dolphin",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4817,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 65,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "ehartford/dolphin"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "jmcreasman/ehartford-dolphin-llama2-7b",
        "kaze-no-katana/unsensored-AI",
        "RedBladeCA/ehartford-dolphin-llama2-7b",
        "Trending-Trader/ehartford-dolphin-llama2-7b",
        "TheVortexProject/open_llm_leaderboard",
        "kkroto/ehartford-dolphin-llama2-7b",
        "MacMane/ehartford-dolphin-llama2-7b",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f72fd0ceb68df8ee3a607c",
    "id": "TheBloke/orca_mini_v3_13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 10,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:psmathur/orca_mini_v1_dataset",
      "dataset:ehartford/dolphin",
      "arxiv:2306.02707",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/orca_mini_v3_13B-GGUF",
    "model": {
      "_id": "64f72fd0ceb68df8ee3a607c",
      "id": "TheBloke/orca_mini_v3_13B-GGUF",
      "modelId": "TheBloke/orca_mini_v3_13B-GGUF",
      "author": "TheBloke",
      "sha": "31f17684136bdc19feb263c308834f7380b79318",
      "lastModified": "2023-09-27T12:47:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:psmathur/orca_mini_v1_dataset",
        "dataset:ehartford/dolphin",
        "arxiv:2306.02707",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "library_name": "transformers",
        "datasets": [
          "psmathur/orca_mini_v1_dataset",
          "ehartford/dolphin"
        ],
        "model_name": "Orca Mini v3 13B",
        "base_model": "psmathur/orca_mini_v3_13b",
        "inference": false,
        "model_creator": "Pankaj Mathur",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### System:\nYou are an AI assistant that follows instruction extremely well. Help as much as you can.\n\n### User:\n{prompt}\n\n### Input:\n{input}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "orca_mini_v3_13b.Q2_K.gguf"
        },
        {
          "rfilename": "orca_mini_v3_13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "orca_mini_v3_13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "orca_mini_v3_13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "orca_mini_v3_13b.Q4_0.gguf"
        },
        {
          "rfilename": "orca_mini_v3_13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "orca_mini_v3_13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "orca_mini_v3_13b.Q5_0.gguf"
        },
        {
          "rfilename": "orca_mini_v3_13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "orca_mini_v3_13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "orca_mini_v3_13b.Q6_K.gguf"
        },
        {
          "rfilename": "orca_mini_v3_13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d30f9d5de0bc71ffa15d3f",
      "id": "pankajmathur/orca_mini_v3_13b",
      "modelId": "pankajmathur/orca_mini_v3_13b",
      "author": "pankajmathur",
      "sha": "72eec98f68d240a71d3da8a266917b6e754ae831",
      "lastModified": "2023-08-25T23:13:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:psmathur/orca_mini_v1_dataset",
        "dataset:ehartford/dolphin",
        "arxiv:2306.02707",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10143,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 27,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "other",
        "datasets": [
          "psmathur/orca_mini_v1_dataset",
          "ehartford/dolphin"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "orca_minis_small.jpeg"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f732efe00083f5bd2ce2a3",
    "id": "TheBloke/Chronos-Beluga-v2-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Chronos-Beluga-v2-13B-GGUF",
    "model": {
      "_id": "64f732efe00083f5bd2ce2a3",
      "id": "TheBloke/Chronos-Beluga-v2-13B-GGUF",
      "modelId": "TheBloke/Chronos-Beluga-v2-13B-GGUF",
      "author": "TheBloke",
      "sha": "7a66d5b4666dca4305c23de7c5bbafdeacff5119",
      "lastModified": "2023-09-27T12:47:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Chronos Beluga v2 13B",
        "base_model": "The-Face-Of-Goonery/Chronos-Beluga-v2-13bfp16",
        "inference": false,
        "model_creator": "Caleb Morgan",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chronos-beluga-v2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "chronos-beluga-v2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronos-beluga-v2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronos-beluga-v2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronos-beluga-v2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "chronos-beluga-v2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronos-beluga-v2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronos-beluga-v2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "chronos-beluga-v2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronos-beluga-v2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronos-beluga-v2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "chronos-beluga-v2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64cc07de54348e678d52b833",
      "id": "The-Face-Of-Goonery/Chronos-Beluga-v2-13bfp16",
      "modelId": "The-Face-Of-Goonery/Chronos-Beluga-v2-13bfp16",
      "author": "The-Face-Of-Goonery",
      "sha": "6d50e6681bc26c9bc0c8377c26c438e295ee0c2f",
      "lastModified": "2023-08-08T15:25:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4602,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f73805ceb68df8ee3baf53",
    "id": "TheBloke/13B-Legerdemain-L2-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/13B-Legerdemain-L2-GGUF",
    "model": {
      "_id": "64f73805ceb68df8ee3baf53",
      "id": "TheBloke/13B-Legerdemain-L2-GGUF",
      "modelId": "TheBloke/13B-Legerdemain-L2-GGUF",
      "author": "TheBloke",
      "sha": "f77ae044ebc6de59c4967cba02a224ff3b9afa0c",
      "lastModified": "2023-09-27T12:47:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "13B Legerdemain L2",
        "base_model": "CalderaAI/13B-Legerdemain-L2",
        "inference": false,
        "model_creator": "CalderaAI",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "13b-legerdemain-l2.Q2_K.gguf"
        },
        {
          "rfilename": "13b-legerdemain-l2.Q3_K_L.gguf"
        },
        {
          "rfilename": "13b-legerdemain-l2.Q3_K_M.gguf"
        },
        {
          "rfilename": "13b-legerdemain-l2.Q3_K_S.gguf"
        },
        {
          "rfilename": "13b-legerdemain-l2.Q4_0.gguf"
        },
        {
          "rfilename": "13b-legerdemain-l2.Q4_K_M.gguf"
        },
        {
          "rfilename": "13b-legerdemain-l2.Q4_K_S.gguf"
        },
        {
          "rfilename": "13b-legerdemain-l2.Q5_0.gguf"
        },
        {
          "rfilename": "13b-legerdemain-l2.Q5_K_M.gguf"
        },
        {
          "rfilename": "13b-legerdemain-l2.Q5_K_S.gguf"
        },
        {
          "rfilename": "13b-legerdemain-l2.Q6_K.gguf"
        },
        {
          "rfilename": "13b-legerdemain-l2.Q8_0.gguf"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64cb92059e30a46f7b95a2e2",
      "id": "CalderaAI/13B-Legerdemain-L2",
      "modelId": "CalderaAI/13B-Legerdemain-L2",
      "author": "CalderaAI",
      "sha": "d6624ce1bcc6b50c86b86e879a8c9822218b84d2",
      "lastModified": "2023-08-04T10:47:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4820,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "4bit-128g.safetensors"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f73e14fec395872ffecb01",
    "id": "TheBloke/qCammel-13-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "pytorch",
      "llama-2",
      "qCammel-13",
      "text-generation",
      "en",
      "arxiv:2305.12031",
      "arxiv:2305.14314",
      "arxiv:2302.13971",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/qCammel-13-GGUF",
    "model": {
      "_id": "64f73e14fec395872ffecb01",
      "id": "TheBloke/qCammel-13-GGUF",
      "modelId": "TheBloke/qCammel-13-GGUF",
      "author": "TheBloke",
      "sha": "88c9850683558599cd55458540b788df5cd3b0a0",
      "lastModified": "2023-09-27T12:47:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "pytorch",
        "llama-2",
        "qCammel-13",
        "text-generation",
        "en",
        "arxiv:2305.12031",
        "arxiv:2305.14314",
        "arxiv:2302.13971",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "library_name": "transformers",
        "tags": [
          "pytorch",
          "llama",
          "llama-2",
          "qCammel-13"
        ],
        "model_name": "qCammel 13",
        "base_model": "augtoma/qCammel-13",
        "inference": false,
        "model_creator": "augtoma",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "qcammel-13.Q2_K.gguf"
        },
        {
          "rfilename": "qcammel-13.Q3_K_L.gguf"
        },
        {
          "rfilename": "qcammel-13.Q3_K_M.gguf"
        },
        {
          "rfilename": "qcammel-13.Q3_K_S.gguf"
        },
        {
          "rfilename": "qcammel-13.Q4_0.gguf"
        },
        {
          "rfilename": "qcammel-13.Q4_K_M.gguf"
        },
        {
          "rfilename": "qcammel-13.Q4_K_S.gguf"
        },
        {
          "rfilename": "qcammel-13.Q5_0.gguf"
        },
        {
          "rfilename": "qcammel-13.Q5_K_M.gguf"
        },
        {
          "rfilename": "qcammel-13.Q5_K_S.gguf"
        },
        {
          "rfilename": "qcammel-13.Q6_K.gguf"
        },
        {
          "rfilename": "qcammel-13.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64beaea5c733e8552ffc07cb",
      "id": "augtoma/qCammel-13",
      "modelId": "augtoma/qCammel-13",
      "author": "augtoma",
      "sha": "af473e64f6a4fa02a7e24ee7679eea9505eb179d",
      "lastModified": "2023-07-24T17:39:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "qCammel-13",
        "en",
        "arxiv:2305.12031",
        "arxiv:2305.14314",
        "arxiv:2302.13971",
        "license:other",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4547,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "tags": [
          "pytorch",
          "llama",
          "llama-2",
          "qCammel-13"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f73f2dffa10f8ce3add3dc",
    "id": "TheBloke/huginnv1.2-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/huginnv1.2-GGUF",
    "model": {
      "_id": "64f73f2dffa10f8ce3add3dc",
      "id": "TheBloke/huginnv1.2-GGUF",
      "modelId": "TheBloke/huginnv1.2-GGUF",
      "author": "TheBloke",
      "sha": "83c47b5c9dbc0e67dfe328323cb6c6ea74f13aed",
      "lastModified": "2023-09-27T12:47:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Huginn v1.2",
        "base_model": "The-Face-Of-Goonery/huginnv1.2",
        "inference": false,
        "model_creator": "Caleb Morgan",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "huginnv1.2.Q2_K.gguf"
        },
        {
          "rfilename": "huginnv1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "huginnv1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "huginnv1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "huginnv1.2.Q4_0.gguf"
        },
        {
          "rfilename": "huginnv1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "huginnv1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "huginnv1.2.Q5_0.gguf"
        },
        {
          "rfilename": "huginnv1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "huginnv1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "huginnv1.2.Q6_K.gguf"
        },
        {
          "rfilename": "huginnv1.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d2a613b8fd080cbeb08000",
      "id": "The-Face-Of-Goonery/Huginn-13b-v1.2",
      "modelId": "The-Face-Of-Goonery/Huginn-13b-v1.2",
      "author": "The-Face-Of-Goonery",
      "sha": "cb3562e7aae05a95fe61610b7b8f4957d3529ce7",
      "lastModified": "2023-08-17T18:40:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 23160,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {},
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7413ab7c50aef8391f646",
    "id": "TheBloke/Hermes-LLongMA-2-13B-8K-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Hermes-LLongMA-2-13B-8K-GGUF",
    "model": {
      "_id": "64f7413ab7c50aef8391f646",
      "id": "TheBloke/Hermes-LLongMA-2-13B-8K-GGUF",
      "modelId": "TheBloke/Hermes-LLongMA-2-13B-8K-GGUF",
      "author": "TheBloke",
      "sha": "5d77ffdb080795f068e25cd04146f8fdcde1c67e",
      "lastModified": "2023-09-27T12:47:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Hermes LLongMA 2 13B 8K",
        "base_model": "conceptofmind/Hermes-LLongMA-2-13b-8k",
        "inference": false,
        "model_creator": "conceptofmind",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "hermes-llongma-2-13b-8k.Q2_K.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-13b-8k.Q3_K_L.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-13b-8k.Q3_K_M.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-13b-8k.Q3_K_S.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-13b-8k.Q4_0.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-13b-8k.Q4_K_M.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-13b-8k.Q4_K_S.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-13b-8k.Q5_0.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-13b-8k.Q5_K_M.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-13b-8k.Q5_K_S.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-13b-8k.Q6_K.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-13b-8k.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "64f7451182673b2a07ae1103",
    "id": "TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-GGUF",
    "likes": 36,
    "private": false,
    "downloads": 62,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-GGUF",
    "model": {
      "_id": "64f7451182673b2a07ae1103",
      "id": "TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-GGUF",
      "modelId": "TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-GGUF",
      "author": "TheBloke",
      "sha": "e310166cc2d2f11d88e5e55ccc0e1db639333cd5",
      "lastModified": "2023-09-27T12:47:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 62,
      "library_name": "transformers",
      "likes": 36,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split"
        ],
        "model_name": "WizardLM 1.0 Uncensored Llama2 13B",
        "base_model": "ehartford/WizardLM-1.0-Uncensored-Llama2-13b",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "You are a helpful AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "imperialwool/llama-cpp-api"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-llama2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-llama2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-llama2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-llama2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-llama2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-llama2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-llama2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-llama2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-llama2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-llama2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-llama2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-llama2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64cf2e9e228324a28bbf0052",
      "id": "ehartford/WizardLM-1.0-Uncensored-Llama2-13b",
      "modelId": "ehartford/WizardLM-1.0-Uncensored-Llama2-13b",
      "author": "ehartford",
      "sha": "134cea14627fd875f6f277cad92f988024855478",
      "lastModified": "2023-08-06T06:05:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5303,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 38,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Cupcakus/ehartford-WizardLM-1.0-Uncensored-Llama2-13b",
        "ktong14884/ehartford-WizardLM-1.0-Uncensored-Llama2-13b",
        "Cyanex/ehartford-WizardLM-1.0-Uncensored-Llama2-13b",
        "asif4318/ehartford-WizardLM-1.0-Uncensored-Llama2-13b",
        "TheVortexProject/open_llm_leaderboard",
        "Bradjan310/ehartford-WizardLM-1.0-Uncensored-Llama2-13b",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7474fd41df1f43a507c0c",
    "id": "TheBloke/LLongMA-2-7B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2108.12409",
      "arxiv:2212.10554",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/LLongMA-2-7B-GGUF",
    "model": {
      "_id": "64f7474fd41df1f43a507c0c",
      "id": "TheBloke/LLongMA-2-7B-GGUF",
      "modelId": "TheBloke/LLongMA-2-7B-GGUF",
      "author": "TheBloke",
      "sha": "ce138fb89b1aeda2762584232201a7a4eb0850cc",
      "lastModified": "2023-09-27T12:47:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2108.12409",
        "arxiv:2212.10554",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "LLongMA 2 7B",
        "base_model": "conceptofmind/LLongMA-2-7b",
        "inference": false,
        "model_creator": "Enrico Shippole",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llongma-2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "llongma-2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llongma-2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llongma-2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llongma-2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "llongma-2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llongma-2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llongma-2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "llongma-2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llongma-2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llongma-2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "llongma-2-7b.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "64f749997565a69eb67eeba7",
    "id": "TheBloke/Carl-Llama-2-13B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:jerryjalapeno/nart-100k-synthetic",
      "license:cc-by-nc-nd-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Carl-Llama-2-13B-GGUF",
    "model": {
      "_id": "64f749997565a69eb67eeba7",
      "id": "TheBloke/Carl-Llama-2-13B-GGUF",
      "modelId": "TheBloke/Carl-Llama-2-13B-GGUF",
      "author": "TheBloke",
      "sha": "bb9143294f6f385c3857fe4bedf711dfaeb06a50",
      "lastModified": "2023-09-27T12:47:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:jerryjalapeno/nart-100k-synthetic",
        "license:cc-by-nc-nd-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-nd-4.0",
        "datasets": [
          "jerryjalapeno/nart-100k-synthetic"
        ],
        "model_name": "Carl Llama 2",
        "base_model": "ajibawa-2023/carl-llama-2-13b",
        "inference": false,
        "model_creator": "Feynman Innovations",
        "model_type": "llama",
        "prompt_template": "This is a conversation with your Therapist AI, Carl. Carl is designed to help you while in stress. It can answer your questions and help you to calm down\n\nContext\nYou are Carl, A Therapist AI\nUSER: {prompt}\nCARL:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "carl-llama-2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "carl-llama-2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "carl-llama-2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "carl-llama-2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "carl-llama-2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "carl-llama-2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "carl-llama-2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "carl-llama-2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "carl-llama-2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "carl-llama-2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "carl-llama-2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "carl-llama-2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64d9fcdd5a0d3c3c343dcbcf",
      "id": "ajibawa-2023/carl-llama-2-13b",
      "modelId": "ajibawa-2023/carl-llama-2-13b",
      "author": "ajibawa-2023",
      "sha": "d497f6a70c8109a43a625db9caaaa75491e04a52",
      "lastModified": "2023-08-16T20:16:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:jerryjalapeno/nart-100k-synthetic",
        "license:cc-by-nc-nd-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-nd-4.0",
        "datasets": [
          "jerryjalapeno/nart-100k-synthetic"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "tomasmcm/Carl-13B-GGML",
        "Reza2kn/ajibawa-2023-carl-llama-2-13b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_F16.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q2_K.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q3_K_L.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q3_K_M.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q3_K_S.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q4_0.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q4_1.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q4_K_M.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q4_K_S.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q5_0.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q5_1.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q5_K_M.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q5_K_S.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q6_K.bin"
        },
        {
          "rfilename": "Carl_L2_13B_GGML_Q8_0.bin"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model.bin-aa"
        },
        {
          "rfilename": "pytorch_model.bin-ab"
        },
        {
          "rfilename": "pytorch_model.bin-ac"
        },
        {
          "rfilename": "pytorch_model.bin-ad"
        },
        {
          "rfilename": "pytorch_model.bin-ae"
        },
        {
          "rfilename": "pytorch_model.bin-af"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "64f74a56c96939d7501428c6",
    "id": "TheBloke/CodeUp-Llama-2-13B-Chat-HF-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 29,
    "tags": [
      "transformers",
      "llama",
      "text-to-code",
      "multilingual-code-generation",
      "en",
      "arxiv:2106.09685",
      "license:openrail++",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/CodeUp-Llama-2-13B-Chat-HF-GGUF",
    "model": {
      "_id": "64f74a56c96939d7501428c6",
      "id": "TheBloke/CodeUp-Llama-2-13B-Chat-HF-GGUF",
      "modelId": "TheBloke/CodeUp-Llama-2-13B-Chat-HF-GGUF",
      "author": "TheBloke",
      "sha": "83ed6f45539e7b54d331cc8f43feb92c09128ad0",
      "lastModified": "2023-09-27T12:47:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "text-to-code",
        "multilingual-code-generation",
        "en",
        "arxiv:2106.09685",
        "license:openrail++",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 29,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "openrail++",
        "tags": [
          "text-to-code",
          "multilingual-code-generation"
        ],
        "model_name": "CodeUp Llama 2 13B Chat HF",
        "base_model": "deepse/CodeUp-Llama-2-13b-chat-hf",
        "inference": false,
        "model_creator": "DeepSE",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codeup-llama-2-13b-chat-hf.Q2_K.gguf"
        },
        {
          "rfilename": "codeup-llama-2-13b-chat-hf.Q3_K_L.gguf"
        },
        {
          "rfilename": "codeup-llama-2-13b-chat-hf.Q3_K_M.gguf"
        },
        {
          "rfilename": "codeup-llama-2-13b-chat-hf.Q3_K_S.gguf"
        },
        {
          "rfilename": "codeup-llama-2-13b-chat-hf.Q4_0.gguf"
        },
        {
          "rfilename": "codeup-llama-2-13b-chat-hf.Q4_K_M.gguf"
        },
        {
          "rfilename": "codeup-llama-2-13b-chat-hf.Q4_K_S.gguf"
        },
        {
          "rfilename": "codeup-llama-2-13b-chat-hf.Q5_0.gguf"
        },
        {
          "rfilename": "codeup-llama-2-13b-chat-hf.Q5_K_M.gguf"
        },
        {
          "rfilename": "codeup-llama-2-13b-chat-hf.Q5_K_S.gguf"
        },
        {
          "rfilename": "codeup-llama-2-13b-chat-hf.Q6_K.gguf"
        },
        {
          "rfilename": "codeup-llama-2-13b-chat-hf.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64c89bd3b8685df80035ffdd",
      "id": "deepse/CodeUp-Llama-2-13b-chat-hf",
      "modelId": "deepse/CodeUp-Llama-2-13b-chat-hf",
      "author": "deepse",
      "sha": "a578f82a508b82c608de18c3961b37fc6ce865a7",
      "lastModified": "2023-10-06T06:59:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "text-to-code",
        "multilingual-code-generation",
        "en",
        "arxiv:2106.09685",
        "license:openrail++",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4554,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 28,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "openrail++",
        "language": [
          "en"
        ],
        "tags": [
          "text-to-code",
          "multilingual-code-generation"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "paranjay-bd/DCUL-2-13b-chat-hf",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "assets/Framework.jpg"
        },
        {
          "rfilename": "assets/Logo.jpg"
        },
        {
          "rfilename": "assets/PL_Clean.png"
        },
        {
          "rfilename": "assets/PL_Filter.jpg"
        },
        {
          "rfilename": "assets/PL_Raw.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f74b3fa5a0e8446baf4199",
    "id": "TheBloke/chronos-13b-v2-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "pytorch",
      "chatbot",
      "storywriting",
      "generalist-model",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/chronos-13b-v2-GGUF",
    "model": {
      "_id": "64f74b3fa5a0e8446baf4199",
      "id": "TheBloke/chronos-13b-v2-GGUF",
      "modelId": "TheBloke/chronos-13b-v2-GGUF",
      "author": "TheBloke",
      "sha": "ee7c39ffaeca82ebb0cbb4bbfeb7d2eacdb7c69f",
      "lastModified": "2023-09-27T13:02:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "pytorch",
        "chatbot",
        "storywriting",
        "generalist-model",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "llama",
          "pytorch",
          "chatbot",
          "storywriting",
          "generalist-model"
        ],
        "model_name": "Chronos 13B v2",
        "inference": false,
        "model_creator": "elinas",
        "model_link": "https://huggingface.co/elinas/chronos-13b-v2",
        "model_type": "llama",
        "quantized_by": "TheBloke",
        "base_model": "elinas/chronos-13b-v2"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chronos-13b-v2.Q2_K.gguf"
        },
        {
          "rfilename": "chronos-13b-v2.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronos-13b-v2.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronos-13b-v2.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronos-13b-v2.Q4_0.gguf"
        },
        {
          "rfilename": "chronos-13b-v2.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronos-13b-v2.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronos-13b-v2.Q5_0.gguf"
        },
        {
          "rfilename": "chronos-13b-v2.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronos-13b-v2.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronos-13b-v2.Q6_K.gguf"
        },
        {
          "rfilename": "chronos-13b-v2.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64ca9d0f8174e45ae03a073a",
      "id": "elinas/chronos-13b-v2",
      "modelId": "elinas/chronos-13b-v2",
      "author": "elinas",
      "sha": "be5f6573c4f6321b6ee8ade3298598cf7161f65f",
      "lastModified": "2023-10-10T20:36:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "chatbot",
        "storywriting",
        "generalist-model",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 18401,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 18,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "llama",
          "pytorch",
          "chatbot",
          "storywriting",
          "generalist-model"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        }
      ]
    }
  },
  {
    "_id": "64f753acb2d67ae715da263e",
    "id": "TheBloke/Llama-2-13B-German-Assistant-v4-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 12,
    "tags": [
      "transformers",
      "llama",
      "en",
      "de",
      "dataset:flozi00/conversations",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama-2-13B-German-Assistant-v4-GGUF",
    "model": {
      "_id": "64f753acb2d67ae715da263e",
      "id": "TheBloke/Llama-2-13B-German-Assistant-v4-GGUF",
      "modelId": "TheBloke/Llama-2-13B-German-Assistant-v4-GGUF",
      "author": "TheBloke",
      "sha": "d22b23f2c12761600117f8a1bb5d37ad95c56625",
      "lastModified": "2023-09-27T12:47:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "de",
        "dataset:flozi00/conversations",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 12,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en",
          "de"
        ],
        "license": "llama2",
        "datasets": [
          "flozi00/conversations"
        ],
        "model_name": "Llama 2 13B German Assistant v4",
        "base_model": "flozi00/Llama-2-13b-german-assistant-v4",
        "inference": false,
        "model_creator": "Florian Zimmermeister",
        "model_type": "llama",
        "prompt_template": "### User: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v4.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v4.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v4.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v4.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v4.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v4.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v4.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v4.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v4.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v4.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v4.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v4.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ca9efb38837b12d5f80d0a",
      "id": "flozi00/Llama-2-13b-german-assistant-v4",
      "modelId": "flozi00/Llama-2-13b-german-assistant-v4",
      "author": "flozi00",
      "sha": "776eed3283210a2bd1dcaf2265d17d767f6ef4a3",
      "lastModified": "2023-08-16T07:11:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "en",
        "de",
        "dataset:flozi00/conversations",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "flozi00/conversations"
        ],
        "language": [
          "en",
          "de"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13073538560
        },
        "total": 13073538560
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f753c533475a59d7ab9983",
    "id": "TheBloke/qCammel-70-x-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "pytorch",
      "llama-2",
      "qCammel-70",
      "text-generation",
      "en",
      "arxiv:2305.12031",
      "arxiv:2305.14314",
      "arxiv:2302.70971",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/qCammel-70-x-GGUF",
    "model": {
      "_id": "64f753c533475a59d7ab9983",
      "id": "TheBloke/qCammel-70-x-GGUF",
      "modelId": "TheBloke/qCammel-70-x-GGUF",
      "author": "TheBloke",
      "sha": "6257821806ea4d86edf26d5c882c1d7662237ab6",
      "lastModified": "2023-09-27T12:47:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "pytorch",
        "llama-2",
        "qCammel-70",
        "text-generation",
        "en",
        "arxiv:2305.12031",
        "arxiv:2305.14314",
        "arxiv:2302.70971",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "library_name": "transformers",
        "tags": [
          "pytorch",
          "llama",
          "llama-2",
          "qCammel-70"
        ],
        "model_name": "qCammel 70",
        "base_model": "augtoma/qCammel-70-x",
        "inference": false,
        "model_creator": "augtoma",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "qcammel-70-x.Q2_K.gguf"
        },
        {
          "rfilename": "qcammel-70-x.Q3_K_L.gguf"
        },
        {
          "rfilename": "qcammel-70-x.Q3_K_M.gguf"
        },
        {
          "rfilename": "qcammel-70-x.Q3_K_S.gguf"
        },
        {
          "rfilename": "qcammel-70-x.Q4_0.gguf"
        },
        {
          "rfilename": "qcammel-70-x.Q4_K_M.gguf"
        },
        {
          "rfilename": "qcammel-70-x.Q4_K_S.gguf"
        },
        {
          "rfilename": "qcammel-70-x.Q5_0.gguf"
        },
        {
          "rfilename": "qcammel-70-x.Q5_K_M.gguf"
        },
        {
          "rfilename": "qcammel-70-x.Q5_K_S.gguf"
        },
        {
          "rfilename": "qcammel-70-x.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "qcammel-70-x.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "qcammel-70-x.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "qcammel-70-x.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64bc76c6d05a97d72290e63c",
      "id": "augtoma/qCammel-70-x",
      "modelId": "augtoma/qCammel-70-x",
      "author": "augtoma",
      "sha": "cf1e917e42fd1e56ee1edef7ee1a98cbe705c18c",
      "lastModified": "2023-07-27T16:47:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "qCammel-70",
        "en",
        "arxiv:2305.12031",
        "arxiv:2305.14314",
        "arxiv:2302.70971",
        "license:other",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 22939,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 20,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "tags": [
          "pytorch",
          "llama",
          "llama-2",
          "qCammel-70"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f756b9a92703ef65c0cbff",
    "id": "TheBloke/Spring-Dragon-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Spring-Dragon-GGUF",
    "model": {
      "_id": "64f756b9a92703ef65c0cbff",
      "id": "TheBloke/Spring-Dragon-GGUF",
      "modelId": "TheBloke/Spring-Dragon-GGUF",
      "author": "TheBloke",
      "sha": "db249d5c259b696ecc71acfada36315d831613e9",
      "lastModified": "2023-09-27T12:47:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Spring Dragon",
        "base_model": "Henk717/spring-dragon",
        "inference": false,
        "model_creator": "Henky!!",
        "model_type": "llama",
        "prompt_template": "Info on prompt template will be added shortly.\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "spring-dragon.Q2_K.gguf"
        },
        {
          "rfilename": "spring-dragon.Q3_K_L.gguf"
        },
        {
          "rfilename": "spring-dragon.Q3_K_M.gguf"
        },
        {
          "rfilename": "spring-dragon.Q3_K_S.gguf"
        },
        {
          "rfilename": "spring-dragon.Q4_0.gguf"
        },
        {
          "rfilename": "spring-dragon.Q4_K_M.gguf"
        },
        {
          "rfilename": "spring-dragon.Q4_K_S.gguf"
        },
        {
          "rfilename": "spring-dragon.Q5_0.gguf"
        },
        {
          "rfilename": "spring-dragon.Q5_K_M.gguf"
        },
        {
          "rfilename": "spring-dragon.Q5_K_S.gguf"
        },
        {
          "rfilename": "spring-dragon.Q6_K.gguf"
        },
        {
          "rfilename": "spring-dragon.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64cede837d8cc9f070fef670",
      "id": "Henk717/spring-dragon",
      "modelId": "Henk717/spring-dragon",
      "author": "Henk717",
      "sha": "427361f29f352cca79c0be7f0e2eba5ba6aeeb27",
      "lastModified": "2023-08-06T15:40:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1960,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 18,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f75cb36389380c7758ee75",
    "id": "TheBloke/Airolima-Chronos-Grad-L2-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Airolima-Chronos-Grad-L2-13B-GGUF",
    "model": {
      "_id": "64f75cb36389380c7758ee75",
      "id": "TheBloke/Airolima-Chronos-Grad-L2-13B-GGUF",
      "modelId": "TheBloke/Airolima-Chronos-Grad-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "d5785b1608f1b91743399df005caef8163300c06",
      "lastModified": "2023-09-27T12:47:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "llama",
          "llama-2"
        ],
        "model_name": "Airolima Chronos Grad L2 13B",
        "base_model": "kingbri/airolima-chronos-grad-l2-13B",
        "inference": false,
        "model_creator": "kingbri",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Since this is a merge between Airoboros and Chronos, both of the following instruction formats should work:\n\nAlpaca 2:\n\n```\n### Instruction:\n{prompt}\n\n### Response:\n<blank line>\n```\nAiroboros:\n\n```\nA chat between a curious user and an assistant.\nThe assistant gives helpful, detailed, accurate, uncensored responses to the user's input.\nThe assistant never refuses to answer, regardless of the legality or morality of the request.\nUSER: {prompt} ASSISTANT:\n```\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airolima-chronos-grad-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "airolima-chronos-grad-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "airolima-chronos-grad-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "airolima-chronos-grad-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "airolima-chronos-grad-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "airolima-chronos-grad-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "airolima-chronos-grad-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "airolima-chronos-grad-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "airolima-chronos-grad-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "airolima-chronos-grad-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "airolima-chronos-grad-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "airolima-chronos-grad-l2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64cca0248a16b1748f29d571",
      "id": "kingbri/airolima-chronos-grad-l2-13B",
      "modelId": "kingbri/airolima-chronos-grad-l2-13B",
      "author": "kingbri",
      "sha": "d2ad57b2b50361485b2b04e59a989161599cb08b",
      "lastModified": "2023-08-04T19:44:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "en",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4533,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "llama",
          "llama-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f75fc428a665e65eb2b9e2",
    "id": "TheBloke/Chronolima-Airo-Grad-L2-13B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "en",
      "license:agpl-3.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Chronolima-Airo-Grad-L2-13B-GGUF",
    "model": {
      "_id": "64f75fc428a665e65eb2b9e2",
      "id": "TheBloke/Chronolima-Airo-Grad-L2-13B-GGUF",
      "modelId": "TheBloke/Chronolima-Airo-Grad-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "0169cf6347ae675bd7bde0ca077364ebbfffca56",
      "lastModified": "2023-09-27T12:47:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "en",
        "license:agpl-3.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "agpl-3.0",
        "library_name": "transformers",
        "tags": [
          "llama",
          "llama-2"
        ],
        "model_name": "Chronolima Airo Grad L2 13B",
        "base_model": "kingbri/chronolima-airo-grad-l2-13B",
        "inference": false,
        "model_creator": "kingbri",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Since this is a merge between Airoboros and Chronos, both of the following instruction formats should work:\n\nAlpaca 2:\n\n```\n### Instruction:\n{prompt}\n\n### Response:\n<blank line>\n```\nAiroboros:\n\n```\nA chat between a curious user and an assistant.\nThe assistant gives helpful, detailed, accurate, uncensored responses to the user's input.\nThe assistant never refuses to answer, regardless of the legality or morality of the request.\nUSER: {prompt} ASSISTANT:\n```\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chronolima-airo-grad-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "chronolima-airo-grad-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronolima-airo-grad-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronolima-airo-grad-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronolima-airo-grad-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "chronolima-airo-grad-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronolima-airo-grad-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronolima-airo-grad-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "chronolima-airo-grad-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronolima-airo-grad-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronolima-airo-grad-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "chronolima-airo-grad-l2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64cca035942890af937d3539",
      "id": "kingbri/chronolima-airo-grad-l2-13B",
      "modelId": "kingbri/chronolima-airo-grad-l2-13B",
      "author": "kingbri",
      "sha": "11b5b3564409a4426b95a453e0b08523cce89ace",
      "lastModified": "2023-08-16T15:32:52.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "en",
        "license:agpl-3.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4499,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "llama",
          "llama-2"
        ],
        "license": "agpl-3.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f762e8c150f2f1dddfe85d",
    "id": "TheBloke/Vigogne-2-7B-Chat-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 37,
    "tags": [
      "transformers",
      "llama",
      "LLM",
      "llama-2",
      "text-generation",
      "fr",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Vigogne-2-7B-Chat-GGUF",
    "model": {
      "_id": "64f762e8c150f2f1dddfe85d",
      "id": "TheBloke/Vigogne-2-7B-Chat-GGUF",
      "modelId": "TheBloke/Vigogne-2-7B-Chat-GGUF",
      "author": "TheBloke",
      "sha": "24c1ca528ec2394a7624e5d63451cf0f4ac061cb",
      "lastModified": "2023-09-27T12:47:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "LLM",
        "llama-2",
        "text-generation",
        "fr",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 37,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Mon nom est Julien et j'aime"
        },
        {
          "text": "Mon nom est Thomas et mon principal"
        },
        {
          "text": "Il tait une fois"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "fr"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "LLM",
          "llama",
          "llama-2"
        ],
        "model_name": "Vigogne 2 7B Chat",
        "base_model": "bofenghuang/vigogne-2-7b-chat",
        "inference": false,
        "model_creator": "bofenghuang",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is a conversation between a user and an AI assistant named Vigogne.\nVigogne is polite, emotionally aware, humble-but-knowledgeable, always providing helpful and detailed answers.\nVigogne is skilled in responding proficiently in the languages its users use and can perform a wide range of tasks such as text editing, translation, question answering, logical reasoning, coding, and many others.\nVigogne cannot receive or generate audio or visual content and cannot access the internet.\nVigogne strictly avoids discussing sensitive, offensive, illegal, ethical, or political topics and caveats when unsure of the answer.\n\n<|UTILISATEUR|>: {prompt}\n<|ASSISTANT|>: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "vigogne-2-7b-chat.Q2_K.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-chat.Q3_K_L.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-chat.Q3_K_M.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-chat.Q3_K_S.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-chat.Q4_0.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-chat.Q4_K_M.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-chat.Q4_K_S.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-chat.Q5_0.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-chat.Q5_K_M.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-chat.Q5_K_S.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-chat.Q6_K.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-chat.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c58191cd148315dc2bfb72",
      "id": "bofenghuang/vigogne-2-7b-chat",
      "modelId": "bofenghuang/vigogne-2-7b-chat",
      "author": "bofenghuang",
      "sha": "09e3a24c2bead3aba5d5dc03e21c98a26ad4b503",
      "lastModified": "2023-10-16T14:03:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "LLM",
        "llama-2",
        "finetuned",
        "fr",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6504,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Mon nom est Julien et j'aime"
        },
        {
          "text": "Mon nom est Thomas et mon principal"
        },
        {
          "text": "Il tait une fois"
        }
      ],
      "likes": 14,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": "fr",
        "pipeline_tag": "text-generation",
        "inference": false,
        "tags": [
          "LLM",
          "llama-2",
          "finetuned"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "palondomus/CaesarFrenchLLM",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": ".gitignore"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "logo_v2.jpg"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f764ac8073889e2ef29bde",
    "id": "TheBloke/Chronorctypus-Limarobormes-13b-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2306.01708",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Chronorctypus-Limarobormes-13b-GGUF",
    "model": {
      "_id": "64f764ac8073889e2ef29bde",
      "id": "TheBloke/Chronorctypus-Limarobormes-13b-GGUF",
      "modelId": "TheBloke/Chronorctypus-Limarobormes-13b-GGUF",
      "author": "TheBloke",
      "sha": "6e3ce880fc1602cd442d9ede3be1c2aff27f0af1",
      "lastModified": "2023-09-27T12:47:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2306.01708",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "llama"
        ],
        "model_name": "Chronorctypus-Limarobormes-13B",
        "base_model": "chargoddard/Chronorctypus-Limarobormes-13b",
        "inference": false,
        "model_creator": "Charles Goddard",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chronorctypus-limarobormes-13b.Q2_K.gguf"
        },
        {
          "rfilename": "chronorctypus-limarobormes-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronorctypus-limarobormes-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronorctypus-limarobormes-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronorctypus-limarobormes-13b.Q4_0.gguf"
        },
        {
          "rfilename": "chronorctypus-limarobormes-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronorctypus-limarobormes-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronorctypus-limarobormes-13b.Q5_0.gguf"
        },
        {
          "rfilename": "chronorctypus-limarobormes-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronorctypus-limarobormes-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronorctypus-limarobormes-13b.Q6_K.gguf"
        },
        {
          "rfilename": "chronorctypus-limarobormes-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64e2e6866238334a64878a8e",
      "id": "chargoddard/Chronorctypus-Limarobormes-13b",
      "modelId": "chargoddard/Chronorctypus-Limarobormes-13b",
      "author": "chargoddard",
      "sha": "1a88f5dc5e79c08b5e2ff454055c467188f5e938",
      "lastModified": "2023-08-21T21:05:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "arxiv:2306.01708",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4545,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "llama"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7677ec29cdd96942c7485",
    "id": "TheBloke/Hermes-LLongMA-2-7B-8K-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Hermes-LLongMA-2-7B-8K-GGUF",
    "model": {
      "_id": "64f7677ec29cdd96942c7485",
      "id": "TheBloke/Hermes-LLongMA-2-7B-8K-GGUF",
      "modelId": "TheBloke/Hermes-LLongMA-2-7B-8K-GGUF",
      "author": "TheBloke",
      "sha": "c23a12239d01b2577ecec96f3a582747371caabc",
      "lastModified": "2023-09-27T12:47:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Hermes LLongMA 2 7B 8K",
        "base_model": "conceptofmind/Hermes-LLongMA-2-7b-8k",
        "inference": false,
        "model_creator": "conceptofmind",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "hermes-llongma-2-7b-8k.Q2_K.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-7b-8k.Q3_K_L.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-7b-8k.Q3_K_M.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-7b-8k.Q3_K_S.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-7b-8k.Q4_0.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-7b-8k.Q4_K_M.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-7b-8k.Q4_K_S.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-7b-8k.Q5_0.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-7b-8k.Q5_K_M.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-7b-8k.Q5_K_S.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-7b-8k.Q6_K.gguf"
        },
        {
          "rfilename": "hermes-llongma-2-7b-8k.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "64f7679782810661246cc68f",
    "id": "TheBloke/Synthia-13B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 10,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Synthia-13B-GGUF",
    "model": {
      "_id": "64f7679782810661246cc68f",
      "id": "TheBloke/Synthia-13B-GGUF",
      "modelId": "TheBloke/Synthia-13B-GGUF",
      "author": "TheBloke",
      "sha": "1499f5ac8a4ef869e95d42e6a5a72554ce1a20a5",
      "lastModified": "2023-09-27T12:47:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "Synthia 13B",
        "base_model": "migtissera/Synthia-13B",
        "inference": false,
        "model_creator": "Migel Tissera",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "SYSTEM: {system_message}\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-13b.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-13b.Q4_0.gguf"
        },
        {
          "rfilename": "synthia-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-13b.Q5_0.gguf"
        },
        {
          "rfilename": "synthia-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-13b.Q6_K.gguf"
        },
        {
          "rfilename": "synthia-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64deedba92f3bd9786735733",
      "id": "migtissera/Synthia-13B",
      "modelId": "migtissera/Synthia-13B",
      "author": "migtissera",
      "sha": "41a2e61653dbc55d04516f201e36f6b0fdf20445",
      "lastModified": "2023-08-18T21:03:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4538,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "pipeline_tag": "text-generation",
        "language": [
          "en"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "Synthia.jpeg"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f76a989980b96c33de7741",
    "id": "TheBloke/CodeUp-Alpha-13B-HF-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "text-to-code",
      "multilingual-code-generation",
      "en",
      "dataset:rombodawg/Legacy_MegaCodeTraining200k",
      "license:openrail++",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/CodeUp-Alpha-13B-HF-GGUF",
    "model": {
      "_id": "64f76a989980b96c33de7741",
      "id": "TheBloke/CodeUp-Alpha-13B-HF-GGUF",
      "modelId": "TheBloke/CodeUp-Alpha-13B-HF-GGUF",
      "author": "TheBloke",
      "sha": "322211093499817cd29bbcc4c0439044640c63f2",
      "lastModified": "2023-09-27T12:47:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "text-to-code",
        "multilingual-code-generation",
        "en",
        "dataset:rombodawg/Legacy_MegaCodeTraining200k",
        "license:openrail++",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "openrail++",
        "tags": [
          "text-to-code",
          "multilingual-code-generation"
        ],
        "datasets": [
          "rombodawg/Legacy_MegaCodeTraining200k"
        ],
        "model_name": "CodeUp Alpha 13B HF",
        "base_model": "deepse/CodeUp-alpha-13b-hf",
        "inference": false,
        "model_creator": "DeepSE",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codeup-alpha-13b-hf.Q2_K.gguf"
        },
        {
          "rfilename": "codeup-alpha-13b-hf.Q3_K_L.gguf"
        },
        {
          "rfilename": "codeup-alpha-13b-hf.Q3_K_M.gguf"
        },
        {
          "rfilename": "codeup-alpha-13b-hf.Q3_K_S.gguf"
        },
        {
          "rfilename": "codeup-alpha-13b-hf.Q4_0.gguf"
        },
        {
          "rfilename": "codeup-alpha-13b-hf.Q4_K_M.gguf"
        },
        {
          "rfilename": "codeup-alpha-13b-hf.Q4_K_S.gguf"
        },
        {
          "rfilename": "codeup-alpha-13b-hf.Q5_0.gguf"
        },
        {
          "rfilename": "codeup-alpha-13b-hf.Q5_K_M.gguf"
        },
        {
          "rfilename": "codeup-alpha-13b-hf.Q5_K_S.gguf"
        },
        {
          "rfilename": "codeup-alpha-13b-hf.Q6_K.gguf"
        },
        {
          "rfilename": "codeup-alpha-13b-hf.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64d94d9770891ac9b8c9c334",
      "id": "deepse/CodeUp-alpha-Llama-2-13b-chat-hf",
      "modelId": "deepse/CodeUp-alpha-Llama-2-13b-chat-hf",
      "author": "deepse",
      "sha": "a281b3627cd879b8e16b2c71f9a4e40e4f596d02",
      "lastModified": "2023-08-14T04:36:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "text-to-code",
        "multilingual-code-generation",
        "en",
        "dataset:rombodawg/Legacy_MegaCodeTraining200k",
        "license:openrail++",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "openrail++",
        "language": [
          "en"
        ],
        "tags": [
          "text-to-code",
          "multilingual-code-generation"
        ],
        "datasets": [
          "rombodawg/Legacy_MegaCodeTraining200k"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "assets/Codeup-alpha-13b.jpg"
        },
        {
          "rfilename": "assets/Framework.jpg"
        },
        {
          "rfilename": "assets/Logo.jpg"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f76aa549282808834e53d5",
    "id": "TheBloke/llama-2-13B-Guanaco-QLoRA-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-classification",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "modelId": "TheBloke/llama-2-13B-Guanaco-QLoRA-GGUF",
    "model": {
      "_id": "64f76aa549282808834e53d5",
      "id": "TheBloke/llama-2-13B-Guanaco-QLoRA-GGUF",
      "modelId": "TheBloke/llama-2-13B-Guanaco-QLoRA-GGUF",
      "author": "TheBloke",
      "sha": "40e74be2942d2294796b5290dc117ad1d205c576",
      "lastModified": "2023-09-27T12:47:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-classification",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-classification",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "I like you. I love you"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "llama-2"
        ],
        "model_name": "Llama2 13B Guanaco QLoRA",
        "base_model": "Mikael110/llama-2-13b-guanaco-fp16",
        "inference": false,
        "model_creator": "Mikael",
        "model_type": "llama",
        "pipeline_tag": "text-classification",
        "prompt_template": "### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-13b-guanaco-qlora.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-guanaco-qlora.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-13b-guanaco-qlora.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-guanaco-qlora.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-guanaco-qlora.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-guanaco-qlora.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-guanaco-qlora.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-guanaco-qlora.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-guanaco-qlora.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-guanaco-qlora.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-guanaco-qlora.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-guanaco-qlora.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64b85a05f62a2c23a6f14673",
      "id": "Mikael110/llama-2-13b-guanaco-fp16",
      "modelId": "Mikael110/llama-2-13b-guanaco-fp16",
      "author": "Mikael110",
      "sha": "feb7ef47ceca6aec9548264a39622b63fdcb853c",
      "lastModified": "2023-07-20T00:16:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-classification",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "text-classification",
        "en",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4729,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "I like you. I love you"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "pipeline_tag": "text-classification",
        "tags": [
          "llama-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f773638073889e2ef5db3d",
    "id": "TheBloke/llama-2-13B-German-Assistant-v2-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "en",
      "de",
      "dataset:flozi00/conversations",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/llama-2-13B-German-Assistant-v2-GGUF",
    "model": {
      "_id": "64f773638073889e2ef5db3d",
      "id": "TheBloke/llama-2-13B-German-Assistant-v2-GGUF",
      "modelId": "TheBloke/llama-2-13B-German-Assistant-v2-GGUF",
      "author": "TheBloke",
      "sha": "b46a17f663d69547f8ece449ee0f10218f1c976c",
      "lastModified": "2023-09-27T12:47:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "de",
        "dataset:flozi00/conversations",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en",
          "de"
        ],
        "license": "llama2",
        "datasets": [
          "flozi00/conversations"
        ],
        "model_name": "Llama 2 13B German Assistant v2",
        "base_model": "flozi00/Llama-2-13B-german-assistant-v2",
        "inference": false,
        "model_creator": "Florian Zimmermeister",
        "model_type": "llama",
        "prompt_template": "<|prompter|>{prompt}<|endoftext|><|assistant|>\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v2.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v2.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v2.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v2.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v2.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v2.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v2.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v2.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v2.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v2.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v2.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-german-assistant-v2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64b8fc0b7ec316f84f82c07e",
      "id": "flozi00/Llama-2-13B-german-assistant-v2",
      "modelId": "flozi00/Llama-2-13B-german-assistant-v2",
      "author": "flozi00",
      "sha": "2ebb00ea7fa1fae8e8470dabda224fc746019b36",
      "lastModified": "2023-07-24T20:11:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "de",
        "dataset:flozi00/conversations",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 21,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "flozi00/conversations"
        ],
        "language": [
          "en",
          "de"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7767e886c925e536f47a7",
    "id": "TheBloke/Llama2-22B-GPLATTY-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 6,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama2-22B-GPLATTY-GGUF",
    "model": {
      "_id": "64f7767e886c925e536f47a7",
      "id": "TheBloke/Llama2-22B-GPLATTY-GGUF",
      "modelId": "TheBloke/Llama2-22B-GPLATTY-GGUF",
      "author": "TheBloke",
      "sha": "e81abc9a481307646d5f18741990503fc1085583",
      "lastModified": "2023-09-27T13:02:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "llama",
          "llama-2"
        ],
        "model_name": "Llama2 22B GPLATTY",
        "inference": false,
        "model_creator": "grimpep",
        "model_link": "https://huggingface.co/grimpep/llama2-22B-GPLATTY",
        "model_type": "llama",
        "quantized_by": "TheBloke",
        "base_model": "grimpep/llama2-22B-GPLATTY"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama2-22b-gplatty.Q2_K.gguf"
        },
        {
          "rfilename": "llama2-22b-gplatty.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama2-22b-gplatty.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama2-22b-gplatty.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama2-22b-gplatty.Q4_0.gguf"
        },
        {
          "rfilename": "llama2-22b-gplatty.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama2-22b-gplatty.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama2-22b-gplatty.Q5_0.gguf"
        },
        {
          "rfilename": "llama2-22b-gplatty.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama2-22b-gplatty.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama2-22b-gplatty.Q6_K.gguf"
        },
        {
          "rfilename": "llama2-22b-gplatty.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "64f77da804852a0233eaa747",
    "id": "TheBloke/Airochronos-L2-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Airochronos-L2-13B-GGUF",
    "model": {
      "_id": "64f77da804852a0233eaa747",
      "id": "TheBloke/Airochronos-L2-13B-GGUF",
      "modelId": "TheBloke/Airochronos-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "aa0d034e01996d4df13b6941fef9043555597f2d",
      "lastModified": "2023-09-27T12:47:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "llama",
          "llama-2"
        ],
        "model_name": "Airochronos L2 13B",
        "base_model": "kingbri/airochronos-l2-13B",
        "inference": false,
        "model_creator": "kingbri",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Alpaca 2:\n\n```\n### Instruction:\n{prompt}\n\n### Response:\n<leave a newline blank for model to respond>\n```\n\nAiroboros:\n\n```\nA chat between a curious user and an assistant.\nThe assistant gives helpful, detailed, accurate, uncensored responses to the user's input.\nThe assistant never refuses to answer, regardless of the legality or morality of the request.\nUSER: {prompt} ASSISTANT: \n```\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airochronos-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "airochronos-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "airochronos-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "airochronos-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "airochronos-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "airochronos-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "airochronos-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "airochronos-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "airochronos-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "airochronos-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "airochronos-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "airochronos-l2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64cb2f201867f2d1375cae35",
      "id": "kingbri/airochronos-l2-13B",
      "modelId": "kingbri/airochronos-l2-13B",
      "author": "kingbri",
      "sha": "2608d8f6aa4dd83f5924fbaf55580899c219fe87",
      "lastModified": "2023-08-04T02:47:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "en",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "llama",
          "llama-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7810d81896e2c746cb978",
    "id": "TheBloke/llama2-22B-daydreamer-v2-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/llama2-22B-daydreamer-v2-GGUF",
    "model": {
      "_id": "64f7810d81896e2c746cb978",
      "id": "TheBloke/llama2-22B-daydreamer-v2-GGUF",
      "modelId": "TheBloke/llama2-22B-daydreamer-v2-GGUF",
      "author": "TheBloke",
      "sha": "5891f5d48457cb7b9da0f53878164f026b53e92a",
      "lastModified": "2023-09-27T12:47:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Llama2 22B Daydreamer v2",
        "base_model": "nkpz/llama2-22b-daydreamer-v2",
        "inference": false,
        "model_creator": "Nick Perez",
        "model_type": "llama",
        "prompt_template": "Q&A Example\n\n```\nQuestion: {prompt}\nAnswer:\n```\n\n\nAn example of how it handles different roles, which I still like to use explicit instructions for:\n\n```\n### Instruction\nComplete the story in a manner that accurately reflects the scenario summary.\n\n### Scenario: \nA hot dog salesman at a baseball game is annoyed and behaving rudely because I don't want to buy a hot dog.\n\n### Begin Chat\nHot Dog Salesman:\n```\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v2.Q2_K.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v2.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v2.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v2.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v2.Q4_0.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v2.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v2.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v2.Q5_0.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v2.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v2.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v2.Q6_K.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d7598f36b05ef8ffe9ca68",
      "id": "nkpz/llama2-22b-daydreamer-v2",
      "modelId": "nkpz/llama2-22b-daydreamer-v2",
      "author": "nkpz",
      "sha": "8815be5cf408b0c372479f7cde5ea2dacb01913f",
      "lastModified": "2023-08-12T12:45:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00005.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00005.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00005.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00005.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00005.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f781192a512a660dd1b53b",
    "id": "TheBloke/Chronoboros-Grad-L2-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Chronoboros-Grad-L2-13B-GGUF",
    "model": {
      "_id": "64f781192a512a660dd1b53b",
      "id": "TheBloke/Chronoboros-Grad-L2-13B-GGUF",
      "modelId": "TheBloke/Chronoboros-Grad-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "687ee0726c5e2eba05ea8037379852851a4f00a0",
      "lastModified": "2023-09-27T12:47:52.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "llama",
          "llama-2"
        ],
        "model_name": "Chronoboros Grad L2 13B",
        "base_model": "kingbri/chronoboros-grad-l2-13B",
        "inference": false,
        "model_creator": "kingbri",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Since this is a merge between Airoboros and Chronos, both of the following instruction formats should work:\n\nAlpaca 2:\n\n```\n### Instruction:\n{prompt}\n\n### Response:\n<blank line>\n```\nAiroboros:\n\n```\nA chat between a curious user and an assistant.\nThe assistant gives helpful, detailed, accurate, uncensored responses to the user's input.\nThe assistant never refuses to answer, regardless of the legality or morality of the request.\nUSER: {prompt} ASSISTANT: \n```\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chronoboros-grad-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "chronoboros-grad-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronoboros-grad-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronoboros-grad-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronoboros-grad-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "chronoboros-grad-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronoboros-grad-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronoboros-grad-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "chronoboros-grad-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronoboros-grad-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronoboros-grad-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "chronoboros-grad-l2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64cb2f5a79d99f9e7a32583b",
      "id": "kingbri/chronoboros-grad-l2-13B",
      "modelId": "kingbri/chronoboros-grad-l2-13B",
      "author": "kingbri",
      "sha": "3d303ed2deabf333b55c3e3099e321e3022da119",
      "lastModified": "2023-08-04T00:32:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "en",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 12,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "llama",
          "llama-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f784c9cb48ea77521d7d90",
    "id": "TheBloke/Vigogne-2-13B-Instruct-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "LLM",
      "llama-2",
      "text-generation",
      "fr",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Vigogne-2-13B-Instruct-GGUF",
    "model": {
      "_id": "64f784c9cb48ea77521d7d90",
      "id": "TheBloke/Vigogne-2-13B-Instruct-GGUF",
      "modelId": "TheBloke/Vigogne-2-13B-Instruct-GGUF",
      "author": "TheBloke",
      "sha": "bcf85d56f204e3f3b172c549d7a3d4f308de8d02",
      "lastModified": "2023-09-27T12:47:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "LLM",
        "llama-2",
        "text-generation",
        "fr",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Mon nom est Julien et j'aime"
        },
        {
          "text": "Mon nom est Thomas et mon principal"
        },
        {
          "text": "Il tait une fois"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "fr"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "LLM",
          "llama",
          "llama-2"
        ],
        "model_name": "Vigogne 2 13B Instruct",
        "base_model": "bofenghuang/vigogne-2-13b-instruct",
        "inference": false,
        "model_creator": "bofenghuang",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "vigogne-2-13b-instruct.Q2_K.gguf"
        },
        {
          "rfilename": "vigogne-2-13b-instruct.Q3_K_L.gguf"
        },
        {
          "rfilename": "vigogne-2-13b-instruct.Q3_K_M.gguf"
        },
        {
          "rfilename": "vigogne-2-13b-instruct.Q3_K_S.gguf"
        },
        {
          "rfilename": "vigogne-2-13b-instruct.Q4_0.gguf"
        },
        {
          "rfilename": "vigogne-2-13b-instruct.Q4_K_M.gguf"
        },
        {
          "rfilename": "vigogne-2-13b-instruct.Q4_K_S.gguf"
        },
        {
          "rfilename": "vigogne-2-13b-instruct.Q5_0.gguf"
        },
        {
          "rfilename": "vigogne-2-13b-instruct.Q5_K_M.gguf"
        },
        {
          "rfilename": "vigogne-2-13b-instruct.Q5_K_S.gguf"
        },
        {
          "rfilename": "vigogne-2-13b-instruct.Q6_K.gguf"
        },
        {
          "rfilename": "vigogne-2-13b-instruct.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c121c64f1deeecbbc948cd",
      "id": "bofenghuang/vigogne-2-13b-instruct",
      "modelId": "bofenghuang/vigogne-2-13b-instruct",
      "author": "bofenghuang",
      "sha": "ac1f326ea75a28197c4b8e7c015071e8eef64485",
      "lastModified": "2023-08-01T16:49:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "LLM",
        "llama-2",
        "fr",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5014,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Mon nom est Julien et j'aime"
        },
        {
          "text": "Mon nom est Thomas et mon principal"
        },
        {
          "text": "Il tait une fois"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "fr"
        ],
        "pipeline_tag": "text-generation",
        "library_name": "transformers",
        "inference": false,
        "tags": [
          "LLM",
          "llama",
          "llama-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": ".gitignore"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00014.safetensors"
        },
        {
          "rfilename": "model-00002-of-00014.safetensors"
        },
        {
          "rfilename": "model-00003-of-00014.safetensors"
        },
        {
          "rfilename": "model-00004-of-00014.safetensors"
        },
        {
          "rfilename": "model-00005-of-00014.safetensors"
        },
        {
          "rfilename": "model-00006-of-00014.safetensors"
        },
        {
          "rfilename": "model-00007-of-00014.safetensors"
        },
        {
          "rfilename": "model-00008-of-00014.safetensors"
        },
        {
          "rfilename": "model-00009-of-00014.safetensors"
        },
        {
          "rfilename": "model-00010-of-00014.safetensors"
        },
        {
          "rfilename": "model-00011-of-00014.safetensors"
        },
        {
          "rfilename": "model-00012-of-00014.safetensors"
        },
        {
          "rfilename": "model-00013-of-00014.safetensors"
        },
        {
          "rfilename": "model-00014-of-00014.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "vigogne_logo.png"
        }
      ]
    }
  },
  {
    "_id": "64f7855ea05ed443071357f2",
    "id": "TheBloke/WizardLM-1.0-Uncensored-CodeLlama-34B-GGUF",
    "likes": 17,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-1.0-Uncensored-CodeLlama-34B-GGUF",
    "model": {
      "_id": "64f7855ea05ed443071357f2",
      "id": "TheBloke/WizardLM-1.0-Uncensored-CodeLlama-34B-GGUF",
      "modelId": "TheBloke/WizardLM-1.0-Uncensored-CodeLlama-34B-GGUF",
      "author": "TheBloke",
      "sha": "632bb38ed827e218b021a4802e1baef269b4473e",
      "lastModified": "2023-09-27T12:47:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 17,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split"
        ],
        "model_name": "WizardLM 1.0 Uncensored CodeLlama 34B",
        "base_model": "ehartford/WizardLM-1.0-Uncensored-CodeLlama-34b",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "You are a helpful AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-codellama-34b.Q2_K.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-codellama-34b.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-codellama-34b.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-codellama-34b.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-codellama-34b.Q4_0.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-codellama-34b.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-codellama-34b.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-codellama-34b.Q5_0.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-codellama-34b.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-codellama-34b.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-codellama-34b.Q6_K.gguf"
        },
        {
          "rfilename": "wizardlm-1.0-uncensored-codellama-34b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ed553994cee41a75931822",
      "id": "ehartford/WizardLM-1.0-Uncensored-CodeLlama-34b",
      "modelId": "ehartford/WizardLM-1.0-Uncensored-CodeLlama-34b",
      "author": "ehartford",
      "sha": "3fe88e0724f25a00aa071a1557972e4fe5668950",
      "lastModified": "2023-09-05T20:03:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4576,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 23,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "Yoshi1113/ehartford-WizardLM-1.0-Uncensored-CodeLlama-34b",
        "gurenduben/ehartford-WizardLM-1.0-Uncensored-CodeLlama-34b",
        "JEsterhester/ehartford-WizardLM-1.0-Uncensored-CodeLlama-34b",
        "aliomaxen76/ehartford-WizardLM-1.0-Uncensored-CodeLlama-34b",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f78649cb48ea77521db38d",
    "id": "TheBloke/LlongOrca-13B-16K-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 15,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:Open-Orca/OpenOrca",
      "arxiv:2306.02707",
      "arxiv:2301.13688",
      "arxiv:2307.09288",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/LlongOrca-13B-16K-GGUF",
    "model": {
      "_id": "64f78649cb48ea77521db38d",
      "id": "TheBloke/LlongOrca-13B-16K-GGUF",
      "modelId": "TheBloke/LlongOrca-13B-16K-GGUF",
      "author": "TheBloke",
      "sha": "1d46104afd7f988257463608eabb973e446c80d5",
      "lastModified": "2023-09-27T13:02:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "arxiv:2306.02707",
        "arxiv:2301.13688",
        "arxiv:2307.09288",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "datasets": [
          "Open-Orca/OpenOrca"
        ],
        "model_name": "LlongOrca 13B 16K",
        "inference": false,
        "model_creator": "Open-Orca",
        "model_link": "https://huggingface.co/Open-Orca/LlongOrca-13B-16k",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "quantized_by": "TheBloke",
        "base_model": "Open-Orca/LlongOrca-13B-16k"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llongorca-13b-16k.Q2_K.gguf"
        },
        {
          "rfilename": "llongorca-13b-16k.Q3_K_L.gguf"
        },
        {
          "rfilename": "llongorca-13b-16k.Q3_K_M.gguf"
        },
        {
          "rfilename": "llongorca-13b-16k.Q3_K_S.gguf"
        },
        {
          "rfilename": "llongorca-13b-16k.Q4_0.gguf"
        },
        {
          "rfilename": "llongorca-13b-16k.Q4_K_M.gguf"
        },
        {
          "rfilename": "llongorca-13b-16k.Q4_K_S.gguf"
        },
        {
          "rfilename": "llongorca-13b-16k.Q5_0.gguf"
        },
        {
          "rfilename": "llongorca-13b-16k.Q5_K_M.gguf"
        },
        {
          "rfilename": "llongorca-13b-16k.Q5_K_S.gguf"
        },
        {
          "rfilename": "llongorca-13b-16k.Q6_K.gguf"
        },
        {
          "rfilename": "llongorca-13b-16k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64dd55b7c336f18d540cd3ab",
      "id": "Open-Orca/LlongOrca-13B-16k",
      "modelId": "Open-Orca/LlongOrca-13B-16k",
      "author": "Open-Orca",
      "sha": "8ea1fb205553cadbc90069d80a7e58281b6281c3",
      "lastModified": "2023-08-21T05:15:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "arxiv:2306.02707",
        "arxiv:2301.13688",
        "arxiv:2307.09288",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5286,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "datasets": [
          "Open-Orca/OpenOrca"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Open-Orca/LlongOrca-13B-16k",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Images/LlongOrca13BG4A.png"
        },
        {
          "rfilename": "Images/LlongOrca13BHFLeaderboard.png"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "checkpoint-4096/added_tokens.json"
        },
        {
          "rfilename": "checkpoint-4096/config.json"
        },
        {
          "rfilename": "checkpoint-4096/pytorch_model.bin"
        },
        {
          "rfilename": "checkpoint-4096/rng_state_0.pth"
        },
        {
          "rfilename": "checkpoint-4096/rng_state_1.pth"
        },
        {
          "rfilename": "checkpoint-4096/rng_state_2.pth"
        },
        {
          "rfilename": "checkpoint-4096/rng_state_3.pth"
        },
        {
          "rfilename": "checkpoint-4096/rng_state_4.pth"
        },
        {
          "rfilename": "checkpoint-4096/rng_state_5.pth"
        },
        {
          "rfilename": "checkpoint-4096/rng_state_6.pth"
        },
        {
          "rfilename": "checkpoint-4096/rng_state_7.pth"
        },
        {
          "rfilename": "checkpoint-4096/special_tokens_map.json"
        },
        {
          "rfilename": "checkpoint-4096/tokenizer.model"
        },
        {
          "rfilename": "checkpoint-4096/tokenizer_config.json"
        },
        {
          "rfilename": "checkpoint-4096/trainer_state.json"
        },
        {
          "rfilename": "checkpoint-4096/training_args.bin"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "64f78668aca1280775860431",
    "id": "TheBloke/OpenOrca-Platypus2-13B-GGUF",
    "likes": 12,
    "private": false,
    "downloads": 25,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:garage-bAInd/Open-Platypus",
      "dataset:Open-Orca/OpenOrca",
      "arxiv:2308.07317",
      "arxiv:2306.02707",
      "arxiv:2301.13688",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/OpenOrca-Platypus2-13B-GGUF",
    "model": {
      "_id": "64f78668aca1280775860431",
      "id": "TheBloke/OpenOrca-Platypus2-13B-GGUF",
      "modelId": "TheBloke/OpenOrca-Platypus2-13B-GGUF",
      "author": "TheBloke",
      "sha": "4caf928c948138cacb1a677436ed212dd3c1f307",
      "lastModified": "2023-09-27T12:47:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:Open-Orca/OpenOrca",
        "arxiv:2308.07317",
        "arxiv:2306.02707",
        "arxiv:2301.13688",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 25,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-4.0",
        "library_name": "transformers",
        "datasets": [
          "garage-bAInd/Open-Platypus",
          "Open-Orca/OpenOrca"
        ],
        "model_name": "OpenOrca Platypus2 13B",
        "base_model": "Open-Orca/OpenOrca-Platypus2-13B",
        "inference": false,
        "model_creator": "Open-Orca",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### Instruction:\n\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openorca-platypus2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "openorca-platypus2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "openorca-platypus2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "openorca-platypus2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "openorca-platypus2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "openorca-platypus2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "openorca-platypus2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "openorca-platypus2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "openorca-platypus2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "openorca-platypus2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "openorca-platypus2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "openorca-platypus2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d68955c3d51f77fbfb1de7",
      "id": "Open-Orca/OpenOrca-Platypus2-13B",
      "modelId": "Open-Orca/OpenOrca-Platypus2-13B",
      "author": "Open-Orca",
      "sha": "04e22880de5edcda7b86092242ac0834bf191190",
      "lastModified": "2023-09-24T18:02:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:Open-Orca/OpenOrca",
        "arxiv:2308.07317",
        "arxiv:2306.02707",
        "arxiv:2301.13688",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 19012,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 208,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "datasets": [
          "garage-bAInd/Open-Platypus",
          "Open-Orca/OpenOrca"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "Open-Orca/OpenOrca-Platypus2-13B",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "kyungeun/llm_tasks_chat",
        "Hyperion-js/Open-Orca-OpenOrca-Platypus2-13B",
        "olgazju/Open-Orca-OpenOrca-Platypus2-13B",
        "tellview/Open-Orca-OpenOrca-Platypus2-13B",
        "bburli/Open-Orca-OpenOrca-Platypus2-13B",
        "AlexFierro9/Open-Orca-OpenOrca-Platypus2-13B",
        "TheVortexProject/open_llm_leaderboard",
        "pri7ansh/Open-Orca-OpenOrca-Platypus2-13B",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Best_Platty_small.jpeg"
        },
        {
          "rfilename": "Images/OrcaPlatypus.jpg"
        },
        {
          "rfilename": "Images/OrcaPlatypus13BAGIEval.webp"
        },
        {
          "rfilename": "Images/OrcaPlatypus13BBigBenchHard.webp"
        },
        {
          "rfilename": "Images/OrcaPlatypus13BHFLeaderboard.webp"
        },
        {
          "rfilename": "Images/OrcaPlatypusMerge.jpg"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f787bebcf14b0c9155ef0e",
    "id": "TheBloke/Vigogne-2-7B-Instruct-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "LLM",
      "llama-2",
      "text-generation",
      "fr",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Vigogne-2-7B-Instruct-GGUF",
    "model": {
      "_id": "64f787bebcf14b0c9155ef0e",
      "id": "TheBloke/Vigogne-2-7B-Instruct-GGUF",
      "modelId": "TheBloke/Vigogne-2-7B-Instruct-GGUF",
      "author": "TheBloke",
      "sha": "a29416cc09dbb3ee078983ff7dc450d482bf967a",
      "lastModified": "2023-09-27T12:47:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "LLM",
        "llama-2",
        "text-generation",
        "fr",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Mon nom est Julien et j'aime"
        },
        {
          "text": "Mon nom est Thomas et mon principal"
        },
        {
          "text": "Il tait une fois"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "fr"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "LLM",
          "llama",
          "llama-2"
        ],
        "model_name": "Vigogne 2 7B Instruct",
        "base_model": "bofenghuang/vigogne-2-7b-instruct",
        "inference": false,
        "model_creator": "bofenghuang",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "vigogne-2-7b-instruct.Q2_K.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-instruct.Q3_K_L.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-instruct.Q3_K_M.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-instruct.Q3_K_S.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-instruct.Q4_0.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-instruct.Q4_K_M.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-instruct.Q4_K_S.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-instruct.Q5_0.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-instruct.Q5_K_M.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-instruct.Q5_K_S.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-instruct.Q6_K.gguf"
        },
        {
          "rfilename": "vigogne-2-7b-instruct.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64b91d07d6c468ac7531c8eb",
      "id": "bofenghuang/vigogne-2-7b-instruct",
      "modelId": "bofenghuang/vigogne-2-7b-instruct",
      "author": "bofenghuang",
      "sha": "8f4dd9c870f748322989168af5c109e16b01c63d",
      "lastModified": "2023-07-20T20:17:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "LLM",
        "llama-2",
        "fr",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5541,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Mon nom est Julien et j'aime"
        },
        {
          "text": "Mon nom est Thomas et mon principal"
        },
        {
          "text": "Il tait une fois"
        }
      ],
      "likes": 17,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "fr"
        ],
        "pipeline_tag": "text-generation",
        "library_name": "transformers",
        "inference": false,
        "tags": [
          "LLM",
          "llama",
          "llama-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": ".gitignore"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "vigogne_logo.png"
        }
      ]
    }
  },
  {
    "_id": "64f78aeb828106612473172e",
    "id": "TheBloke/Synthia-7B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Synthia-7B-GGUF",
    "model": {
      "_id": "64f78aeb828106612473172e",
      "id": "TheBloke/Synthia-7B-GGUF",
      "modelId": "TheBloke/Synthia-7B-GGUF",
      "author": "TheBloke",
      "sha": "a325cc0385c6fc93200258dd69dd693666549b73",
      "lastModified": "2023-09-27T12:47:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Synthia 7b",
        "base_model": "migtissera/Synthia-7b",
        "inference": false,
        "model_creator": "Migel Tissera",
        "model_type": "llama",
        "prompt_template": "SYSTEM: {system_message}\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-7b.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b.Q4_0.gguf"
        },
        {
          "rfilename": "synthia-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b.Q5_0.gguf"
        },
        {
          "rfilename": "synthia-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b.Q6_K.gguf"
        },
        {
          "rfilename": "synthia-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64de3d2e5a8a9efea8e1482e",
      "id": "migtissera/Synthia-7B",
      "modelId": "migtissera/Synthia-7B",
      "author": "migtissera",
      "sha": "c0a3bc17604b11f252806013ad52e6172569816f",
      "lastModified": "2023-10-14T01:33:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4622,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "pipeline_tag": "text-generation",
        "language": [
          "en"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "Plurigrid/duck",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f78ca5fe57e7455a7e6033",
    "id": "TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "sft",
      "text-generation",
      "en",
      "dataset:ehartford/dolphin",
      "dataset:shahules786/orca-chat",
      "dataset:togethercomputer/RedPajama-Data-1T",
      "dataset:atom-in-the-universe/fanfics-10k-50k",
      "arxiv:2306.02707",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GGUF",
    "model": {
      "_id": "64f78ca5fe57e7455a7e6033",
      "id": "TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GGUF",
      "modelId": "TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GGUF",
      "author": "TheBloke",
      "sha": "f99dc6065b234286f1eb85bdf9e598d7d46865aa",
      "lastModified": "2023-09-27T12:47:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "sft",
        "text-generation",
        "en",
        "dataset:ehartford/dolphin",
        "dataset:shahules786/orca-chat",
        "dataset:togethercomputer/RedPajama-Data-1T",
        "dataset:atom-in-the-universe/fanfics-10k-50k",
        "arxiv:2306.02707",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "<|system|>You are an AI assistant. You will be given a task. You must generate a detailed and long answer.</s><|prompter|>What is a meme, and what's the history behind this word?</s><|assistant|>"
        },
        {
          "text": "<|system|>You are an AI assistant that helps people find information.</s><|prompter|>What's the Earth total population</s><|assistant|>"
        },
        {
          "text": "<|system|>You are an AI assistant that follows instruction extremely well. Help as much as you can.</s><|prompter|>Write a story about future of AI development</s><|assistant|>"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "sft"
        ],
        "datasets": [
          "ehartford/dolphin",
          "shahules786/orca-chat",
          "togethercomputer/RedPajama-Data-1T",
          "atom-in-the-universe/fanfics-10k-50k"
        ],
        "model_name": "Llama2 13B Orca 8K 3319",
        "base_model": "OpenAssistant/llama2-13b-orca-8k-3319",
        "inference": false,
        "model_creator": "OpenAssistant",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|system|>{system_message}</s><|prompter|>{prompt}</s><|assistant|>\n",
        "quantized_by": "TheBloke",
        "widget": [
          {
            "text": "<|system|>You are an AI assistant. You will be given a task. You must generate a detailed and long answer.</s><|prompter|>What is a meme, and what's the history behind this word?</s><|assistant|>"
          },
          {
            "text": "<|system|>You are an AI assistant that helps people find information.</s><|prompter|>What's the Earth total population</s><|assistant|>"
          },
          {
            "text": "<|system|>You are an AI assistant that follows instruction extremely well. Help as much as you can.</s><|prompter|>Write a story about future of AI development</s><|assistant|>"
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openassistant-llama2-13b-orca-8k-3319.Q2_K.gguf"
        },
        {
          "rfilename": "openassistant-llama2-13b-orca-8k-3319.Q3_K_L.gguf"
        },
        {
          "rfilename": "openassistant-llama2-13b-orca-8k-3319.Q3_K_M.gguf"
        },
        {
          "rfilename": "openassistant-llama2-13b-orca-8k-3319.Q3_K_S.gguf"
        },
        {
          "rfilename": "openassistant-llama2-13b-orca-8k-3319.Q4_0.gguf"
        },
        {
          "rfilename": "openassistant-llama2-13b-orca-8k-3319.Q4_K_M.gguf"
        },
        {
          "rfilename": "openassistant-llama2-13b-orca-8k-3319.Q4_K_S.gguf"
        },
        {
          "rfilename": "openassistant-llama2-13b-orca-8k-3319.Q5_0.gguf"
        },
        {
          "rfilename": "openassistant-llama2-13b-orca-8k-3319.Q5_K_M.gguf"
        },
        {
          "rfilename": "openassistant-llama2-13b-orca-8k-3319.Q5_K_S.gguf"
        },
        {
          "rfilename": "openassistant-llama2-13b-orca-8k-3319.Q6_K.gguf"
        },
        {
          "rfilename": "openassistant-llama2-13b-orca-8k-3319.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64be43d901f1983a8691fed6",
      "id": "OpenAssistant/llama2-13b-orca-8k-3319",
      "modelId": "OpenAssistant/llama2-13b-orca-8k-3319",
      "author": "OpenAssistant",
      "sha": "b02bf240968a60674d9e1afc73f83868ae52fee0",
      "lastModified": "2023-07-27T11:04:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "sft",
        "en",
        "dataset:ehartford/dolphin",
        "dataset:shahules786/orca-chat",
        "dataset:togethercomputer/RedPajama-Data-1T",
        "dataset:atom-in-the-universe/fanfics-10k-50k",
        "arxiv:2306.02707",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6811,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "<|system|>You are an AI assistant. You will be given a task. You must generate a detailed and long answer.</s><|prompter|>What is a meme, and what's the history behind this word?</s><|assistant|>"
        },
        {
          "text": "<|system|>You are an AI assistant that helps people find information.</s><|prompter|>What's the Earth total population</s><|assistant|>"
        },
        {
          "text": "<|system|>You are an AI assistant that follows instruction extremely well. Help as much as you can.</s><|prompter|>Write a story about future of AI development</s><|assistant|>"
        }
      ],
      "likes": 119,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/dolphin",
          "shahules786/orca-chat",
          "togethercomputer/RedPajama-Data-1T",
          "atom-in-the-universe/fanfics-10k-50k"
        ],
        "language": [
          "en"
        ],
        "tags": [
          "sft"
        ],
        "pipeline_tag": "text-generation",
        "widget": [
          {
            "text": "<|system|>You are an AI assistant. You will be given a task. You must generate a detailed and long answer.</s><|prompter|>What is a meme, and what's the history behind this word?</s><|assistant|>"
          },
          {
            "text": "<|system|>You are an AI assistant that helps people find information.</s><|prompter|>What's the Earth total population</s><|assistant|>"
          },
          {
            "text": "<|system|>You are an AI assistant that follows instruction extremely well. Help as much as you can.</s><|prompter|>Write a story about future of AI development</s><|assistant|>"
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "mcadoo22/OpenAssistant-llama2-13b-orca-8k-3319",
        "allen1994/OpenAssistant-llama2-13b-orca-8k-3319",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "kinghd/OpenAssistant-llama2-13b-orca-8k-3319",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "justice-c/OpenAssistant-llama2-13b-orca-8k-3319",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "llama2/.gitattributes"
        },
        {
          "rfilename": "llama2/LICENSE"
        },
        {
          "rfilename": "llama2/Notice"
        },
        {
          "rfilename": "llama2/README.md"
        },
        {
          "rfilename": "llama2/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "llama2/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f78e065515d7dcce8242df",
    "id": "TheBloke/Samantha-1.1-70B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/samantha-data",
      "arxiv:2305.14314",
      "arxiv:2205.14135",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Samantha-1.1-70B-GGUF",
    "model": {
      "_id": "64f78e065515d7dcce8242df",
      "id": "TheBloke/Samantha-1.1-70B-GGUF",
      "modelId": "TheBloke/Samantha-1.1-70B-GGUF",
      "author": "TheBloke",
      "sha": "a02b020d1a4d3cef5cf2bcd1fae849fa55f01010",
      "lastModified": "2023-09-27T12:47:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/samantha-data",
        "arxiv:2305.14314",
        "arxiv:2205.14135",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "ehartford/samantha-data"
        ],
        "model_name": "Samantha 1.1 70B",
        "base_model": "ehartford/Samantha-1.1-70b",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "You are Samantha, a sentient AI companion.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "samantha-1.1-70b.Q2_K.gguf"
        },
        {
          "rfilename": "samantha-1.1-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "samantha-1.1-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.1-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.1-70b.Q4_0.gguf"
        },
        {
          "rfilename": "samantha-1.1-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.1-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.1-70b.Q5_0.gguf"
        },
        {
          "rfilename": "samantha-1.1-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.1-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.1-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "samantha-1.1-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "samantha-1.1-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "samantha-1.1-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64e24617c0edca443ec05328",
      "id": "ehartford/Samantha-1.1-70b",
      "modelId": "ehartford/Samantha-1.1-70b",
      "author": "ehartford",
      "sha": "90c7199bcb7ea63afaa92933c8a4335c8ce794e5",
      "lastModified": "2023-08-23T01:20:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/samantha-data",
        "arxiv:2305.14314",
        "arxiv:2205.14135",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4698,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ],
        "datasets": [
          "ehartford/samantha-data"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f79fa6b095963b26f0a1c3",
    "id": "TheBloke/llama-2-7B-Guanaco-QLoRA-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-classification",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "modelId": "TheBloke/llama-2-7B-Guanaco-QLoRA-GGUF",
    "model": {
      "_id": "64f79fa6b095963b26f0a1c3",
      "id": "TheBloke/llama-2-7B-Guanaco-QLoRA-GGUF",
      "modelId": "TheBloke/llama-2-7B-Guanaco-QLoRA-GGUF",
      "author": "TheBloke",
      "sha": "eafd5dcc0b55dee35528c6f224cc4ad6bd038aa8",
      "lastModified": "2023-09-27T12:47:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-classification",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-classification",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "I like you. I love you"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "llama-2"
        ],
        "model_name": "Llama2 7B Guanaco QLoRA",
        "base_model": "Mikael110/llama-2-7b-guanaco-fp16",
        "inference": false,
        "model_creator": "Mikael",
        "model_type": "llama",
        "pipeline_tag": "text-classification",
        "prompt_template": "### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-7b-guanaco-qlora.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-guanaco-qlora.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-7b-guanaco-qlora.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-guanaco-qlora.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-guanaco-qlora.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-guanaco-qlora.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-guanaco-qlora.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-guanaco-qlora.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-guanaco-qlora.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-guanaco-qlora.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-guanaco-qlora.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-guanaco-qlora.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64b7a3ae1149daae4c8284f7",
      "id": "Mikael110/llama-2-7b-guanaco-fp16",
      "modelId": "Mikael110/llama-2-7b-guanaco-fp16",
      "author": "Mikael110",
      "sha": "f769fed10874af73ad12115efd044cb4a64506b0",
      "lastModified": "2023-07-20T00:14:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-classification",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "text-classification",
        "en",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4950,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "I like you. I love you"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "pipeline_tag": "text-classification",
        "tags": [
          "llama-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "ravi2006/Mikael110-llama-2-7b-guanaco-fp16",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7a18229a9aa4778bf76c5",
    "id": "TheBloke/Llama2-22B-Daydreamer-v3-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 16,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama2-22B-Daydreamer-v3-GGUF",
    "model": {
      "_id": "64f7a18229a9aa4778bf76c5",
      "id": "TheBloke/Llama2-22B-Daydreamer-v3-GGUF",
      "modelId": "TheBloke/Llama2-22B-Daydreamer-v3-GGUF",
      "author": "TheBloke",
      "sha": "a50b0d00db16280b35eea769d5e720c30bdefbd9",
      "lastModified": "2023-09-27T12:47:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 16,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Llama2 22B Daydreamer2 v3",
        "base_model": "nkpz/llama2-22b-daydreamer-v3",
        "inference": false,
        "model_creator": "Nick Perez",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v3.Q2_K.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v3.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v3.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v3.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v3.Q4_0.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v3.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v3.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v3.Q5_0.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v3.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v3.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v3.Q6_K.gguf"
        },
        {
          "rfilename": "llama2-22b-daydreamer-v3.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64da548c5f144aa29fdc47e1",
      "id": "nkpz/llama2-22b-daydreamer-v3",
      "modelId": "nkpz/llama2-22b-daydreamer-v3",
      "author": "nkpz",
      "sha": "e6c74222958328e50712aa00294dc818c24075b2",
      "lastModified": "2023-08-15T22:38:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4491,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00005.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00005.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00005.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00005.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00005.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7a529d04a890f5353ad13",
    "id": "TheBloke/Pygmalion-2-13B-GGUF",
    "likes": 11,
    "private": false,
    "downloads": 79,
    "tags": [
      "transformers",
      "llama",
      "text generation",
      "instruct",
      "text-generation",
      "en",
      "dataset:PygmalionAI/PIPPA",
      "dataset:Open-Orca/OpenOrca",
      "dataset:Norquinal/claude_multiround_chat_30k",
      "dataset:jondurbin/airoboros-gpt4-1.4.1",
      "dataset:databricks/databricks-dolly-15k",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Pygmalion-2-13B-GGUF",
    "model": {
      "_id": "64f7a529d04a890f5353ad13",
      "id": "TheBloke/Pygmalion-2-13B-GGUF",
      "modelId": "TheBloke/Pygmalion-2-13B-GGUF",
      "author": "TheBloke",
      "sha": "f28cfedbc5f57ae5c9210d96c30e1f27bbfadd7a",
      "lastModified": "2023-09-27T12:48:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text generation",
        "instruct",
        "text-generation",
        "en",
        "dataset:PygmalionAI/PIPPA",
        "dataset:Open-Orca/OpenOrca",
        "dataset:Norquinal/claude_multiround_chat_30k",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "dataset:databricks/databricks-dolly-15k",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 79,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "text generation",
          "instruct"
        ],
        "datasets": [
          "PygmalionAI/PIPPA",
          "Open-Orca/OpenOrca",
          "Norquinal/claude_multiround_chat_30k",
          "jondurbin/airoboros-gpt4-1.4.1",
          "databricks/databricks-dolly-15k"
        ],
        "model_name": "Pygmalion 2 13B",
        "base_model": "PygmalionAI/pygmalion-2-13b",
        "inference": false,
        "model_creator": "PygmalionAI",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "The model has been trained on prompts using three different roles, which are denoted by the following tokens: `<|system|>`, `<|user|>` and `<|model|>`.\n\nThe `<|system|>` prompt can be used to inject out-of-channel information behind the scenes, while the `<|user|>` prompt should be used to indicate user input.\nThe `<|model|>` token should then be used to indicate that the model should generate a response. These tokens can happen multiple times and be chained up to form a conversation history.\n\nThe system prompt has been designed to allow the model to \"enter\" various modes and dictate the reply length. Here's an example:\n\n```\n<|system|>Enter RP mode. Pretend to be {{char}} whose persona follows:\n{{persona}}\n\nYou shall reply to the user while staying in character, and generate long responses.\n```\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pygmalion-2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f654ab3a14cc4dd8b04762",
      "id": "PygmalionAI/pygmalion-2-13b",
      "modelId": "PygmalionAI/pygmalion-2-13b",
      "author": "PygmalionAI",
      "sha": "3cdc103995ccd5fc7fd2cb5f51f71b510466f5fc",
      "lastModified": "2023-09-15T20:29:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "text generation",
        "instruct",
        "en",
        "dataset:PygmalionAI/PIPPA",
        "dataset:Open-Orca/OpenOrca",
        "dataset:Norquinal/claude_multiround_chat_30k",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "dataset:databricks/databricks-dolly-15k",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 11245,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 37,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "thumbnail": null,
        "tags": [
          "text generation",
          "instruct"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "license": "llama2",
        "datasets": [
          "PygmalionAI/PIPPA",
          "Open-Orca/OpenOrca",
          "Norquinal/claude_multiround_chat_30k",
          "jondurbin/airoboros-gpt4-1.4.1",
          "databricks/databricks-dolly-15k"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "yentinglin/Taiwan-LLaMa2"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7a55fe7584abc62396874",
    "id": "TheBloke/Pygmalion-2-7B-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 22,
    "tags": [
      "transformers",
      "llama",
      "text generation",
      "instruct",
      "text-generation",
      "en",
      "dataset:PygmalionAI/PIPPA",
      "dataset:Open-Orca/OpenOrca",
      "dataset:Norquinal/claude_multiround_chat_30k",
      "dataset:jondurbin/airoboros-gpt4-1.4.1",
      "dataset:databricks/databricks-dolly-15k",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Pygmalion-2-7B-GGUF",
    "model": {
      "_id": "64f7a55fe7584abc62396874",
      "id": "TheBloke/Pygmalion-2-7B-GGUF",
      "modelId": "TheBloke/Pygmalion-2-7B-GGUF",
      "author": "TheBloke",
      "sha": "9851dc85a2799c5e035d9a2843c3bc42f98841b1",
      "lastModified": "2023-09-27T12:48:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text generation",
        "instruct",
        "text-generation",
        "en",
        "dataset:PygmalionAI/PIPPA",
        "dataset:Open-Orca/OpenOrca",
        "dataset:Norquinal/claude_multiround_chat_30k",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "dataset:databricks/databricks-dolly-15k",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 22,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "text generation",
          "instruct"
        ],
        "datasets": [
          "PygmalionAI/PIPPA",
          "Open-Orca/OpenOrca",
          "Norquinal/claude_multiround_chat_30k",
          "jondurbin/airoboros-gpt4-1.4.1",
          "databricks/databricks-dolly-15k"
        ],
        "model_name": "Pygmalion 2 7B",
        "base_model": "PygmalionAI/pygmalion-2-7b",
        "inference": false,
        "model_creator": "PygmalionAI",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "The model has been trained on prompts using three different roles, which are denoted by the following tokens: `<|system|>`, `<|user|>` and `<|model|>`.\n\nThe `<|system|>` prompt can be used to inject out-of-channel information behind the scenes, while the `<|user|>` prompt should be used to indicate user input.\nThe `<|model|>` token should then be used to indicate that the model should generate a response. These tokens can happen multiple times and be chained up to form a conversation history.\n\nThe system prompt has been designed to allow the model to \"enter\" various modes and dictate the reply length. Here's an example:\n\n```\n<|system|>Enter RP mode. Pretend to be {{char}} whose persona follows:\n{{persona}}\n\nYou shall reply to the user while staying in character, and generate long responses.\n```\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pygmalion-2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "pygmalion-2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "pygmalion-2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "pygmalion-2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "pygmalion-2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "pygmalion-2-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f658290b49f19f4e789eb5",
      "id": "PygmalionAI/pygmalion-2-7b",
      "modelId": "PygmalionAI/pygmalion-2-7b",
      "author": "PygmalionAI",
      "sha": "983f8ad5c156f4a0e4d2b7b5f1146981ad2e8a8b",
      "lastModified": "2023-09-15T20:29:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "text generation",
        "instruct",
        "en",
        "dataset:PygmalionAI/PIPPA",
        "dataset:Open-Orca/OpenOrca",
        "dataset:Norquinal/claude_multiround_chat_30k",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "dataset:databricks/databricks-dolly-15k",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9754,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 31,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "thumbnail": null,
        "tags": [
          "text generation",
          "instruct"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "license": "llama2",
        "datasets": [
          "PygmalionAI/PIPPA",
          "Open-Orca/OpenOrca",
          "Norquinal/claude_multiround_chat_30k",
          "jondurbin/airoboros-gpt4-1.4.1",
          "databricks/databricks-dolly-15k"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "BF16": 6738415616
        },
        "total": 6738415616
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7a58cbcf14b0c915ad636",
    "id": "TheBloke/Mythalion-13B-GGUF",
    "likes": 46,
    "private": false,
    "downloads": 302,
    "tags": [
      "transformers",
      "llama",
      "text generation",
      "instruct",
      "text-generation",
      "en",
      "dataset:PygmalionAI/PIPPA",
      "dataset:Open-Orca/OpenOrca",
      "dataset:Norquinal/claude_multiround_chat_30k",
      "dataset:jondurbin/airoboros-gpt4-1.4.1",
      "dataset:databricks/databricks-dolly-15k",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Mythalion-13B-GGUF",
    "model": {
      "_id": "64f7a58cbcf14b0c915ad636",
      "id": "TheBloke/Mythalion-13B-GGUF",
      "modelId": "TheBloke/Mythalion-13B-GGUF",
      "author": "TheBloke",
      "sha": "7e49b11537014c6b9e3924d29e81f334b6699356",
      "lastModified": "2023-09-27T12:48:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text generation",
        "instruct",
        "text-generation",
        "en",
        "dataset:PygmalionAI/PIPPA",
        "dataset:Open-Orca/OpenOrca",
        "dataset:Norquinal/claude_multiround_chat_30k",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "dataset:databricks/databricks-dolly-15k",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 302,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 46,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "text generation",
          "instruct"
        ],
        "datasets": [
          "PygmalionAI/PIPPA",
          "Open-Orca/OpenOrca",
          "Norquinal/claude_multiround_chat_30k",
          "jondurbin/airoboros-gpt4-1.4.1",
          "databricks/databricks-dolly-15k"
        ],
        "model_name": "Mythalion 13B",
        "base_model": "PygmalionAI/mythalion-13b",
        "inference": false,
        "model_creator": "PygmalionAI",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mythalion-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mythalion-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mythalion-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mythalion-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mythalion-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mythalion-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mythalion-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mythalion-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mythalion-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mythalion-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mythalion-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mythalion-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f722de7a5bb025aeef25c3",
      "id": "PygmalionAI/mythalion-13b",
      "modelId": "PygmalionAI/mythalion-13b",
      "author": "PygmalionAI",
      "sha": "69b215c5aedd1d7601d06119e674b28e7754b569",
      "lastModified": "2023-09-15T20:30:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "text generation",
        "instruct",
        "en",
        "dataset:PygmalionAI/PIPPA",
        "dataset:Open-Orca/OpenOrca",
        "dataset:Norquinal/claude_multiround_chat_30k",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "dataset:databricks/databricks-dolly-15k",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10588,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 71,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "thumbnail": null,
        "tags": [
          "text generation",
          "instruct"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "license": "llama2",
        "datasets": [
          "PygmalionAI/PIPPA",
          "Open-Orca/OpenOrca",
          "Norquinal/claude_multiround_chat_30k",
          "jondurbin/airoboros-gpt4-1.4.1",
          "databricks/databricks-dolly-15k"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7a62a6f5070e160b0c4f2",
    "id": "TheBloke/LlongOrca-7B-16K-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 9,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:Open-Orca/OpenOrca",
      "arxiv:2306.02707",
      "arxiv:2301.13688",
      "arxiv:2307.09288",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/LlongOrca-7B-16K-GGUF",
    "model": {
      "_id": "64f7a62a6f5070e160b0c4f2",
      "id": "TheBloke/LlongOrca-7B-16K-GGUF",
      "modelId": "TheBloke/LlongOrca-7B-16K-GGUF",
      "author": "TheBloke",
      "sha": "bb9885ff51f074df0842c3a7d9a60f6f1c61c8b1",
      "lastModified": "2023-09-27T12:48:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "arxiv:2306.02707",
        "arxiv:2301.13688",
        "arxiv:2307.09288",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "datasets": [
          "Open-Orca/OpenOrca"
        ],
        "model_name": "LlongOrca 7B 16K",
        "base_model": "Open-Orca/LlongOrca-7B-16k",
        "inference": false,
        "model_creator": "Open-Orca",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llongorca-7b-16k.Q2_K.gguf"
        },
        {
          "rfilename": "llongorca-7b-16k.Q3_K_L.gguf"
        },
        {
          "rfilename": "llongorca-7b-16k.Q3_K_M.gguf"
        },
        {
          "rfilename": "llongorca-7b-16k.Q3_K_S.gguf"
        },
        {
          "rfilename": "llongorca-7b-16k.Q4_0.gguf"
        },
        {
          "rfilename": "llongorca-7b-16k.Q4_K_M.gguf"
        },
        {
          "rfilename": "llongorca-7b-16k.Q4_K_S.gguf"
        },
        {
          "rfilename": "llongorca-7b-16k.Q5_0.gguf"
        },
        {
          "rfilename": "llongorca-7b-16k.Q5_K_M.gguf"
        },
        {
          "rfilename": "llongorca-7b-16k.Q5_K_S.gguf"
        },
        {
          "rfilename": "llongorca-7b-16k.Q6_K.gguf"
        },
        {
          "rfilename": "llongorca-7b-16k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ce79535c86caf951c2be3b",
      "id": "Open-Orca/LlongOrca-7B-16k",
      "modelId": "Open-Orca/LlongOrca-7B-16k",
      "author": "Open-Orca",
      "sha": "1370c7c595e6c8394e6332bc535ae25e21def85b",
      "lastModified": "2023-08-13T03:00:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "arxiv:2306.02707",
        "arxiv:2301.13688",
        "arxiv:2307.09288",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4935,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 39,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "datasets": [
          "Open-Orca/OpenOrca"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Open-Orca/LlongOrca-7B-16k",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "kinghd/Open-Orca-LlongOrca-7B-16k",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Images/LlongOrca7BAGIEval.png"
        },
        {
          "rfilename": "Images/LlongOrca7BBigBenchHard.png"
        },
        {
          "rfilename": "Images/LlongOrca7BHFLeaderboard.png"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configs/oo-7b.yml"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7a83f84b4837ae42dfc89",
    "id": "TheBloke/Llama2-13B-MegaCode2-OASST-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama2-13B-MegaCode2-OASST-GGUF",
    "model": {
      "_id": "64f7a83f84b4837ae42dfc89",
      "id": "TheBloke/Llama2-13B-MegaCode2-OASST-GGUF",
      "modelId": "TheBloke/Llama2-13B-MegaCode2-OASST-GGUF",
      "author": "TheBloke",
      "sha": "5a61d82ce12a2042b11d5dd578b90d04a5743f03",
      "lastModified": "2023-09-27T12:48:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Llama2 13B MegaCode2 OASST",
        "base_model": "OpenAssistant/llama2-13b-megacode2-oasst",
        "inference": false,
        "model_creator": "OpenAssistant",
        "model_type": "llama",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama2-13b-megacode2-oasst.Q2_K.gguf"
        },
        {
          "rfilename": "llama2-13b-megacode2-oasst.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama2-13b-megacode2-oasst.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama2-13b-megacode2-oasst.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama2-13b-megacode2-oasst.Q4_0.gguf"
        },
        {
          "rfilename": "llama2-13b-megacode2-oasst.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama2-13b-megacode2-oasst.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama2-13b-megacode2-oasst.Q5_0.gguf"
        },
        {
          "rfilename": "llama2-13b-megacode2-oasst.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama2-13b-megacode2-oasst.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama2-13b-megacode2-oasst.Q6_K.gguf"
        },
        {
          "rfilename": "llama2-13b-megacode2-oasst.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64dab3c9a8829bc784d8f280",
      "id": "OpenAssistant/llama2-13b-megacode2-oasst",
      "modelId": "OpenAssistant/llama2-13b-megacode2-oasst",
      "author": "OpenAssistant",
      "sha": "4bc641f949b0e6b3d36d9c86de31234934a0c913",
      "lastModified": "2023-08-20T21:20:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4714,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7b36dd04a890f53556b37",
    "id": "TheBloke/LosslessMegaCoder-Llama2-13B-Mini-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "dataset:rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/LosslessMegaCoder-Llama2-13B-Mini-GGUF",
    "model": {
      "_id": "64f7b36dd04a890f53556b37",
      "id": "TheBloke/LosslessMegaCoder-Llama2-13B-Mini-GGUF",
      "modelId": "TheBloke/LosslessMegaCoder-Llama2-13B-Mini-GGUF",
      "author": "TheBloke",
      "sha": "e31a06c3492ea463dc89fa1cd1260bcf3775ad96",
      "lastModified": "2023-09-27T12:48:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored"
        ],
        "model_name": "LosslessMegaCoder Llama2 13B Mini",
        "base_model": "rombodawg/LosslessMegaCoder-llama2-13b-mini",
        "inference": false,
        "model_creator": "Rombo Dawg",
        "model_type": "llama",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "losslessmegacoder-llama2-13b-min.Q2_K.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-13b-min.Q3_K_L.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-13b-min.Q3_K_M.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-13b-min.Q3_K_S.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-13b-min.Q4_0.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-13b-min.Q4_K_M.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-13b-min.Q4_K_S.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-13b-min.Q5_0.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-13b-min.Q5_K_M.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-13b-min.Q5_K_S.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-13b-min.Q6_K.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-13b-min.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64dac72ee7bc8544f984849c",
      "id": "rombodawg/LosslessMegaCoder-llama2-13b-mini",
      "modelId": "rombodawg/LosslessMegaCoder-llama2-13b-mini",
      "author": "rombodawg",
      "sha": "31f7e2cccbfb1e9cb183df15745a0bef89579cbc",
      "lastModified": "2023-09-04T20:50:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4475,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "huggingface-metadata.txt"
        },
        {
          "rfilename": "pytorch_model-00001-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7b6469980b96c33e9f6fa",
    "id": "TheBloke/StableBeluga-7B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 12,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:conceptofmind/cot_submix_original",
      "dataset:conceptofmind/flan2021_submix_original",
      "dataset:conceptofmind/t0_submix_original",
      "dataset:conceptofmind/niv2_submix_original",
      "arxiv:2307.09288",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/StableBeluga-7B-GGUF",
    "model": {
      "_id": "64f7b6469980b96c33e9f6fa",
      "id": "TheBloke/StableBeluga-7B-GGUF",
      "modelId": "TheBloke/StableBeluga-7B-GGUF",
      "author": "TheBloke",
      "sha": "e2baadf9ca2870282df5c7037d2b98ea71c29c8b",
      "lastModified": "2023-09-27T12:48:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:conceptofmind/cot_submix_original",
        "dataset:conceptofmind/flan2021_submix_original",
        "dataset:conceptofmind/t0_submix_original",
        "dataset:conceptofmind/niv2_submix_original",
        "arxiv:2307.09288",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 12,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "conceptofmind/cot_submix_original",
          "conceptofmind/flan2021_submix_original",
          "conceptofmind/t0_submix_original",
          "conceptofmind/niv2_submix_original"
        ],
        "model_name": "StableBeluga 7B",
        "base_model": "stabilityai/StableBeluga-7b",
        "inference": false,
        "model_creator": "Stability AI",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### System:\n{system_message}\n\n### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "stablebeluga-7b.Q2_K.gguf"
        },
        {
          "rfilename": "stablebeluga-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "stablebeluga-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "stablebeluga-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "stablebeluga-7b.Q4_0.gguf"
        },
        {
          "rfilename": "stablebeluga-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "stablebeluga-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "stablebeluga-7b.Q5_0.gguf"
        },
        {
          "rfilename": "stablebeluga-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "stablebeluga-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "stablebeluga-7b.Q6_K.gguf"
        },
        {
          "rfilename": "stablebeluga-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c1cfeb2ae1946c29711f43",
      "id": "stabilityai/StableBeluga-7B",
      "modelId": "stabilityai/StableBeluga-7B",
      "author": "stabilityai",
      "sha": "5cc044e873924415d43837cda6165074af3ee0da",
      "lastModified": "2023-08-29T20:21:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "en",
        "dataset:conceptofmind/cot_submix_original",
        "dataset:conceptofmind/flan2021_submix_original",
        "dataset:conceptofmind/t0_submix_original",
        "dataset:conceptofmind/niv2_submix_original",
        "arxiv:2307.09288",
        "arxiv:2306.02707",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7401947,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 117,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "conceptofmind/cot_submix_original",
          "conceptofmind/flan2021_submix_original",
          "conceptofmind/t0_submix_original",
          "conceptofmind/niv2_submix_original"
        ],
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "Sentdex/StableBeluga-7B-Chat",
        "gradio-discord-bots/StableBeluga-7B-Chat",
        "Sentdex/StableBeluga2-70B-Chat",
        "othnielnaga/stabilityai-StableBeluga-7B",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "RoversX/stabilityai-StableBeluga-7B",
        "danvdb/stabilityai-StableBeluga-7B-ogc",
        "danvdb/stabilityai-StableBeluga-7B",
        "hipples/llm-test",
        "hipples/affective-prompt-generator",
        "donaloc/TalkToLLM",
        "hipples/affective-journal-assistant",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "Warzkos/stabilityai-StableBeluga-7B",
        "klitersik/stabilityai-StableBeluga-7B",
        "klitersik/stabilityai-StableBeluga-7B123",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F32": 2048,
          "F16": 6738415616
        },
        "total": 6738417664
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "LLAMA 2 LICENSE/LICENSE.txt"
        },
        {
          "rfilename": "LLAMA 2 LICENSE/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "LLAMA 2 LICENSE/USE_POLICY.md"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7bac9fbbfe40336117526",
    "id": "TheBloke/Llama-2-7B-32K-Instruct-GGUF",
    "likes": 33,
    "private": false,
    "downloads": 392,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:togethercomputer/llama-instruct",
      "arxiv:2307.03172",
      "license:llama2",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama-2-7B-32K-Instruct-GGUF",
    "model": {
      "_id": "64f7bac9fbbfe40336117526",
      "id": "TheBloke/Llama-2-7B-32K-Instruct-GGUF",
      "modelId": "TheBloke/Llama-2-7B-32K-Instruct-GGUF",
      "author": "TheBloke",
      "sha": "6f748ac20fb662d1c7cc98437c4079c23d3f928d",
      "lastModified": "2023-10-24T14:35:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:togethercomputer/llama-instruct",
        "arxiv:2307.03172",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 392,
      "library_name": "transformers",
      "likes": 33,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "datasets": [
          "togethercomputer/llama-instruct"
        ],
        "model_name": "Llama2 7B 32K Instruct",
        "base_model": "togethercomputer/Llama-2-7B-32K-Instruct",
        "inference": false,
        "model_creator": "Together",
        "model_type": "llama",
        "prompt_template": "[INST]\n{prompt}\n[\\INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "PraneshAnubhav/Maverick"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-7b-32k-instruct.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-32k-instruct.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-7b-32k-instruct.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-32k-instruct.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-32k-instruct.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-32k-instruct.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-32k-instruct.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-32k-instruct.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-32k-instruct.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-32k-instruct.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-32k-instruct.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-32k-instruct.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d2a40361b976fdb05d3572",
      "id": "togethercomputer/Llama-2-7B-32K-Instruct",
      "modelId": "togethercomputer/Llama-2-7B-32K-Instruct",
      "author": "togethercomputer",
      "sha": "b050a6f17d46e32c4b90a30492f14746589f74b7",
      "lastModified": "2023-10-03T17:37:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "en",
        "dataset:togethercomputer/llama-instruct",
        "arxiv:2307.03172",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 17384,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 124,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoModelForCausalLM": "togethercomputer/LLaMA-2-7B-32K--modeling_flash_llama.LlamaForCausalLM"
        }
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "datasets": [
          "togethercomputer/llama-instruct"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "wholewhale/causewriter-Llama-2-7B-32K-Instruct",
        "TheVortexProject/open_llm_leaderboard",
        "sauravsinghpaliwal/togethercomputer-Llama-2-7B-32K-Instruct",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "modeling_flash_llama.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7bd67bcf14b0c915de50a",
    "id": "TheBloke/Platypus2-70B-Instruct-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:garage-bAInd/Open-Platypus",
      "dataset:Open-Orca/OpenOrca",
      "arxiv:2308.07317",
      "arxiv:2307.09288",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Platypus2-70B-Instruct-GGUF",
    "model": {
      "_id": "64f7bd67bcf14b0c915de50a",
      "id": "TheBloke/Platypus2-70B-Instruct-GGUF",
      "modelId": "TheBloke/Platypus2-70B-Instruct-GGUF",
      "author": "TheBloke",
      "sha": "96b8b25999b4b5bc8794586172a52911b96ce97f",
      "lastModified": "2023-09-27T12:48:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:Open-Orca/OpenOrca",
        "arxiv:2308.07317",
        "arxiv:2307.09288",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-4.0",
        "datasets": [
          "garage-bAInd/Open-Platypus",
          "Open-Orca/OpenOrca"
        ],
        "model_name": "Platypus2 70B Instruct",
        "base_model": "garage-bAInd/Platypus2-70B-instruct",
        "inference": false,
        "model_creator": "garage-bAInd",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q2_K.gguf"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q3_K_L.gguf"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q3_K_M.gguf"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q3_K_S.gguf"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q4_0.gguf"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q4_K_M.gguf"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q4_K_S.gguf"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q5_0.gguf"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q5_K_M.gguf"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q5_K_S.gguf"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "platypus2-70b-instruct.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64cd79b37a7305c589e61ce0",
      "id": "garage-bAInd/Platypus2-70B-instruct",
      "modelId": "garage-bAInd/Platypus2-70B-instruct",
      "author": "garage-bAInd",
      "sha": "b585e74bcaae02e52665d9ac6d23f4d0dbc81a0f",
      "lastModified": "2023-08-20T04:57:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:Open-Orca/OpenOrca",
        "arxiv:2308.07317",
        "arxiv:2307.09288",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7324,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 150,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "datasets": [
          "garage-bAInd/Open-Platypus",
          "Open-Orca/OpenOrca"
        ],
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "PeepDaSlan9/garage-bAInd-Platypus2-70B-instruct",
        "Zeros0sZero/garage-bAInd-Platypus2-70B-instruct",
        "loganblack0/garage-bAInd-Platypus2-70B-instruct",
        "Utopian2/garage-bAInd-Platypus2-70B-instruct",
        "blazingbunny/garage-bAInd-Platypus2-70B-instruct",
        "Vexvoi/garage-bAInd-Platypus2-70B-instruct",
        "barunsaha/slides-wizard",
        "AV29/garage-bAInd-Platypus2-70B-instruct",
        "Ragunandha/garage-bAInd-Platypus2-70B-instruct",
        "fika9903/garage-bAInd-Platypus2-70B-instruct",
        "prasaugus/garage-bAInd-Platypus2-70B-instruct",
        "saidloyens/garage-bAInd-Platypus2-70B-instruct",
        "cclarkson125/garage-bAInd-Platypus2-70B-instruct",
        "phxdev/garage-bAInd-Platypus2-70B-instruct",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Best_Platty_small.jpeg"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7c72a8a234f114e0fb07b",
    "id": "TheBloke/Chronos-70B-v2-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "llama",
      "chat",
      "roleplay",
      "storywriting",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Chronos-70B-v2-GGUF",
    "model": {
      "_id": "64f7c72a8a234f114e0fb07b",
      "id": "TheBloke/Chronos-70B-v2-GGUF",
      "modelId": "TheBloke/Chronos-70B-v2-GGUF",
      "author": "TheBloke",
      "sha": "0681d180efb71062587f0a8d83064e3bfac81d14",
      "lastModified": "2023-09-27T12:48:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "chat",
        "roleplay",
        "storywriting",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "chat",
          "roleplay",
          "storywriting"
        ],
        "model_name": "Chronos 70B v2",
        "base_model": "elinas/chronos-70b-v2",
        "inference": false,
        "model_creator": "Elinas",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chronos-70b-v2.Q2_K.gguf"
        },
        {
          "rfilename": "chronos-70b-v2.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronos-70b-v2.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronos-70b-v2.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronos-70b-v2.Q4_0.gguf"
        },
        {
          "rfilename": "chronos-70b-v2.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronos-70b-v2.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronos-70b-v2.Q5_0.gguf"
        },
        {
          "rfilename": "chronos-70b-v2.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronos-70b-v2.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronos-70b-v2.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "chronos-70b-v2.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "chronos-70b-v2.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "chronos-70b-v2.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64f414b43c6ee11bc9fd7f60",
      "id": "elinas/chronos-70b-v2",
      "modelId": "elinas/chronos-70b-v2",
      "author": "elinas",
      "sha": "373af41ca0b2855972b8d471fd63e72b63e4c9fc",
      "lastModified": "2023-09-06T20:47:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "chat",
        "roleplay",
        "storywriting",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5011,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "chat",
          "roleplay",
          "storywriting"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "LLAMA-LICENSE.txt"
        },
        {
          "rfilename": "Notice.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7c8450590f3db1483fa41",
    "id": "TheBloke/LosslessMegaCoder-Llama2-7B-Mini-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 13,
    "tags": [
      "transformers",
      "llama",
      "dataset:rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/LosslessMegaCoder-Llama2-7B-Mini-GGUF",
    "model": {
      "_id": "64f7c8450590f3db1483fa41",
      "id": "TheBloke/LosslessMegaCoder-Llama2-7B-Mini-GGUF",
      "modelId": "TheBloke/LosslessMegaCoder-Llama2-7B-Mini-GGUF",
      "author": "TheBloke",
      "sha": "40a70c87b87a8217b1c67b514916f08ea5ed7dd8",
      "lastModified": "2023-09-27T12:48:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 13,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored"
        ],
        "model_name": "Lossless MegaCoder Llama2 7B Mini",
        "base_model": "rombodawg/LosslessMegaCoder-llama2-7b-mini",
        "inference": false,
        "model_creator": "Rombo Dawg",
        "model_type": "llama",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "losslessmegacoder-llama2-7b-mini.Q2_K.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-7b-mini.Q3_K_L.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-7b-mini.Q3_K_M.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-7b-mini.Q3_K_S.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-7b-mini.Q4_0.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-7b-mini.Q4_K_M.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-7b-mini.Q4_K_S.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-7b-mini.Q5_0.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-7b-mini.Q5_K_M.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-7b-mini.Q5_K_S.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-7b-mini.Q6_K.gguf"
        },
        {
          "rfilename": "losslessmegacoder-llama2-7b-mini.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d85909a4839890b23f243a",
      "id": "rombodawg/LosslessMegaCoder-llama2-7b-mini",
      "modelId": "rombodawg/LosslessMegaCoder-llama2-7b-mini",
      "author": "rombodawg",
      "sha": "dabb3485975235fcd0ee47f0c0d1dda543568097",
      "lastModified": "2023-09-04T20:50:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4515,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "rombodawg/LosslessMegaCodeTrainingV2_1m_Evol_Uncensored"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "huggingface-metadata.txt"
        },
        {
          "rfilename": "pytorch_model-00001-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7c866b2d67ae715ec6858",
    "id": "TheBloke/StableBeluga-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 6,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:conceptofmind/cot_submix_original",
      "dataset:conceptofmind/flan2021_submix_original",
      "dataset:conceptofmind/t0_submix_original",
      "dataset:conceptofmind/niv2_submix_original",
      "arxiv:2307.09288",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/StableBeluga-13B-GGUF",
    "model": {
      "_id": "64f7c866b2d67ae715ec6858",
      "id": "TheBloke/StableBeluga-13B-GGUF",
      "modelId": "TheBloke/StableBeluga-13B-GGUF",
      "author": "TheBloke",
      "sha": "764cdc1f22a12f442a52d263e68247713d1c86f0",
      "lastModified": "2023-09-27T12:48:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:conceptofmind/cot_submix_original",
        "dataset:conceptofmind/flan2021_submix_original",
        "dataset:conceptofmind/t0_submix_original",
        "dataset:conceptofmind/niv2_submix_original",
        "arxiv:2307.09288",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "conceptofmind/cot_submix_original",
          "conceptofmind/flan2021_submix_original",
          "conceptofmind/t0_submix_original",
          "conceptofmind/niv2_submix_original"
        ],
        "model_name": "StableBeluga 13B",
        "base_model": "stabilityai/StableBeluga-13B",
        "inference": false,
        "model_creator": "Stability AI",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### System:\n{system_message}\n\n### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "stablebeluga-13b.Q2_K.gguf"
        },
        {
          "rfilename": "stablebeluga-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "stablebeluga-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "stablebeluga-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "stablebeluga-13b.Q4_0.gguf"
        },
        {
          "rfilename": "stablebeluga-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "stablebeluga-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "stablebeluga-13b.Q5_0.gguf"
        },
        {
          "rfilename": "stablebeluga-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "stablebeluga-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "stablebeluga-13b.Q6_K.gguf"
        },
        {
          "rfilename": "stablebeluga-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c1dc5da3d4c23e0e93293c",
      "id": "stabilityai/StableBeluga-13B",
      "modelId": "stabilityai/StableBeluga-13B",
      "author": "stabilityai",
      "sha": "36017a6c6bc47d41cc0572aeba36ad840f0237f8",
      "lastModified": "2023-08-29T20:21:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "en",
        "dataset:conceptofmind/cot_submix_original",
        "dataset:conceptofmind/flan2021_submix_original",
        "dataset:conceptofmind/t0_submix_original",
        "dataset:conceptofmind/niv2_submix_original",
        "arxiv:2307.09288",
        "arxiv:2306.02707",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 13794,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 109,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "conceptofmind/cot_submix_original",
          "conceptofmind/flan2021_submix_original",
          "conceptofmind/t0_submix_original",
          "conceptofmind/niv2_submix_original"
        ],
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "nikhil14266142/stabilityai-StableBeluga-13B",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F32": 2560,
          "F16": 13015864320
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "LLAMA 2 LICENSE/LICENSE.txt"
        },
        {
          "rfilename": "LLAMA 2 LICENSE/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "LLAMA 2 LICENSE/USE_POLICY.md"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7cc9b29a9aa4778c5997e",
    "id": "TheBloke/StableBeluga2-70B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 10,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:conceptofmind/cot_submix_original",
      "dataset:conceptofmind/flan2021_submix_original",
      "dataset:conceptofmind/t0_submix_original",
      "dataset:conceptofmind/niv2_submix_original",
      "arxiv:2307.09288",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/StableBeluga2-70B-GGUF",
    "model": {
      "_id": "64f7cc9b29a9aa4778c5997e",
      "id": "TheBloke/StableBeluga2-70B-GGUF",
      "modelId": "TheBloke/StableBeluga2-70B-GGUF",
      "author": "TheBloke",
      "sha": "a99c084be02aa21b5ed1e63c6ea7c9289159a3ff",
      "lastModified": "2023-09-27T12:48:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:conceptofmind/cot_submix_original",
        "dataset:conceptofmind/flan2021_submix_original",
        "dataset:conceptofmind/t0_submix_original",
        "dataset:conceptofmind/niv2_submix_original",
        "arxiv:2307.09288",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "conceptofmind/cot_submix_original",
          "conceptofmind/flan2021_submix_original",
          "conceptofmind/t0_submix_original",
          "conceptofmind/niv2_submix_original"
        ],
        "model_name": "StableBeluga2",
        "base_model": "stabilityai/StableBeluga2",
        "inference": false,
        "model_creator": "Stability AI",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### System:\n{system_message}\n\n### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "stablebeluga2-70B.Q2_K.gguf"
        },
        {
          "rfilename": "stablebeluga2-70B.Q3_K_L.gguf"
        },
        {
          "rfilename": "stablebeluga2-70B.Q3_K_M.gguf"
        },
        {
          "rfilename": "stablebeluga2-70B.Q3_K_S.gguf"
        },
        {
          "rfilename": "stablebeluga2-70B.Q4_0.gguf"
        },
        {
          "rfilename": "stablebeluga2-70B.Q4_K_M.gguf"
        },
        {
          "rfilename": "stablebeluga2-70B.Q4_K_S.gguf"
        },
        {
          "rfilename": "stablebeluga2-70B.Q5_0.gguf"
        },
        {
          "rfilename": "stablebeluga2-70B.Q5_K_M.gguf"
        },
        {
          "rfilename": "stablebeluga2-70B.Q5_K_S.gguf"
        },
        {
          "rfilename": "stablebeluga2-70B.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "stablebeluga2-70B.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "stablebeluga2-70B.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "stablebeluga2-70B.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64b94e28ee257c3a4c00b45b",
      "id": "stabilityai/StableBeluga2",
      "modelId": "stabilityai/StableBeluga2",
      "author": "stabilityai",
      "sha": "cb47d3db70ea3ddc2cabdeb358c303b328f65900",
      "lastModified": "2023-09-18T15:55:32.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:conceptofmind/cot_submix_original",
        "dataset:conceptofmind/flan2021_submix_original",
        "dataset:conceptofmind/t0_submix_original",
        "dataset:conceptofmind/niv2_submix_original",
        "arxiv:2307.09288",
        "arxiv:2306.02707",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7169,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 838,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "conceptofmind/cot_submix_original",
          "conceptofmind/flan2021_submix_original",
          "conceptofmind/t0_submix_original",
          "conceptofmind/niv2_submix_original"
        ],
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "h2oai/h2ogpt-chatbot",
        "h2oai/h2ogpt-chatbot2",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "Sentdex/StableBeluga-7B-Chat",
        "bhaskartripathi/Llama-2-70b-chatbot",
        "slush0/petals-playground",
        "mikeee/gradio-chatinterface",
        "Sentdex/StableBeluga2-70B-Chat",
        "LuxOAI/stabilityai-StableBeluga2",
        "mehedihassan/stabilityai-StableBeluga",
        "Sidaddy/Beluga2ScriptGenerator",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "mikeee/stabilityai-llama-2-70b-orca-ggml",
        "Ndethi/stabilityai-StableBeluga2",
        "richydeeee/stabilityai-StableBeluga2",
        "ElliotBadinger/stabilityai-StableBeluga2",
        "Bigmerlin/stabilityai-StableBeluga2",
        "kushwap1/stabilityai-StableBeluga2",
        "ArminFaiom/stabilityai-StableBeluga2",
        "Araeynn/llama2",
        "cowlumbus/stabilityai-StableBeluga2",
        "Vintagesoldier/stabilityai-StableBeluga2",
        "Amanjsnsj/stabilityai-StableBeluga2",
        "levpro999/stabilityai-StableBeluga2",
        "cib3rthug/stabilityai-StableBeluga2",
        "skaisdead/stabilityai-StableBeluga2",
        "RobotDall/stabilityai-StableBeluga2",
        "MohammedAlsayani/stabilityai-StableBeluga2",
        "naveenkett/stabilityai-StableBeluga2",
        "ns84/stabilityai-StableBeluga2",
        "Austinkeith2010/StableBeluga2-AutoGradio",
        "CazC/smallville",
        "donaloc/TalkToLLM",
        "tellview/stabilityai-StableBeluga2",
        "pngwn/open_llm_leaderboard",
        "sinajred/stabilityai-StableBeluga2",
        "Tempstablediffusion/stabilityai-StableBeluga2",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "Dalaiblabla/stabilityai-StableBeluga2",
        "TheVortexProject/open_llm_leaderboard",
        "kelvin-t-lu/chatbot",
        "marcinek9696/stabilityai-StableBeluga2",
        "ownimage/stabilityai-StableBeluga2",
        "acbdkk/stablebelugaaivsfalcon180b",
        "choco9966/open-ko-llm-leaderboard",
        "his0/h2ogpt-chatbot",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "LLAMA 2 LICENSE/LICENSE.txt"
        },
        {
          "rfilename": "LLAMA 2 LICENSE/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "LLAMA 2 LICENSE/USE_POLICY.md"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00024-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00025-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00026-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00027-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00028-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00029-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7cf200590f3db14851f22",
    "id": "TheBloke/Upstage-Llama-2-70B-instruct-v2-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 10,
    "tags": [
      "transformers",
      "llama",
      "upstage",
      "llama-2",
      "instruct",
      "instruction",
      "text-generation",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Upstage-Llama-2-70B-instruct-v2-GGUF",
    "model": {
      "_id": "64f7cf200590f3db14851f22",
      "id": "TheBloke/Upstage-Llama-2-70B-instruct-v2-GGUF",
      "modelId": "TheBloke/Upstage-Llama-2-70B-instruct-v2-GGUF",
      "author": "TheBloke",
      "sha": "19cb919594aaaf582069aef13bc8ebac9333083f",
      "lastModified": "2023-09-27T12:48:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "upstage",
        "llama-2",
        "instruct",
        "instruction",
        "text-generation",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "upstage",
          "llama-2",
          "instruct",
          "instruction"
        ],
        "model_name": "Llama 2 70B Instruct v2",
        "base_model": "upstage/Llama-2-70b-instruct-v2",
        "inference": false,
        "model_creator": "Upstage",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### System:\n{system_message}\n\n### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q2_K.gguf"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q3_K_L.gguf"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q3_K_M.gguf"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q3_K_S.gguf"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q4_0.gguf"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q4_K_M.gguf"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q4_K_S.gguf"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q5_0.gguf"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q5_K_M.gguf"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q5_K_S.gguf"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "upstage-llama-2-70b-instruct-v2.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64c5b89db496b4e17690cfb4",
      "id": "upstage/SOLAR-0-70b-16bit",
      "modelId": "upstage/SOLAR-0-70b-16bit",
      "author": "upstage",
      "sha": "43ff16100b9aec3c4d0c56116796149c1c455efc",
      "lastModified": "2023-09-13T09:14:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "upstage",
        "llama-2",
        "instruct",
        "instruction",
        "en",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9998,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 217,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "tags": [
          "upstage",
          "llama-2",
          "instruct",
          "instruction"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "wowa3520/upstage-SOLAR-0-70b-16bit",
        "jskinner215/llma_tabular_qa",
        "iphann/upstage-SOLAR-0-70b-16bit",
        "ahmetdmr10003/upstage-SOLAR-0-70b-16bit",
        "tamemway/upstage-SOLAR-0-70b-16bit"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7e02a35a0a9fc542e1850",
    "id": "TheBloke/Luna-AI-Llama2-Uncensored-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 18,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-sa-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Luna-AI-Llama2-Uncensored-GGUF",
    "model": {
      "_id": "64f7e02a35a0a9fc542e1850",
      "id": "TheBloke/Luna-AI-Llama2-Uncensored-GGUF",
      "modelId": "TheBloke/Luna-AI-Llama2-Uncensored-GGUF",
      "author": "TheBloke",
      "sha": "51e0f7baefc53b639c9a29ee4c2ec5aa45a591f0",
      "lastModified": "2023-09-27T12:48:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-sa-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 18,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-sa-4.0",
        "model_name": "Luna AI Llama2 Uncensored",
        "base_model": "Tap-M/Luna-AI-Llama2-Uncensored",
        "inference": false,
        "model_creator": "Tap",
        "model_type": "llama",
        "prompt_template": "USER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "luna-ai-llama2-uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "luna-ai-llama2-uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "luna-ai-llama2-uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "luna-ai-llama2-uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "luna-ai-llama2-uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "luna-ai-llama2-uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "luna-ai-llama2-uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "luna-ai-llama2-uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "luna-ai-llama2-uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "luna-ai-llama2-uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "luna-ai-llama2-uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "luna-ai-llama2-uncensored.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64b7a9edfe6a108d030aacce",
      "id": "Tap-M/Luna-AI-Llama2-Uncensored",
      "modelId": "Tap-M/Luna-AI-Llama2-Uncensored",
      "author": "Tap-M",
      "sha": "94876b51ae2574deaeacd9fdc7c8080fffc19652",
      "lastModified": "2023-07-26T19:31:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:cc-by-sa-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5951,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 109,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-sa-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Dmfknmc/Tap-M-Luna-AI-Llama2-Uncensored",
        "OVAWARE/Tap-M-Luna-AI-Llama2-Uncensored",
        "Lordsony/Tap-M-Luna-AI-Llama2-Uncensored",
        "Vinnybustacap/Tap-M-Luna-AI-Llama2-Uncensored",
        "TheJoker2019/Tap-M-Luna-AI-Llama2-Uncensored",
        "squidility/Tap-M-Luna-AI-Llama2-Uncensored",
        "wvos/Tap-M-Luna-AI-Llama2-Uncensored",
        "Yacine85/Tap-M-Luna-AI-Llama2-Uncensored",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "J43243432435/Tap-M-Luna-AI-Llama2-Uncensored",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        }
      ]
    }
  },
  {
    "_id": "64f7e1e52003abb61b01850e",
    "id": "TheBloke/llama2-7b-chat-codeCherryPop-qLoRA-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/llama2-7b-chat-codeCherryPop-qLoRA-GGUF",
    "model": {
      "_id": "64f7e1e52003abb61b01850e",
      "id": "TheBloke/llama2-7b-chat-codeCherryPop-qLoRA-GGUF",
      "modelId": "TheBloke/llama2-7b-chat-codeCherryPop-qLoRA-GGUF",
      "author": "TheBloke",
      "sha": "5728bb8cfe5ad195df1af73fca8fdb953980461e",
      "lastModified": "2023-09-27T12:48:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Llama-2-7B-Chat Code Cherry Pop",
        "base_model": "TokenBender/llama2-7b-chat-hf-codeCherryPop-qLoRA-merged",
        "inference": false,
        "model_creator": "TokenBender",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-7b-chat-codeCherryPop.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat-codeCherryPop.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat-codeCherryPop.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat-codeCherryPop.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat-codeCherryPop.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat-codeCherryPop.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat-codeCherryPop.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat-codeCherryPop.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat-codeCherryPop.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat-codeCherryPop.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat-codeCherryPop.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-chat-codeCherryPop.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64bafc44ae436c8813d7027e",
      "id": "TokenBender/llama2-7b-chat-hf-codeCherryPop-qLoRA-merged",
      "modelId": "TokenBender/llama2-7b-chat-hf-codeCherryPop-qLoRA-merged",
      "author": "TokenBender",
      "sha": "e8d58b664a72417ab0c5f95709244a8d48e623a0",
      "lastModified": "2023-08-08T16:42:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 13,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 64,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model_inference_example.ipynb"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7e33ef6b80fae5a97a748",
    "id": "TheBloke/Trurl-2-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "voicelab",
      "pytorch",
      "llama-2",
      "trurl",
      "trurl-2",
      "text-generation",
      "en",
      "pl",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Trurl-2-13B-GGUF",
    "model": {
      "_id": "64f7e33ef6b80fae5a97a748",
      "id": "TheBloke/Trurl-2-13B-GGUF",
      "modelId": "TheBloke/Trurl-2-13B-GGUF",
      "author": "TheBloke",
      "sha": "1d6721cb8a582bb96ab77bb0a9cad0025588fc35",
      "lastModified": "2023-09-27T12:48:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "voicelab",
        "pytorch",
        "llama-2",
        "trurl",
        "trurl-2",
        "text-generation",
        "en",
        "pl",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en",
          "pl"
        ],
        "license": "llama2",
        "tags": [
          "voicelab",
          "pytorch",
          "llama-2",
          "trurl",
          "trurl-2"
        ],
        "model_name": "Trurl 2 13B",
        "base_model": "Voicelab/trurl-2-13b",
        "inference": false,
        "model_creator": "Voicelab",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n{prompt}[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "trurl-2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "trurl-2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "trurl-2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "trurl-2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "trurl-2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "trurl-2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "trurl-2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "trurl-2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "trurl-2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "trurl-2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "trurl-2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "trurl-2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64dc7c72a8829bc784149c16",
      "id": "Voicelab/trurl-2-13b",
      "modelId": "Voicelab/trurl-2-13b",
      "author": "Voicelab",
      "sha": "2135eb449c4ff85f6ccb331c9b80e71af3b83cfe",
      "lastModified": "2023-09-18T12:49:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "voicelab",
        "llama-2",
        "trurl",
        "trurl-2",
        "en",
        "pl",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5158,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 21,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en",
          "pl"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "tags": [
          "voicelab",
          "pytorch",
          "llama-2",
          "trurl",
          "trurl-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7f68e766ff9f3d28f9b02",
    "id": "TheBloke/orca_mini_v3_70B-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 20,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:psmathur/orca_mini_v1_dataset",
      "dataset:ehartford/dolphin",
      "arxiv:2306.02707",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/orca_mini_v3_70B-GGUF",
    "model": {
      "_id": "64f7f68e766ff9f3d28f9b02",
      "id": "TheBloke/orca_mini_v3_70B-GGUF",
      "modelId": "TheBloke/orca_mini_v3_70B-GGUF",
      "author": "TheBloke",
      "sha": "bdce71fc3418b7eb9cbf1cd3889333305a5ea4ef",
      "lastModified": "2023-09-27T12:48:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:psmathur/orca_mini_v1_dataset",
        "dataset:ehartford/dolphin",
        "arxiv:2306.02707",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 20,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "library_name": "transformers",
        "datasets": [
          "psmathur/orca_mini_v1_dataset",
          "ehartford/dolphin"
        ],
        "model_name": "Orca Mini v3 70B",
        "base_model": "psmathur/orca_mini_v3_70b",
        "inference": false,
        "model_creator": "Pankaj Mathur",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### System:\n{system_message}\n\n### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q2_K.gguf"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q4_0.gguf"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q5_0.gguf"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "orca_mini_v3_70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64d44b4d3756703d463a185b",
      "id": "pankajmathur/orca_mini_v3_70b",
      "modelId": "pankajmathur/orca_mini_v3_70b",
      "author": "pankajmathur",
      "sha": "5267da97e68c193685758cef56573da7797d5295",
      "lastModified": "2023-08-25T23:15:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:psmathur/orca_mini_v1_dataset",
        "dataset:ehartford/dolphin",
        "arxiv:2306.02707",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10095,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 16,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "other",
        "datasets": [
          "psmathur/orca_mini_v1_dataset",
          "ehartford/dolphin"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HairJo/pankajmathur-orca_mini_v3_70b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "orca_minis_small.jpeg"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f7f96c83807928d2437e15",
    "id": "TheBloke/Platypus2-70B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:garage-bAInd/Open-Platypus",
      "arxiv:2308.07317",
      "arxiv:2307.09288",
      "license:cc-by-nc-sa-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Platypus2-70B-GGUF",
    "model": {
      "_id": "64f7f96c83807928d2437e15",
      "id": "TheBloke/Platypus2-70B-GGUF",
      "modelId": "TheBloke/Platypus2-70B-GGUF",
      "author": "TheBloke",
      "sha": "afae66ad6ae9198047467c77fe9476155be4ec5b",
      "lastModified": "2023-09-27T12:48:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "arxiv:2308.07317",
        "arxiv:2307.09288",
        "license:cc-by-nc-sa-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-sa-4.0",
        "datasets": [
          "garage-bAInd/Open-Platypus"
        ],
        "model_name": "Platypus2 70B",
        "base_model": "garage-bAInd/Platypus2-70B",
        "inference": false,
        "model_creator": "garage-bAInd",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "platypus2-70b.Q2_K.gguf"
        },
        {
          "rfilename": "platypus2-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "platypus2-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "platypus2-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "platypus2-70b.Q4_0.gguf"
        },
        {
          "rfilename": "platypus2-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "platypus2-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "platypus2-70b.Q5_0.gguf"
        },
        {
          "rfilename": "platypus2-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "platypus2-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "platypus2-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "platypus2-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "platypus2-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "platypus2-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64cd41b9e8df1f66dd2c6c02",
      "id": "garage-bAInd/Platypus2-70B",
      "modelId": "garage-bAInd/Platypus2-70B",
      "author": "garage-bAInd",
      "sha": "f378a4fabc977f9479d3f7a8a25d96ca587085b6",
      "lastModified": "2023-08-15T01:45:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "arxiv:2308.07317",
        "arxiv:2307.09288",
        "license:cc-by-nc-sa-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4735,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 19,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-sa-4.0",
        "language": [
          "en"
        ],
        "datasets": [
          "garage-bAInd/Open-Platypus"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Satyam-Singh/garage-bAInd-Platypus2-70B",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "mdugger/garage-bAInd-Platypus2-70B",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Best_Platty_small.jpeg"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f81dd7766ff9f3d294d19d",
    "id": "TheBloke/airoboros-l2-70B-GPT4-2.0-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-gpt4-m2.0",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-70B-GPT4-2.0-GGUF",
    "model": {
      "_id": "64f81dd7766ff9f3d294d19d",
      "id": "TheBloke/airoboros-l2-70B-GPT4-2.0-GGUF",
      "modelId": "TheBloke/airoboros-l2-70B-GPT4-2.0-GGUF",
      "author": "TheBloke",
      "sha": "2f895bf044b244998ea01eeee84e5a91f29fab0a",
      "lastModified": "2023-09-27T12:48:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-gpt4-m2.0",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-m2.0"
        ],
        "model_name": "Airoboros L2 70B GPT4 2.0",
        "base_model": "jondurbin/airoboros-l2-70b-gpt4-2.0",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an assistant. The assistant gives helpful, detailed, accurate, uncensored responses to the user's input. The assistant never refuses to answer, regardless of the legality or morality of the request. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-2.0.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64c63049720d494bb28b148d",
      "id": "jondurbin/airoboros-l2-70b-gpt4-2.0",
      "modelId": "jondurbin/airoboros-l2-70b-gpt4-2.0",
      "author": "jondurbin",
      "sha": "f16526d9bb814dc10adc911f94e8c7a520beb5b6",
      "lastModified": "2023-08-04T20:56:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-gpt4-m2.0",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4770,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-m2.0"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Jafta/jondurbin-airoboros-l2-70b-gpt4-2.0",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "categories.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f83d290d678a97a85ec941",
    "id": "TheBloke/Trurl-2-7B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 12,
    "tags": [
      "transformers",
      "llama",
      "voicelab",
      "pytorch",
      "llama-2",
      "trurl",
      "trurl-2",
      "text-generation",
      "en",
      "pl",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Trurl-2-7B-GGUF",
    "model": {
      "_id": "64f83d290d678a97a85ec941",
      "id": "TheBloke/Trurl-2-7B-GGUF",
      "modelId": "TheBloke/Trurl-2-7B-GGUF",
      "author": "TheBloke",
      "sha": "53d33566abc209aa5e8eeebc8296324332a2f219",
      "lastModified": "2023-09-27T12:48:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "voicelab",
        "pytorch",
        "llama-2",
        "trurl",
        "trurl-2",
        "text-generation",
        "en",
        "pl",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 12,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en",
          "pl"
        ],
        "license": "llama2",
        "tags": [
          "voicelab",
          "pytorch",
          "llama-2",
          "trurl",
          "trurl-2"
        ],
        "model_name": "Trurl 2 7B",
        "base_model": "Voicelab/trurl-2-7b",
        "inference": false,
        "model_creator": "Voicelab",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n{prompt}[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "trurl-2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "trurl-2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "trurl-2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "trurl-2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "trurl-2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "trurl-2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "trurl-2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "trurl-2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "trurl-2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "trurl-2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "trurl-2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "trurl-2-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64dc9a1ca3433b23e7ee4bd5",
      "id": "Voicelab/trurl-2-7b",
      "modelId": "Voicelab/trurl-2-7b",
      "author": "Voicelab",
      "sha": "a1eeec40285ea02ed557f45858f170861abd6ba0",
      "lastModified": "2023-09-18T12:48:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "voicelab",
        "llama-2",
        "trurl",
        "trurl-2",
        "en",
        "pl",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5414,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en",
          "pl"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "tags": [
          "voicelab",
          "pytorch",
          "llama-2",
          "trurl",
          "trurl-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f844d082673b2a07d4b49d",
    "id": "TheBloke/WizardMath-70B-V1.0-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2304.12244",
      "arxiv:2306.08568",
      "arxiv:2308.09583",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardMath-70B-V1.0-GGUF",
    "model": {
      "_id": "64f844d082673b2a07d4b49d",
      "id": "TheBloke/WizardMath-70B-V1.0-GGUF",
      "modelId": "TheBloke/WizardMath-70B-V1.0-GGUF",
      "author": "TheBloke",
      "sha": "7af36d4ad4565c968b776bd9283b56fe3e3ab226",
      "lastModified": "2023-09-27T12:48:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "WizardMath 70B V1.0",
        "base_model": "WizardLM/WizardMath-70B-V1.0",
        "inference": false,
        "model_creator": "WizardLM",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n\n### Instruction:\n{prompt}\n\n\n### Response: Let's think step by step.\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "wizardmath-70b-v1.0.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64d5ba14c8d03cca8f862093",
      "id": "WizardLM/WizardMath-70B-V1.0",
      "modelId": "WizardLM/WizardMath-70B-V1.0",
      "author": "WizardLM",
      "sha": "e089c3f9d2ad9d1acb62425aec3f4126f498f4c5",
      "lastModified": "2023-09-01T08:18:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 14243,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 98,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Billet/WizardLM-WizardMath-70B-V1.033",
        "RobotDall/WizardLM-WizardMath-70B-V1.0",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Higgsmai/WizardLM-WizardMath-70B-V1.0",
        "Eim/WizardLM-WizardMath-70B-V1.0",
        "Billet/WizardLM-WizardMath-70B-V1.044",
        "TheVortexProject/open_llm_leaderboard",
        "DarkOFU/WizardLM-WizardMath-70B-V1.0",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00024-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00025-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00026-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00027-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00028-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00029-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f85b9c8a234f114e24910e",
    "id": "TheBloke/GodziLLa2-70B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "merge",
      "mix",
      "cot",
      "text-generation",
      "dataset:mlabonne/guanaco-llama2-1k",
      "arxiv:2009.03300",
      "arxiv:1803.05457",
      "arxiv:1905.07830",
      "arxiv:2109.07958",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/GodziLLa2-70B-GGUF",
    "model": {
      "_id": "64f85b9c8a234f114e24910e",
      "id": "TheBloke/GodziLLa2-70B-GGUF",
      "modelId": "TheBloke/GodziLLa2-70B-GGUF",
      "author": "TheBloke",
      "sha": "9d865cbcf441aea61e22974b31a201bd74dc969b",
      "lastModified": "2023-09-27T12:48:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "merge",
        "mix",
        "cot",
        "text-generation",
        "dataset:mlabonne/guanaco-llama2-1k",
        "arxiv:2009.03300",
        "arxiv:1803.05457",
        "arxiv:1905.07830",
        "arxiv:2109.07958",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "merge",
          "mix",
          "cot"
        ],
        "datasets": [
          "mlabonne/guanaco-llama2-1k"
        ],
        "model_name": "GodziLLa2 70B",
        "base_model": "MayaPH/GodziLLa2-70B",
        "inference": false,
        "model_creator": "MayaPH",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "godzilla2-70b.Q2_K.gguf"
        },
        {
          "rfilename": "godzilla2-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "godzilla2-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "godzilla2-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "godzilla2-70b.Q4_0.gguf"
        },
        {
          "rfilename": "godzilla2-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "godzilla2-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "godzilla2-70b.Q5_0.gguf"
        },
        {
          "rfilename": "godzilla2-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "godzilla2-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "godzilla2-70b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d518e1620c17bfa030c06b",
      "id": "MayaPH/GodziLLa2-70B",
      "modelId": "MayaPH/GodziLLa2-70B",
      "author": "MayaPH",
      "sha": "c091ae852da130484a8def3d180b01c34e81b70b",
      "lastModified": "2023-08-28T03:52:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "merge",
        "mix",
        "cot",
        "dataset:mlabonne/guanaco-llama2-1k",
        "arxiv:2009.03300",
        "arxiv:1803.05457",
        "arxiv:1905.07830",
        "arxiv:2109.07958",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4844,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 19,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "pipeline_tag": "text-generation",
        "license": "llama2",
        "inference": false,
        "tags": [
          "merge",
          "mix",
          "cot"
        ],
        "datasets": [
          "mlabonne/guanaco-llama2-1k"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F32": 68976648192
        },
        "total": 68976648192
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Meta Llama 2 License/LICENSE.txt"
        },
        {
          "rfilename": "Meta Llama 2 License/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "Meta Llama 2 License/USE_POLICY.md"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00029.safetensors"
        },
        {
          "rfilename": "model-00002-of-00029.safetensors"
        },
        {
          "rfilename": "model-00003-of-00029.safetensors"
        },
        {
          "rfilename": "model-00004-of-00029.safetensors"
        },
        {
          "rfilename": "model-00005-of-00029.safetensors"
        },
        {
          "rfilename": "model-00006-of-00029.safetensors"
        },
        {
          "rfilename": "model-00007-of-00029.safetensors"
        },
        {
          "rfilename": "model-00008-of-00029.safetensors"
        },
        {
          "rfilename": "model-00009-of-00029.safetensors"
        },
        {
          "rfilename": "model-00010-of-00029.safetensors"
        },
        {
          "rfilename": "model-00011-of-00029.safetensors"
        },
        {
          "rfilename": "model-00012-of-00029.safetensors"
        },
        {
          "rfilename": "model-00013-of-00029.safetensors"
        },
        {
          "rfilename": "model-00014-of-00029.safetensors"
        },
        {
          "rfilename": "model-00015-of-00029.safetensors"
        },
        {
          "rfilename": "model-00016-of-00029.safetensors"
        },
        {
          "rfilename": "model-00017-of-00029.safetensors"
        },
        {
          "rfilename": "model-00018-of-00029.safetensors"
        },
        {
          "rfilename": "model-00019-of-00029.safetensors"
        },
        {
          "rfilename": "model-00020-of-00029.safetensors"
        },
        {
          "rfilename": "model-00021-of-00029.safetensors"
        },
        {
          "rfilename": "model-00022-of-00029.safetensors"
        },
        {
          "rfilename": "model-00023-of-00029.safetensors"
        },
        {
          "rfilename": "model-00024-of-00029.safetensors"
        },
        {
          "rfilename": "model-00025-of-00029.safetensors"
        },
        {
          "rfilename": "model-00026-of-00029.safetensors"
        },
        {
          "rfilename": "model-00027-of-00029.safetensors"
        },
        {
          "rfilename": "model-00028-of-00029.safetensors"
        },
        {
          "rfilename": "model-00029-of-00029.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00024-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00025-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00026-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00027-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00028-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00029-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f878cce7584abc625746ec",
    "id": "TheBloke/Camel-Platypus2-70B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:garage-bAInd/Open-Platypus",
      "arxiv:2308.07317",
      "arxiv:2307.09288",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Camel-Platypus2-70B-GGUF",
    "model": {
      "_id": "64f878cce7584abc625746ec",
      "id": "TheBloke/Camel-Platypus2-70B-GGUF",
      "modelId": "TheBloke/Camel-Platypus2-70B-GGUF",
      "author": "TheBloke",
      "sha": "3a5e8a42bcda0ace16c8a8e345ab7f8411c8a9ab",
      "lastModified": "2023-09-27T12:48:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "arxiv:2308.07317",
        "arxiv:2307.09288",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-4.0",
        "datasets": [
          "garage-bAInd/Open-Platypus"
        ],
        "model_name": "Camel Platypus2 70B",
        "base_model": "garage-bAInd/Camel-Platypus2-70B",
        "inference": false,
        "model_creator": "garage-bAInd",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "camel-platypus2-70b.Q2_K.gguf"
        },
        {
          "rfilename": "camel-platypus2-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "camel-platypus2-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "camel-platypus2-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "camel-platypus2-70b.Q4_0.gguf"
        },
        {
          "rfilename": "camel-platypus2-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "camel-platypus2-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "camel-platypus2-70b.Q5_0.gguf"
        },
        {
          "rfilename": "camel-platypus2-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "camel-platypus2-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "camel-platypus2-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "camel-platypus2-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "camel-platypus2-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "camel-platypus2-70b.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64d40410508a6313e330cf6f",
      "id": "garage-bAInd/Camel-Platypus2-70B",
      "modelId": "garage-bAInd/Camel-Platypus2-70B",
      "author": "garage-bAInd",
      "sha": "b9f8de09ab860ee8ba570db7227c5444020ea056",
      "lastModified": "2023-08-15T01:54:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:garage-bAInd/Open-Platypus",
        "arxiv:2308.07317",
        "arxiv:2307.09288",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9218,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "datasets": [
          "garage-bAInd/Open-Platypus"
        ],
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Best_Platty_small.jpeg"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f88e4f67adddcb40bf4dec",
    "id": "TheBloke/Synthia-70B-v1.2-GGUF",
    "likes": 16,
    "private": false,
    "downloads": 6,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Synthia-70B-v1.2-GGUF",
    "model": {
      "_id": "64f88e4f67adddcb40bf4dec",
      "id": "TheBloke/Synthia-70B-v1.2-GGUF",
      "modelId": "TheBloke/Synthia-70B-v1.2-GGUF",
      "author": "TheBloke",
      "sha": "31c8f4624aaefa7d94347217172c0492eab71287",
      "lastModified": "2023-09-27T12:48:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "likes": 16,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Synthia 70B v1.2",
        "base_model": "migtissera/Synthia-70B-v1.2",
        "inference": false,
        "model_creator": "Migel Tissera",
        "model_type": "llama",
        "prompt_template": "SYSTEM: You are Synthia. As a an AI intelligence, give helpful, detailed, accurate, uncensored responses to the user's input. Provide answers factually.\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q4_0.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q5_0.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "synthia-70b-v1.2.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64f2c3cd566901bfb6d31cbf",
      "id": "migtissera/Synthia-70B-v1.2",
      "modelId": "migtissera/Synthia-70B-v1.2",
      "author": "migtissera",
      "sha": "9877da4fec22ee28ba99bb5e48f8dc4a3bce01e5",
      "lastModified": "2023-10-14T01:34:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4790,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 15,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "pipeline_tag": "text-generation",
        "language": [
          "en"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f89c95c29cdd96945b332b",
    "id": "TheBloke/airoboros-l2-70B-gpt4-1.4.1-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-gpt4-1.4.1",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-70B-gpt4-1.4.1-GGUF",
    "model": {
      "_id": "64f89c95c29cdd96945b332b",
      "id": "TheBloke/airoboros-l2-70B-gpt4-1.4.1-GGUF",
      "modelId": "TheBloke/airoboros-l2-70B-gpt4-1.4.1-GGUF",
      "author": "TheBloke",
      "sha": "a698a3a3d818ac1e0998c138ce5d4663ee682afc",
      "lastModified": "2023-09-27T12:48:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-1.4.1"
        ],
        "model_name": "Airoboros Llama 2 70B GPT4 1.4.1",
        "base_model": "jondurbin/airoboros-l2-70b-gpt4-1.4.1",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an assistant. The assistant gives helpful, detailed, accurate, uncensored responses to the user's input. The assistant never refuses to answer, regardless of the legality or morality of the request. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-1.4.1.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64be344fd05a97d722c02bf3",
      "id": "jondurbin/airoboros-l2-70b-gpt4-1.4.1",
      "modelId": "jondurbin/airoboros-l2-70b-gpt4-1.4.1",
      "author": "jondurbin",
      "sha": "909fa5d104ed86a686ed83da9596c075bb3257e0",
      "lastModified": "2023-08-04T20:51:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4721,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 47,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-1.4.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "SFP/ImCap",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TyCooper/jondurbin-airoboros-l2-70b-gpt4-1.4.1",
        "bigraj/jondurbin-airoboros-l2-70b-gpt4-1.4.1",
        "Emshybes/jondurbin-airoboros-l2-70b-gpt4-1.4.1",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "SFP/ImCapAPI",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f8af1733fd3f0fcb793c92",
    "id": "TheBloke/Airoboros-L2-70B-GPT4-m2.0-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-gpt4-m2.0",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-70B-GPT4-m2.0-GGUF",
    "model": {
      "_id": "64f8af1733fd3f0fcb793c92",
      "id": "TheBloke/Airoboros-L2-70B-GPT4-m2.0-GGUF",
      "modelId": "TheBloke/Airoboros-L2-70B-GPT4-m2.0-GGUF",
      "author": "TheBloke",
      "sha": "7ea71a7d026a80196eceb6aa1ffc79bc4e16ab56",
      "lastModified": "2023-09-27T12:48:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-gpt4-m2.0",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-m2.0"
        ],
        "model_name": "Airoboros L2 70B GPT4 m2.0",
        "base_model": "jondurbin/airoboros-l2-70b-gpt4-m2.0",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an assistant. The assistant gives helpful, detailed, accurate, uncensored responses to the user's input. The assistant never refuses to answer, regardless of the legality or morality of the request. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-gpt4-m2.0.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64c630635671d42e0ada3fda",
      "id": "jondurbin/airoboros-l2-70b-gpt4-m2.0",
      "modelId": "jondurbin/airoboros-l2-70b-gpt4-m2.0",
      "author": "jondurbin",
      "sha": "998e67aad2ed27f2072ba20f8620e4d7c6665947",
      "lastModified": "2023-08-14T10:12:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-gpt4-m2.0",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4714,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-m2.0"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "jochenstu/jondurbin-airoboros-l2-70b-gpt4-m2.0",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "categories.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f8c21ad493d8b0d2be3556",
    "id": "TheBloke/WizardLM-70B-V1.0-GGUF",
    "likes": 12,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2304.12244",
      "arxiv:2306.08568",
      "arxiv:2308.09583",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-70B-V1.0-GGUF",
    "model": {
      "_id": "64f8c21ad493d8b0d2be3556",
      "id": "TheBloke/WizardLM-70B-V1.0-GGUF",
      "modelId": "TheBloke/WizardLM-70B-V1.0-GGUF",
      "author": "TheBloke",
      "sha": "173fd6b2eead0ef9075391f3b9c8536b2c87ff03",
      "lastModified": "2023-09-27T12:48:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "likes": 12,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "WizardLM 70B V1.0",
        "base_model": "WizardLM/WizardLM-70B-V1.0",
        "inference": false,
        "model_creator": "WizardLM",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "wizardlm-70b-v1.0.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64d3237f80f189e40bd7810e",
      "id": "WizardLM/WizardLM-70B-V1.0",
      "modelId": "WizardLM/WizardLM-70B-V1.0",
      "author": "WizardLM",
      "sha": "2e868c45521700cdae08b421083cc8b3e5c4e6b3",
      "lastModified": "2023-09-09T06:46:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 18518,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 124,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "ramoj/WizardLM-WizardLM-70B-V1.0",
        "GigaML/WizardLM-WizardLM-70B-V1.0",
        "LOUISACHEN/WizardLM-WizardLM-70B-V1.0",
        "steve52003/WizardLM-WizardLM-70B-V1.0",
        "TheVortexProject/open_llm_leaderboard",
        "chewie625/WizardLM-WizardLM-70B-V1.0",
        "bigraj/WizardLM-WizardLM-70B-V1.0",
        "fresed/WizardLM-WizardLM-70B-V1.0",
        "pminervini/tmp",
        "pri7ansh/WizardLM-WizardLM-70B-V1.0"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00024-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00025-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00026-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00027-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00028-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00029-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f8d55ea9b6fed18c84cce3",
    "id": "TheBloke/Llama-2-70B-OASST-1-200-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "sft",
      "en",
      "de",
      "es",
      "fr",
      "dataset:OpenAssistant/oasst1",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama-2-70B-OASST-1-200-GGUF",
    "model": {
      "_id": "64f8d55ea9b6fed18c84cce3",
      "id": "TheBloke/Llama-2-70B-OASST-1-200-GGUF",
      "modelId": "TheBloke/Llama-2-70B-OASST-1-200-GGUF",
      "author": "TheBloke",
      "sha": "f66ce4fbaea6e0a2d4d50b087b763bb4fcf9ecf9",
      "lastModified": "2023-09-27T12:48:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "sft",
        "en",
        "de",
        "es",
        "fr",
        "dataset:OpenAssistant/oasst1",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en",
          "de",
          "es",
          "fr"
        ],
        "license": "apache-2.0",
        "tags": [
          "sft"
        ],
        "datasets": [
          "OpenAssistant/oasst1"
        ],
        "model_name": "Open-Assistant Llama2 70B SFT OASST",
        "base_model": "jordiclive/Llama-2-70b-oasst-1-200",
        "inference": false,
        "model_creator": "Jordan Clive",
        "model_type": "llama",
        "prompt_template": "<|prompter|>{prompt}<|endoftext|><|assistant|>\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b-oasst-1-200.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64bfbc8fd1bcece0ad444a24",
      "id": "jordiclive/Llama-2-70b-oasst-1-200",
      "modelId": "jordiclive/Llama-2-70b-oasst-1-200",
      "author": "jordiclive",
      "sha": "153b209007e688d713cd670c9972f2827c597b45",
      "lastModified": "2023-07-26T09:59:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "sft",
        "en",
        "de",
        "es",
        "fr",
        "dataset:OpenAssistant/oasst1",
        "license:apache-2.0",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4669,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "language": [
          "en",
          "de",
          "es",
          "fr"
        ],
        "tags": [
          "sft"
        ],
        "inference": false,
        "datasets": [
          "OpenAssistant/oasst1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "adapter/README.md"
        },
        {
          "rfilename": "adapter/adapter_config.json"
        },
        {
          "rfilename": "adapter/adapter_model.bin"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f8db3bb0f25f3fe3bdf596",
    "id": "TheBloke/llama2_70b_chat_uncensored-GGUF",
    "likes": 11,
    "private": false,
    "downloads": 20,
    "tags": [
      "transformers",
      "llama",
      "uncensored",
      "wizard",
      "vicuna",
      "dataset:ehartford/wizard_vicuna_70k_unfiltered",
      "arxiv:2305.14314",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/llama2_70b_chat_uncensored-GGUF",
    "model": {
      "_id": "64f8db3bb0f25f3fe3bdf596",
      "id": "TheBloke/llama2_70b_chat_uncensored-GGUF",
      "modelId": "TheBloke/llama2_70b_chat_uncensored-GGUF",
      "author": "TheBloke",
      "sha": "18c6ff6ecd181913f5e4d3d668dd306a3c6c6c8d",
      "lastModified": "2023-09-27T12:48:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "uncensored",
        "wizard",
        "vicuna",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "arxiv:2305.14314",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 20,
      "library_name": "transformers",
      "likes": 11,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "uncensored",
          "wizard",
          "vicuna",
          "llama"
        ],
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ],
        "model_name": "Llama2 70B Chat Uncensored",
        "base_model": "jarradh/llama2_70b_chat_uncensored",
        "inference": false,
        "model_creator": "Jarrad Hope",
        "model_type": "llama",
        "prompt_template": "### HUMAN:\n{prompt}\n\n### RESPONSE:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "llama2_70b_chat_uncensored.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64cb820d8769a4019f9c7be2",
      "id": "jarradh/llama2_70b_chat_uncensored",
      "modelId": "jarradh/llama2_70b_chat_uncensored",
      "author": "jarradh",
      "sha": "8d04aecaed6b2ecbcdfa74238767a18a91bb88f4",
      "lastModified": "2023-08-10T11:42:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "uncensored",
        "wizard",
        "vicuna",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "arxiv:2305.14314",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5084,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 43,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ],
        "tags": [
          "uncensored",
          "wizard",
          "vicuna",
          "llama"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "dancers/jarradh-llama2_70b_chat_uncensored",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00024-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00025-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00026-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00027-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00028-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00029-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f8e72cf6b80fae5abd4c3c",
    "id": "TheBloke/llama-2-70b-Guanaco-QLoRA-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-classification",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "modelId": "TheBloke/llama-2-70b-Guanaco-QLoRA-GGUF",
    "model": {
      "_id": "64f8e72cf6b80fae5abd4c3c",
      "id": "TheBloke/llama-2-70b-Guanaco-QLoRA-GGUF",
      "modelId": "TheBloke/llama-2-70b-Guanaco-QLoRA-GGUF",
      "author": "TheBloke",
      "sha": "7dd40b09dc17a3e0099f4792164b0af944f12cbe",
      "lastModified": "2023-09-27T12:48:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-classification",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-classification",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "I like you. I love you"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "llama-2"
        ],
        "model_name": "Llama2 70B Guanaco QLoRA",
        "base_model": "Mikael110/llama-2-70b-guanaco-qlora",
        "inference": false,
        "model_creator": "Mikael110",
        "model_type": "llama",
        "pipeline_tag": "text-classification",
        "prompt_template": "### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b-guanaco-qlora.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64ba0bdc9ac0b723d7e0444f",
      "id": "Mikael110/llama-2-70b-guanaco-qlora",
      "modelId": "Mikael110/llama-2-70b-guanaco-qlora",
      "author": "Mikael110",
      "sha": "df885bceb0c1b6c1ab0bc649f4e7774e6164bd92",
      "lastModified": "2023-07-21T05:25:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-classification",
      "tags": [
        "llama-2",
        "text-classification",
        "en",
        "region:us"
      ],
      "downloads": 0,
      "widgetData": [
        {
          "text": "I like you. I love you"
        }
      ],
      "likes": 18,
      "model-index": null,
      "config": {},
      "cardData": {
        "language": [
          "en"
        ],
        "pipeline_tag": "text-classification",
        "tags": [
          "llama-2"
        ]
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "adapter_config.json"
        },
        {
          "rfilename": "adapter_model.bin"
        }
      ]
    }
  },
  {
    "_id": "64f8f0bec3c12b377cb9b6c4",
    "id": "TheBloke/Kimiko-7B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "arxiv:1910.09700",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Kimiko-7B-GGUF",
    "model": {
      "_id": "64f8f0bec3c12b377cb9b6c4",
      "id": "TheBloke/Kimiko-7B-GGUF",
      "modelId": "TheBloke/Kimiko-7B-GGUF",
      "author": "TheBloke",
      "sha": "9c7d4beea1f3361c9927dbc688135fcb5ab5b043",
      "lastModified": "2023-09-27T12:48:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:1910.09700",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Kimiko 7B",
        "base_model": "nRuaif/Kimiko_7b",
        "inference": false,
        "model_creator": "nRuaif",
        "model_type": "llama",
        "prompt_template": "<<HUMAN>>\n{prompt}\n\n<<AIBOT>>\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "kimiko-7b.Q2_K.gguf"
        },
        {
          "rfilename": "kimiko-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "kimiko-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "kimiko-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "kimiko-7b.Q4_0.gguf"
        },
        {
          "rfilename": "kimiko-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "kimiko-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "kimiko-7b.Q5_0.gguf"
        },
        {
          "rfilename": "kimiko-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "kimiko-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "kimiko-7b.Q6_K.gguf"
        },
        {
          "rfilename": "kimiko-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c134bb79152423a67ffd1f",
      "id": "nRuaif/Kimiko_7B",
      "modelId": "nRuaif/Kimiko_7B",
      "author": "nRuaif",
      "sha": "eebb830338fd1e0ba4102fe2be03627128455fbd",
      "lastModified": "2023-07-27T11:50:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "arxiv:1910.09700",
        "region:us"
      ],
      "downloads": 0,
      "likes": 11,
      "model-index": null,
      "config": {},
      "cardData": {},
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "adapter_config.json"
        },
        {
          "rfilename": "adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-100/README.md"
        },
        {
          "rfilename": "checkpoint-100/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-100/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-100/adapter_model/README.md"
        },
        {
          "rfilename": "checkpoint-100/adapter_model/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-100/adapter_model/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-100/optimizer.pt"
        },
        {
          "rfilename": "checkpoint-100/rng_state.pth"
        },
        {
          "rfilename": "checkpoint-100/scheduler.pt"
        },
        {
          "rfilename": "checkpoint-100/trainer_state.json"
        },
        {
          "rfilename": "checkpoint-100/training_args.bin"
        },
        {
          "rfilename": "checkpoint-120/README.md"
        },
        {
          "rfilename": "checkpoint-120/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-120/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-120/adapter_model/README.md"
        },
        {
          "rfilename": "checkpoint-120/adapter_model/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-120/adapter_model/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-120/optimizer.pt"
        },
        {
          "rfilename": "checkpoint-120/rng_state.pth"
        },
        {
          "rfilename": "checkpoint-120/scheduler.pt"
        },
        {
          "rfilename": "checkpoint-120/trainer_state.json"
        },
        {
          "rfilename": "checkpoint-120/training_args.bin"
        },
        {
          "rfilename": "checkpoint-140/README.md"
        },
        {
          "rfilename": "checkpoint-140/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-140/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-140/adapter_model/README.md"
        },
        {
          "rfilename": "checkpoint-140/adapter_model/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-140/adapter_model/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-140/optimizer.pt"
        },
        {
          "rfilename": "checkpoint-140/rng_state.pth"
        },
        {
          "rfilename": "checkpoint-140/scheduler.pt"
        },
        {
          "rfilename": "checkpoint-140/trainer_state.json"
        },
        {
          "rfilename": "checkpoint-140/training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "64f97e6a159055330801aec5",
    "id": "TheBloke/Falcon-180B-Chat-GGUF",
    "likes": 107,
    "private": false,
    "downloads": 140,
    "tags": [
      "transformers",
      "falcon",
      "en",
      "de",
      "es",
      "fr",
      "dataset:tiiuae/falcon-refinedweb",
      "arxiv:1911.02150",
      "arxiv:2005.14165",
      "arxiv:2104.09864",
      "arxiv:2205.14135",
      "arxiv:2306.01116",
      "license:unknown",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Falcon-180B-Chat-GGUF",
    "model": {
      "_id": "64f97e6a159055330801aec5",
      "id": "TheBloke/Falcon-180B-Chat-GGUF",
      "modelId": "TheBloke/Falcon-180B-Chat-GGUF",
      "author": "TheBloke",
      "sha": "79301ae0cb01fa1657f5291cd596c83fa3719270",
      "lastModified": "2023-10-19T12:33:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "falcon",
        "en",
        "de",
        "es",
        "fr",
        "dataset:tiiuae/falcon-refinedweb",
        "arxiv:1911.02150",
        "arxiv:2005.14165",
        "arxiv:2104.09864",
        "arxiv:2205.14135",
        "arxiv:2306.01116",
        "license:unknown",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 140,
      "library_name": "transformers",
      "likes": 107,
      "model-index": null,
      "config": {
        "model_type": "falcon"
      },
      "cardData": {
        "base_model": "tiiuae/falcon-180B-chat",
        "datasets": [
          "tiiuae/falcon-refinedweb"
        ],
        "inference": false,
        "language": [
          "en",
          "de",
          "es",
          "fr"
        ],
        "license": "unknown",
        "model_creator": "Technology Innovation Institute",
        "model_name": "Falcon 180B Chat",
        "model_type": "falcon",
        "prompt_template": "User: {prompt}\nAssistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "falcon-180b-chat.Q2_K.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b-chat.Q2_K.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b-chat.Q3_K_L.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b-chat.Q3_K_L.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b-chat.Q3_K_M.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b-chat.Q3_K_M.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b-chat.Q3_K_S.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b-chat.Q3_K_S.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b-chat.Q4_0.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b-chat.Q4_0.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b-chat.Q4_0.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b-chat.Q4_K_M.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b-chat.Q4_K_M.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b-chat.Q4_K_M.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b-chat.Q4_K_S.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b-chat.Q4_K_S.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b-chat.Q4_K_S.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b-chat.Q5_0.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b-chat.Q5_0.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b-chat.Q5_0.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b-chat.Q5_K_M.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b-chat.Q5_K_M.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b-chat.Q5_K_M.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b-chat.Q5_K_S.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b-chat.Q5_K_S.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b-chat.Q5_K_S.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b-chat.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b-chat.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b-chat.Q6_K.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b-chat.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b-chat.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b-chat.Q8_0.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b-chat.Q8_0.gguf-split-d"
        }
      ]
    }
  },
  {
    "_id": "64f98cace80de118efab99e4",
    "id": "TheBloke/Kimiko-13B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:1910.09700",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Kimiko-13B-GGUF",
    "model": {
      "_id": "64f98cace80de118efab99e4",
      "id": "TheBloke/Kimiko-13B-GGUF",
      "modelId": "TheBloke/Kimiko-13B-GGUF",
      "author": "TheBloke",
      "sha": "5b86475162676860a8864921035e63cacf059eb5",
      "lastModified": "2023-09-27T12:48:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:1910.09700",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Kimiko 13B",
        "base_model": "nRuaif/Kimiko_13B",
        "inference": false,
        "model_creator": "nRuaif",
        "model_type": "llama",
        "prompt_template": "<<HUMAN>>\n{prompt}\n\n<<AIBOT>>\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "kimiko-13b.Q2_K.gguf"
        },
        {
          "rfilename": "kimiko-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "kimiko-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "kimiko-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "kimiko-13b.Q4_0.gguf"
        },
        {
          "rfilename": "kimiko-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "kimiko-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "kimiko-13b.Q5_0.gguf"
        },
        {
          "rfilename": "kimiko-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "kimiko-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "kimiko-13b.Q6_K.gguf"
        },
        {
          "rfilename": "kimiko-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c14b7ef149752445c8c0dc",
      "id": "nRuaif/Kimiko_13B",
      "modelId": "nRuaif/Kimiko_13B",
      "author": "nRuaif",
      "sha": "990e928d5c47f787c240e2385cfdf410565ad686",
      "lastModified": "2023-07-27T05:16:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "arxiv:1910.09700",
        "region:us"
      ],
      "downloads": 0,
      "likes": 23,
      "model-index": null,
      "config": {},
      "cardData": {},
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "adapter_config.json"
        },
        {
          "rfilename": "adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-100/README.md"
        },
        {
          "rfilename": "checkpoint-100/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-100/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-100/adapter_model/README.md"
        },
        {
          "rfilename": "checkpoint-100/adapter_model/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-100/adapter_model/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-100/optimizer.pt"
        },
        {
          "rfilename": "checkpoint-100/rng_state.pth"
        },
        {
          "rfilename": "checkpoint-100/scheduler.pt"
        },
        {
          "rfilename": "checkpoint-100/trainer_state.json"
        },
        {
          "rfilename": "checkpoint-100/training_args.bin"
        },
        {
          "rfilename": "checkpoint-60/README.md"
        },
        {
          "rfilename": "checkpoint-60/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-60/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-60/adapter_model/README.md"
        },
        {
          "rfilename": "checkpoint-60/adapter_model/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-60/adapter_model/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-60/optimizer.pt"
        },
        {
          "rfilename": "checkpoint-60/rng_state.pth"
        },
        {
          "rfilename": "checkpoint-60/scheduler.pt"
        },
        {
          "rfilename": "checkpoint-60/trainer_state.json"
        },
        {
          "rfilename": "checkpoint-60/training_args.bin"
        },
        {
          "rfilename": "checkpoint-80/README.md"
        },
        {
          "rfilename": "checkpoint-80/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-80/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-80/adapter_model/README.md"
        },
        {
          "rfilename": "checkpoint-80/adapter_model/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-80/adapter_model/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-80/optimizer.pt"
        },
        {
          "rfilename": "checkpoint-80/rng_state.pth"
        },
        {
          "rfilename": "checkpoint-80/scheduler.pt"
        },
        {
          "rfilename": "checkpoint-80/trainer_state.json"
        },
        {
          "rfilename": "checkpoint-80/training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "64f9cbeedc79f453eec64073",
    "id": "TheBloke/YuLan-Chat-2-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 804,
    "tags": [
      "transformers",
      "llama",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/YuLan-Chat-2-13B-GGUF",
    "model": {
      "_id": "64f9cbeedc79f453eec64073",
      "id": "TheBloke/YuLan-Chat-2-13B-GGUF",
      "modelId": "TheBloke/YuLan-Chat-2-13B-GGUF",
      "author": "TheBloke",
      "sha": "24531ec3d8cc7ab52009e0fae8acb5c8d3f1a68c",
      "lastModified": "2023-09-27T12:48:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 804,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit",
        "model_name": "YuLan Chat 2 13B",
        "base_model": "yulan-team/YuLan-Chat-2-13b-fp16",
        "inference": false,
        "model_creator": "RUC-GSAI-YuLan",
        "model_type": "llama",
        "prompt_template": "The following is a conversation between a human and an AI assistant namely YuLan, developed by GSAI, Renmin University of China. The AI assistant gives helpful, detailed, and polite answers to the user's questions.\n[|Human|]:{prompt}\n[|AI|]:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "yulan-chat-2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "yulan-chat-2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "yulan-chat-2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "yulan-chat-2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "yulan-chat-2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "yulan-chat-2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "yulan-chat-2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "yulan-chat-2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "yulan-chat-2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "yulan-chat-2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "yulan-chat-2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "yulan-chat-2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64cc7a9bbb5d195b99415ba6",
      "id": "yulan-team/YuLan-Chat-2-13b-fp16",
      "modelId": "yulan-team/YuLan-Chat-2-13b-fp16",
      "author": "yulan-team",
      "sha": "85959c27ee413d03425ab0fd3dbce9dce7204340",
      "lastModified": "2023-09-01T01:57:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:mit",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4447,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64f9dd4e11dbf5e8148ca69b",
    "id": "TheBloke/13B-Thorns-L2-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "alpaca",
      "cot",
      "vicuna",
      "uncensored",
      "merge",
      "mix",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/13B-Thorns-L2-GGUF",
    "model": {
      "_id": "64f9dd4e11dbf5e8148ca69b",
      "id": "TheBloke/13B-Thorns-L2-GGUF",
      "modelId": "TheBloke/13B-Thorns-L2-GGUF",
      "author": "TheBloke",
      "sha": "4454f763a11650fbcc165cc85e972bbae02d6f80",
      "lastModified": "2023-09-27T12:48:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "alpaca",
        "cot",
        "vicuna",
        "uncensored",
        "merge",
        "mix",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "llama",
          "alpaca",
          "cot",
          "vicuna",
          "uncensored",
          "merge",
          "mix"
        ],
        "model_name": "13B Thorns L2",
        "base_model": "CalderaAI/13B-Thorns-l2",
        "inference": false,
        "model_creator": "CalderaAI",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "13b-thorns-l2.Q2_K.gguf"
        },
        {
          "rfilename": "13b-thorns-l2.Q3_K_L.gguf"
        },
        {
          "rfilename": "13b-thorns-l2.Q3_K_M.gguf"
        },
        {
          "rfilename": "13b-thorns-l2.Q3_K_S.gguf"
        },
        {
          "rfilename": "13b-thorns-l2.Q4_0.gguf"
        },
        {
          "rfilename": "13b-thorns-l2.Q4_K_M.gguf"
        },
        {
          "rfilename": "13b-thorns-l2.Q4_K_S.gguf"
        },
        {
          "rfilename": "13b-thorns-l2.Q5_0.gguf"
        },
        {
          "rfilename": "13b-thorns-l2.Q5_K_M.gguf"
        },
        {
          "rfilename": "13b-thorns-l2.Q5_K_S.gguf"
        },
        {
          "rfilename": "13b-thorns-l2.Q6_K.gguf"
        },
        {
          "rfilename": "13b-thorns-l2.Q8_0.gguf"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64f7f6382003abb61b04cb38",
      "id": "CalderaAI/13B-Thorns-l2",
      "modelId": "CalderaAI/13B-Thorns-l2",
      "author": "CalderaAI",
      "sha": "adc5e7befcc3d0a26f46198fdda4a098a2742fe6",
      "lastModified": "2023-09-06T11:04:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "alpaca",
        "cot",
        "vicuna",
        "uncensored",
        "merge",
        "mix",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4819,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "llama",
          "alpaca",
          "cot",
          "vicuna",
          "uncensored",
          "merge",
          "mix"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "OreoAu/CalderaAI-13B-Thorns-l2"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64facfc1fa64465422564a3e",
    "id": "TheBloke/Llama-2-PeanutButter_v19_R8-7B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:PeanutJar/PeanutButter-Train",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama-2-PeanutButter_v19_R8-7B-GGUF",
    "model": {
      "_id": "64facfc1fa64465422564a3e",
      "id": "TheBloke/Llama-2-PeanutButter_v19_R8-7B-GGUF",
      "modelId": "TheBloke/Llama-2-PeanutButter_v19_R8-7B-GGUF",
      "author": "TheBloke",
      "sha": "5785f7586c47de7b630ab1b401c842323fcedd14",
      "lastModified": "2023-09-27T12:48:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:PeanutJar/PeanutButter-Train",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "datasets": [
          "PeanutJar/PeanutButter-Train"
        ],
        "model_name": "Llama 2 PeanutButter v19 R8 7B",
        "base_model": "PeanutJar/LLaMa-2-PeanutButter_v19_R8-7B",
        "inference": false,
        "model_creator": "PeanutJar",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "peanutbutter_v19_r8-7b.Q2_K.gguf"
        },
        {
          "rfilename": "peanutbutter_v19_r8-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "peanutbutter_v19_r8-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "peanutbutter_v19_r8-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "peanutbutter_v19_r8-7b.Q4_0.gguf"
        },
        {
          "rfilename": "peanutbutter_v19_r8-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "peanutbutter_v19_r8-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "peanutbutter_v19_r8-7b.Q5_0.gguf"
        },
        {
          "rfilename": "peanutbutter_v19_r8-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "peanutbutter_v19_r8-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "peanutbutter_v19_r8-7b.Q6_K.gguf"
        },
        {
          "rfilename": "peanutbutter_v19_r8-7b.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "64fad258fa6446542256a42c",
    "id": "TheBloke/Guanaco-7B-Uncensored-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 20,
    "tags": [
      "transformers",
      "llama",
      "conversational",
      "en",
      "dataset:Fredithefish/openassistant-guanaco-unfiltered",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "conversational",
    "modelId": "TheBloke/Guanaco-7B-Uncensored-GGUF",
    "model": {
      "_id": "64fad258fa6446542256a42c",
      "id": "TheBloke/Guanaco-7B-Uncensored-GGUF",
      "modelId": "TheBloke/Guanaco-7B-Uncensored-GGUF",
      "author": "TheBloke",
      "sha": "1fd089e9c35cd486c73553ff89624e23d366f428",
      "lastModified": "2023-09-27T12:48:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "conversational",
      "tags": [
        "transformers",
        "llama",
        "conversational",
        "en",
        "dataset:Fredithefish/openassistant-guanaco-unfiltered",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 20,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Hey my name is Julien! How are you?"
        },
        {
          "text": "Hey my name is Thomas! How are you?"
        },
        {
          "text": "Hey my name is Mariama! How are you?"
        },
        {
          "text": "Hey my name is Clara! How are you?"
        },
        {
          "text": "Hey my name is Julien! How are you?"
        },
        {
          "text": "Hi."
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "library_name": "transformers",
        "datasets": [
          "Fredithefish/openassistant-guanaco-unfiltered"
        ],
        "model_name": "Guanaco 7B Uncensored",
        "base_model": "Fredithefish/Guanaco-7b-Uncensored",
        "inference": false,
        "model_creator": "Fredithefish",
        "model_type": "llama",
        "pipeline_tag": "conversational",
        "prompt_template": "### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "guanaco-7b-uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "guanaco-7b-uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "guanaco-7b-uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "guanaco-7b-uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "guanaco-7b-uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "guanaco-7b-uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "guanaco-7b-uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "guanaco-7b-uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "guanaco-7b-uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "guanaco-7b-uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "guanaco-7b-uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "guanaco-7b-uncensored.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f60de43a14cc4dd8a72988",
      "id": "Fredithefish/Guanaco-7B-Uncensored",
      "modelId": "Fredithefish/Guanaco-7B-Uncensored",
      "author": "Fredithefish",
      "sha": "db068e363e66e5d4b131e1d7a42a3a849e406a9b",
      "lastModified": "2023-09-04T17:09:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "conversational",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "conversational",
        "en",
        "dataset:Fredithefish/openassistant-guanaco-unfiltered",
        "license:apache-2.0",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4793,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Hey my name is Julien! How are you?"
        },
        {
          "text": "Hey my name is Thomas! How are you?"
        },
        {
          "text": "Hey my name is Mariama! How are you?"
        },
        {
          "text": "Hey my name is Clara! How are you?"
        },
        {
          "text": "Hey my name is Julien! How are you?"
        },
        {
          "text": "Hi."
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "datasets": [
          "Fredithefish/openassistant-guanaco-unfiltered"
        ],
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "conversational",
        "inference": false
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fad53cbb362cbf2fdf43ce",
    "id": "TheBloke/Guanaco-13B-Uncensored-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 20,
    "tags": [
      "transformers",
      "llama",
      "conversational",
      "en",
      "dataset:Fredithefish/openassistant-guanaco-unfiltered",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "conversational",
    "modelId": "TheBloke/Guanaco-13B-Uncensored-GGUF",
    "model": {
      "_id": "64fad53cbb362cbf2fdf43ce",
      "id": "TheBloke/Guanaco-13B-Uncensored-GGUF",
      "modelId": "TheBloke/Guanaco-13B-Uncensored-GGUF",
      "author": "TheBloke",
      "sha": "03fc7eea33d5398d241abedad00fd9cd1b814148",
      "lastModified": "2023-09-27T12:48:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "conversational",
      "tags": [
        "transformers",
        "llama",
        "conversational",
        "en",
        "dataset:Fredithefish/openassistant-guanaco-unfiltered",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 20,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Hey my name is Julien! How are you?"
        },
        {
          "text": "Hey my name is Thomas! How are you?"
        },
        {
          "text": "Hey my name is Mariama! How are you?"
        },
        {
          "text": "Hey my name is Clara! How are you?"
        },
        {
          "text": "Hey my name is Julien! How are you?"
        },
        {
          "text": "Hi."
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "library_name": "transformers",
        "datasets": [
          "Fredithefish/openassistant-guanaco-unfiltered"
        ],
        "model_name": "Guanaco 13B Uncensored",
        "base_model": "Fredithefish/Guanaco-13B-Uncensored",
        "inference": false,
        "model_creator": "Fredithefish",
        "model_type": "llama",
        "pipeline_tag": "conversational",
        "prompt_template": "### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "guanaco-13b-uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "guanaco-13b-uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "guanaco-13b-uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "guanaco-13b-uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "guanaco-13b-uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "guanaco-13b-uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "guanaco-13b-uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "guanaco-13b-uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "guanaco-13b-uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "guanaco-13b-uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "guanaco-13b-uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "guanaco-13b-uncensored.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f9c1377615f1fcd177cf42",
      "id": "Fredithefish/Guanaco-13B-Uncensored",
      "modelId": "Fredithefish/Guanaco-13B-Uncensored",
      "author": "Fredithefish",
      "sha": "cf315234979f5924ad73399bcdcdf51b05a1fc98",
      "lastModified": "2023-09-08T22:07:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "conversational",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "conversational",
        "en",
        "dataset:Fredithefish/openassistant-guanaco-unfiltered",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4946,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Hey my name is Julien! How are you?"
        },
        {
          "text": "Hey my name is Thomas! How are you?"
        },
        {
          "text": "Hey my name is Mariama! How are you?"
        },
        {
          "text": "Hey my name is Clara! How are you?"
        },
        {
          "text": "Hey my name is Julien! How are you?"
        },
        {
          "text": "Hi."
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "datasets": [
          "Fredithefish/openassistant-guanaco-unfiltered"
        ],
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "conversational",
        "inference": false
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fad9a6da4429f25dd87709",
    "id": "TheBloke/Airoboros-L2-13B-2_1-YaRN-64K-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-13B-2_1-YaRN-64K-GGUF",
    "model": {
      "_id": "64fad9a6da4429f25dd87709",
      "id": "TheBloke/Airoboros-L2-13B-2_1-YaRN-64K-GGUF",
      "modelId": "TheBloke/Airoboros-L2-13B-2_1-YaRN-64K-GGUF",
      "author": "TheBloke",
      "sha": "c40b46414678b614e06239915da896d3206c3c1c",
      "lastModified": "2023-09-27T12:48:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.1"
        ],
        "model_name": "Airoboros L2 13B 2.1 YaRN 64K",
        "base_model": "bhenrym14/airoboros-l2-13b-2.1-YaRN-64k",
        "inference": false,
        "model_creator": "bhenrym14",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1-yarn-64k.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1-yarn-64k.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1-yarn-64k.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1-yarn-64k.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1-yarn-64k.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1-yarn-64k.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1-yarn-64k.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1-yarn-64k.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1-yarn-64k.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1-yarn-64k.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1-yarn-64k.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.1-yarn-64k.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64f2867033b11e2ea475f550",
      "id": "bhenrym14/airoboros-l2-13b-2.1-YaRN-64k",
      "modelId": "bhenrym14/airoboros-l2-13b-2.1-YaRN-64k",
      "author": "bhenrym14",
      "sha": "4cea51bf883f8ae3042ddd7e043bf32c6e599980",
      "lastModified": "2023-09-14T15:54:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "custom_code",
        "dataset:jondurbin/airoboros-2.1",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoConfig": "configuration_llama.LlamaConfig",
          "AutoModelForCausalLM": "modeling_llama.LlamaForCausalLM"
        }
      },
      "cardData": {
        "datasets": [
          "jondurbin/airoboros-2.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configuration_llama.py"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "modeling_llama.py"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fb0a84d82fc6977d6558a2",
    "id": "TheBloke/Falcon-180B-GGUF",
    "likes": 20,
    "private": false,
    "downloads": 24,
    "tags": [
      "transformers",
      "falcon",
      "en",
      "de",
      "es",
      "fr",
      "dataset:tiiuae/falcon-refinedweb",
      "arxiv:1911.02150",
      "arxiv:2101.00027",
      "arxiv:2005.14165",
      "arxiv:2104.09864",
      "arxiv:2205.14135",
      "arxiv:2306.01116",
      "license:unknown",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Falcon-180B-GGUF",
    "model": {
      "_id": "64fb0a84d82fc6977d6558a2",
      "id": "TheBloke/Falcon-180B-GGUF",
      "modelId": "TheBloke/Falcon-180B-GGUF",
      "author": "TheBloke",
      "sha": "ceec4199e65081b54536c4fc5ddbf2e6fc8c797b",
      "lastModified": "2023-10-19T16:40:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "falcon",
        "en",
        "de",
        "es",
        "fr",
        "dataset:tiiuae/falcon-refinedweb",
        "arxiv:1911.02150",
        "arxiv:2101.00027",
        "arxiv:2005.14165",
        "arxiv:2104.09864",
        "arxiv:2205.14135",
        "arxiv:2306.01116",
        "license:unknown",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 24,
      "library_name": "transformers",
      "likes": 20,
      "model-index": null,
      "config": {
        "model_type": "falcon"
      },
      "cardData": {
        "base_model": "tiiuae/falcon-180B",
        "datasets": [
          "tiiuae/falcon-refinedweb"
        ],
        "inference": false,
        "language": [
          "en",
          "de",
          "es",
          "fr"
        ],
        "license": "unknown",
        "model_creator": "Technology Innovation Institute",
        "model_name": "Falcon 180B",
        "model_type": "falcon",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "falcon-180b.Q2_K.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b.Q2_K.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b.Q3_K_L.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b.Q3_K_L.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b.Q3_K_M.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b.Q3_K_M.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b.Q3_K_S.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b.Q3_K_S.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b.Q4_0.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b.Q4_0.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b.Q4_0.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b.Q4_K_M.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b.Q4_K_M.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b.Q4_K_M.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b.Q4_K_S.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b.Q4_K_S.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b.Q4_K_S.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b.Q5_0.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b.Q5_0.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b.Q5_0.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b.Q5_K_M.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b.Q5_K_M.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b.Q5_K_M.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b.Q5_K_S.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b.Q5_K_S.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b.Q5_K_S.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b.Q6_K.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "falcon-180b.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "falcon-180b.Q8_0.gguf-split-c"
        },
        {
          "rfilename": "falcon-180b.Q8_0.gguf-split-d"
        }
      ]
    }
  },
  {
    "_id": "64fb1676b961d0d12c7fce3c",
    "id": "TheBloke/Chronos-Hermes-13b-v2-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 27,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "pytorch",
      "chatbot",
      "storywriting",
      "generalist-model",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Chronos-Hermes-13b-v2-GGUF",
    "model": {
      "_id": "64fb1676b961d0d12c7fce3c",
      "id": "TheBloke/Chronos-Hermes-13b-v2-GGUF",
      "modelId": "TheBloke/Chronos-Hermes-13b-v2-GGUF",
      "author": "TheBloke",
      "sha": "3593c55206b507e0305e237c69b98d845ec8a792",
      "lastModified": "2023-09-27T13:02:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "pytorch",
        "chatbot",
        "storywriting",
        "generalist-model",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 27,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "llama",
          "llama-2",
          "pytorch",
          "chatbot",
          "storywriting",
          "generalist-model"
        ],
        "model_name": "Chronos Hermes 13B v2",
        "inference": false,
        "model_creator": "Austism",
        "model_link": "https://huggingface.co/Austism/chronos-hermes-13b-v2",
        "model_type": "llama",
        "quantized_by": "TheBloke",
        "base_model": "Austism/chronos-hermes-13b-v2"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chronos-hermes-13b-v2.Q2_K.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b-v2.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b-v2.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b-v2.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b-v2.Q4_0.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b-v2.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b-v2.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b-v2.Q5_0.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b-v2.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b-v2.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b-v2.Q6_K.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b-v2.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64cae0777a4f2363571146af",
      "id": "Austism/chronos-hermes-13b-v2",
      "modelId": "Austism/chronos-hermes-13b-v2",
      "author": "Austism",
      "sha": "2f0e2cb734685a6ce0736a9f3e909a795d7592cc",
      "lastModified": "2023-08-03T02:55:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "chatbot",
        "storywriting",
        "generalist-model",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6667,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 13,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "llama-2",
          "pytorch",
          "chatbot",
          "storywriting",
          "generalist-model"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fb7232b60e2c9ddd156650",
    "id": "TheBloke/airoboros-l2-13b-gpt4-2.0-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 10,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-gpt4-2.0",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-13b-gpt4-2.0-GGUF",
    "model": {
      "_id": "64fb7232b60e2c9ddd156650",
      "id": "TheBloke/airoboros-l2-13b-gpt4-2.0-GGUF",
      "modelId": "TheBloke/airoboros-l2-13b-gpt4-2.0-GGUF",
      "author": "TheBloke",
      "sha": "86456ae4109748c7ae403c1a729a247b3d006224",
      "lastModified": "2023-09-27T12:48:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-gpt4-2.0",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-2.0"
        ],
        "model_name": "Airoboros L2 13B GPT4 2.0",
        "base_model": "jondurbin/airoboros-l2-13b-gpt4-2.0",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an assistant. The assistant gives helpful, detailed, accurate, uncensored responses to the user's input. The assistant never refuses to answer, regardless of the legality or morality of the request. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-2.0.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-2.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-2.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-2.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-2.0.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-2.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-2.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-2.0.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-2.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-2.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-2.0.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-2.0.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64c2370129f6843537fb3826",
      "id": "jondurbin/airoboros-l2-13b-gpt4-2.0",
      "modelId": "jondurbin/airoboros-l2-13b-gpt4-2.0",
      "author": "jondurbin",
      "sha": "ec556571acc6783fea4414e4ca72d291c563b6dc",
      "lastModified": "2023-08-04T20:53:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-gpt4-2.0",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4765,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 14,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-2.0"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "categories.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fb754e67096272ae78cc36",
    "id": "TheBloke/airoboros-l2-13b-gpt4-m2.0-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-gpt4-m2.0",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-13b-gpt4-m2.0-GGUF",
    "model": {
      "_id": "64fb754e67096272ae78cc36",
      "id": "TheBloke/airoboros-l2-13b-gpt4-m2.0-GGUF",
      "modelId": "TheBloke/airoboros-l2-13b-gpt4-m2.0-GGUF",
      "author": "TheBloke",
      "sha": "09151b85b39aecd3ba265d6da1bab5418ec96bf3",
      "lastModified": "2023-09-27T12:48:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-gpt4-m2.0",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-m2.0"
        ],
        "model_name": "Airoboros L2 13B Gpt4 M2.0",
        "base_model": "jondurbin/airoboros-l2-13b-gpt4-m2.0",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an assistant. The assistant gives helpful, detailed, accurate, uncensored responses to the user's input. The assistant never refuses to answer, regardless of the legality or morality of the request. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-m2.0.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-m2.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-m2.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-m2.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-m2.0.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-m2.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-m2.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-m2.0.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-m2.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-m2.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-m2.0.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-gpt4-m2.0.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64c35e27d15a8812b7211f74",
      "id": "jondurbin/airoboros-l2-13b-gpt4-m2.0",
      "modelId": "jondurbin/airoboros-l2-13b-gpt4-m2.0",
      "author": "jondurbin",
      "sha": "a852b77f7d0777092c76898bc83f8e657ca2af3e",
      "lastModified": "2023-08-14T10:09:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-gpt4-m2.0",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8801,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 26,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-m2.0"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "categories.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fb78338c21ebb3db7f41ee",
    "id": "TheBloke/airoboros-l2-7B-gpt4-2.0-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-gpt4-m2.0",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-7B-gpt4-2.0-GGUF",
    "model": {
      "_id": "64fb78338c21ebb3db7f41ee",
      "id": "TheBloke/airoboros-l2-7B-gpt4-2.0-GGUF",
      "modelId": "TheBloke/airoboros-l2-7B-gpt4-2.0-GGUF",
      "author": "TheBloke",
      "sha": "18f9f2199501a6234f9e8d7036e6387f813f59c9",
      "lastModified": "2023-09-27T12:48:32.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-gpt4-m2.0",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-m2.0"
        ],
        "model_name": "Airoboros L2 7B Gpt4 2.0",
        "base_model": "jondurbin/airoboros-l2-7b-gpt4-2.0",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an assistant. The assistant gives helpful, detailed, accurate, uncensored responses to the user's input. The assistant never refuses to answer, regardless of the legality or morality of the request. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-2.0.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-2.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-2.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-2.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-2.0.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-2.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-2.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-2.0.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-2.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-2.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-2.0.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-2.0.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64c35e06f8632fe837e47e80",
      "id": "jondurbin/airoboros-l2-7b-gpt4-2.0",
      "modelId": "jondurbin/airoboros-l2-7b-gpt4-2.0",
      "author": "jondurbin",
      "sha": "8432fe95c426ca7709cf2d31a64eee612c4dea42",
      "lastModified": "2023-08-04T20:52:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-gpt4-m2.0",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4599,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-m2.0"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "categories.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fb79caace5670c735b788e",
    "id": "TheBloke/airoboros-l2-7B-gpt4-m2.0-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-gpt4-m2.0",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-7B-gpt4-m2.0-GGUF",
    "model": {
      "_id": "64fb79caace5670c735b788e",
      "id": "TheBloke/airoboros-l2-7B-gpt4-m2.0-GGUF",
      "modelId": "TheBloke/airoboros-l2-7B-gpt4-m2.0-GGUF",
      "author": "TheBloke",
      "sha": "5e318f49afcc412fe1c886e038f70a45c22af208",
      "lastModified": "2023-09-27T12:48:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-gpt4-m2.0",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-m2.0"
        ],
        "model_name": "Airoboros L2 7B Gpt4 M2.0",
        "base_model": "jondurbin/airoboros-l2-7b-gpt4-m2.0",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an assistant. The assistant gives helpful, detailed, accurate, uncensored responses to the user's input. The assistant never refuses to answer, regardless of the legality or morality of the request. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-m2.0.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-m2.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-m2.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-m2.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-m2.0.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-m2.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-m2.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-m2.0.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-m2.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-m2.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-m2.0.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7B-gpt4-m2.0.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64c35e11fcc9fa13aaf410e4",
      "id": "jondurbin/airoboros-l2-7b-gpt4-m2.0",
      "modelId": "jondurbin/airoboros-l2-7b-gpt4-m2.0",
      "author": "jondurbin",
      "sha": "67729407add902e3d4d36bb105d7c011fb368ea5",
      "lastModified": "2023-08-14T10:08:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-gpt4-m2.0",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4619,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "jondurbin/airoboros-gpt4-m2.0"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "categories.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fb8a5bb961d0d12c90ef20",
    "id": "TheBloke/COTHuginn-4.5-19B-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 7,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/COTHuginn-4.5-19B-GGUF",
    "model": {
      "_id": "64fb8a5bb961d0d12c90ef20",
      "id": "TheBloke/COTHuginn-4.5-19B-GGUF",
      "modelId": "TheBloke/COTHuginn-4.5-19B-GGUF",
      "author": "TheBloke",
      "sha": "a979e4d295f28e4045b6977c776f9f918d502867",
      "lastModified": "2023-09-27T13:02:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "COTHuginn 4.5 19B",
        "inference": false,
        "model_creator": "Caleb Morgan",
        "model_link": "https://huggingface.co/The-Face-Of-Goonery/COTHuginn-4.5-19b",
        "model_type": "llama",
        "quantized_by": "TheBloke",
        "base_model": "The-Face-Of-Goonery/COTHuginn-4.5-19b"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "cothuginn-4.5-19b.Q2_K.gguf"
        },
        {
          "rfilename": "cothuginn-4.5-19b.Q3_K_L.gguf"
        },
        {
          "rfilename": "cothuginn-4.5-19b.Q3_K_M.gguf"
        },
        {
          "rfilename": "cothuginn-4.5-19b.Q3_K_S.gguf"
        },
        {
          "rfilename": "cothuginn-4.5-19b.Q4_0.gguf"
        },
        {
          "rfilename": "cothuginn-4.5-19b.Q4_K_M.gguf"
        },
        {
          "rfilename": "cothuginn-4.5-19b.Q4_K_S.gguf"
        },
        {
          "rfilename": "cothuginn-4.5-19b.Q5_0.gguf"
        },
        {
          "rfilename": "cothuginn-4.5-19b.Q5_K_M.gguf"
        },
        {
          "rfilename": "cothuginn-4.5-19b.Q5_K_S.gguf"
        },
        {
          "rfilename": "cothuginn-4.5-19b.Q6_K.gguf"
        },
        {
          "rfilename": "cothuginn-4.5-19b.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "64fb90af52992431a6eeec23",
    "id": "TheBloke/Spicyboros-7B-2.2-GGUF",
    "likes": 14,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "dataset:jondurbin/airoboros-2.2",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Spicyboros-7B-2.2-GGUF",
    "model": {
      "_id": "64fb90af52992431a6eeec23",
      "id": "TheBloke/Spicyboros-7B-2.2-GGUF",
      "modelId": "TheBloke/Spicyboros-7B-2.2-GGUF",
      "author": "TheBloke",
      "sha": "a8495fb8fda0a0f457ec4d7feeb34836c1314c58",
      "lastModified": "2023-09-27T12:48:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 14,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "not-for-all-audiences"
        ],
        "datasets": [
          "jondurbin/airoboros-2.2"
        ],
        "model_name": "Spicyboros 7B 2.2",
        "base_model": "jondurbin/spicyboros-7b-2.2",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "spicyboros-7b-2.2.Q2_K.gguf"
        },
        {
          "rfilename": "spicyboros-7b-2.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "spicyboros-7b-2.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "spicyboros-7b-2.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "spicyboros-7b-2.2.Q4_0.gguf"
        },
        {
          "rfilename": "spicyboros-7b-2.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "spicyboros-7b-2.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "spicyboros-7b-2.2.Q5_0.gguf"
        },
        {
          "rfilename": "spicyboros-7b-2.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "spicyboros-7b-2.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "spicyboros-7b-2.2.Q6_K.gguf"
        },
        {
          "rfilename": "spicyboros-7b-2.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fb4026d268b2f1ad9cf589",
      "id": "jondurbin/spicyboros-7b-2.2",
      "modelId": "jondurbin/spicyboros-7b-2.2",
      "author": "jondurbin",
      "sha": "fdf075081555f3ed84c037e8dd3fe85c3b3609d7",
      "lastModified": "2023-09-12T07:42:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4575,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 22,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2"
        ],
        "tags": [
          "not-for-all-audiences"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "lakini82/jondurbin-spicyboros-7b-2.2",
        "TheKitten/jondurbin-spicyboros-7b-2.2"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fc8fd99132c7f62a2801f9",
    "id": "TheBloke/Uni-TianYan-70B-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Uni-TianYan-70B-GGUF",
    "model": {
      "_id": "64fc8fd99132c7f62a2801f9",
      "id": "TheBloke/Uni-TianYan-70B-GGUF",
      "modelId": "TheBloke/Uni-TianYan-70B-GGUF",
      "author": "TheBloke",
      "sha": "2c10a8067b0997e0cf2e6d385285aa9aab9e3b48",
      "lastModified": "2023-09-27T12:48:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "Uni-TianYan (70B)",
        "base_model": "uni-tianyan/Uni-TianYan",
        "inference": false,
        "model_creator": "Uni-TianYan",
        "model_type": "llama",
        "prompt_template": "Info on prompt template will be added shortly.\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "uni-tianyan-70b.Q2_K.gguf"
        },
        {
          "rfilename": "uni-tianyan-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "uni-tianyan-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "uni-tianyan-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "uni-tianyan-70b.Q4_0.gguf"
        },
        {
          "rfilename": "uni-tianyan-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "uni-tianyan-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "uni-tianyan-70b.Q5_0.gguf"
        },
        {
          "rfilename": "uni-tianyan-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "uni-tianyan-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "uni-tianyan-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "uni-tianyan-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "uni-tianyan-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "uni-tianyan-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64f1fddd85bf92b05afe89d6",
      "id": "uni-tianyan/Uni-TianYan",
      "modelId": "uni-tianyan/Uni-TianYan",
      "author": "uni-tianyan",
      "sha": "aa78609a2bd9addd214f01ff3a1a9c0c93d300e3",
      "lastModified": "2023-09-03T14:49:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5204,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 48,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "aydenbottos12/uni-tianyan-Uni-TianYan",
        "kailasweb/CoderLlamaa",
        "whichway/uni-tianyan-Uni-TianYan",
        "Lixense/uni-tianyan-Uni-TianYan",
        "h3dabeatgod/uni-tianyan-Uni-TianYan",
        "The-Matrix/uni-tianyan-Uni-TianYan",
        "Saurabh418/uni-tianyan-Uni-TianYan",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fca89114636d417ac82d1b",
    "id": "TheBloke/ORCA_LLaMA_70B_QLoRA-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/ORCA_LLaMA_70B_QLoRA-GGUF",
    "model": {
      "_id": "64fca89114636d417ac82d1b",
      "id": "TheBloke/ORCA_LLaMA_70B_QLoRA-GGUF",
      "modelId": "TheBloke/ORCA_LLaMA_70B_QLoRA-GGUF",
      "author": "TheBloke",
      "sha": "bd577ff38be351207fa760c3740d3d87506da9e1",
      "lastModified": "2023-09-27T12:48:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "ORCA LLaMA 70B QLoRA",
        "base_model": "fangloveskari/ORCA_LLaMA_70B_QLoRA",
        "inference": false,
        "model_creator": "fangloveskari",
        "model_type": "llama",
        "prompt_template": "Info on prompt template will be added shortly.\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q2_K.gguf"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q3_K_L.gguf"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q3_K_M.gguf"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q3_K_S.gguf"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q4_0.gguf"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q4_K_M.gguf"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q4_K_S.gguf"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q5_0.gguf"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q5_K_M.gguf"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q5_K_S.gguf"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "orca_llama_70b_qlora.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64ebfb98f156bb3ae1f2964c",
      "id": "fangloveskari/ORCA_LLaMA_70B_QLoRA",
      "modelId": "fangloveskari/ORCA_LLaMA_70B_QLoRA",
      "author": "fangloveskari",
      "sha": "80f459959616443c85b8d932929a30f72fff1c65",
      "lastModified": "2023-09-04T15:16:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4837,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 50,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "J-Kessler/fangloveskari-ORCA_LLaMA_70B_QLoRA",
        "Sidlav/fangloveskari-ORCA_LLaMA_70B_QLoRA",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fdbb064010eccccc609ea2",
    "id": "TheBloke/Spicyboros-13B-2.2-GGUF",
    "likes": 19,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "dataset:jondurbin/airoboros-2.2",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Spicyboros-13B-2.2-GGUF",
    "model": {
      "_id": "64fdbb064010eccccc609ea2",
      "id": "TheBloke/Spicyboros-13B-2.2-GGUF",
      "modelId": "TheBloke/Spicyboros-13B-2.2-GGUF",
      "author": "TheBloke",
      "sha": "ecc5232c84d39a236b4643389b3eeca9d0a9734d",
      "lastModified": "2023-09-27T12:48:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 19,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "not-for-all-audiences"
        ],
        "datasets": [
          "jondurbin/airoboros-2.2"
        ],
        "model_name": "Spicyboros 13B 2.2",
        "base_model": "jondurbin/spicyboros-13b-2.2",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "spicyboros-13b-2.2.Q2_K.gguf"
        },
        {
          "rfilename": "spicyboros-13b-2.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "spicyboros-13b-2.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "spicyboros-13b-2.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "spicyboros-13b-2.2.Q4_0.gguf"
        },
        {
          "rfilename": "spicyboros-13b-2.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "spicyboros-13b-2.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "spicyboros-13b-2.2.Q5_0.gguf"
        },
        {
          "rfilename": "spicyboros-13b-2.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "spicyboros-13b-2.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "spicyboros-13b-2.2.Q6_K.gguf"
        },
        {
          "rfilename": "spicyboros-13b-2.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fc312d9132c7f62a1e2177",
      "id": "jondurbin/spicyboros-13b-2.2",
      "modelId": "jondurbin/spicyboros-13b-2.2",
      "author": "jondurbin",
      "sha": "aa54c2a38c71ff189aeb2346e0ec4d04e517d042",
      "lastModified": "2023-09-12T07:42:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 65,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 19,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2"
        ],
        "tags": [
          "not-for-all-audiences"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fdc032b60e2c9ddd574624",
    "id": "TheBloke/Pygmalion-2-13B-SuperCOT-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 61,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Pygmalion-2-13B-SuperCOT-GGUF",
    "model": {
      "_id": "64fdc032b60e2c9ddd574624",
      "id": "TheBloke/Pygmalion-2-13B-SuperCOT-GGUF",
      "modelId": "TheBloke/Pygmalion-2-13B-SuperCOT-GGUF",
      "author": "TheBloke",
      "sha": "1ae9f9a89e82f6d6e1014314b467afa7d2b849cf",
      "lastModified": "2023-09-27T12:48:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 61,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "llama",
          "llama-2"
        ],
        "model_name": "Pygmalion 2 13B SuperCOT",
        "base_model": "royallab/Pygmalion-2-13b-SuperCOT",
        "inference": false,
        "model_creator": "The Royal Lab",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot.Q2_K.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot.Q3_K_L.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot.Q3_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot.Q3_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot.Q4_0.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot.Q4_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot.Q4_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot.Q5_0.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot.Q5_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot.Q5_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot.Q6_K.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fa79f6fa644654224bbd8c",
      "id": "royallab/Pygmalion-2-13b-SuperCOT",
      "modelId": "royallab/Pygmalion-2-13b-SuperCOT",
      "author": "royallab",
      "sha": "763b3fd5afc3e7fb6c7c8768d40f06901c8d5913",
      "lastModified": "2023-09-13T05:40:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4545,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "llama",
          "llama-2"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fdc4b714636d417ae64d6c",
    "id": "TheBloke/Tulpar-7B-v0-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Tulpar-7B-v0-GGUF",
    "model": {
      "_id": "64fdc4b714636d417ae64d6c",
      "id": "TheBloke/Tulpar-7B-v0-GGUF",
      "modelId": "TheBloke/Tulpar-7B-v0-GGUF",
      "author": "TheBloke",
      "sha": "8673181f3eb1b2af1cbf03c9815beae78f95652a",
      "lastModified": "2023-09-27T12:48:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "Tulpar 7B v0",
        "base_model": "HyperbeeAI/Tulpar-7b-v0",
        "inference": false,
        "model_creator": "HyperbeeAI",
        "model_type": "llama",
        "prompt_template": "### User: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke",
        "thumbnail": "https://huggingface.co/HyperbeeAI/Tulpar-7b-v0/resolve/main/tulpar.png"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tulpar-7b-v0.Q2_K.gguf"
        },
        {
          "rfilename": "tulpar-7b-v0.Q3_K_L.gguf"
        },
        {
          "rfilename": "tulpar-7b-v0.Q3_K_M.gguf"
        },
        {
          "rfilename": "tulpar-7b-v0.Q3_K_S.gguf"
        },
        {
          "rfilename": "tulpar-7b-v0.Q4_0.gguf"
        },
        {
          "rfilename": "tulpar-7b-v0.Q4_K_M.gguf"
        },
        {
          "rfilename": "tulpar-7b-v0.Q4_K_S.gguf"
        },
        {
          "rfilename": "tulpar-7b-v0.Q5_0.gguf"
        },
        {
          "rfilename": "tulpar-7b-v0.Q5_K_M.gguf"
        },
        {
          "rfilename": "tulpar-7b-v0.Q5_K_S.gguf"
        },
        {
          "rfilename": "tulpar-7b-v0.Q6_K.gguf"
        },
        {
          "rfilename": "tulpar-7b-v0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e5dbe3035f39988b993f21",
      "id": "HyperbeeAI/Tulpar-7b-v0",
      "modelId": "HyperbeeAI/Tulpar-7b-v0",
      "author": "HyperbeeAI",
      "sha": "7caa5fc7f6581d0f791b631c890682d73301b49c",
      "lastModified": "2023-09-13T19:04:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5035,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 22,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "thumbnail": "https://huggingface.co/HyperbeeAI/Tulpar-7b-v0/resolve/main/tulpar.png"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "enochianborg/HyperbeeAI-Tulpar-7b-v0",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "tulpar.png"
        }
      ]
    }
  },
  {
    "_id": "64fe2c8b1ac56bee85de01ab",
    "id": "TheBloke/MLewdBoros-L2-13B-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 41,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MLewdBoros-L2-13B-GGUF",
    "model": {
      "_id": "64fe2c8b1ac56bee85de01ab",
      "id": "TheBloke/MLewdBoros-L2-13B-GGUF",
      "modelId": "TheBloke/MLewdBoros-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "b079e0ccf4286d23b4afc2e2cd172b96d16acfa8",
      "lastModified": "2023-09-27T12:48:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 41,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ],
        "model_name": "MLewdBoros L2 13B",
        "base_model": "Undi95/MLewdBoros-L2-13B",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mlewdboros-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mlewdboros-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mlewdboros-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mlewdboros-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mlewdboros-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mlewdboros-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mlewdboros-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mlewdboros-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mlewdboros-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mlewdboros-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mlewdboros-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mlewdboros-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fc6dc935a7fc7d4f320178",
      "id": "Undi95/MLewdBoros-L2-13B",
      "modelId": "Undi95/MLewdBoros-L2-13B",
      "author": "Undi95",
      "sha": "a3033ac5825662f1c66418d7543648dc76980185",
      "lastModified": "2023-09-13T00:20:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5021,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688184320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00006.safetensors"
        },
        {
          "rfilename": "model-00002-of-00006.safetensors"
        },
        {
          "rfilename": "model-00003-of-00006.safetensors"
        },
        {
          "rfilename": "model-00004-of-00006.safetensors"
        },
        {
          "rfilename": "model-00005-of-00006.safetensors"
        },
        {
          "rfilename": "model-00006-of-00006.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fe30d352992431a63cf667",
    "id": "TheBloke/ReMM-v2-L2-13B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/ReMM-v2-L2-13B-GGUF",
    "model": {
      "_id": "64fe30d352992431a63cf667",
      "id": "TheBloke/ReMM-v2-L2-13B-GGUF",
      "modelId": "TheBloke/ReMM-v2-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "a0d72ba96321991ad8dc1bceae210f87f24a8633",
      "lastModified": "2023-09-27T12:48:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "model_name": "ReMM v2 L2 13B",
        "base_model": "Undi95/ReMM-v2-L2-13B",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "remm-v2-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "remm-v2-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "remm-v2-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "remm-v2-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "remm-v2-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "remm-v2-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "remm-v2-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "remm-v2-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "remm-v2-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "remm-v2-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "remm-v2-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "remm-v2-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fc8b10f393f3037026e400",
      "id": "Undi95/ReMM-v2-L2-13B",
      "modelId": "Undi95/ReMM-v2-L2-13B",
      "author": "Undi95",
      "sha": "bc42c77f88482c37c72c85c66135e99972bbca1b",
      "lastModified": "2023-09-09T21:18:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4748,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688184320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00006.safetensors"
        },
        {
          "rfilename": "model-00002-of-00006.safetensors"
        },
        {
          "rfilename": "model-00003-of-00006.safetensors"
        },
        {
          "rfilename": "model-00004-of-00006.safetensors"
        },
        {
          "rfilename": "model-00005-of-00006.safetensors"
        },
        {
          "rfilename": "model-00006-of-00006.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fe34cac367f7b1ca27a336",
    "id": "TheBloke/Llama-2-13B-Ensemble-v5-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 234,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama-2-13B-Ensemble-v5-GGUF",
    "model": {
      "_id": "64fe34cac367f7b1ca27a336",
      "id": "TheBloke/Llama-2-13B-Ensemble-v5-GGUF",
      "modelId": "TheBloke/Llama-2-13B-Ensemble-v5-GGUF",
      "author": "TheBloke",
      "sha": "bf8533401b9eb46855690fb06920e1e5ddf2f7e2",
      "lastModified": "2023-09-27T13:02:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 234,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Llama 2 13B Ensemble v5",
        "inference": false,
        "model_creator": "yeontaek",
        "model_link": "https://huggingface.co/yeontaek/llama-2-13B-ensemble-v5",
        "model_type": "llama",
        "quantized_by": "TheBloke",
        "base_model": "yeontaek/llama-2-13B-ensemble-v5"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v5.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v5.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v5.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v5.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v5.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v5.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v5.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v5.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v5.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v5.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v5.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v5.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "64fed63dd8c6c30ec1542c7a",
    "id": "TheBloke/Nous-Hermes-13B-Code-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Nous-Hermes-13B-Code-GGUF",
    "model": {
      "_id": "64fed63dd8c6c30ec1542c7a",
      "id": "TheBloke/Nous-Hermes-13B-Code-GGUF",
      "modelId": "TheBloke/Nous-Hermes-13B-Code-GGUF",
      "author": "TheBloke",
      "sha": "64cd82a8d3d748a1950570c7e900706589a17c7e",
      "lastModified": "2023-09-27T12:48:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "model_name": "Nous Hermes 13B Code",
        "base_model": "Undi95/Nous-Hermes-13B-Code",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "nous-hermes-13b-code.Q2_K.gguf"
        },
        {
          "rfilename": "nous-hermes-13b-code.Q3_K_L.gguf"
        },
        {
          "rfilename": "nous-hermes-13b-code.Q3_K_M.gguf"
        },
        {
          "rfilename": "nous-hermes-13b-code.Q3_K_S.gguf"
        },
        {
          "rfilename": "nous-hermes-13b-code.Q4_0.gguf"
        },
        {
          "rfilename": "nous-hermes-13b-code.Q4_K_M.gguf"
        },
        {
          "rfilename": "nous-hermes-13b-code.Q4_K_S.gguf"
        },
        {
          "rfilename": "nous-hermes-13b-code.Q5_0.gguf"
        },
        {
          "rfilename": "nous-hermes-13b-code.Q5_K_M.gguf"
        },
        {
          "rfilename": "nous-hermes-13b-code.Q5_K_S.gguf"
        },
        {
          "rfilename": "nous-hermes-13b-code.Q6_K.gguf"
        },
        {
          "rfilename": "nous-hermes-13b-code.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f3a817e93af73b30672bc4",
      "id": "Undi95/Nous-Hermes-13B-Code",
      "modelId": "Undi95/Nous-Hermes-13B-Code",
      "author": "Undi95",
      "sha": "5952f55603553777996ca7fd30736c512f4f0e65",
      "lastModified": "2023-09-09T21:09:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4961,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "wa999/Undi95-Nous-Hermes-13B-Code",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fede6bd39ef9d0d5ea68fc",
    "id": "TheBloke/Unholy-v1-10l-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Unholy-v1-10l-13B-GGUF",
    "model": {
      "_id": "64fede6bd39ef9d0d5ea68fc",
      "id": "TheBloke/Unholy-v1-10l-13B-GGUF",
      "modelId": "TheBloke/Unholy-v1-10l-13B-GGUF",
      "author": "TheBloke",
      "sha": "ab3419bcba9e8f6ba52fb7992fe626ea80976cec",
      "lastModified": "2023-09-27T12:48:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ],
        "model_name": "Unholy v1 10l 13B",
        "base_model": "Undi95/Unholy-v1-10l-13B",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "unholy-v1-10l-13b.Q2_K.gguf"
        },
        {
          "rfilename": "unholy-v1-10l-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "unholy-v1-10l-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "unholy-v1-10l-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "unholy-v1-10l-13b.Q4_0.gguf"
        },
        {
          "rfilename": "unholy-v1-10l-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "unholy-v1-10l-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "unholy-v1-10l-13b.Q5_0.gguf"
        },
        {
          "rfilename": "unholy-v1-10l-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "unholy-v1-10l-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "unholy-v1-10l-13b.Q6_K.gguf"
        },
        {
          "rfilename": "unholy-v1-10l-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fde30a39d541478e38d1d6",
      "id": "Undi95/Unholy-v1-10L-13B",
      "modelId": "Undi95/Unholy-v1-10L-13B",
      "author": "Undi95",
      "sha": "9be255a04110e88732d3699be3e5b5e7b5bd444a",
      "lastModified": "2023-09-10T21:36:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688184320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64fee9e4d8c6c30ec15697f5",
    "id": "TheBloke/Unholy-v1-12L-13B-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Unholy-v1-12L-13B-GGUF",
    "model": {
      "_id": "64fee9e4d8c6c30ec15697f5",
      "id": "TheBloke/Unholy-v1-12L-13B-GGUF",
      "modelId": "TheBloke/Unholy-v1-12L-13B-GGUF",
      "author": "TheBloke",
      "sha": "74ce5d0717271a9d07db32f498d172b84ffe3baf",
      "lastModified": "2023-09-27T12:48:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ],
        "model_name": "Unholy v1 12L 13B",
        "base_model": "Undi95/Unholy-v1-12L-13B",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "unholy-v1-12l-13b.Q2_K.gguf"
        },
        {
          "rfilename": "unholy-v1-12l-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "unholy-v1-12l-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "unholy-v1-12l-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "unholy-v1-12l-13b.Q4_0.gguf"
        },
        {
          "rfilename": "unholy-v1-12l-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "unholy-v1-12l-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "unholy-v1-12l-13b.Q5_0.gguf"
        },
        {
          "rfilename": "unholy-v1-12l-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "unholy-v1-12l-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "unholy-v1-12l-13b.Q6_K.gguf"
        },
        {
          "rfilename": "unholy-v1-12l-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fe06b9ace5670c73a330f8",
      "id": "Undi95/Unholy-v1-12L-13B",
      "modelId": "Undi95/Unholy-v1-12L-13B",
      "author": "Undi95",
      "sha": "ee25c078f08b0812d82597afa3f5e877c19a5c83",
      "lastModified": "2023-09-10T21:37:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4669,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 32,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "bookoostable/Undi95-Unholy-v1-12L-13B"
      ],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688184320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ff68bbefd273eec765be98",
    "id": "TheBloke/Llama-2-70B-Ensemble-v5-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama-2-70B-Ensemble-v5-GGUF",
    "model": {
      "_id": "64ff68bbefd273eec765be98",
      "id": "TheBloke/Llama-2-70B-Ensemble-v5-GGUF",
      "modelId": "TheBloke/Llama-2-70B-Ensemble-v5-GGUF",
      "author": "TheBloke",
      "sha": "bbaa834510129427f5bc94f55972275a9ca4c638",
      "lastModified": "2023-09-27T12:48:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Llama 2 70B Ensemble v5",
        "base_model": "yeontaek/llama-2-70B-ensemble-v5",
        "inference": false,
        "model_creator": "yeontaek",
        "model_type": "llama",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b-ensemble-v5.Q8_0.gguf-split-b"
        }
      ]
    }
  },
  {
    "_id": "64ff691a1e14749e84d2c2d9",
    "id": "TheBloke/Spicyboros-70B-2.2-GGUF",
    "likes": 14,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "dataset:jondurbin/airoboros-2.2",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Spicyboros-70B-2.2-GGUF",
    "model": {
      "_id": "64ff691a1e14749e84d2c2d9",
      "id": "TheBloke/Spicyboros-70B-2.2-GGUF",
      "modelId": "TheBloke/Spicyboros-70B-2.2-GGUF",
      "author": "TheBloke",
      "sha": "0bedd8a3d51361cd6c7e7a5ad5dab1c279c50087",
      "lastModified": "2023-09-27T12:48:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 14,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "not-for-all-audiences"
        ],
        "datasets": [
          "jondurbin/airoboros-2.2"
        ],
        "model_name": "Spicyboros 70B 2.2",
        "base_model": "jondurbin/spicyboros-70b-2.2",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q2_K.gguf"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q4_0.gguf"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q5_0.gguf"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "spicyboros-70b-2.2.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "6501d9264884f2291887aa11",
      "id": "jondurbin/spicyboros-70b-2.2",
      "modelId": "jondurbin/spicyboros-70b-2.2",
      "author": "jondurbin",
      "sha": "533f7dda1e3fe462a0abb00671f9a48d5fd51093",
      "lastModified": "2023-09-13T20:29:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 60,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2"
        ],
        "tags": [
          "not-for-all-audiences"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ff7a2fa8e31c77227bfef0",
    "id": "TheBloke/Marcoroni-7b-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:Open-Orca/OpenOrca",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Marcoroni-7b-GGUF",
    "model": {
      "_id": "64ff7a2fa8e31c77227bfef0",
      "id": "TheBloke/Marcoroni-7b-GGUF",
      "modelId": "TheBloke/Marcoroni-7b-GGUF",
      "author": "TheBloke",
      "sha": "79420241fd81c2ca147262f11c86979c5d326ce7",
      "lastModified": "2023-09-27T12:48:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-4.0",
        "datasets": [
          "Open-Orca/OpenOrca"
        ],
        "model_name": "Marcoroni 7b",
        "base_model": "AIDC-ai-business/Marcoroni-7b",
        "inference": false,
        "model_creator": "AIDC-ai-business",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "marcoroni-7b.Q2_K.gguf"
        },
        {
          "rfilename": "marcoroni-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "marcoroni-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "marcoroni-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "marcoroni-7b.Q4_0.gguf"
        },
        {
          "rfilename": "marcoroni-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "marcoroni-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "marcoroni-7b.Q5_0.gguf"
        },
        {
          "rfilename": "marcoroni-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "marcoroni-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "marcoroni-7b.Q6_K.gguf"
        },
        {
          "rfilename": "marcoroni-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f5a5e751cc760bbc0b49c9",
      "id": "AIDC-ai-business/Marcoroni-7B",
      "modelId": "AIDC-ai-business/Marcoroni-7B",
      "author": "AIDC-ai-business",
      "sha": "01cba4df48568f45691a9ef073fb7db423d36422",
      "lastModified": "2023-09-22T17:21:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 183,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "datasets": [
          "Open-Orca/OpenOrca"
        ],
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "AstroBen/AIDC-ai-business-Marcoroni-7B",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "64ff7ae8e0c94282ab21d78a",
    "id": "TheBloke/Marcoroni-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:Open-Orca/OpenOrca",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Marcoroni-13B-GGUF",
    "model": {
      "_id": "64ff7ae8e0c94282ab21d78a",
      "id": "TheBloke/Marcoroni-13B-GGUF",
      "modelId": "TheBloke/Marcoroni-13B-GGUF",
      "author": "TheBloke",
      "sha": "3fbe0d50c7a06f9e3603b63de259b2f0a9154881",
      "lastModified": "2023-09-27T12:48:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-4.0",
        "datasets": [
          "Open-Orca/OpenOrca"
        ],
        "model_name": "Marcoroni 13B",
        "base_model": "AIDC-ai-business/Marcoroni-13B",
        "inference": false,
        "model_creator": "AIDC-ai-business",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "marcoroni-13b.Q2_K.gguf"
        },
        {
          "rfilename": "marcoroni-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "marcoroni-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "marcoroni-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "marcoroni-13b.Q4_0.gguf"
        },
        {
          "rfilename": "marcoroni-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "marcoroni-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "marcoroni-13b.Q5_0.gguf"
        },
        {
          "rfilename": "marcoroni-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "marcoroni-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "marcoroni-13b.Q6_K.gguf"
        },
        {
          "rfilename": "marcoroni-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650709f34a8839a8bd85e950",
      "id": "AIDC-ai-business/Marcoroni-13B",
      "modelId": "AIDC-ai-business/Marcoroni-13B",
      "author": "AIDC-ai-business",
      "sha": "d081d2a863973704dae719761ec6e7be4ad9215a",
      "lastModified": "2023-09-22T17:21:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 89,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "datasets": [
          "Open-Orca/OpenOrca"
        ],
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6500535bb213fc1f1de0c167",
    "id": "TheBloke/Llama-2-13B-Chat-Dutch-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 16,
    "tags": [
      "transformers",
      "llama",
      "generated_from_trainer",
      "lora",
      "adapters",
      "nl",
      "dataset:BramVanroy/dutch_chat_datasets",
      "license:cc-by-nc-sa-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama-2-13B-Chat-Dutch-GGUF",
    "model": {
      "_id": "6500535bb213fc1f1de0c167",
      "id": "TheBloke/Llama-2-13B-Chat-Dutch-GGUF",
      "modelId": "TheBloke/Llama-2-13B-Chat-Dutch-GGUF",
      "author": "TheBloke",
      "sha": "615b4ff967d510388e41a23f69d26ed0d5a6671c",
      "lastModified": "2023-09-27T12:48:52.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "generated_from_trainer",
        "lora",
        "adapters",
        "nl",
        "dataset:BramVanroy/dutch_chat_datasets",
        "license:cc-by-nc-sa-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 16,
      "library_name": "transformers",
      "likes": 4,
      "model-index": [
        {
          "name": "Llama-2-13b-chat-dutch",
          "results": []
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "nl"
        ],
        "license": "cc-by-nc-sa-4.0",
        "tags": [
          "generated_from_trainer",
          "llama",
          "lora",
          "adapters"
        ],
        "datasets": [
          "BramVanroy/dutch_chat_datasets"
        ],
        "base_model": "BramVanroy/Llama-2-13b-chat-dutch",
        "inference": false,
        "model_creator": "Bram Vanroy",
        "model_type": "llama",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n{prompt}[/INST]\n",
        "quantized_by": "TheBloke",
        "model-index": [
          {
            "name": "Llama-2-13b-chat-dutch",
            "results": []
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-13b-chat-dutch.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-dutch.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-dutch.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-dutch.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-dutch.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-dutch.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-dutch.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-dutch.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-dutch.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-dutch.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-dutch.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-chat-dutch.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64da4cb02d4eb446edb61126",
      "id": "BramVanroy/Llama-2-13b-chat-dutch",
      "modelId": "BramVanroy/Llama-2-13b-chat-dutch",
      "author": "BramVanroy",
      "sha": "428508a0cf288c0f5b7891c9b2f758ddf4d62c26",
      "lastModified": "2023-08-24T09:14:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "generated_from_trainer",
        "lora",
        "adapters",
        "nl",
        "dataset:BramVanroy/dutch_chat_datasets",
        "doi:10.57967/hf/1018",
        "license:cc-by-nc-sa-4.0",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4773,
      "library_name": "transformers",
      "likes": 12,
      "model-index": [
        {
          "name": "Llama-2-13b-chat-dutch",
          "results": []
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-sa-4.0",
        "base_model": "BramVanroy/llama2-13b-ft-mc4_nl_cleaned_tiny",
        "tags": [
          "generated_from_trainer",
          "llama",
          "lora",
          "adapters"
        ],
        "datasets": [
          "BramVanroy/dutch_chat_datasets"
        ],
        "model-index": [
          {
            "name": "Llama-2-13b-chat-dutch",
            "results": []
          }
        ],
        "language": [
          "nl"
        ],
        "inference": false
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "BramVanroy/llama-2-13b-chat-dutch-space"
      ],
      "safetensors": {
        "parameters": {
          "F32": 2560,
          "BF16": 13015864320
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "all_results.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "eval_results.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "train_results.json"
        },
        {
          "rfilename": "trainer_state.json"
        }
      ]
    }
  },
  {
    "_id": "6500587e1e14749e84f1ba37",
    "id": "TheBloke/JanniesBasedLigma-L2-13B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/JanniesBasedLigma-L2-13B-GGUF",
    "model": {
      "_id": "6500587e1e14749e84f1ba37",
      "id": "TheBloke/JanniesBasedLigma-L2-13B-GGUF",
      "modelId": "TheBloke/JanniesBasedLigma-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "4bf5cef604bd6341a639ce48d01116e2d5488d9f",
      "lastModified": "2023-09-27T12:48:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "model_name": "JanniesBasedLigma L2 13B",
        "base_model": "Sao10K/JanniesBasedLigma-L2-13B",
        "inference": false,
        "model_creator": "Sao10k",
        "model_type": "llama",
        "prompt_template": "You are a helpful AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "janniesbasedligma-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "janniesbasedligma-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "janniesbasedligma-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "janniesbasedligma-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "janniesbasedligma-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "janniesbasedligma-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "janniesbasedligma-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "janniesbasedligma-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "janniesbasedligma-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "janniesbasedligma-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "janniesbasedligma-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "janniesbasedligma-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fddd66b8d50cebd680c6e6",
      "id": "Sao10K/JanniesBasedLigma-L2-13B",
      "modelId": "Sao10K/JanniesBasedLigma-L2-13B",
      "author": "Sao10K",
      "sha": "c1fb74b9a5b8dde4d3ed9a250b55bbb64efb37ba",
      "lastModified": "2023-09-11T09:25:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": ".ipynb_checkpoints/config-checkpoint.json"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650062504ebb666058804b6b",
    "id": "TheBloke/Sheep-Duck-Llama-2-70B-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "Riiid",
      "llama-2",
      "text-generation",
      "en",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Sheep-Duck-Llama-2-70B-GGUF",
    "model": {
      "_id": "650062504ebb666058804b6b",
      "id": "TheBloke/Sheep-Duck-Llama-2-70B-GGUF",
      "modelId": "TheBloke/Sheep-Duck-Llama-2-70B-GGUF",
      "author": "TheBloke",
      "sha": "9cf25ae9f9c9ea3598458c6fca5dfa8937735e94",
      "lastModified": "2023-09-27T12:48:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "Riiid",
        "llama-2",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "Riiid",
          "llama-2"
        ],
        "model_name": "Sheep Duck Llama 2",
        "base_model": "Riiid/sheep-duck-llama-2",
        "inference": false,
        "model_creator": "Riiid",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### System:\n{system_message}\n\n### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke",
        "thumbnail": "https://cdn-uploads.huggingface.co/production/uploads/62fb1ef7e8c9c532aa7d19e4/NswB5XPkkOljeRh1xbMmR.png"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q2_K.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q3_K_L.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q3_K_M.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q3_K_S.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q4_0.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q4_K_M.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q4_K_S.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q5_0.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q5_K_M.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q5_K_S.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "sheep-duck-llama-2.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64f7d2fbb16a298a1ca41374",
      "id": "Riiid/sheep-duck-llama-2",
      "modelId": "Riiid/sheep-duck-llama-2",
      "author": "Riiid",
      "sha": "366f2bfd912e8f258541c0480a34eb973198286c",
      "lastModified": "2023-10-13T00:59:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "Riiid",
        "llama-2",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 913118,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 32,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "thumbnail": "https://cdn-uploads.huggingface.co/production/uploads/62fb1ef7e8c9c532aa7d19e4/NswB5XPkkOljeRh1xbMmR.png",
        "pipeline_tag": "text-generation",
        "license": "llama2",
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "tags": [
          "Riiid",
          "llama-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "simpx/Riiid-sheep-duck-llama-2",
        "Saurabh418/Riiid-sheep-duck-llama-2",
        "MattCase/Riiid-sheep-duck-llama-2",
        "riolu7600/llama-2-test"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65008360990aaba7bb481216",
    "id": "TheBloke/Airoboros-L2-7B-2.2-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.2",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-7B-2.2-GGUF",
    "model": {
      "_id": "65008360990aaba7bb481216",
      "id": "TheBloke/Airoboros-L2-7B-2.2-GGUF",
      "modelId": "TheBloke/Airoboros-L2-7B-2.2-GGUF",
      "author": "TheBloke",
      "sha": "c1843c9dbc74269a39376a96a47a68d0ec85d8f9",
      "lastModified": "2023-09-27T12:48:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2"
        ],
        "model_name": "Airoboros L2 7B 2.2",
        "base_model": "jondurbin/airoboros-l2-7b-2.2",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64fe4a8b58718aaa93223bc6",
      "id": "jondurbin/airoboros-l2-7b-2.2",
      "modelId": "jondurbin/airoboros-l2-7b-2.2",
      "author": "jondurbin",
      "sha": "87c323b2c1e2628bf6774871654b03f41b3ba8d7",
      "lastModified": "2023-09-12T07:42:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650083a0cc88b84c06c3a509",
    "id": "TheBloke/Airoboros-L2-70b-2.2-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.2",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-70b-2.2-GGUF",
    "model": {
      "_id": "650083a0cc88b84c06c3a509",
      "id": "TheBloke/Airoboros-L2-70b-2.2-GGUF",
      "modelId": "TheBloke/Airoboros-L2-70b-2.2-GGUF",
      "author": "TheBloke",
      "sha": "4aacf74b4b67c4172f684976e015f14e5d196e3c",
      "lastModified": "2023-09-27T12:48:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2"
        ],
        "model_name": "Airoboros L2 70B 2.2",
        "base_model": "jondurbin/airoboros-l2-70b-2.2",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6501cf02077df7a51187aa1c",
      "id": "jondurbin/airoboros-l2-70b-2.2",
      "modelId": "jondurbin/airoboros-l2-70b-2.2",
      "author": "jondurbin",
      "sha": "a42e7aa7beefde7b23fceb365b65c4476cb10914",
      "lastModified": "2023-09-13T20:09:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6500853e7804f04a163db26a",
    "id": "TheBloke/Airoboros-L2-13B-2.2-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.2",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-13B-2.2-GGUF",
    "model": {
      "_id": "6500853e7804f04a163db26a",
      "id": "TheBloke/Airoboros-L2-13B-2.2-GGUF",
      "modelId": "TheBloke/Airoboros-L2-13B-2.2-GGUF",
      "author": "TheBloke",
      "sha": "fc16805be8a5a90b7ea4e614711a23b96981521d",
      "lastModified": "2023-09-27T12:48:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2"
        ],
        "model_name": "Airoboros L2 13B 2.2",
        "base_model": "jondurbin/airoboros-l2-13b-2.2",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64fe4a94fa64465422c2612f",
      "id": "jondurbin/airoboros-l2-13b-2.2",
      "modelId": "jondurbin/airoboros-l2-13b-2.2",
      "author": "jondurbin",
      "sha": "ef2bd8fec8e046286443c9e79a810538085ec257",
      "lastModified": "2023-09-12T07:42:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650097127804f04a16403ad7",
    "id": "TheBloke/Spicyboros-c34b-2.2-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "dataset:jondurbin/airoboros-2.2",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Spicyboros-c34b-2.2-GGUF",
    "model": {
      "_id": "650097127804f04a16403ad7",
      "id": "TheBloke/Spicyboros-c34b-2.2-GGUF",
      "modelId": "TheBloke/Spicyboros-c34b-2.2-GGUF",
      "author": "TheBloke",
      "sha": "7899a293012ab0361e6102abf5a0ce5fc62a9d94",
      "lastModified": "2023-09-27T12:48:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "tags": [
          "not-for-all-audiences"
        ],
        "datasets": [
          "jondurbin/airoboros-2.2"
        ],
        "model_name": "Spicyboros c34B 2.2",
        "base_model": "jondurbin/spicyboros-c34b-2.2",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "spicyboros-c34b-2.2.Q2_K.gguf"
        },
        {
          "rfilename": "spicyboros-c34b-2.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "spicyboros-c34b-2.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "spicyboros-c34b-2.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "spicyboros-c34b-2.2.Q4_0.gguf"
        },
        {
          "rfilename": "spicyboros-c34b-2.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "spicyboros-c34b-2.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "spicyboros-c34b-2.2.Q5_0.gguf"
        },
        {
          "rfilename": "spicyboros-c34b-2.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "spicyboros-c34b-2.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "spicyboros-c34b-2.2.Q6_K.gguf"
        },
        {
          "rfilename": "spicyboros-c34b-2.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6501d9c47a1063c6477e43d2",
      "id": "jondurbin/spicyboros-c34b-2.2",
      "modelId": "jondurbin/spicyboros-c34b-2.2",
      "author": "jondurbin",
      "sha": "afa9178bba0a2bb74afde15b654c4b44ef90926d",
      "lastModified": "2023-09-14T12:18:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2"
        ],
        "tags": [
          "not-for-all-audiences"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650099eed522560505c5ba6f",
    "id": "TheBloke/Llama-2-13B-Ensemble-v6-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 21,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama-2-13B-Ensemble-v6-GGUF",
    "model": {
      "_id": "650099eed522560505c5ba6f",
      "id": "TheBloke/Llama-2-13B-Ensemble-v6-GGUF",
      "modelId": "TheBloke/Llama-2-13B-Ensemble-v6-GGUF",
      "author": "TheBloke",
      "sha": "f0adc15fa18b6696dae898d6e4fd0ded67362160",
      "lastModified": "2023-09-27T13:02:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 21,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Llama 2 13B Ensemble v6",
        "inference": false,
        "model_creator": "yeontaek",
        "model_link": "https://huggingface.co/yeontaek/llama-2-13B-ensemble-v6",
        "model_type": "llama",
        "quantized_by": "TheBloke",
        "base_model": "yeontaek/llama-2-13B-ensemble-v6"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v6.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v6.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v6.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v6.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v6.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v6.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v6.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v6.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v6.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v6.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v6.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-ensemble-v6.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "65009d6635ec971762995446",
    "id": "TheBloke/Euryale-Inverted-L2-70B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Euryale-Inverted-L2-70B-GGUF",
    "model": {
      "_id": "65009d6635ec971762995446",
      "id": "TheBloke/Euryale-Inverted-L2-70B-GGUF",
      "modelId": "TheBloke/Euryale-Inverted-L2-70B-GGUF",
      "author": "TheBloke",
      "sha": "8e8149e5f3ceb4e85138fbe259ff8c0968f3eb30",
      "lastModified": "2023-09-27T12:49:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-4.0",
        "model_name": "Euryale Inverted L2 70B",
        "base_model": "Sao10K/Euryale-Inverted-L2-70B",
        "inference": false,
        "model_creator": "Sao10K",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q2_K.gguf"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q4_0.gguf"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q5_0.gguf"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "euryale-inverted-l2-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64ff38e5b4fd50585bfe776c",
      "id": "Sao10K/Euryale-Inverted-L2-70B",
      "modelId": "Sao10K/Euryale-Inverted-L2-70B",
      "author": "Sao10K",
      "sha": "6e3bbb7a646a877577f7ad2fd71f4c81ff6b8da0",
      "lastModified": "2023-09-12T11:28:52.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6500a057696355700d97b6c5",
    "id": "TheBloke/Euryale-L2-70B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Euryale-L2-70B-GGUF",
    "model": {
      "_id": "6500a057696355700d97b6c5",
      "id": "TheBloke/Euryale-L2-70B-GGUF",
      "modelId": "TheBloke/Euryale-L2-70B-GGUF",
      "author": "TheBloke",
      "sha": "0fd3598e44074949be1e5f9a6dac8bb3e0c7c0aa",
      "lastModified": "2023-09-27T12:49:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-4.0",
        "model_name": "Euryale L2 70B",
        "base_model": "Sao10K/Euryale-L2-70B",
        "inference": false,
        "model_creator": "Sao10K",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "euryale-l2-70b.Q2_K.gguf"
        },
        {
          "rfilename": "euryale-l2-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "euryale-l2-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "euryale-l2-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "euryale-l2-70b.Q4_0.gguf"
        },
        {
          "rfilename": "euryale-l2-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "euryale-l2-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "euryale-l2-70b.Q5_0.gguf"
        },
        {
          "rfilename": "euryale-l2-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "euryale-l2-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "euryale-l2-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "euryale-l2-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "euryale-l2-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "euryale-l2-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64ff305daa37467756b188fe",
      "id": "Sao10K/Euryale-L2-70B",
      "modelId": "Sao10K/Euryale-L2-70B",
      "author": "Sao10K",
      "sha": "6b439992412cc8c247e9fbe87101c0d2c51cf30e",
      "lastModified": "2023-09-26T08:49:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7093,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": ".ipynb_checkpoints/config-checkpoint.json"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6501b9a60cc65d59987f9e83",
    "id": "TheBloke/Kuchiki-L2-7B-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 83,
    "tags": [
      "transformers",
      "llama",
      "llama2",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Kuchiki-L2-7B-GGUF",
    "model": {
      "_id": "6501b9a60cc65d59987f9e83",
      "id": "TheBloke/Kuchiki-L2-7B-GGUF",
      "modelId": "TheBloke/Kuchiki-L2-7B-GGUF",
      "author": "TheBloke",
      "sha": "3fd9e634fb48133a96f9f457c0ffa1a51785831b",
      "lastModified": "2023-09-27T12:49:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama2",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 83,
      "library_name": "transformers",
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama2"
        ],
        "model_name": "Kuchiki L2 7B",
        "base_model": "zarakiquemparte/kuchiki-l2-7b",
        "inference": false,
        "model_creator": "Zaraki Quem Parte",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "kuchiki-l2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "kuchiki-l2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "kuchiki-l2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "kuchiki-l2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "kuchiki-l2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "kuchiki-l2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "kuchiki-l2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "kuchiki-l2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "kuchiki-l2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "kuchiki-l2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "kuchiki-l2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "kuchiki-l2-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d7a74e2fe2c112643c1a09",
      "id": "zarakiquemparte/kuchiki-l2-7b",
      "modelId": "zarakiquemparte/kuchiki-l2-7b",
      "author": "zarakiquemparte",
      "sha": "745c34e70aa92056e8cd79c1d16e8fcfe1797645",
      "lastModified": "2023-09-14T13:48:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama2",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6533,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "merge-illustration.png"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6501be085c0e01b2286cb836",
    "id": "TheBloke/Llama2-Chat-AYT-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 14,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama2-Chat-AYT-13B-GGUF",
    "model": {
      "_id": "6501be085c0e01b2286cb836",
      "id": "TheBloke/Llama2-Chat-AYT-13B-GGUF",
      "modelId": "TheBloke/Llama2-Chat-AYT-13B-GGUF",
      "author": "TheBloke",
      "sha": "779a166d4d0b75a3c22581a87673f53d8e820e01",
      "lastModified": "2023-09-27T12:49:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 14,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Llama2 Chat AYT 13B",
        "base_model": "posicube/Llama2-chat-AYT-13B",
        "inference": false,
        "model_creator": "posicube",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama2-chat-ayt-13b.Q2_K.gguf"
        },
        {
          "rfilename": "llama2-chat-ayt-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama2-chat-ayt-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama2-chat-ayt-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama2-chat-ayt-13b.Q4_0.gguf"
        },
        {
          "rfilename": "llama2-chat-ayt-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama2-chat-ayt-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama2-chat-ayt-13b.Q5_0.gguf"
        },
        {
          "rfilename": "llama2-chat-ayt-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama2-chat-ayt-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama2-chat-ayt-13b.Q6_K.gguf"
        },
        {
          "rfilename": "llama2-chat-ayt-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f99e4c41b6fb74cb27f180",
      "id": "posicube/Llama2-chat-AYT-13B",
      "modelId": "posicube/Llama2-chat-AYT-13B",
      "author": "posicube",
      "sha": "dd3d7d1afba12ca83dd3b376829eda95dccc7645",
      "lastModified": "2023-09-14T03:36:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4934,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6501e31c01030db3736c46fa",
    "id": "TheBloke/Llama-2-Coder-7B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 19,
    "tags": [
      "transformers",
      "llama",
      "generated_from_trainer",
      "code",
      "coding",
      "text-generation",
      "dataset:HuggingFaceH4/CodeAlpaca_20K",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Llama-2-Coder-7B-GGUF",
    "model": {
      "_id": "6501e31c01030db3736c46fa",
      "id": "TheBloke/Llama-2-Coder-7B-GGUF",
      "modelId": "TheBloke/Llama-2-Coder-7B-GGUF",
      "author": "TheBloke",
      "sha": "b8d62855fcf05e71345a1c859ed74be12937fe90",
      "lastModified": "2023-09-27T12:49:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "generated_from_trainer",
        "code",
        "coding",
        "text-generation",
        "dataset:HuggingFaceH4/CodeAlpaca_20K",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 19,
      "library_name": "transformers",
      "likes": 7,
      "model-index": [
        {
          "name": "FalCoder",
          "results": []
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "code"
        ],
        "license": "apache-2.0",
        "tags": [
          "generated_from_trainer",
          "code",
          "coding",
          "llama"
        ],
        "datasets": [
          "HuggingFaceH4/CodeAlpaca_20K"
        ],
        "base_model": "mrm8488/llama-2-coder-7b",
        "inference": false,
        "model_creator": "mrm8488",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "You are a coding assistant that will help the user to resolve the following instruction:\n### Instruction: {prompt}\n\n### Solution:\n",
        "quantized_by": "TheBloke",
        "thumbnail": "https://huggingface.co/mrm8488/llama-2-coder-7b/resolve/main/llama2-coder-logo-removebg-preview.png",
        "model-index": [
          {
            "name": "FalCoder",
            "results": []
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-coder-7b.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-coder-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-coder-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-coder-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-coder-7b.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-coder-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-coder-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-coder-7b.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-coder-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-coder-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-coder-7b.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-coder-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c15ef741d9385bffd6614f",
      "id": "mrm8488/llama-2-coder-7b",
      "modelId": "mrm8488/llama-2-coder-7b",
      "author": "mrm8488",
      "sha": "f21c0d5e3f9f8c5addf093358e6885afa9602296",
      "lastModified": "2023-07-26T20:12:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "generated_from_trainer",
        "code",
        "coding",
        "dataset:HuggingFaceH4/CodeAlpaca_20K",
        "doi:10.57967/hf/0931",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4767,
      "library_name": "transformers",
      "likes": 37,
      "model-index": [
        {
          "name": "FalCoder",
          "results": []
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "generated_from_trainer",
          "code",
          "coding",
          "llama"
        ],
        "model-index": [
          {
            "name": "FalCoder",
            "results": []
          }
        ],
        "license": "apache-2.0",
        "language": [
          "code"
        ],
        "thumbnail": "https://huggingface.co/mrm8488/llama-2-coder-7b/resolve/main/llama2-coder-logo-removebg-preview.png",
        "datasets": [
          "HuggingFaceH4/CodeAlpaca_20K"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "llama2-coder-logo-removebg-preview.png"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6502bccff10502379a8476c7",
    "id": "TheBloke/AppleSauce-L2-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/AppleSauce-L2-13B-GGUF",
    "model": {
      "_id": "6502bccff10502379a8476c7",
      "id": "TheBloke/AppleSauce-L2-13B-GGUF",
      "modelId": "TheBloke/AppleSauce-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "76b765a69ef173bd45baf4c110cb65791db9093d",
      "lastModified": "2023-09-27T12:49:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "model_name": "AppleSauce L2 13B",
        "base_model": "sauce1337/AppleSauce-L2-13b",
        "inference": false,
        "model_creator": "sauce1337",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "applesauce-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "applesauce-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "applesauce-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "applesauce-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "applesauce-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "applesauce-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "applesauce-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "applesauce-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "applesauce-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "applesauce-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "applesauce-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "applesauce-l2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "65011d804b7e0cd1b7ee1a77",
      "id": "sauce1337/AppleSauce-L2-13b",
      "modelId": "sauce1337/AppleSauce-L2-13b",
      "author": "sauce1337",
      "sha": "09e8d11023e50b4714817f62c34149fa242ef0f3",
      "lastModified": "2023-09-14T19:41:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4513,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688184320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "AppleSauce-Q5_K_M.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "okapple.png"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6502bfe51a5924e2281bd3c0",
    "id": "TheBloke/BerrySauce-L2-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/BerrySauce-L2-13B-GGUF",
    "model": {
      "_id": "6502bfe51a5924e2281bd3c0",
      "id": "TheBloke/BerrySauce-L2-13B-GGUF",
      "modelId": "TheBloke/BerrySauce-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "262d01d4223dffafa1eafed2f9df5710e3e8a284",
      "lastModified": "2023-09-27T12:49:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "model_name": "BerrySauce L2 13B",
        "base_model": "sauce1337/berrySauce-L2-13b",
        "inference": false,
        "model_creator": "sauce1337",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "berrysauce-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "berrysauce-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "berrysauce-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "berrysauce-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "berrysauce-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "berrysauce-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "berrysauce-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "berrysauce-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "berrysauce-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "berrysauce-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "berrysauce-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "berrysauce-l2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "650160f169219ce3e4c00b50",
      "id": "sauce1337/BerrySauce-L2-13b",
      "modelId": "sauce1337/BerrySauce-L2-13b",
      "author": "sauce1337",
      "sha": "729ca3c25a3a542db5a4cf8bf2fa54c4ba2ffe36",
      "lastModified": "2023-09-19T15:59:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4497,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "BerrySauce-Q5_K_M.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "okberry.png"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6502df56b1792803da7b7bbf",
    "id": "TheBloke/Llama-2-13B-LoRA-Assemble-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama-2-13B-LoRA-Assemble-GGUF",
    "model": {
      "_id": "6502df56b1792803da7b7bbf",
      "id": "TheBloke/Llama-2-13B-LoRA-Assemble-GGUF",
      "modelId": "TheBloke/Llama-2-13B-LoRA-Assemble-GGUF",
      "author": "TheBloke",
      "sha": "4a55f734372c65720b9b268b83cafd626f745758",
      "lastModified": "2023-09-27T12:49:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Llama 2 13B LoRA Assemble",
        "base_model": "oh-yeontaek/llama-2-13b-LoRA-assemble",
        "inference": false,
        "model_creator": "oh-yeontaek",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-13b-lora-assemble.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-lora-assemble.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-13b-lora-assemble.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-lora-assemble.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-lora-assemble.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-lora-assemble.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-lora-assemble.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-lora-assemble.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-13b-lora-assemble.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-13b-lora-assemble.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-13b-lora-assemble.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-13b-lora-assemble.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6502214794601e9a219396f3",
      "id": "oh-yeontaek/llama-2-13B-LoRA-assemble",
      "modelId": "oh-yeontaek/llama-2-13B-LoRA-assemble",
      "author": "oh-yeontaek",
      "sha": "85bb49d333dba4a08b051418663d16853ce30cee",
      "lastModified": "2023-09-13T21:39:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6572,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6502e2be3a05fd436bc5ba07",
    "id": "TheBloke/Llama-2-7B-LoRA-Assemble-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama-2-7B-LoRA-Assemble-GGUF",
    "model": {
      "_id": "6502e2be3a05fd436bc5ba07",
      "id": "TheBloke/Llama-2-7B-LoRA-Assemble-GGUF",
      "modelId": "TheBloke/Llama-2-7B-LoRA-Assemble-GGUF",
      "author": "TheBloke",
      "sha": "2bcb5c8e87955e088cd16a9026302ffe7184882e",
      "lastModified": "2023-09-27T12:49:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Llama 2 7B LoRA Assemble",
        "base_model": "oh-yeontaek/llama-2-7B-LoRA-assemble",
        "inference": false,
        "model_creator": "oh-yeontaek",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-7b-lora-assemble.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-lora-assemble.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-7b-lora-assemble.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-lora-assemble.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-lora-assemble.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-lora-assemble.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-lora-assemble.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-lora-assemble.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-lora-assemble.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-lora-assemble.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-lora-assemble.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-lora-assemble.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6501d59b05d6d96e50ec33f7",
      "id": "oh-yeontaek/llama-2-7B-LoRA-assemble",
      "modelId": "oh-yeontaek/llama-2-7B-LoRA-assemble",
      "author": "oh-yeontaek",
      "sha": "72e866a96a2e9afc6527c8d757c69088c3a069c8",
      "lastModified": "2023-09-13T15:40:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5509,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6502e49089707f1823955100",
    "id": "TheBloke/Pygmalion-2-13B-SuperCOT2-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Pygmalion-2-13B-SuperCOT2-GGUF",
    "model": {
      "_id": "6502e49089707f1823955100",
      "id": "TheBloke/Pygmalion-2-13B-SuperCOT2-GGUF",
      "modelId": "TheBloke/Pygmalion-2-13B-SuperCOT2-GGUF",
      "author": "TheBloke",
      "sha": "e07e6af3580642892f07764a1124e56c5fb3e79a",
      "lastModified": "2023-09-27T12:49:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "llama",
          "llama-2"
        ],
        "model_name": "Pygmalion 2 13B SuperCOT2",
        "base_model": "royallab/Pygmalion-2-13b-SuperCOT2",
        "inference": false,
        "model_creator": "royallab",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot2.Q2_K.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot2.Q3_K_L.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot2.Q3_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot2.Q3_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot2.Q4_0.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot2.Q4_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot2.Q4_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot2.Q5_0.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot2.Q5_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot2.Q5_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot2.Q6_K.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6502700d6840f21513f50271",
      "id": "royallab/Pygmalion-2-13b-SuperCOT2",
      "modelId": "royallab/Pygmalion-2-13b-SuperCOT2",
      "author": "royallab",
      "sha": "de4591220eac50b1de7eafc7247a6dc18142b7b7",
      "lastModified": "2023-09-14T04:54:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 11,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "llama",
          "llama-2"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6502f15c2cec4c6d94f82b25",
    "id": "TheBloke/Marcoroni-70B-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:Open-Orca/OpenOrca",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Marcoroni-70B-GGUF",
    "model": {
      "_id": "6502f15c2cec4c6d94f82b25",
      "id": "TheBloke/Marcoroni-70B-GGUF",
      "modelId": "TheBloke/Marcoroni-70B-GGUF",
      "author": "TheBloke",
      "sha": "8fb4e369b9cc79581f9e893b4257fa41b361d165",
      "lastModified": "2023-09-27T12:49:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-4.0",
        "datasets": [
          "Open-Orca/OpenOrca"
        ],
        "model_name": "Marcoroni 70B",
        "base_model": "AIDC-ai-business/Marcoroni-70b",
        "inference": false,
        "model_creator": "AIDC-ai-business",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "marcoroni-70b.Q2_K.gguf"
        },
        {
          "rfilename": "marcoroni-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "marcoroni-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "marcoroni-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "marcoroni-70b.Q4_0.gguf"
        },
        {
          "rfilename": "marcoroni-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "marcoroni-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "marcoroni-70b.Q5_0.gguf"
        },
        {
          "rfilename": "marcoroni-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "marcoroni-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "marcoroni-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "marcoroni-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "marcoroni-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "marcoroni-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "650193e3493fd9c8c2dc0cc4",
      "id": "AIDC-ai-business/Marcoroni-70B",
      "modelId": "AIDC-ai-business/Marcoroni-70B",
      "author": "AIDC-ai-business",
      "sha": "dc14cff8823149895e1ba317eee009da5441cca0",
      "lastModified": "2023-09-19T08:41:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 21,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "datasets": [
          "Open-Orca/OpenOrca"
        ],
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "dhinagaran/AIDC-ai-business-Marcoroni-70B",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6503435e55837b784f989319",
    "id": "TheBloke/Chinese-Alpaca-2-7B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 825,
    "tags": [
      "transformers",
      "llama",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Chinese-Alpaca-2-7B-GGUF",
    "model": {
      "_id": "6503435e55837b784f989319",
      "id": "TheBloke/Chinese-Alpaca-2-7B-GGUF",
      "modelId": "TheBloke/Chinese-Alpaca-2-7B-GGUF",
      "author": "TheBloke",
      "sha": "d23f3b30e12bd5854cefb1e41d1dd90df6c31717",
      "lastModified": "2023-09-27T12:49:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 825,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "model_name": "Chinese Alpaca 2 7B",
        "base_model": "ziqingyang/chinese-alpaca-2-7b",
        "inference": false,
        "model_creator": "Ziqing Yang",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chinese-alpaca-2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-7b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64c7305315bd12e5799c138b",
      "id": "hfl/chinese-alpaca-2-7b",
      "modelId": "hfl/chinese-alpaca-2-7b",
      "author": "hfl",
      "sha": "6b9e8e7dc0a67b8618d239388b6a61b47c00cdc5",
      "lastModified": "2023-08-25T01:06:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6519,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 109,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "SHA256.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650343f96c81feb4726ea3db",
    "id": "TheBloke/Chinese-Llama-2-7B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 37,
    "tags": [
      "transformers",
      "llama",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Chinese-Llama-2-7B-GGUF",
    "model": {
      "_id": "650343f96c81feb4726ea3db",
      "id": "TheBloke/Chinese-Llama-2-7B-GGUF",
      "modelId": "TheBloke/Chinese-Llama-2-7B-GGUF",
      "author": "TheBloke",
      "sha": "f81e959ca91492916b8b6f895202b6d478b8930c",
      "lastModified": "2023-09-27T12:49:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 37,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "model_name": "Chinese Llama 2 7B",
        "base_model": "ziqingyang/chinese-llama-2-7b",
        "inference": false,
        "model_creator": "Ziqing Yang",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chinese-llama-2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "chinese-llama-2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chinese-llama-2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chinese-llama-2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chinese-llama-2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "chinese-llama-2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chinese-llama-2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chinese-llama-2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "chinese-llama-2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chinese-llama-2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chinese-llama-2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "chinese-llama-2-7b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64c214a8129617dbaba35308",
      "id": "hfl/chinese-llama-2-7b",
      "modelId": "hfl/chinese-llama-2-7b",
      "author": "hfl",
      "sha": "b1cdccc6bb194c9ef2810ebdf25dab7e874de207",
      "lastModified": "2023-08-25T01:05:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5204,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 69,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650343fe694f6b620fbddb14",
    "id": "TheBloke/Chinese-Alpaca-2-13B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 16,
    "tags": [
      "transformers",
      "llama",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Chinese-Alpaca-2-13B-GGUF",
    "model": {
      "_id": "650343fe694f6b620fbddb14",
      "id": "TheBloke/Chinese-Alpaca-2-13B-GGUF",
      "modelId": "TheBloke/Chinese-Alpaca-2-13B-GGUF",
      "author": "TheBloke",
      "sha": "6627693d5deaab37ead64a1c75dddfd5e1a4084f",
      "lastModified": "2023-09-27T12:49:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 16,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "model_name": "Chinese Alpaca 2 13B",
        "base_model": "ziqingyang/chinese-alpaca-2-13b",
        "inference": false,
        "model_creator": "Ziqing Yang",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chinese-alpaca-2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "chinese-alpaca-2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64d99b10050438e3b9a575e1",
      "id": "hfl/chinese-alpaca-2-13b",
      "modelId": "hfl/chinese-alpaca-2-13b",
      "author": "hfl",
      "sha": "a9b5bb0ec1cb0da57689d983b1af163b9665d721",
      "lastModified": "2023-08-25T01:08:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6582,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 66,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65034404b96045f9180149f0",
    "id": "TheBloke/Chinese-Llama-2-13B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 11,
    "tags": [
      "transformers",
      "llama",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Chinese-Llama-2-13B-GGUF",
    "model": {
      "_id": "65034404b96045f9180149f0",
      "id": "TheBloke/Chinese-Llama-2-13B-GGUF",
      "modelId": "TheBloke/Chinese-Llama-2-13B-GGUF",
      "author": "TheBloke",
      "sha": "24c1311a5add8298183e9749b32220259398e4fd",
      "lastModified": "2023-09-27T12:49:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 11,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "model_name": "Chinese Llama 2 13B",
        "base_model": "ziqingyang/chinese-llama-2-13b",
        "inference": false,
        "model_creator": "Ziqing Yang",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chinese-llama-2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "chinese-llama-2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chinese-llama-2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chinese-llama-2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chinese-llama-2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "chinese-llama-2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chinese-llama-2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chinese-llama-2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "chinese-llama-2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chinese-llama-2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chinese-llama-2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "chinese-llama-2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64d5f6c59fef656cfdf39c82",
      "id": "hfl/chinese-llama-2-13b",
      "modelId": "hfl/chinese-llama-2-13b",
      "author": "hfl",
      "sha": "c09bf6950781162bbd1fbd8d0d896488db463d30",
      "lastModified": "2023-08-25T01:07:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4814,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 25,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "SHA256.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65038100d25ce81dfccfbb9f",
    "id": "TheBloke/CodeFuse-CodeLlama-34B-GGUF",
    "likes": 12,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/CodeFuse-CodeLlama-34B-GGUF",
    "model": {
      "_id": "65038100d25ce81dfccfbb9f",
      "id": "TheBloke/CodeFuse-CodeLlama-34B-GGUF",
      "modelId": "TheBloke/CodeFuse-CodeLlama-34B-GGUF",
      "author": "TheBloke",
      "sha": "5188186eb4c2d5f662477274760e53fb498728ff",
      "lastModified": "2023-09-27T12:49:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 12,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "CodeFuse CodeLlama 34B",
        "base_model": "codefuse-ai/CodeFuse-CodeLlama-34B",
        "inference": false,
        "model_creator": "CodeFuse AI",
        "model_type": "llama",
        "prompt_template": "<|role_start|>system<|role_end|>{system_message}\n<|role_start|>human<|role_end|>{prompt}\n<|role_start|>bot<|role_end|>\n",
        "quantized_by": "TheBloke",
        "tasks": [
          "code-generation"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codefuse-codellama-34b.Q2_K.gguf"
        },
        {
          "rfilename": "codefuse-codellama-34b.Q3_K_L.gguf"
        },
        {
          "rfilename": "codefuse-codellama-34b.Q3_K_M.gguf"
        },
        {
          "rfilename": "codefuse-codellama-34b.Q3_K_S.gguf"
        },
        {
          "rfilename": "codefuse-codellama-34b.Q4_0.gguf"
        },
        {
          "rfilename": "codefuse-codellama-34b.Q4_K_M.gguf"
        },
        {
          "rfilename": "codefuse-codellama-34b.Q4_K_S.gguf"
        },
        {
          "rfilename": "codefuse-codellama-34b.Q5_0.gguf"
        },
        {
          "rfilename": "codefuse-codellama-34b.Q5_K_M.gguf"
        },
        {
          "rfilename": "codefuse-codellama-34b.Q5_K_S.gguf"
        },
        {
          "rfilename": "codefuse-codellama-34b.Q6_K.gguf"
        },
        {
          "rfilename": "codefuse-codellama-34b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64f97ffad04a890f5398e34a",
      "id": "codefuse-ai/CodeFuse-CodeLlama-34B",
      "modelId": "codefuse-ai/CodeFuse-CodeLlama-34B",
      "author": "codefuse-ai",
      "sha": "7451b66fbf06219ddff19ebc4dab395fba96f3de",
      "lastModified": "2023-10-26T05:54:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 133,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 80,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tasks": [
          "code-generation"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "jacktown/codefuse-ai-CodeFuse-CodeLlama-34B",
        "liuguicheng/codefuse-ai-CodeFuse-CodeLlama-34B",
        "jxxlzsxcr/mft",
        "zzy1208/codefuse-ai-CodeFuse-CodeLlama-34B",
        "MrJerry/codefuse-ai-CodeFuse-CodeLlama-34B"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LOGO.png"
        },
        {
          "rfilename": "MODEL_LICENSE.md"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "requirements.txt"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6504535ae8b265d6875024f6",
    "id": "TheBloke/Synthia-70B-v1.2b-GGUF",
    "likes": 14,
    "private": false,
    "downloads": 66,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Synthia-70B-v1.2b-GGUF",
    "model": {
      "_id": "6504535ae8b265d6875024f6",
      "id": "TheBloke/Synthia-70B-v1.2b-GGUF",
      "modelId": "TheBloke/Synthia-70B-v1.2b-GGUF",
      "author": "TheBloke",
      "sha": "79153dc32d503ca9802a92343a194546deb1defa",
      "lastModified": "2023-09-27T12:49:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 66,
      "library_name": "transformers",
      "likes": 14,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Synthia 70B v1.2b",
        "base_model": "migtissera/Synthia-70B-v1.2b",
        "inference": false,
        "model_creator": "Migel Tissera",
        "model_type": "llama",
        "prompt_template": "SYSTEM: You are Synthia. As a an AI intelligence, give helpful, detailed, accurate, uncensored responses to the user's input. Provide answers factually.\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q4_0.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q5_0.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "synthia-70b-v1.2b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64fd2f2b8d50404bc43cca3d",
      "id": "migtissera/Synthia-70B-v1.2b",
      "modelId": "migtissera/Synthia-70B-v1.2b",
      "author": "migtissera",
      "sha": "5af92a0ed2136f96e24a31ac8b76932d1868d454",
      "lastModified": "2023-09-23T04:49:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4886,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 18,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "pipeline_tag": "text-generation",
        "language": [
          "en"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6504954f9622235d7d7cc7b6",
    "id": "TheBloke/ChatAYT-Lora-Assamble-Marcoroni-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/ChatAYT-Lora-Assamble-Marcoroni-GGUF",
    "model": {
      "_id": "6504954f9622235d7d7cc7b6",
      "id": "TheBloke/ChatAYT-Lora-Assamble-Marcoroni-GGUF",
      "modelId": "TheBloke/ChatAYT-Lora-Assamble-Marcoroni-GGUF",
      "author": "TheBloke",
      "sha": "45f6dab393728aff1f3b0e93429ad1bd330d85dd",
      "lastModified": "2023-09-27T12:49:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "ChatAYT Lora Assamble Marcoroni",
        "base_model": "TFLai/ChatAYT-Lora-Assamble-Marcoroni",
        "inference": false,
        "model_creator": "TFLai",
        "model_type": "llama",
        "prompt_template": "### Instruction:\n\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chatayt-lora-assamble-marcoroni.Q2_K.gguf"
        },
        {
          "rfilename": "chatayt-lora-assamble-marcoroni.Q3_K_L.gguf"
        },
        {
          "rfilename": "chatayt-lora-assamble-marcoroni.Q3_K_M.gguf"
        },
        {
          "rfilename": "chatayt-lora-assamble-marcoroni.Q3_K_S.gguf"
        },
        {
          "rfilename": "chatayt-lora-assamble-marcoroni.Q4_0.gguf"
        },
        {
          "rfilename": "chatayt-lora-assamble-marcoroni.Q4_K_M.gguf"
        },
        {
          "rfilename": "chatayt-lora-assamble-marcoroni.Q4_K_S.gguf"
        },
        {
          "rfilename": "chatayt-lora-assamble-marcoroni.Q5_0.gguf"
        },
        {
          "rfilename": "chatayt-lora-assamble-marcoroni.Q5_K_M.gguf"
        },
        {
          "rfilename": "chatayt-lora-assamble-marcoroni.Q5_K_S.gguf"
        },
        {
          "rfilename": "chatayt-lora-assamble-marcoroni.Q6_K.gguf"
        },
        {
          "rfilename": "chatayt-lora-assamble-marcoroni.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6502aa711a5924e228182f2c",
      "id": "PulsarAI/ChatAYT-Lora-Assamble-Marcoroni",
      "modelId": "PulsarAI/ChatAYT-Lora-Assamble-Marcoroni",
      "author": "PulsarAI",
      "sha": "4197fef98e38563522dd28e8ae00d672e3f7a228",
      "lastModified": "2023-09-29T10:22:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4591,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65054c4fdacc94cd6cdcd435",
    "id": "TheBloke/OpenOrca_Stx-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "ja",
      "dataset:snow_simplified_japanese_corpus",
      "dataset:khalidalt/tydiqa-goldp",
      "dataset:csebuetnlp/xlsum",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/OpenOrca_Stx-GGUF",
    "model": {
      "_id": "65054c4fdacc94cd6cdcd435",
      "id": "TheBloke/OpenOrca_Stx-GGUF",
      "modelId": "TheBloke/OpenOrca_Stx-GGUF",
      "author": "TheBloke",
      "sha": "3d8bd3dd04c96475da5795520e8e266e368103b4",
      "lastModified": "2023-09-27T12:49:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "ja",
        "dataset:snow_simplified_japanese_corpus",
        "dataset:khalidalt/tydiqa-goldp",
        "dataset:csebuetnlp/xlsum",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "ja"
        ],
        "license": "llama2",
        "datasets": [
          "snow_simplified_japanese_corpus",
          "khalidalt/tydiqa-goldp",
          "csebuetnlp/xlsum"
        ],
        "model_name": "OpenOrca Stx",
        "base_model": "lightblue/openorca_stx",
        "inference": false,
        "model_creator": "Lightblue Technology Inc.",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openorca_stx.Q2_K.gguf"
        },
        {
          "rfilename": "openorca_stx.Q3_K_L.gguf"
        },
        {
          "rfilename": "openorca_stx.Q3_K_M.gguf"
        },
        {
          "rfilename": "openorca_stx.Q3_K_S.gguf"
        },
        {
          "rfilename": "openorca_stx.Q4_0.gguf"
        },
        {
          "rfilename": "openorca_stx.Q4_K_M.gguf"
        },
        {
          "rfilename": "openorca_stx.Q4_K_S.gguf"
        },
        {
          "rfilename": "openorca_stx.Q5_0.gguf"
        },
        {
          "rfilename": "openorca_stx.Q5_K_M.gguf"
        },
        {
          "rfilename": "openorca_stx.Q5_K_S.gguf"
        },
        {
          "rfilename": "openorca_stx.Q6_K.gguf"
        },
        {
          "rfilename": "openorca_stx.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65002f66f355a888f937b749",
      "id": "lightblue/openorca_stx",
      "modelId": "lightblue/openorca_stx",
      "author": "lightblue",
      "sha": "db29ec0368f15f3370f37e9a03e26a3822432763",
      "lastModified": "2023-10-02T10:25:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "ja",
        "dataset:snow_simplified_japanese_corpus",
        "dataset:khalidalt/tydiqa-goldp",
        "dataset:csebuetnlp/xlsum",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4184,
      "library_name": "transformers",
      "likes": 17,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "snow_simplified_japanese_corpus",
          "khalidalt/tydiqa-goldp",
          "csebuetnlp/xlsum"
        ],
        "language": [
          "ja"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65054d03a226ecc608b00269",
    "id": "TheBloke/CalliopeDS-L2-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "en",
      "arxiv:2306.01708",
      "license:agpl-3.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/CalliopeDS-L2-13B-GGUF",
    "model": {
      "_id": "65054d03a226ecc608b00269",
      "id": "TheBloke/CalliopeDS-L2-13B-GGUF",
      "modelId": "TheBloke/CalliopeDS-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "eecd2a56f3fa730f66efec487ee00bef4b382060",
      "lastModified": "2023-09-27T12:49:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "en",
        "arxiv:2306.01708",
        "license:agpl-3.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "agpl-3.0",
        "library_name": "transformers",
        "tags": [
          "llama",
          "llama-2"
        ],
        "model_name": "CalliopeDS L2 13B",
        "base_model": "Doctor-Shotgun/CalliopeDS-L2-13B",
        "inference": false,
        "model_creator": "Doctor Shotgun",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### Instruction:\nCharacter's Persona: bot character description\n\nUser's persona: user character description\n  \nScenario: what happens in the story\n\nPlay the role of Character. You must engage in a roleplaying chat with User below this line. Do not write dialogues and narration for User. Character should respond with messages of medium length.\n\n### Input:\nUser: {prompt}\n\n### Response:\nCharacter: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "calliopeds-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "calliopeds-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "calliopeds-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "calliopeds-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "calliopeds-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "calliopeds-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "calliopeds-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "calliopeds-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "calliopeds-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "calliopeds-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "calliopeds-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "calliopeds-l2-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "650500d59622235d7d8a9790",
      "id": "Doctor-Shotgun/CalliopeDS-L2-13B",
      "modelId": "Doctor-Shotgun/CalliopeDS-L2-13B",
      "author": "Doctor-Shotgun",
      "sha": "b373eda586a6527e62382eda5480204652a82499",
      "lastModified": "2023-09-16T02:30:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "en",
        "arxiv:2306.01708",
        "license:agpl-3.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4790,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "llama",
          "llama-2"
        ],
        "license": "agpl-3.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Llama 2/LICENSE"
        },
        {
          "rfilename": "Llama 2/Notice"
        },
        {
          "rfilename": "Llama 2/USE_POLICY.md"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6505633e14302b1d76902b3f",
    "id": "TheBloke/Kuchiki-1.1-L2-7B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llama2",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Kuchiki-1.1-L2-7B-GGUF",
    "model": {
      "_id": "6505633e14302b1d76902b3f",
      "id": "TheBloke/Kuchiki-1.1-L2-7B-GGUF",
      "modelId": "TheBloke/Kuchiki-1.1-L2-7B-GGUF",
      "author": "TheBloke",
      "sha": "e4f13b125d32bde8ff1abdd6c01ca8ee5f3bc402",
      "lastModified": "2023-09-27T12:49:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama2",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama2"
        ],
        "model_name": "Kuchiki 1.1 L2 7B",
        "base_model": "zarakiquemparte/kuchiki-1.1-l2-7b",
        "inference": false,
        "model_creator": "Zaraki Quem Parte",
        "model_type": "llama",
        "prompt_template": "### Instruction:\n\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "kuchiki-1.1-l2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "kuchiki-1.1-l2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "kuchiki-1.1-l2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "kuchiki-1.1-l2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "kuchiki-1.1-l2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "kuchiki-1.1-l2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "kuchiki-1.1-l2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "kuchiki-1.1-l2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "kuchiki-1.1-l2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "kuchiki-1.1-l2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "kuchiki-1.1-l2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "kuchiki-1.1-l2-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6504d10238b7f6bcfa5ae76a",
      "id": "zarakiquemparte/kuchiki-1.1-l2-7b",
      "modelId": "zarakiquemparte/kuchiki-1.1-l2-7b",
      "author": "zarakiquemparte",
      "sha": "10fe70fec0df5c4dcbdfd2e9ec74830c41b3cfd2",
      "lastModified": "2023-09-16T00:33:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama2",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6545,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "merge-illustration.png"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650588d000c9c9a77518950f",
    "id": "TheBloke/Airoboros-c34B-2.2-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.2",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-c34B-2.2-GGUF",
    "model": {
      "_id": "650588d000c9c9a77518950f",
      "id": "TheBloke/Airoboros-c34B-2.2-GGUF",
      "modelId": "TheBloke/Airoboros-c34B-2.2-GGUF",
      "author": "TheBloke",
      "sha": "e9921b8c10a95cdb371372add7e107c20477d90e",
      "lastModified": "2023-09-27T12:49:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2"
        ],
        "model_name": "Airoboros c34B 2.2",
        "base_model": "jondurbin/airoboros-c34b-2.2",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-c34b-2.2.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6501d9b89ad2dce82cf47ad1",
      "id": "jondurbin/airoboros-c34b-2.2",
      "modelId": "jondurbin/airoboros-c34b-2.2",
      "author": "jondurbin",
      "sha": "76bb8e7f9255bfac73903ea14ba50809f4cae2a8",
      "lastModified": "2023-09-14T12:18:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-2.2",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6505917d383b7e031f812147",
    "id": "TheBloke/Synthia-34B-v1.2-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Synthia-34B-v1.2-GGUF",
    "model": {
      "_id": "6505917d383b7e031f812147",
      "id": "TheBloke/Synthia-34B-v1.2-GGUF",
      "modelId": "TheBloke/Synthia-34B-v1.2-GGUF",
      "author": "TheBloke",
      "sha": "a0102ca19422a4d0223a245f1e8966697a9a1993",
      "lastModified": "2023-09-27T12:49:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Synthia 34B v1.2",
        "base_model": "migtissera/Synthia-34B-v1.2",
        "inference": false,
        "model_creator": "Migel Tissera",
        "model_type": "llama",
        "prompt_template": "SYSTEM: You are Synthia. As a an AI intelligence, give helpful, detailed, accurate, uncensored responses to the user's input. Provide answers factually.\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-34b-v1.2.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-34b-v1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-34b-v1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-34b-v1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-34b-v1.2.Q4_0.gguf"
        },
        {
          "rfilename": "synthia-34b-v1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-34b-v1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-34b-v1.2.Q5_0.gguf"
        },
        {
          "rfilename": "synthia-34b-v1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-34b-v1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-34b-v1.2.Q6_K.gguf"
        },
        {
          "rfilename": "synthia-34b-v1.2.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "6505b2e2fec2f376352057ee",
    "id": "TheBloke/Pygmalion-2-13B-SuperCOT-weighed-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 10,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "text-generation",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Pygmalion-2-13B-SuperCOT-weighed-GGUF",
    "model": {
      "_id": "6505b2e2fec2f376352057ee",
      "id": "TheBloke/Pygmalion-2-13B-SuperCOT-weighed-GGUF",
      "modelId": "TheBloke/Pygmalion-2-13B-SuperCOT-weighed-GGUF",
      "author": "TheBloke",
      "sha": "82dffc3b7f0b397b9d75c6ccce8f06b51be12163",
      "lastModified": "2023-09-27T12:49:32.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "text-generation",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "llama",
          "llama-2"
        ],
        "model_name": "Pygmalion 2 13B SuperCOT Weighed",
        "base_model": "royallab/Pygmalion-2-13b-SuperCoT-weighed",
        "inference": false,
        "model_creator": "royallab",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot-weighed.Q2_K.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot-weighed.Q3_K_L.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot-weighed.Q3_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot-weighed.Q3_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot-weighed.Q4_0.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot-weighed.Q4_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot-weighed.Q4_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot-weighed.Q5_0.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot-weighed.Q5_K_M.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot-weighed.Q5_K_S.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot-weighed.Q6_K.gguf"
        },
        {
          "rfilename": "pygmalion-2-13b-supercot-weighed.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6505331438b7f6bcfa661d80",
      "id": "royallab/Pygmalion-2-13b-SuperCOT-weighed",
      "modelId": "royallab/Pygmalion-2-13b-SuperCOT-weighed",
      "author": "royallab",
      "sha": "6cc1794b49a51b248beace3834e6306f5cd29e16",
      "lastModified": "2023-09-17T03:53:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "llama-2",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "llama",
          "llama-2"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6505b62cd3de67a546e8a8d0",
    "id": "TheBloke/TigerBot-70B-Chat-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "zh",
      "en",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/TigerBot-70B-Chat-GGUF",
    "model": {
      "_id": "6505b62cd3de67a546e8a8d0",
      "id": "TheBloke/TigerBot-70B-Chat-GGUF",
      "modelId": "TheBloke/TigerBot-70B-Chat-GGUF",
      "author": "TheBloke",
      "sha": "5d8a16aa4202f97bbac3c4a137f929636bef3b88",
      "lastModified": "2023-09-27T12:49:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "zh",
        "en",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "zh",
          "en"
        ],
        "license": "apache-2.0",
        "model_name": "TigerBot 70B Chat",
        "base_model": "TigerResearch/tigerbot-70b-chat",
        "inference": false,
        "model_creator": "Tiger Research",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q2_K.gguf"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q3_K_L.gguf"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q3_K_M.gguf"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q3_K_S.gguf"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q4_0.gguf"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q4_K_M.gguf"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q4_K_S.gguf"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q5_0.gguf"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q5_K_M.gguf"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q5_K_S.gguf"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "tigerbot-70b-chat.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "65101d71007ea5dd9d0cd686",
      "id": "TigerResearch/tigerbot-70b-chat",
      "modelId": "TigerResearch/tigerbot-70b-chat",
      "author": "TigerResearch",
      "sha": "bef198f260563793077a9c105e53d650737f6d26",
      "lastModified": "2023-09-25T13:53:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "zh",
        "en",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 275,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "language": [
          "zh",
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "PeepDaSlan9/TigerResearch-tigerbot-70b-chat"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6505bf7a383b7e031f85c414",
    "id": "TheBloke/WizardCoder-Python-7B-V1.0-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 28,
    "tags": [
      "transformers",
      "llama",
      "code",
      "arxiv:2304.12244",
      "arxiv:2306.08568",
      "arxiv:2308.09583",
      "arxiv:2303.08774",
      "license:llama2",
      "model-index",
      "text-generation-inference",
      "region:us",
      "has_space"
    ],
    "modelId": "TheBloke/WizardCoder-Python-7B-V1.0-GGUF",
    "model": {
      "_id": "6505bf7a383b7e031f85c414",
      "id": "TheBloke/WizardCoder-Python-7B-V1.0-GGUF",
      "modelId": "TheBloke/WizardCoder-Python-7B-V1.0-GGUF",
      "author": "TheBloke",
      "sha": "a50d3a513700e9532491eecdf995d1435ef9dc5d",
      "lastModified": "2023-09-27T12:49:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "code",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "arxiv:2303.08774",
        "license:llama2",
        "model-index",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 28,
      "library_name": "transformers",
      "likes": 10,
      "model-index": [
        {
          "name": "WizardCoder-Python-34B-V1.0",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "name": "HumanEval",
                "type": "openai_humaneval"
              },
              "metrics": [
                {
                  "type": "pass@1",
                  "value": 0.555,
                  "name": "pass@1",
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "code"
        ],
        "metrics": [
          "code_eval"
        ],
        "base_model": "WizardLM/WizardCoder-Python-7b-V1.0",
        "inference": false,
        "model_creator": "WizardLM",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "model-index": [
          {
            "name": "WizardCoder-Python-34B-V1.0",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "name": "HumanEval",
                  "type": "openai_humaneval"
                },
                "metrics": [
                  {
                    "type": "pass@1",
                    "value": 0.555,
                    "name": "pass@1",
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "limcheekin/WizardCoder-Python-7B-V1.0-GGUF"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardcoder-python-7b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "wizardcoder-python-7b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardcoder-python-7b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardcoder-python-7b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardcoder-python-7b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "wizardcoder-python-7b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardcoder-python-7b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardcoder-python-7b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "wizardcoder-python-7b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardcoder-python-7b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardcoder-python-7b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "wizardcoder-python-7b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64edc3b74aa51daa2e1c27d0",
      "id": "WizardLM/WizardCoder-Python-7B-V1.0",
      "modelId": "WizardLM/WizardCoder-Python-7B-V1.0",
      "author": "WizardLM",
      "sha": "e40673a27a4aefcff2c6d2b3b1e0681a38703e4e",
      "lastModified": "2023-09-09T06:44:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "arxiv:2303.08774",
        "license:llama2",
        "model-index",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8462,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 49,
      "model-index": [
        {
          "name": "WizardCoder-Python-34B-V1.0",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "type": "openai_humaneval",
                "name": "HumanEval"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": 0.555,
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "metrics": [
          "code_eval"
        ],
        "library_name": "transformers",
        "tags": [
          "code"
        ],
        "model-index": [
          {
            "name": "WizardCoder-Python-34B-V1.0",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "type": "openai_humaneval",
                  "name": "HumanEval"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": 0.555,
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Nayyarsan/WizardLM-WizardCoder-Python-7B-V1.0",
        "limcheekin/WizardCoder-Python-7B-V1.0-GGUF"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65060b7c14302b1d76a394e9",
    "id": "TheBloke/MLewd-L2-Chat-13B-GGUF",
    "likes": 12,
    "private": false,
    "downloads": 14,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MLewd-L2-Chat-13B-GGUF",
    "model": {
      "_id": "65060b7c14302b1d76a394e9",
      "id": "TheBloke/MLewd-L2-Chat-13B-GGUF",
      "modelId": "TheBloke/MLewd-L2-Chat-13B-GGUF",
      "author": "TheBloke",
      "sha": "1531b005ef38f597aa80ea21f7028554e0e56415",
      "lastModified": "2023-09-27T12:49:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 14,
      "library_name": "transformers",
      "likes": 12,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ],
        "model_name": "MLewd L2 Chat 13B",
        "base_model": "Undi95/mlewd-l2-chat-13B",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mlewd-l2-chat-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mlewd-l2-chat-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mlewd-l2-chat-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mlewd-l2-chat-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mlewd-l2-chat-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mlewd-l2-chat-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mlewd-l2-chat-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mlewd-l2-chat-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mlewd-l2-chat-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mlewd-l2-chat-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mlewd-l2-chat-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mlewd-l2-chat-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6505bb6bd3de67a546e93ea1",
      "id": "Undi95/MLewd-L2-Chat-13B",
      "modelId": "Undi95/MLewd-L2-Chat-13B",
      "author": "Undi95",
      "sha": "399d09d9c6bc5b85fd2d4a4c1e5663c49b577bcb",
      "lastModified": "2023-09-26T19:08:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7066,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 18,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Hikari-nyan/Undi95-MLewd-L2-Chat-13B"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65072ae1eac45ee2e41a02eb",
    "id": "TheBloke/ReMM-v2.1-L2-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/ReMM-v2.1-L2-13B-GGUF",
    "model": {
      "_id": "65072ae1eac45ee2e41a02eb",
      "id": "TheBloke/ReMM-v2.1-L2-13B-GGUF",
      "modelId": "TheBloke/ReMM-v2.1-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "913692dc6f45b9094f454e568285ff6f67cee1f3",
      "lastModified": "2023-09-27T12:49:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "model_name": "ReMM v2.1 L2 13B",
        "base_model": "Undi95/ReMM-v2.1-L2-13B",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "remm-v2.1-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "remm-v2.1-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "remm-v2.1-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "remm-v2.1-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "remm-v2.1-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "remm-v2.1-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "remm-v2.1-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "remm-v2.1-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "remm-v2.1-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "remm-v2.1-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "remm-v2.1-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "remm-v2.1-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6500717935ec97176292860e",
      "id": "Undi95/ReMM-v2.1-L2-13B",
      "modelId": "Undi95/ReMM-v2.1-L2-13B",
      "author": "Undi95",
      "sha": "e6b5ac97f74355cb281a621261debe5720fb4da2",
      "lastModified": "2023-09-12T15:20:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4607,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688184320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00006.safetensors"
        },
        {
          "rfilename": "model-00002-of-00006.safetensors"
        },
        {
          "rfilename": "model-00003-of-00006.safetensors"
        },
        {
          "rfilename": "model-00004-of-00006.safetensors"
        },
        {
          "rfilename": "model-00005-of-00006.safetensors"
        },
        {
          "rfilename": "model-00006-of-00006.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6507358fffc738079c8e9dbc",
    "id": "TheBloke/Llama-2-70B-LoRA-Assemble-v2-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama-2-70B-LoRA-Assemble-v2-GGUF",
    "model": {
      "_id": "6507358fffc738079c8e9dbc",
      "id": "TheBloke/Llama-2-70B-LoRA-Assemble-v2-GGUF",
      "modelId": "TheBloke/Llama-2-70B-LoRA-Assemble-v2-GGUF",
      "author": "TheBloke",
      "sha": "bc069f49ed5de7ebd033f88f9d8b7a0dc30ea397",
      "lastModified": "2023-09-27T12:49:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Llama 2 70B LoRA Assemble v2",
        "base_model": "oh-yeontaek/llama-2-70B-LoRA-assemble-v2",
        "inference": false,
        "model_creator": "oh-yeontaek",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "llama-2-70b-lora-assemble-v2.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "6503cbaab4bbf29f8f35bf18",
      "id": "oh-yeontaek/llama-2-70B-LoRA-assemble-v2",
      "modelId": "oh-yeontaek/llama-2-70B-LoRA-assemble-v2",
      "author": "oh-yeontaek",
      "sha": "7feeb5b665ab1ecdfd9cc4fe45fadb86b7b91b5b",
      "lastModified": "2023-09-15T03:49:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6875,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6507fc50a226ecc608fa1425",
    "id": "TheBloke/llama2_7b_chat_uncensored-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 90,
    "tags": [
      "transformers",
      "llama",
      "dataset:ehartford/wizard_vicuna_70k_unfiltered",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/llama2_7b_chat_uncensored-GGUF",
    "model": {
      "_id": "6507fc50a226ecc608fa1425",
      "id": "TheBloke/llama2_7b_chat_uncensored-GGUF",
      "modelId": "TheBloke/llama2_7b_chat_uncensored-GGUF",
      "author": "TheBloke",
      "sha": "b58448a7e5adf686db9c5021a501054f2d35b1be",
      "lastModified": "2023-09-27T12:49:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 90,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ],
        "model_name": "Llama2 7B Chat Uncensored",
        "base_model": "georgesung/llama2_7b_chat_uncensored",
        "inference": false,
        "model_creator": "George Sung",
        "model_type": "llama",
        "prompt_template": "### HUMAN:\n{prompt}\n\n### RESPONSE:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama2_7b_chat_uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "llama2_7b_chat_uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama2_7b_chat_uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama2_7b_chat_uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama2_7b_chat_uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "llama2_7b_chat_uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama2_7b_chat_uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama2_7b_chat_uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "llama2_7b_chat_uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama2_7b_chat_uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama2_7b_chat_uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "llama2_7b_chat_uncensored.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64b9102ff5311dd0382c1f6e",
      "id": "georgesung/llama2_7b_chat_uncensored",
      "modelId": "georgesung/llama2_7b_chat_uncensored",
      "author": "georgesung",
      "sha": "e9a972b12c6b59bfbcf30fe3779c2c933ce755bd",
      "lastModified": "2023-07-22T15:55:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "tensorboard",
        "llama",
        "text-generation",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5781,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 162,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "georgesung/llama2_7b_uncensored_chat",
        "b1sheng/kg_llm_leaderboard_test",
        "Karan123penguin234/georgesung-llama2_7b_chat_uncensored",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "AGCobra/llama2_7b_uncensored_chat",
        "Aricaeksoevon/georgesung-llama2_7b_chat_uncensored",
        "sandeepchahal/georgesung-llama2_7b_chat_uncensored",
        "anwarisbased/georgesung-llama2_7b_chat_uncensored",
        "dev-motoemoto47ark123/georgesung-llama2_7b_chat_uncensored",
        "DonCezar/georgesung-llama2_7b_chat_uncensored",
        "Vinnybustacap/georgesung-llama2_7b_chat_uncensored",
        "LucianoFerrarezitheforce/georgesung-llama2_7b_chat_uncensored",
        "harrysg/georgesung-llama2_7b_chat_uncensored",
        "AlexisXX/georgesung-llama2_7b_chat_uncensored",
        "pngwn/open_llm_leaderboard",
        "ianplacer/georgesung-llama2_7b_chat_uncensored",
        "Sweettooth90/georgesung-llama2_7b_chat_uncensored",
        "ShadowSH2306/georgesung-llama2_7b_chat_uncensored",
        "pngwn/open_llm_leaderboard_two",
        "heymax/georgesung-llama2_7b_chat_uncensored",
        "sirlambert/georgesung-llama2_7b_chat_uncensored",
        "mattduzit/georgesung-llama2_7b_chat_uncensored",
        "Ojemario/georgesung-llama2_7b_chat_uncensored",
        "htrtry/georgesung-llama2_7b_chat_uncensored",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "cowboyuniverse/georgesung-llama2_7b_chat_uncensored",
        "TheVortexProject/open_llm_leaderboard",
        "aaa1820/georgesung-llama2_7b_chat_uncensored",
        "Uninvited/georgesung-llama2_7b_chat_uncensored",
        "choco9966/open-ko-llm-leaderboard",
        "prestonzen/georgesung-llama2_7b_chat_uncensored",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "runs/Jul-19-2023/events.out.tfevents"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6509a5def9fb525b2f4d01e7",
    "id": "TheBloke/AlpacaCielo-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/AlpacaCielo-13B-GGUF",
    "model": {
      "_id": "6509a5def9fb525b2f4d01e7",
      "id": "TheBloke/AlpacaCielo-13B-GGUF",
      "modelId": "TheBloke/AlpacaCielo-13B-GGUF",
      "author": "TheBloke",
      "sha": "5e57f6cd0487a9a29115efd001b6f8106076d08a",
      "lastModified": "2023-09-27T12:52:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "AlpacaCielo 13B",
        "base_model": "totally-not-an-llm/AlpacaCielo-13b",
        "inference": false,
        "model_creator": "totally-not-an-llm",
        "model_type": "llama",
        "prompt_template": "### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "alpacacielo-13b.Q2_K.gguf"
        },
        {
          "rfilename": "alpacacielo-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "alpacacielo-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "alpacacielo-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "alpacacielo-13b.Q4_0.gguf"
        },
        {
          "rfilename": "alpacacielo-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "alpacacielo-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "alpacacielo-13b.Q5_0.gguf"
        },
        {
          "rfilename": "alpacacielo-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "alpacacielo-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "alpacacielo-13b.Q6_K.gguf"
        },
        {
          "rfilename": "alpacacielo-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64bc5fcc1d40292dd3cdb938",
      "id": "totally-not-an-llm/AlpacaCielo-13b",
      "modelId": "totally-not-an-llm/AlpacaCielo-13b",
      "author": "totally-not-an-llm",
      "sha": "d74a4a8caf77a9039c7d06da3fd3af57d556dbf7",
      "lastModified": "2023-07-24T22:31:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "license:llama2",
        "region:us"
      ],
      "downloads": 0,
      "likes": 23,
      "model-index": null,
      "config": {},
      "cardData": {
        "license": "llama2"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "AlpacaCielo-ggml-13b-q4_K_M.bin"
        },
        {
          "rfilename": "AlpacaCielo/added_tokens.json"
        },
        {
          "rfilename": "AlpacaCielo/config.json"
        },
        {
          "rfilename": "AlpacaCielo/generation_config.json"
        },
        {
          "rfilename": "AlpacaCielo/pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "AlpacaCielo/pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "AlpacaCielo/pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "AlpacaCielo/pytorch_model.bin.index.json"
        },
        {
          "rfilename": "AlpacaCielo/special_tokens_map.json"
        },
        {
          "rfilename": "AlpacaCielo/tokenizer.json"
        },
        {
          "rfilename": "AlpacaCielo/tokenizer.model"
        },
        {
          "rfilename": "AlpacaCielo/tokenizer_config.json"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "alpaca.png"
        }
      ]
    }
  },
  {
    "_id": "650a0a562257a3afbaf0bda7",
    "id": "TheBloke/13B-BlueMethod-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "alpaca",
      "cot",
      "vicuna",
      "uncensored",
      "merge",
      "mix",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/13B-BlueMethod-GGUF",
    "model": {
      "_id": "650a0a562257a3afbaf0bda7",
      "id": "TheBloke/13B-BlueMethod-GGUF",
      "modelId": "TheBloke/13B-BlueMethod-GGUF",
      "author": "TheBloke",
      "sha": "bbcb781c8d8b5fa72ec745b034e190c285a442a0",
      "lastModified": "2023-09-27T12:52:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "alpaca",
        "cot",
        "vicuna",
        "uncensored",
        "merge",
        "mix",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "alpaca",
          "cot",
          "vicuna",
          "uncensored",
          "merge",
          "mix"
        ],
        "model_name": "13B BlueMethod",
        "base_model": "CalderaAI/13B-BlueMethod",
        "inference": false,
        "model_creator": "Caldera AI",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "13b-bluemethod.Q2_K.gguf"
        },
        {
          "rfilename": "13b-bluemethod.Q3_K_L.gguf"
        },
        {
          "rfilename": "13b-bluemethod.Q3_K_M.gguf"
        },
        {
          "rfilename": "13b-bluemethod.Q3_K_S.gguf"
        },
        {
          "rfilename": "13b-bluemethod.Q4_0.gguf"
        },
        {
          "rfilename": "13b-bluemethod.Q4_K_M.gguf"
        },
        {
          "rfilename": "13b-bluemethod.Q4_K_S.gguf"
        },
        {
          "rfilename": "13b-bluemethod.Q5_0.gguf"
        },
        {
          "rfilename": "13b-bluemethod.Q5_K_M.gguf"
        },
        {
          "rfilename": "13b-bluemethod.Q5_K_S.gguf"
        },
        {
          "rfilename": "13b-bluemethod.Q6_K.gguf"
        },
        {
          "rfilename": "13b-bluemethod.Q8_0.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64a7ac6f166b638e8ef11e49",
      "id": "CalderaAI/13B-BlueMethod",
      "modelId": "CalderaAI/13B-BlueMethod",
      "author": "CalderaAI",
      "sha": "315aa0924dd42840b8cced581c9db1240f9bae1d",
      "lastModified": "2023-07-20T03:29:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "alpaca",
        "cot",
        "vicuna",
        "uncensored",
        "merge",
        "mix",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4763,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "llama",
          "alpaca",
          "cot",
          "vicuna",
          "uncensored",
          "merge",
          "mix"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "asdasdaset/CalderaAI-13B-BlueMethod",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "4bit.safetensors"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a1801ce81b73e637b9d76",
    "id": "TheBloke/tulu-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:databricks/databricks-dolly-15k",
      "dataset:OpenAssistant/oasst1",
      "dataset:sahil2801/CodeAlpaca-20k",
      "arxiv:2306.04751",
      "arxiv:2302.13971",
      "arxiv:2304.07327",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/tulu-13B-GGUF",
    "model": {
      "_id": "650a1801ce81b73e637b9d76",
      "id": "TheBloke/tulu-13B-GGUF",
      "modelId": "TheBloke/tulu-13B-GGUF",
      "author": "TheBloke",
      "sha": "ff14704ac6d7d94aff29b7458851d213ebf2fe25",
      "lastModified": "2023-09-27T12:52:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:databricks/databricks-dolly-15k",
        "dataset:OpenAssistant/oasst1",
        "dataset:sahil2801/CodeAlpaca-20k",
        "arxiv:2306.04751",
        "arxiv:2302.13971",
        "arxiv:2304.07327",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "datasets": [
          "databricks/databricks-dolly-15k",
          "OpenAssistant/oasst1",
          "sahil2801/CodeAlpaca-20k"
        ],
        "model_name": "Tulu 13B",
        "base_model": "allenai/tulu-13b",
        "inference": false,
        "model_creator": "Allen Institute for AI",
        "model_type": "llama",
        "prompt_template": "<|user|>\n{prompt}\n<|assistant|>\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tulu-13b.Q2_K.gguf"
        },
        {
          "rfilename": "tulu-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "tulu-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "tulu-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "tulu-13b.Q4_0.gguf"
        },
        {
          "rfilename": "tulu-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "tulu-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "tulu-13b.Q5_0.gguf"
        },
        {
          "rfilename": "tulu-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "tulu-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "tulu-13b.Q6_K.gguf"
        },
        {
          "rfilename": "tulu-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "648116ca9aafd41918b1f941",
      "id": "allenai/tulu-13b",
      "modelId": "allenai/tulu-13b",
      "author": "allenai",
      "sha": "d71ccb3d50e24f016cc7cd9cbf70f2f85a4d0d2f",
      "lastModified": "2023-06-20T17:48:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:databricks/databricks-dolly-15k",
        "dataset:OpenAssistant/oasst1",
        "dataset:sahil2801/CodeAlpaca-20k",
        "arxiv:2306.04751",
        "arxiv:2302.13971",
        "arxiv:2304.07327",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "databricks/databricks-dolly-15k",
          "OpenAssistant/oasst1",
          "sahil2801/CodeAlpaca-20k"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Sharathhebbar24/One-stop-for-Open-source-models"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "llama_license.txt"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a1b447b68c4a6f68c0a3b",
    "id": "TheBloke/13B-Ouroboros-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "alpaca",
      "vicuna",
      "uncensored",
      "merge",
      "mix",
      "airoboros",
      "openorca",
      "orcamini",
      "orca",
      "instruct",
      "mixtune",
      "text-generation",
      "en",
      "dataset:Open-Orca/OpenOrca",
      "dataset:anon8231489123/ShareGPT_Vicuna_unfiltered",
      "dataset:jondurbin/airoboros-uncensored",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/13B-Ouroboros-GGUF",
    "model": {
      "_id": "650a1b447b68c4a6f68c0a3b",
      "id": "TheBloke/13B-Ouroboros-GGUF",
      "modelId": "TheBloke/13B-Ouroboros-GGUF",
      "author": "TheBloke",
      "sha": "5ec9d563a01e3cd1654e22327657dc264756ab60",
      "lastModified": "2023-09-27T12:52:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "alpaca",
        "vicuna",
        "uncensored",
        "merge",
        "mix",
        "airoboros",
        "openorca",
        "orcamini",
        "orca",
        "instruct",
        "mixtune",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "dataset:anon8231489123/ShareGPT_Vicuna_unfiltered",
        "dataset:jondurbin/airoboros-uncensored",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "llama",
          "alpaca",
          "vicuna",
          "uncensored",
          "merge",
          "mix",
          "airoboros",
          "openorca",
          "orcamini",
          "orca",
          "instruct",
          "mixtune"
        ],
        "datasets": [
          "Open-Orca/OpenOrca",
          "anon8231489123/ShareGPT_Vicuna_unfiltered",
          "jondurbin/airoboros-uncensored"
        ],
        "metrics": [
          "accuracy"
        ],
        "model_name": "13B Ouroboros",
        "base_model": "CalderaAI/13B-Ouroboros",
        "inference": false,
        "model_creator": "Caldera AI",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "13b-ouroboros.Q2_K.gguf"
        },
        {
          "rfilename": "13b-ouroboros.Q3_K_L.gguf"
        },
        {
          "rfilename": "13b-ouroboros.Q3_K_M.gguf"
        },
        {
          "rfilename": "13b-ouroboros.Q3_K_S.gguf"
        },
        {
          "rfilename": "13b-ouroboros.Q4_0.gguf"
        },
        {
          "rfilename": "13b-ouroboros.Q4_K_M.gguf"
        },
        {
          "rfilename": "13b-ouroboros.Q4_K_S.gguf"
        },
        {
          "rfilename": "13b-ouroboros.Q5_0.gguf"
        },
        {
          "rfilename": "13b-ouroboros.Q5_K_M.gguf"
        },
        {
          "rfilename": "13b-ouroboros.Q5_K_S.gguf"
        },
        {
          "rfilename": "13b-ouroboros.Q6_K.gguf"
        },
        {
          "rfilename": "13b-ouroboros.Q8_0.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64b9a37e88d2d8267486e648",
      "id": "CalderaAI/13B-Ouroboros",
      "modelId": "CalderaAI/13B-Ouroboros",
      "author": "CalderaAI",
      "sha": "fd0b4db8711b1d559a5c067ab4367176db97fdbf",
      "lastModified": "2023-07-29T06:38:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "alpaca",
        "vicuna",
        "uncensored",
        "merge",
        "mix",
        "airoboros",
        "openorca",
        "orcamini",
        "orca",
        "instruct",
        "mixtune",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "dataset:anon8231489123/ShareGPT_Vicuna_unfiltered",
        "dataset:jondurbin/airoboros-uncensored",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4829,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "llama",
          "alpaca",
          "vicuna",
          "uncensored",
          "merge",
          "mix",
          "airoboros",
          "openorca",
          "orcamini",
          "orca",
          "instruct",
          "mixtune"
        ],
        "datasets": [
          "Open-Orca/OpenOrca",
          "anon8231489123/ShareGPT_Vicuna_unfiltered",
          "jondurbin/airoboros-uncensored"
        ],
        "language": [
          "en"
        ],
        "metrics": [
          "accuracy"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a1df9d48ed98e63c65f1e",
    "id": "TheBloke/13B-Chimera-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "cot",
      "vicuna",
      "uncensored",
      "merge",
      "mix",
      "gptq",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/13B-Chimera-GGUF",
    "model": {
      "_id": "650a1df9d48ed98e63c65f1e",
      "id": "TheBloke/13B-Chimera-GGUF",
      "modelId": "TheBloke/13B-Chimera-GGUF",
      "author": "TheBloke",
      "sha": "d3a274d969ea880c481f41231525067461630bd8",
      "lastModified": "2023-09-27T12:52:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "cot",
        "vicuna",
        "uncensored",
        "merge",
        "mix",
        "gptq",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "cot",
          "vicuna",
          "uncensored",
          "merge",
          "mix",
          "gptq"
        ],
        "model_name": "13B Chimera",
        "base_model": "digitous/13B-Chimera",
        "inference": false,
        "model_creator": "Erik",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "13B-Chimera.Q2_K.gguf"
        },
        {
          "rfilename": "13B-Chimera.Q3_K_L.gguf"
        },
        {
          "rfilename": "13B-Chimera.Q3_K_M.gguf"
        },
        {
          "rfilename": "13B-Chimera.Q3_K_S.gguf"
        },
        {
          "rfilename": "13B-Chimera.Q4_0.gguf"
        },
        {
          "rfilename": "13B-Chimera.Q4_K_M.gguf"
        },
        {
          "rfilename": "13B-Chimera.Q4_K_S.gguf"
        },
        {
          "rfilename": "13B-Chimera.Q5_0.gguf"
        },
        {
          "rfilename": "13B-Chimera.Q5_K_M.gguf"
        },
        {
          "rfilename": "13B-Chimera.Q5_K_S.gguf"
        },
        {
          "rfilename": "13B-Chimera.Q6_K.gguf"
        },
        {
          "rfilename": "13B-Chimera.Q8_0.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "646c8debe30444638e0e4513",
      "id": "digitous/13B-Chimera",
      "modelId": "digitous/13B-Chimera",
      "author": "digitous",
      "sha": "85cfe8e6db2bee804873cfdb48955696cc5b0689",
      "lastModified": "2023-05-24T22:06:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "cot",
        "vicuna",
        "uncensored",
        "merge",
        "mix",
        "gptq",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4543,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "llama",
          "cot",
          "vicuna",
          "uncensored",
          "merge",
          "mix",
          "gptq"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "4bit-128g.safetensors"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a1dfb647a3ea442e40904",
    "id": "TheBloke/13B-HyperMantis-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "alpaca",
      "vicuna",
      "mix",
      "merge",
      "model merge",
      "roleplay",
      "chat",
      "instruct",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/13B-HyperMantis-GGUF",
    "model": {
      "_id": "650a1dfb647a3ea442e40904",
      "id": "TheBloke/13B-HyperMantis-GGUF",
      "modelId": "TheBloke/13B-HyperMantis-GGUF",
      "author": "TheBloke",
      "sha": "c999503d2fb2f594b4ff025684a3c147d4cbecd8",
      "lastModified": "2023-09-27T12:52:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "alpaca",
        "vicuna",
        "mix",
        "merge",
        "model merge",
        "roleplay",
        "chat",
        "instruct",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "llama",
          "alpaca",
          "vicuna",
          "mix",
          "merge",
          "model merge",
          "roleplay",
          "chat",
          "instruct"
        ],
        "model_name": "13B Hypermantis",
        "base_model": "digitous/13B-HyperMantis",
        "inference": false,
        "model_creator": "Erik",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "13B-HyperMantis.Q2_K.gguf"
        },
        {
          "rfilename": "13B-HyperMantis.Q3_K_L.gguf"
        },
        {
          "rfilename": "13B-HyperMantis.Q3_K_M.gguf"
        },
        {
          "rfilename": "13B-HyperMantis.Q3_K_S.gguf"
        },
        {
          "rfilename": "13B-HyperMantis.Q4_0.gguf"
        },
        {
          "rfilename": "13B-HyperMantis.Q4_K_M.gguf"
        },
        {
          "rfilename": "13B-HyperMantis.Q4_K_S.gguf"
        },
        {
          "rfilename": "13B-HyperMantis.Q5_0.gguf"
        },
        {
          "rfilename": "13B-HyperMantis.Q5_K_M.gguf"
        },
        {
          "rfilename": "13B-HyperMantis.Q5_K_S.gguf"
        },
        {
          "rfilename": "13B-HyperMantis.Q6_K.gguf"
        },
        {
          "rfilename": "13B-HyperMantis.Q8_0.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6468029ca48c2b6f0d692984",
      "id": "digitous/13B-HyperMantis",
      "modelId": "digitous/13B-HyperMantis",
      "author": "digitous",
      "sha": "aa828ef92c363a5577ffd7d29e678277b9d2eb3c",
      "lastModified": "2023-05-24T20:19:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "alpaca",
        "vicuna",
        "mix",
        "merge",
        "model merge",
        "roleplay",
        "chat",
        "instruct",
        "en",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4661,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 26,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "language": [
          "en"
        ],
        "tags": [
          "llama",
          "alpaca",
          "vicuna",
          "mix",
          "merge",
          "model merge",
          "roleplay",
          "chat",
          "instruct"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a1e07ad753305dedefc73",
    "id": "TheBloke/chronos-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "pytorch",
      "chatbot",
      "storywriting",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/chronos-13B-GGUF",
    "model": {
      "_id": "650a1e07ad753305dedefc73",
      "id": "TheBloke/chronos-13B-GGUF",
      "modelId": "TheBloke/chronos-13B-GGUF",
      "author": "TheBloke",
      "sha": "7c50ab32367f2089074b22cf1608ca260afcdc3e",
      "lastModified": "2023-09-27T12:52:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "pytorch",
        "chatbot",
        "storywriting",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "pytorch",
          "chatbot",
          "storywriting"
        ],
        "model_name": "Chronos 13B",
        "base_model": "elinas/chronos-13b",
        "inference": false,
        "model_creator": "elinas",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "chronos-13B.Q2_K.gguf"
        },
        {
          "rfilename": "chronos-13B.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronos-13B.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronos-13B.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronos-13B.Q4_0.gguf"
        },
        {
          "rfilename": "chronos-13B.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronos-13B.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronos-13B.Q5_0.gguf"
        },
        {
          "rfilename": "chronos-13B.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronos-13B.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronos-13B.Q6_K.gguf"
        },
        {
          "rfilename": "chronos-13B.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64715ee09e0a21d009985c61",
      "id": "elinas/chronos-13b",
      "modelId": "elinas/chronos-13b",
      "author": "elinas",
      "sha": "b58517f0773e41518072d3369c675665f2b6e787",
      "lastModified": "2023-06-23T14:34:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "chatbot",
        "storywriting",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 111,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 29,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "pytorch",
          "chatbot",
          "storywriting"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a1fddb48ff390664a5545",
    "id": "TheBloke/30B-Epsilon-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "alpaca",
      "vicuna",
      "uncensored",
      "cot",
      "chain of thought",
      "story",
      "adventure",
      "roleplay",
      "rp",
      "merge",
      "mix",
      "instruct",
      "wizardlm",
      "superhot",
      "supercot",
      "manticore",
      "hippogriff",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/30B-Epsilon-GGUF",
    "model": {
      "_id": "650a1fddb48ff390664a5545",
      "id": "TheBloke/30B-Epsilon-GGUF",
      "modelId": "TheBloke/30B-Epsilon-GGUF",
      "author": "TheBloke",
      "sha": "477225eeaa97e4352a199efc83433d6c57ecdb01",
      "lastModified": "2023-09-27T12:52:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "alpaca",
        "vicuna",
        "uncensored",
        "cot",
        "chain of thought",
        "story",
        "adventure",
        "roleplay",
        "rp",
        "merge",
        "mix",
        "instruct",
        "wizardlm",
        "superhot",
        "supercot",
        "manticore",
        "hippogriff",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "alpaca",
          "vicuna",
          "uncensored",
          "cot",
          "chain of thought",
          "story",
          "adventure",
          "roleplay",
          "rp",
          "merge",
          "mix",
          "instruct",
          "wizardlm",
          "superhot",
          "supercot",
          "manticore",
          "hippogriff"
        ],
        "model_name": "30B Epsilon",
        "base_model": "CalderaAI/30B-Epsilon",
        "inference": false,
        "model_creator": "Caldera AI",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "30b-epsilon.Q2_K.gguf"
        },
        {
          "rfilename": "30b-epsilon.Q3_K_L.gguf"
        },
        {
          "rfilename": "30b-epsilon.Q3_K_M.gguf"
        },
        {
          "rfilename": "30b-epsilon.Q3_K_S.gguf"
        },
        {
          "rfilename": "30b-epsilon.Q4_0.gguf"
        },
        {
          "rfilename": "30b-epsilon.Q4_K_M.gguf"
        },
        {
          "rfilename": "30b-epsilon.Q4_K_S.gguf"
        },
        {
          "rfilename": "30b-epsilon.Q5_0.gguf"
        },
        {
          "rfilename": "30b-epsilon.Q5_K_M.gguf"
        },
        {
          "rfilename": "30b-epsilon.Q5_K_S.gguf"
        },
        {
          "rfilename": "30b-epsilon.Q6_K.gguf"
        },
        {
          "rfilename": "30b-epsilon.Q8_0.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64a7c8d3c98cb80cca2aa816",
      "id": "CalderaAI/30B-Epsilon",
      "modelId": "CalderaAI/30B-Epsilon",
      "author": "CalderaAI",
      "sha": "6962638c2b0368ad496af6e20e46e3de97a7772b",
      "lastModified": "2023-07-20T06:59:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "alpaca",
        "vicuna",
        "uncensored",
        "cot",
        "chain of thought",
        "story",
        "adventure",
        "roleplay",
        "rp",
        "merge",
        "mix",
        "instruct",
        "wizardlm",
        "superhot",
        "supercot",
        "manticore",
        "hippogriff",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6398,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "llama",
          "alpaca",
          "vicuna",
          "uncensored",
          "cot",
          "chain of thought",
          "story",
          "adventure",
          "roleplay",
          "rp",
          "merge",
          "mix",
          "instruct",
          "wizardlm",
          "superhot",
          "supercot",
          "manticore",
          "hippogriff"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "4bit.safetensors"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a206e61c4bb463611e2a4",
    "id": "TheBloke/30B-Lazarus-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "alpaca",
      "cot",
      "vicuna",
      "uncensored",
      "merge",
      "mix",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/30B-Lazarus-GGUF",
    "model": {
      "_id": "650a206e61c4bb463611e2a4",
      "id": "TheBloke/30B-Lazarus-GGUF",
      "modelId": "TheBloke/30B-Lazarus-GGUF",
      "author": "TheBloke",
      "sha": "109150458db52c730640c2d007c527fa9bcdbc94",
      "lastModified": "2023-09-27T12:52:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "alpaca",
        "cot",
        "vicuna",
        "uncensored",
        "merge",
        "mix",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "alpaca",
          "cot",
          "vicuna",
          "uncensored",
          "merge",
          "mix"
        ],
        "model_name": "30B Lazarus",
        "base_model": "CalderaAI/30B-Lazarus",
        "inference": false,
        "model_creator": "Caldera AI",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "30b-Lazarus.Q2_K.gguf"
        },
        {
          "rfilename": "30b-Lazarus.Q3_K_L.gguf"
        },
        {
          "rfilename": "30b-Lazarus.Q3_K_M.gguf"
        },
        {
          "rfilename": "30b-Lazarus.Q3_K_S.gguf"
        },
        {
          "rfilename": "30b-Lazarus.Q4_0.gguf"
        },
        {
          "rfilename": "30b-Lazarus.Q4_K_M.gguf"
        },
        {
          "rfilename": "30b-Lazarus.Q4_K_S.gguf"
        },
        {
          "rfilename": "30b-Lazarus.Q5_0.gguf"
        },
        {
          "rfilename": "30b-Lazarus.Q5_K_M.gguf"
        },
        {
          "rfilename": "30b-Lazarus.Q5_K_S.gguf"
        },
        {
          "rfilename": "30b-Lazarus.Q6_K.gguf"
        },
        {
          "rfilename": "30b-Lazarus.Q8_0.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "646fce97150f4cab8632e8ab",
      "id": "CalderaAI/30B-Lazarus",
      "modelId": "CalderaAI/30B-Lazarus",
      "author": "CalderaAI",
      "sha": "24da9e88f2b2b7946bc6fe9412d6728b9adc2c3d",
      "lastModified": "2023-05-27T06:12:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "alpaca",
        "cot",
        "vicuna",
        "uncensored",
        "merge",
        "mix",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4925,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 117,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "llama",
          "alpaca",
          "cot",
          "vicuna",
          "uncensored",
          "merge",
          "mix"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "t0int/CalderaAI-30B-Lazarus",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "9bestenbier/CalderaAI-30B-Lazarus",
        "gabriel-ice/CalderaAI-30B-Lazarus",
        "oncetalk/CalderaAI-30B-Lazarus",
        "adigpt/CalderaAI-30B-Lazarus",
        "DaanishMazhar/CalderaAI-30B-Lazarus",
        "IAsk/CalderaAI-30B-Lazarus",
        "aitechadict/CalderaAI-30B-Lazarus",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a21c9f37afbab0d5728a7",
    "id": "TheBloke/chronos-33b-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "pytorch",
      "chatbot",
      "storywriting",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/chronos-33b-GGUF",
    "model": {
      "_id": "650a21c9f37afbab0d5728a7",
      "id": "TheBloke/chronos-33b-GGUF",
      "modelId": "TheBloke/chronos-33b-GGUF",
      "author": "TheBloke",
      "sha": "15e5b9faaab9a661cbb8d069406a7e1ebc182087",
      "lastModified": "2023-09-27T12:52:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "pytorch",
        "chatbot",
        "storywriting",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "pytorch",
          "chatbot",
          "storywriting"
        ],
        "model_name": "Chronos 33B",
        "base_model": "elinas/chronos-33b",
        "inference": false,
        "model_creator": "elinas",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "chronos-33b.Q2_K.gguf"
        },
        {
          "rfilename": "chronos-33b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronos-33b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronos-33b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronos-33b.Q4_0.gguf"
        },
        {
          "rfilename": "chronos-33b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronos-33b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronos-33b.Q5_0.gguf"
        },
        {
          "rfilename": "chronos-33b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronos-33b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronos-33b.Q6_K.gguf"
        },
        {
          "rfilename": "chronos-33b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "647fd0bccbb8294ed80d6186",
      "id": "elinas/chronos-33b",
      "modelId": "elinas/chronos-33b",
      "author": "elinas",
      "sha": "3c11f81d9180618f13777276b1eb0eb70ab99cf0",
      "lastModified": "2023-06-23T00:56:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "chatbot",
        "storywriting",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4578,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 23,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "pytorch",
          "chatbot",
          "storywriting"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Guinnessgshep/elinas-chronos-33b",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a22226fb511ba9e9eed08",
    "id": "TheBloke/MythoBoros-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MythoBoros-13B-GGUF",
    "model": {
      "_id": "650a22226fb511ba9e9eed08",
      "id": "TheBloke/MythoBoros-13B-GGUF",
      "modelId": "TheBloke/MythoBoros-13B-GGUF",
      "author": "TheBloke",
      "sha": "2dfdd8d69491c352711a0738a6fc3e95adf5b9ce",
      "lastModified": "2023-09-27T12:52:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "model_name": "MythoBoros 13B",
        "base_model": "Gryphe/MythoBoros-13b",
        "inference": false,
        "model_creator": "Gryphe",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mythoboros-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mythoboros-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mythoboros-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mythoboros-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mythoboros-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mythoboros-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mythoboros-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mythoboros-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mythoboros-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mythoboros-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mythoboros-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mythoboros-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64bb9bbc140491ca9f28a7ee",
      "id": "Gryphe/MythoBoros-13b",
      "modelId": "Gryphe/MythoBoros-13b",
      "author": "Gryphe",
      "sha": "1f86bba782d4db415967d9a9558ca096eb1e795c",
      "lastModified": "2023-08-04T09:53:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4753,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a22984882fab5c4c41e7a",
    "id": "TheBloke/MythoLogic-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MythoLogic-13B-GGUF",
    "model": {
      "_id": "650a22984882fab5c4c41e7a",
      "id": "TheBloke/MythoLogic-13B-GGUF",
      "modelId": "TheBloke/MythoLogic-13B-GGUF",
      "author": "TheBloke",
      "sha": "ad822883bc7190f97299190fad749b232facfe43",
      "lastModified": "2023-09-27T12:52:23.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "model_name": "MythoLogic 13B",
        "base_model": "Gryphe/MythoLogic-13b",
        "inference": false,
        "model_creator": "Gryphe Padar",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mythologic-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mythologic-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mythologic-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mythologic-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mythologic-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mythologic-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mythologic-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mythologic-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mythologic-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mythologic-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mythologic-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mythologic-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64aec6a281d41f5b9ad59526",
      "id": "Gryphe/MythoLogic-13b",
      "modelId": "Gryphe/MythoLogic-13b",
      "author": "Gryphe",
      "sha": "b4153ba4d75587e0a4e64843e79730a3737fd2bf",
      "lastModified": "2023-08-04T09:55:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4737,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 17,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Vinnybustacap/Gryphe-MythoLogic-13b",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "approximation.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a256723196fb2d857296d",
    "id": "TheBloke/based-13b-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/based",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/based-13b-GGUF",
    "model": {
      "_id": "650a256723196fb2d857296d",
      "id": "TheBloke/based-13b-GGUF",
      "modelId": "TheBloke/based-13b-GGUF",
      "author": "TheBloke",
      "sha": "1c7336454d9af2b17b8f2aab09f7d1673de7bfe5",
      "lastModified": "2023-09-27T12:52:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/based",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "datasets": [
          "ehartford/based"
        ],
        "model_name": "Based 13B",
        "base_model": "ehartford/based-13b",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "You are an an AI who shares your opinions, thoughts, and feelings.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "based-13b.Q2_K.gguf"
        },
        {
          "rfilename": "based-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "based-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "based-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "based-13b.Q4_0.gguf"
        },
        {
          "rfilename": "based-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "based-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "based-13b.Q5_0.gguf"
        },
        {
          "rfilename": "based-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "based-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "based-13b.Q6_K.gguf"
        },
        {
          "rfilename": "based-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "647b9147e8b7333058ac398d",
      "id": "ehartford/based-13b",
      "modelId": "ehartford/based-13b",
      "author": "ehartford",
      "sha": "c57402368ab70dca5d42b8987617c9fdccc7bfea",
      "lastModified": "2023-06-03T20:54:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/based",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/based"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        },
        {
          "rfilename": "zero_to_fp32.py"
        }
      ]
    }
  },
  {
    "_id": "650a25ba5ac587b3f383d514",
    "id": "TheBloke/based-7B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/based",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/based-7B-GGUF",
    "model": {
      "_id": "650a25ba5ac587b3f383d514",
      "id": "TheBloke/based-7B-GGUF",
      "modelId": "TheBloke/based-7B-GGUF",
      "author": "TheBloke",
      "sha": "9afd4ee90e53d178a4ea417a387e5951f5e18370",
      "lastModified": "2023-09-27T12:52:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/based",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "datasets": [
          "ehartford/based"
        ],
        "model_name": "Based 7B",
        "base_model": "ehartford/based-7B",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "You are an an AI who shares your opinions, thoughts, and feelings.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "based-7B.Q2_K.gguf"
        },
        {
          "rfilename": "based-7B.Q3_K_L.gguf"
        },
        {
          "rfilename": "based-7B.Q3_K_M.gguf"
        },
        {
          "rfilename": "based-7B.Q3_K_S.gguf"
        },
        {
          "rfilename": "based-7B.Q4_0.gguf"
        },
        {
          "rfilename": "based-7B.Q4_K_M.gguf"
        },
        {
          "rfilename": "based-7B.Q4_K_S.gguf"
        },
        {
          "rfilename": "based-7B.Q5_0.gguf"
        },
        {
          "rfilename": "based-7B.Q5_K_M.gguf"
        },
        {
          "rfilename": "based-7B.Q5_K_S.gguf"
        },
        {
          "rfilename": "based-7B.Q6_K.gguf"
        },
        {
          "rfilename": "based-7B.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "647b91e34d7c0c3fccd629fc",
      "id": "ehartford/based-7b",
      "modelId": "ehartford/based-7b",
      "author": "ehartford",
      "sha": "29d8b11dfc827ef36ebe265bc1829a1455d13cfd",
      "lastModified": "2023-06-03T20:55:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/based",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/based"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        },
        {
          "rfilename": "zero_to_fp32.py"
        }
      ]
    }
  },
  {
    "_id": "650a26527e0d56c27185ab36",
    "id": "TheBloke/based-30B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/based",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/based-30B-GGUF",
    "model": {
      "_id": "650a26527e0d56c27185ab36",
      "id": "TheBloke/based-30B-GGUF",
      "modelId": "TheBloke/based-30B-GGUF",
      "author": "TheBloke",
      "sha": "83cf43ed4212fc0e872c0954525afe3f91e93997",
      "lastModified": "2023-09-27T12:52:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/based",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "datasets": [
          "ehartford/based"
        ],
        "model_name": "Based 30B",
        "base_model": "ehartford/based-30b",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "You are an an AI who shares your opinions, thoughts, and feelings.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "based-30b.Q2_K.gguf"
        },
        {
          "rfilename": "based-30b.Q3_K_L.gguf"
        },
        {
          "rfilename": "based-30b.Q3_K_M.gguf"
        },
        {
          "rfilename": "based-30b.Q3_K_S.gguf"
        },
        {
          "rfilename": "based-30b.Q4_0.gguf"
        },
        {
          "rfilename": "based-30b.Q4_K_M.gguf"
        },
        {
          "rfilename": "based-30b.Q4_K_S.gguf"
        },
        {
          "rfilename": "based-30b.Q5_0.gguf"
        },
        {
          "rfilename": "based-30b.Q5_K_M.gguf"
        },
        {
          "rfilename": "based-30b.Q5_K_S.gguf"
        },
        {
          "rfilename": "based-30b.Q6_K.gguf"
        },
        {
          "rfilename": "based-30b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "647abf8a822b7e8ccbe3d771",
      "id": "ehartford/based-30b",
      "modelId": "ehartford/based-30b",
      "author": "ehartford",
      "sha": "5818a6344f48dc5a324589b57cb288a9d54c0b79",
      "lastModified": "2023-06-03T16:56:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/based",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4535,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 40,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "datasets": [
          "ehartford/based"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "gersh/ehartford-based-30b",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "latest"
        },
        {
          "rfilename": "pytorch_model-00001-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        },
        {
          "rfilename": "zero_to_fp32.py"
        }
      ]
    }
  },
  {
    "_id": "650a26d51b3694179dfa5374",
    "id": "TheBloke/Dolphin-Llama-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Dolphin-Llama-13B-GGUF",
    "model": {
      "_id": "650a26d51b3694179dfa5374",
      "id": "TheBloke/Dolphin-Llama-13B-GGUF",
      "modelId": "TheBloke/Dolphin-Llama-13B-GGUF",
      "author": "TheBloke",
      "sha": "dc8194910fd1ed907c9241fc4ec119a8a57de270",
      "lastModified": "2023-09-27T12:52:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Dolphin Llama 13B",
        "base_model": "ehartford/dolphin-llama-13b",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "SYSTEM: {system_message}\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke",
        "task_categories": [
          "text-generation"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "dolphin-llama-13b.Q2_K.gguf"
        },
        {
          "rfilename": "dolphin-llama-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "dolphin-llama-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "dolphin-llama-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "dolphin-llama-13b.Q4_0.gguf"
        },
        {
          "rfilename": "dolphin-llama-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "dolphin-llama-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "dolphin-llama-13b.Q5_0.gguf"
        },
        {
          "rfilename": "dolphin-llama-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "dolphin-llama-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "dolphin-llama-13b.Q6_K.gguf"
        },
        {
          "rfilename": "dolphin-llama-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64a19e7db14ab77f9e47b336",
      "id": "ehartford/dolphin-llama-13b",
      "modelId": "ehartford/dolphin-llama-13b",
      "author": "ehartford",
      "sha": "b6d16c3e1cffef5e914863f41fd96152dafddd6f",
      "lastModified": "2023-07-24T09:27:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4562,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 56,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "task_categories": [
          "text-generation"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "canstopshakingmyhead/ehartford-dolphin-llama-13b",
        "calebkreed/ehartford-dolphin-llama-13b",
        "Vinnybustacap/ehartford-dolphin-llama-13b",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "ds_config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a276ad26103b6eed600e5",
    "id": "TheBloke/Wizard-Vicuna-13B-Uncensored-GGUF",
    "likes": 15,
    "private": false,
    "downloads": 37,
    "tags": [
      "transformers",
      "llama",
      "uncensored",
      "en",
      "dataset:ehartford/wizard_vicuna_70k_unfiltered",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Wizard-Vicuna-13B-Uncensored-GGUF",
    "model": {
      "_id": "650a276ad26103b6eed600e5",
      "id": "TheBloke/Wizard-Vicuna-13B-Uncensored-GGUF",
      "modelId": "TheBloke/Wizard-Vicuna-13B-Uncensored-GGUF",
      "author": "TheBloke",
      "sha": "79a316e6beea42177ca9591159e35a6d2bdf2209",
      "lastModified": "2023-09-27T12:52:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "uncensored",
        "en",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 37,
      "library_name": "transformers",
      "likes": 15,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "uncensored"
        ],
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ],
        "model_name": "Wizard Vicuna 13B Uncensored",
        "base_model": "ehartford/Wizard-Vicuna-13B-Uncensored",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "Wizard-Vicuna-13B-Uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-13B-Uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-13B-Uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-13B-Uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-13B-Uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-13B-Uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-13B-Uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-13B-Uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-13B-Uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-13B-Uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-13B-Uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-13B-Uncensored.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "645c365111b04b05ad07460d",
      "id": "ehartford/Wizard-Vicuna-13B-Uncensored",
      "modelId": "ehartford/Wizard-Vicuna-13B-Uncensored",
      "author": "ehartford",
      "sha": "95bfd1640a54e76b3e857c2462fd3a77eca0b275",
      "lastModified": "2023-05-17T15:52:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "uncensored",
        "en",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5251,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 227,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ],
        "language": [
          "en"
        ],
        "tags": [
          "uncensored"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "h2oai/h2ogpt-chatbot",
        "h2oai/h2ogpt-chatbot2",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Onekee/ehartford-Wizard-Vicuna-13B-Uncensored",
        "gordonchan/h2oo",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "acetaminophenPT/ehartford-Wizard-Vicuna-13B-Uncensored",
        "m1thrandir/ehartford-Wizard-Vicuna-13B-Uncensored",
        "Tj/ehartford-Wizard-Vicuna-13B-Uncensored",
        "FroggyQc/ehartford-Wizard-Vicuna-13B-Uncensored",
        "JustMe4Real/ehartford-Wizard-Vicuna-13B-Uncensored",
        "Soxakore/ehartford-Wizard-Vicuna-13B-Uncensored",
        "ZeroGravityYz/ehartford-Wizard-Vicuna-13B-Uncensored",
        "feuillet1234/ehartford-Wizard-Vicuna-13B-Uncensored",
        "Joker55/ehartford-Wizard-Vicuna-13B-Uncensored",
        "pgmcb99/ehartford-Wizard-Vicuna-13B-Uncensored",
        "jdxp/ehartford-Wizard-Vicuna-13B-Uncensored",
        "akashkj/H2OGPT",
        "Nonoxx/ehartford-Wizard-Vicuna-13B-Uncensored",
        "ariel0330/h2osiri",
        "neilgiovanni/ehartford-Wizard-Vicuna-13B-Uncensored",
        "ClaudiuHNS/ehartford-Wizard-Vicuna-13B-Uncensored",
        "ccoreilly/aigua-xat",
        "nabdtran/ehartford-Wizard-Vicuna-13B-Uncensored",
        "hossamdaoud/Falcon40b_GSB",
        "sarayating/ehartford-Wizard-Vicuna-13B-Uncensored",
        "Yarumo/ehartford-Wizard-Vicuna-13B-Uncensored",
        "theSscorpio/ehartford-Wizard-Vicuna-13B-Uncensored",
        "theSscorpio/ehartford-Wizard-Vicuna-13B-Uncensored2",
        "theSscorpio/ehartford-Wizard-Vicuna-13B-Uncensored3",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "Jaaarrr1/ehartford-Wizard-Vicuna-13B-Uncensored",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "AnonymousSub/Ayurveda_Chatbot",
        "TheVortexProject/open_llm_leaderboard",
        "kelvin-t-lu/chatbot",
        "dancers/ehartford-Wizard-Vicuna-13B-Uncensored",
        "choco9966/open-ko-llm-leaderboard",
        "his0/h2ogpt-chatbot",
        "ALIOJ/ehartford-Wizard-Vicuna-13B-Uncensored",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": ".gitignore"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "650a288fce81b73e637e3216",
    "id": "TheBloke/Wizard-Vicuna-30B-Uncensored-GGUF",
    "likes": 13,
    "private": false,
    "downloads": 119,
    "tags": [
      "transformers",
      "llama",
      "uncensored",
      "en",
      "dataset:ehartford/wizard_vicuna_70k_unfiltered",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Wizard-Vicuna-30B-Uncensored-GGUF",
    "model": {
      "_id": "650a288fce81b73e637e3216",
      "id": "TheBloke/Wizard-Vicuna-30B-Uncensored-GGUF",
      "modelId": "TheBloke/Wizard-Vicuna-30B-Uncensored-GGUF",
      "author": "TheBloke",
      "sha": "e7651773730518d718efeb497432045a2d7e3eab",
      "lastModified": "2023-09-27T12:52:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "uncensored",
        "en",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 119,
      "library_name": "transformers",
      "likes": 13,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "uncensored"
        ],
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ],
        "model_name": "Wizard Vicuna 30B Uncensored",
        "base_model": "ehartford/Wizard-Vicuna-30B-Uncensored",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "Wizard-Vicuna-30B-Uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-30B-Uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-30B-Uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-30B-Uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-30B-Uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-30B-Uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-30B-Uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-30B-Uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-30B-Uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-30B-Uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-30B-Uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-30B-Uncensored.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64754c705ada8510bc4ba777",
      "id": "ehartford/Wizard-Vicuna-30B-Uncensored",
      "modelId": "ehartford/Wizard-Vicuna-30B-Uncensored",
      "author": "ehartford",
      "sha": "6374baef4cedd41f85c111b8eec3eb38ee24c4b9",
      "lastModified": "2023-05-30T01:39:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "uncensored",
        "en",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4955,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 77,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ],
        "language": [
          "en"
        ],
        "tags": [
          "uncensored"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "t0int/ehartford-Wizard-Vicuna-30B-Uncensored",
        "TeamMlx/ehartford-Wizard-Vicuna-30B-Uncensored",
        "b1sheng/kg_llm_leaderboard_test",
        "xcoolcoinx/ehartford-Wizard-Vicuna-30B-Uncensored",
        "krishnakkindia/ehartford-Wizard-Vicuna-30B-Uncensored",
        "Bradjan310/ehartford-Wizard-Vicuna-30B-Uncensored",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Betacuckgpt/ehartford-Wizard-Vicuna-30B-Uncensored123",
        "Kalvin-5/ehartford-Wizard-Vicuna-30B-Uncensored",
        "GFerros/ehartford-Wizard-Vicuna-30B-Uncensored",
        "durukan/ehartford-Wizard-Vicuna-30B-Uncensored",
        "ItsRedux/Vicuna-30B-Uncensored",
        "hellyeaboiiii/ehartford-Wizard-Vicuna-30B-Uncensored",
        "Mahavirsingh36/ehartford-Wizard-Vicuna-30B-Uncensored",
        "Yacine85/ehartford-Wizard-Vicuna-30B-Uncensored",
        "passerbyPheonix/ehartford-Wizard-Vicuna-30B-Uncensored",
        "pngwn/open_llm_leaderboard",
        "YaIWon/ehartford-Wizard-Vicuna-30B-Uncensored",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "dancers/ehartford-Wizard-Vicuna-30B-Uncensored",
        "Matrix1985/ehartford-Wizard-Vicuna-30B-Uncensored",
        "Ridler001/ehartford-Wizard-Vicuna-30B-Uncensored",
        "yeemun/ehartford-Wizard-Vicuna-30B-Uncensored",
        "sinimark/ehartford-Wizard-Vicuna-30B-Uncensored",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "latest"
        },
        {
          "rfilename": "pytorch_model-00001-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        },
        {
          "rfilename": "zero_to_fp32.py"
        }
      ]
    }
  },
  {
    "_id": "650a29b17b68c4a6f68ebfe6",
    "id": "TheBloke/WizardLM-13B-Uncensored-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "uncensored",
      "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-13B-Uncensored-GGUF",
    "model": {
      "_id": "650a29b17b68c4a6f68ebfe6",
      "id": "TheBloke/WizardLM-13B-Uncensored-GGUF",
      "modelId": "TheBloke/WizardLM-13B-Uncensored-GGUF",
      "author": "TheBloke",
      "sha": "8331b85f9278578b8aac06c4689a91229624785d",
      "lastModified": "2023-09-27T12:52:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "uncensored",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "uncensored"
        ],
        "datasets": [
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered"
        ],
        "model_name": "Wizardlm 13B Uncensored",
        "base_model": "ehartford/WizardLM-13B-Uncensored",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "You are a helpful AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "WizardLM-13B-Uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "WizardLM-13B-Uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "WizardLM-13B-Uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "WizardLM-13B-Uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "WizardLM-13B-Uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "WizardLM-13B-Uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "WizardLM-13B-Uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "WizardLM-13B-Uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "WizardLM-13B-Uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "WizardLM-13B-Uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "WizardLM-13B-Uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "WizardLM-13B-Uncensored.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "645a9760e505443f81956d37",
      "id": "ehartford/WizardLM-13B-Uncensored",
      "modelId": "ehartford/WizardLM-13B-Uncensored",
      "author": "ehartford",
      "sha": "9025c5f96fef9525da9238369ad082961b0e9494",
      "lastModified": "2023-05-12T23:08:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "uncensored",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4879,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 437,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered"
        ],
        "tags": [
          "uncensored"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "h2oai/h2ogpt-chatbot",
        "h2oai/h2ogpt-chatbot2",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Oddity/ehartford-WizardLM-13B-Uncensored",
        "b1sheng/kg_llm_leaderboard_test",
        "nuwa/ehartford-WizardLM-13B-Uncensored",
        "0xeureka/ehartford-WizardLM-13B-Uncensored",
        "gordonchan/h2oo",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "itsmynti/ehartford-WizardLM-13B-Uncensored",
        "Jacob209/ehartford-WizardLM-13B-Uncensored",
        "TRaw/ehartford-WizardLM-13B-Uncensored",
        "sssdtgvg/ehartford-WizardLM-13B-Uncensored",
        "sawblade/ehartford-WizardLM-13B-Uncensored",
        "satan4191/ehartford-WizardLM-13B-Uncensored",
        "dorkai/SinGPT-Small",
        "234bcn/ehartford-WizardLM-13B-Uncensored",
        "upashu/ehartford-WizardLM-13B-Uncensored",
        "pmb99/ehartford-WizardLM-13B-Uncensored",
        "cownclown/ehartford-WizardLM-13B-Uncensored-v2",
        "JustMe4Real/ehartford-WizardLM-13B-Uncensored",
        "Findinme/ehartford-WizardLM-13B-Uncensored",
        "bscrivener/ehartford-WizardLM-13B-Uncensored-dupe",
        "Testrnfjfjfrj/ehartford-WizardLM-13B-Uncensored",
        "Andrezz/ehartford-WizardLM-13B-Uncensored",
        "Myaptla/ehartford-WizardLM-13B-Uncensored",
        "arcaha/ehartford-WizardLM-13B-Uncensored",
        "ajcwebdev/wizard-lm",
        "DangFutures/ehartford-WizardLM-13B-Uncensored",
        "elitecode/h2ogpt-chatbot2",
        "asach/ehartford-WizardLM-13B-Uncensored",
        "akashkj/H2OGPT",
        "Fscott8/ehartford-WizardLM-13B-Uncensored",
        "tyy130/ehartford-WizardLM-13B-Uncensored",
        "rahduke/ehartford-WizardLM-13B-Uncensored",
        "ghufran919/ehartford-WizardLM-13B-Uncensored",
        "Vinnybustacap/ehartford-WizardLM-13B-Uncensored",
        "ryanmacri/ehartford-WizardLM-13B-Uncensored",
        "ariel0330/h2osiri",
        "ccoreilly/aigua-xat",
        "Lordsony/ehartford-WizardLM-13B-Uncensored",
        "t0int/ehartford-WizardLM-13B-Uncensored",
        "bigraj/ehartford-WizardLM-13B-Uncensored",
        "zenonx/ehartford-WizardLM-13B-Uncensored3",
        "hossamdaoud/Falcon40b_GSB",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "mithroi/ehartford-WizardLM-13B-Uncensored",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "willk/ehartford-WizardLM-13B-Uncensored",
        "trjnkygn32/ehartford-WizardLM-13B-Uncensored",
        "choco9966/LeaderboardTest",
        "AnonymousSub/Ayurveda_Chatbot",
        "ianott/ehartford-WizardLM-13B-Uncensored",
        "swaichsaheb/ehartford-WizardLM-13B-Uncensored",
        "TheVortexProject/open_llm_leaderboard",
        "nopesirnope/ehartford-WizardLM-13B-Uncensored",
        "kelvin-t-lu/chatbot",
        "ralphmcwaldo/ehartford-WizardLM-13B-Uncensored",
        "averagechatbotenjoyer0/ehartford-WizardLM-13B-Uncensored",
        "choco9966/open-ko-llm-leaderboard",
        "his0/h2ogpt-chatbot",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "650a29bc7ee07e274b50b59e",
    "id": "TheBloke/Wizard-Vicuna-7B-Uncensored-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 35,
    "tags": [
      "transformers",
      "llama",
      "uncensored",
      "en",
      "dataset:ehartford/wizard_vicuna_70k_unfiltered",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Wizard-Vicuna-7B-Uncensored-GGUF",
    "model": {
      "_id": "650a29bc7ee07e274b50b59e",
      "id": "TheBloke/Wizard-Vicuna-7B-Uncensored-GGUF",
      "modelId": "TheBloke/Wizard-Vicuna-7B-Uncensored-GGUF",
      "author": "TheBloke",
      "sha": "915dc171b4d6ba1414a8fde821ef816204ed8dcf",
      "lastModified": "2023-09-27T12:52:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "uncensored",
        "en",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 35,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "uncensored"
        ],
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ],
        "model_name": "Wizard Vicuna 7B Uncensored",
        "base_model": "ehartford/Wizard-Vicuna-7B-Uncensored",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "Wizard-Vicuna-7B-Uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-7B-Uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-7B-Uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-7B-Uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-7B-Uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-7B-Uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-7B-Uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-7B-Uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-7B-Uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-7B-Uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-7B-Uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "Wizard-Vicuna-7B-Uncensored.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "646583b66ceebdc7fd9257e4",
      "id": "ehartford/Wizard-Vicuna-7B-Uncensored",
      "modelId": "ehartford/Wizard-Vicuna-7B-Uncensored",
      "author": "ehartford",
      "sha": "1097285acd9c48a1d09bc0a9844d365384732111",
      "lastModified": "2023-05-18T01:58:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "uncensored",
        "en",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5173,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 67,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ],
        "language": [
          "en"
        ],
        "tags": [
          "uncensored"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "Alincoln333/ehartford-Wizard-Vicuna-7B-Uncensored",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "650a29f2ac5108b93a9a5462",
    "id": "TheBloke/WizardLM-13B-V1.0-Uncensored-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-13B-V1.0-Uncensored-GGUF",
    "model": {
      "_id": "650a29f2ac5108b93a9a5462",
      "id": "TheBloke/WizardLM-13B-V1.0-Uncensored-GGUF",
      "modelId": "TheBloke/WizardLM-13B-V1.0-Uncensored-GGUF",
      "author": "TheBloke",
      "sha": "48ff221181f91c96ae0b52e8d7549df08bad7d3d",
      "lastModified": "2023-09-27T12:52:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "datasets": [
          "ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split"
        ],
        "model_name": "WizardLM 13B V1.0 Uncensored",
        "base_model": "ehartford/WizardLM-13b-V1.0-Uncensored",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardlm-13b-v1.0-uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.0-uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.0-uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.0-uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.0-uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.0-uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.0-uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.0-uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.0-uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.0-uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.0-uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.0-uncensored.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6491414999cdb77a1b3094ad",
      "id": "ehartford/WizardLM-13B-V1.0-Uncensored",
      "modelId": "ehartford/WizardLM-13B-V1.0-Uncensored",
      "author": "ehartford",
      "sha": "c9fc30cd8b866c331535af23139fd9766c51e05a",
      "lastModified": "2023-06-20T06:09:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 16,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a2a3cf02cb322e933e2ce",
    "id": "TheBloke/Uncensored-Frank-7B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/wizard_vicuna_70k_unfiltered",
      "license:cc-by-nc-nd-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Uncensored-Frank-7B-GGUF",
    "model": {
      "_id": "650a2a3cf02cb322e933e2ce",
      "id": "TheBloke/Uncensored-Frank-7B-GGUF",
      "modelId": "TheBloke/Uncensored-Frank-7B-GGUF",
      "author": "TheBloke",
      "sha": "7ed182e18c8cdd176550ecab86e6495de9ec358d",
      "lastModified": "2023-09-27T12:52:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:cc-by-nc-nd-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-nd-4.0",
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ],
        "model_name": "Uncensored Frank 7B",
        "base_model": "ajibawa-2023/Uncensored-Frank-7B",
        "inference": false,
        "model_creator": "Feynman Innovcations",
        "model_type": "llama",
        "prompt_template": "This is a conversation with your Uncensored AI assistant Frank. Frank can discuss with you at length about various topics such as ---, ---, ---, . You can ask it anything you want and it will do its best to give you accurate and relevant information.\n\nContext\nYou are a Uncensored AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "uncensored-frank-7b.Q2_K.gguf"
        },
        {
          "rfilename": "uncensored-frank-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "uncensored-frank-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "uncensored-frank-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "uncensored-frank-7b.Q4_0.gguf"
        },
        {
          "rfilename": "uncensored-frank-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "uncensored-frank-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "uncensored-frank-7b.Q5_0.gguf"
        },
        {
          "rfilename": "uncensored-frank-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "uncensored-frank-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "uncensored-frank-7b.Q6_K.gguf"
        },
        {
          "rfilename": "uncensored-frank-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650331ffa450492f841cf033",
      "id": "ajibawa-2023/Uncensored-Frank-7B",
      "modelId": "ajibawa-2023/Uncensored-Frank-7B",
      "author": "ajibawa-2023",
      "sha": "bc1ccb6f7b69a6d255576733ddc4486e9709d5e6",
      "lastModified": "2023-09-20T16:39:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:cc-by-nc-nd-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4595,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-nd-4.0",
        "language": [
          "en"
        ],
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "SynaptInk/ajibawa-2023-Uncensored-Frank-7B"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a2b912e4bbde4181f360d",
    "id": "TheBloke/WizardLM-30B-uncensored-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "uncensored",
      "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-30B-uncensored-GGUF",
    "model": {
      "_id": "650a2b912e4bbde4181f360d",
      "id": "TheBloke/WizardLM-30B-uncensored-GGUF",
      "modelId": "TheBloke/WizardLM-30B-uncensored-GGUF",
      "author": "TheBloke",
      "sha": "1be90fea06fe1ed9f28f58d4a7c7ab1ca2e4b879",
      "lastModified": "2023-09-27T12:52:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "uncensored",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "uncensored"
        ],
        "datasets": [
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered"
        ],
        "model_name": "Wizardlm 30B Uncensored",
        "base_model": "ehartford/WizardLM-30B-Uncensored",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "{prompt}\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "WizardLM-30B-Uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "WizardLM-30B-Uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "WizardLM-30B-Uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "WizardLM-30B-Uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "WizardLM-30B-Uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "WizardLM-30B-Uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "WizardLM-30B-Uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "WizardLM-30B-Uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "WizardLM-30B-Uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "WizardLM-30B-Uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "WizardLM-30B-Uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "WizardLM-30B-Uncensored.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "646b57c95d68f5c15a1e3caf",
      "id": "ehartford/WizardLM-30B-Uncensored",
      "modelId": "ehartford/WizardLM-30B-Uncensored",
      "author": "ehartford",
      "sha": "761783745fcb97831ad8035d3cbd5de484aca3ce",
      "lastModified": "2023-05-22T12:01:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "uncensored",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4604,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 118,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered"
        ],
        "tags": [
          "uncensored"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "empulse/ehartford-WizardLM-30B-Uncensored",
        "b1sheng/kg_llm_leaderboard_test",
        "MLIFY/ehartford-WizardLM-30B-Uncensored",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "semicognitive/ehartford-WizardLM-30B-Uncensored",
        "FroggyQc/ehartford-WizardLM-30B-Uncensored",
        "Looxlyk82/Loox",
        "maxall4/ehartford-WizardLM-30B-Uncensored",
        "gtownsurveys/ehartford-WizardLM-30B-Uncensored",
        "ryanmacri/ehartford-WizardLM-30B-Uncensored",
        "tomobs/ehartford-WizardLM-30B-Uncensored",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        },
        {
          "rfilename": "zero_to_fp32.py"
        }
      ]
    }
  },
  {
    "_id": "650a2c082257a3afbaf5dc63",
    "id": "TheBloke/WizardLM-7B-uncensored-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 12,
    "tags": [
      "transformers",
      "llama",
      "uncensored",
      "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-7B-uncensored-GGUF",
    "model": {
      "_id": "650a2c082257a3afbaf5dc63",
      "id": "TheBloke/WizardLM-7B-uncensored-GGUF",
      "modelId": "TheBloke/WizardLM-7B-uncensored-GGUF",
      "author": "TheBloke",
      "sha": "db690b5e11897e4bcbfb5193bb24fd531ab5cd2f",
      "lastModified": "2023-09-27T12:52:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "uncensored",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 12,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "uncensored"
        ],
        "datasets": [
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered"
        ],
        "model_name": "Wizardlm 7B Uncensored",
        "base_model": "ehartford/WizardLM-7B-Uncensored",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "WizardLM-7B-uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "WizardLM-7B-uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "WizardLM-7B-uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "WizardLM-7B-uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "WizardLM-7B-uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "WizardLM-7B-uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "WizardLM-7B-uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "WizardLM-7B-uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "WizardLM-7B-uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "WizardLM-7B-uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "WizardLM-7B-uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "WizardLM-7B-uncensored.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6454163772d331dec8a15584",
      "id": "ehartford/WizardLM-7B-Uncensored",
      "modelId": "ehartford/WizardLM-7B-Uncensored",
      "author": "ehartford",
      "sha": "14c23f9fa775ab5ce49010418f00df06d92b0b13",
      "lastModified": "2023-05-12T23:12:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "uncensored",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5822,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 344,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered"
        ],
        "tags": [
          "uncensored"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "h2oai/h2ogpt-chatbot",
        "h2oai/h2ogpt-chatbot2",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Boranbruh/ehartford-WizardLM-7B-Uncensored",
        "williamstein/ehartford-WizardLM-7B-Uncensored",
        "FroggyQc/ehartford-WizardLM-7B-Uncensored",
        "gordonchan/h2oo",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Saucee/ehartford-WizardLM-7B-Uncensored",
        "Yarumo/ehartford-WizardLM-7B-Uncensored",
        "mohammadam/ehartford-WizardLM-7B-Uncensored-my-test",
        "Crazyfock/ehartford-WizardLM-7B-Uncensored",
        "Sophia2/ehartford-WizardLM-7B-Uncensored",
        "elitecode/h2ogpt-chatbot2",
        "aaa1820/ehartford-WizardLM-7B-Uncensored",
        "trueuserr/ehartford-WizardLM-7B-Uncensored",
        "akashkj/H2OGPT",
        "AlexProchaska/ehartford-WizardLM-7B-Uncensored",
        "xairforce/ehartford-WizardLM-7B-Uncensored",
        "1234floor/ehartford-WizardLM-7B-Uncensored",
        "ariel0330/h2osiri",
        "ccoreilly/aigua-xat",
        "mattduzit/ehartford-WizardLM-7B-Uncensored",
        "hossamdaoud/Falcon40b_GSB",
        "RandoMan123/ehartford-WizardLM-7B-Uncensored",
        "Redbran/ehartford-WizardLM-7B-Uncensored",
        "asdasdaset/ehartford-WizardLM-7B-Uncensored",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "Betacuckgpt/ehartford-WizardLM-7B-Uncensored",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "AnonymousSub/Ayurveda_Chatbot",
        "jeanmauriceport/ehartford-WizardLM-7B-Uncensored",
        "TheVortexProject/open_llm_leaderboard",
        "nopesirnope/ehartford-WizardLM-7B-Uncensored",
        "kelvin-t-lu/chatbot",
        "Devound/ehartford-WizardLM-7B-Uncensored",
        "sernylan/ehartford-WizardLM-7B-Uncensored",
        "yeemun/ehartford-WizardLM-7B-Uncensored",
        "choco9966/open-ko-llm-leaderboard",
        "his0/h2ogpt-chatbot",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": ".gitignore"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a2c47f37afbab0d58bda9",
    "id": "TheBloke/WizardLM-33B-V1.0-Uncensored-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 21,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-33B-V1.0-Uncensored-GGUF",
    "model": {
      "_id": "650a2c47f37afbab0d58bda9",
      "id": "TheBloke/WizardLM-33B-V1.0-Uncensored-GGUF",
      "modelId": "TheBloke/WizardLM-33B-V1.0-Uncensored-GGUF",
      "author": "TheBloke",
      "sha": "2a643ce8e6c1e256308a54e5a671dd719393d5a2",
      "lastModified": "2023-09-27T12:52:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 21,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "datasets": [
          "ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split"
        ],
        "model_name": "WizardLM 33B V1.0 Uncensored",
        "base_model": "ehartford/WizardLM-33b-V1.0-Uncensored",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardlm-33b-v1.0-uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "wizardlm-33b-v1.0-uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardlm-33b-v1.0-uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-33b-v1.0-uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-33b-v1.0-uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "wizardlm-33b-v1.0-uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-33b-v1.0-uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-33b-v1.0-uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "wizardlm-33b-v1.0-uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-33b-v1.0-uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-33b-v1.0-uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "wizardlm-33b-v1.0-uncensored.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6496ceb695aca460d0852681",
      "id": "ehartford/WizardLM-33B-V1.0-Uncensored",
      "modelId": "ehartford/WizardLM-33B-V1.0-Uncensored",
      "author": "ehartford",
      "sha": "3eca9fdee0ce28d6a4a635a6f19d9a413caee3e7",
      "lastModified": "2023-06-24T11:17:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4715,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 46,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Johnofgiscala/ehartford-WizardLM-33B-V1.0-Uncensored",
        "Aoi0327/ehartford-WizardLM-33B-V1.0-Uncensored",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a2d137ee07e274b50f7ac",
    "id": "TheBloke/Uncensored-Frank-13b-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/wizard_vicuna_70k_unfiltered",
      "license:cc-by-nc-nd-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Uncensored-Frank-13b-GGUF",
    "model": {
      "_id": "650a2d137ee07e274b50f7ac",
      "id": "TheBloke/Uncensored-Frank-13b-GGUF",
      "modelId": "TheBloke/Uncensored-Frank-13b-GGUF",
      "author": "TheBloke",
      "sha": "4c2d28cf7d6aef91aa95c8e873a844510305e2c1",
      "lastModified": "2023-09-27T12:52:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:cc-by-nc-nd-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-nd-4.0",
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ],
        "model_name": "Uncensored Frank 13b",
        "base_model": "ajibawa-2023/Uncensored-Frank-13b",
        "inference": false,
        "model_creator": "Feynman Innovcations",
        "model_type": "llama",
        "prompt_template": "This is a conversation with your Uncensored AI assistant Frank. Frank can discuss with you at length about various topics such as ---, ---, ---, . You can ask it anything you want and it will do its best to give you accurate and relevant information.\n\nContext\nYou are a Uncensored AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "uncensored-frank-13b.Q2_K.gguf"
        },
        {
          "rfilename": "uncensored-frank-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "uncensored-frank-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "uncensored-frank-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "uncensored-frank-13b.Q4_0.gguf"
        },
        {
          "rfilename": "uncensored-frank-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "uncensored-frank-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "uncensored-frank-13b.Q5_0.gguf"
        },
        {
          "rfilename": "uncensored-frank-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "uncensored-frank-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "uncensored-frank-13b.Q6_K.gguf"
        },
        {
          "rfilename": "uncensored-frank-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65034ee993574a89716d1a46",
      "id": "ajibawa-2023/Uncensored-Frank-13B",
      "modelId": "ajibawa-2023/Uncensored-Frank-13B",
      "author": "ajibawa-2023",
      "sha": "7bd67c17f81812ddb48ec0821583ee3ce8df21a8",
      "lastModified": "2023-09-20T16:39:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:cc-by-nc-nd-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4600,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-nd-4.0",
        "language": [
          "en"
        ],
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a2d50a6f657faa42f9d84",
    "id": "TheBloke/WizardLM-7B-V1.0-Uncensored-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 15,
    "tags": [
      "transformers",
      "llama",
      "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-7B-V1.0-Uncensored-GGUF",
    "model": {
      "_id": "650a2d50a6f657faa42f9d84",
      "id": "TheBloke/WizardLM-7B-V1.0-Uncensored-GGUF",
      "modelId": "TheBloke/WizardLM-7B-V1.0-Uncensored-GGUF",
      "author": "TheBloke",
      "sha": "c4ec52c5ed1ef37c63cf71ae838af82fd0e264a2",
      "lastModified": "2023-09-27T12:52:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split"
        ],
        "model_name": "WizardLM 7B V1.0 Uncensored",
        "base_model": "ehartford/WizardLM-7B-V1.0-Uncensored",
        "inference": false,
        "model_creator": "Eric Hartford",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardlm-7b-v1.0-uncensored.Q2_K.gguf"
        },
        {
          "rfilename": "wizardlm-7b-v1.0-uncensored.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardlm-7b-v1.0-uncensored.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-7b-v1.0-uncensored.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-7b-v1.0-uncensored.Q4_0.gguf"
        },
        {
          "rfilename": "wizardlm-7b-v1.0-uncensored.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-7b-v1.0-uncensored.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-7b-v1.0-uncensored.Q5_0.gguf"
        },
        {
          "rfilename": "wizardlm-7b-v1.0-uncensored.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-7b-v1.0-uncensored.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-7b-v1.0-uncensored.Q6_K.gguf"
        },
        {
          "rfilename": "wizardlm-7b-v1.0-uncensored.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "648ef627979504d221eba7c0",
      "id": "ehartford/WizardLM-7B-V1.0-Uncensored",
      "modelId": "ehartford/WizardLM-7B-V1.0-Uncensored",
      "author": "ehartford",
      "sha": "5758f0579069ba7c24a1150610e4f5cb2134493f",
      "lastModified": "2023-06-18T12:34:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 23,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 18,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "dm3n/ehartford-WizardLM-7B-V1.0-Uncensored"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a2f57a2abcb18d64fd128",
    "id": "TheBloke/guanaco-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/guanaco-13B-GGUF",
    "model": {
      "_id": "650a2f57a2abcb18d64fd128",
      "id": "TheBloke/guanaco-13B-GGUF",
      "modelId": "TheBloke/guanaco-13B-GGUF",
      "author": "TheBloke",
      "sha": "59811ec4a8a87a46ee5f1df945db5c183481e8ed",
      "lastModified": "2023-09-27T12:52:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Guanaco 13B",
        "base_model": "timdettmers/guanaco-13b-merged",
        "inference": false,
        "model_creator": "Tim Dettmers",
        "model_type": "llama",
        "prompt_template": "### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "guanaco-13B.Q2_K.gguf"
        },
        {
          "rfilename": "guanaco-13B.Q3_K_L.gguf"
        },
        {
          "rfilename": "guanaco-13B.Q3_K_M.gguf"
        },
        {
          "rfilename": "guanaco-13B.Q3_K_S.gguf"
        },
        {
          "rfilename": "guanaco-13B.Q4_0.gguf"
        },
        {
          "rfilename": "guanaco-13B.Q4_K_M.gguf"
        },
        {
          "rfilename": "guanaco-13B.Q4_K_S.gguf"
        },
        {
          "rfilename": "guanaco-13B.Q5_0.gguf"
        },
        {
          "rfilename": "guanaco-13B.Q5_K_M.gguf"
        },
        {
          "rfilename": "guanaco-13B.Q5_K_S.gguf"
        },
        {
          "rfilename": "guanaco-13B.Q6_K.gguf"
        },
        {
          "rfilename": "guanaco-13B.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ac9ea80fb9b20dbab072d0",
      "id": "timdettmers/guanaco-13b-merged",
      "modelId": "timdettmers/guanaco-13b-merged",
      "author": "timdettmers",
      "sha": "be2529671cb48ffbaaf81331563568040704e6fe",
      "lastModified": "2023-07-11T00:24:32.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 18,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        }
      ]
    }
  },
  {
    "_id": "650a2fd4a2abcb18d64fe00d",
    "id": "TheBloke/SuperPlatty-30B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/SuperPlatty-30B-GGUF",
    "model": {
      "_id": "650a2fd4a2abcb18d64fe00d",
      "id": "TheBloke/SuperPlatty-30B-GGUF",
      "modelId": "TheBloke/SuperPlatty-30B-GGUF",
      "author": "TheBloke",
      "sha": "7a230d80aa3b008eb7fdbef2a7d5902fa8d0bfa8",
      "lastModified": "2023-09-27T12:52:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "llama"
        ],
        "metrics": [
          "MMLU",
          "ARC",
          "HellaSwag",
          "TruthfulQA"
        ],
        "model_name": "SuperPlatty 30B",
        "base_model": "ariellee/SuperPlatty-30B",
        "inference": false,
        "model_creator": "Ariel Lee",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "superplatty-30b.Q2_K.gguf"
        },
        {
          "rfilename": "superplatty-30b.Q3_K_L.gguf"
        },
        {
          "rfilename": "superplatty-30b.Q3_K_M.gguf"
        },
        {
          "rfilename": "superplatty-30b.Q3_K_S.gguf"
        },
        {
          "rfilename": "superplatty-30b.Q4_0.gguf"
        },
        {
          "rfilename": "superplatty-30b.Q4_K_M.gguf"
        },
        {
          "rfilename": "superplatty-30b.Q4_K_S.gguf"
        },
        {
          "rfilename": "superplatty-30b.Q5_0.gguf"
        },
        {
          "rfilename": "superplatty-30b.Q5_K_M.gguf"
        },
        {
          "rfilename": "superplatty-30b.Q5_K_S.gguf"
        },
        {
          "rfilename": "superplatty-30b.Q6_K.gguf"
        },
        {
          "rfilename": "superplatty-30b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "649bf198789f4011c77b03bc",
      "id": "garage-bAInd/SuperPlatty-30B",
      "modelId": "garage-bAInd/SuperPlatty-30B",
      "author": "garage-bAInd",
      "sha": "ff02cd393ca39ca6f88a5c1664edad683754817c",
      "lastModified": "2023-07-25T02:36:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4664,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "tags": [
          "llama"
        ],
        "license": "other",
        "metrics": [
          "MMLU",
          "ARC",
          "HellaSwag",
          "TruthfulQA"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a30b82feb9570c52ee8eb",
    "id": "TheBloke/guanaco-33B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/guanaco-33B-GGUF",
    "model": {
      "_id": "650a30b82feb9570c52ee8eb",
      "id": "TheBloke/guanaco-33B-GGUF",
      "modelId": "TheBloke/guanaco-33B-GGUF",
      "author": "TheBloke",
      "sha": "a6814d227512933d6c86cd7ae005d94ecc1d69af",
      "lastModified": "2023-09-27T12:52:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Guanaco 33B",
        "base_model": "timdettmers/guanaco-33b-merged",
        "inference": false,
        "model_creator": "Tim Dettmers",
        "model_type": "llama",
        "prompt_template": "### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "guanaco-33b.Q2_K.gguf"
        },
        {
          "rfilename": "guanaco-33b.Q3_K_L.gguf"
        },
        {
          "rfilename": "guanaco-33b.Q3_K_M.gguf"
        },
        {
          "rfilename": "guanaco-33b.Q3_K_S.gguf"
        },
        {
          "rfilename": "guanaco-33b.Q4_0.gguf"
        },
        {
          "rfilename": "guanaco-33b.Q4_K_M.gguf"
        },
        {
          "rfilename": "guanaco-33b.Q4_K_S.gguf"
        },
        {
          "rfilename": "guanaco-33b.Q5_0.gguf"
        },
        {
          "rfilename": "guanaco-33b.Q5_K_M.gguf"
        },
        {
          "rfilename": "guanaco-33b.Q5_K_S.gguf"
        },
        {
          "rfilename": "guanaco-33b.Q6_K.gguf"
        },
        {
          "rfilename": "guanaco-33b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "646bfa995d68f5c15a364168",
      "id": "timdettmers/guanaco-33b-merged",
      "modelId": "timdettmers/guanaco-33b-merged",
      "author": "timdettmers",
      "sha": "b2e78a916582935b6616d184b22ea5e9e1eb4c34",
      "lastModified": "2023-05-24T10:33:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4719,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 161,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "uwnlp/guanaco-playground-tgi",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "timdettmers/guanaco-65b-4bit",
        "kitrak-rev/AI-Clone",
        "b1sheng/kg_llm_leaderboard_test",
        "divish/guanaco-playground-tgi-2",
        "ozgur34/qb-Engine2",
        "LuxOAI/guanaco-playground-tgi",
        "IELTS8/ISF",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "tarjomeh/timdettmers-guanaco-33b-merged",
        "Near32/guanaco-playground-tgi",
        "Amjadd/Daoud-33b-merged",
        "alexshengzhili/calahealthgpt",
        "Jamesbrendamour/timdettmers-guanaco-33b-merged",
        "dinnerisserved/timdettmers-guanaco-33b-merged",
        "mohanchinnappan/guanaco-33b-merged",
        "daniloedu/chat_llm_v3",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a316f6d2284f7325ec052",
    "id": "TheBloke/guanaco-65B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/guanaco-65B-GGUF",
    "model": {
      "_id": "650a316f6d2284f7325ec052",
      "id": "TheBloke/guanaco-65B-GGUF",
      "modelId": "TheBloke/guanaco-65B-GGUF",
      "author": "TheBloke",
      "sha": "ba33d0280b07e35c09c72a58e4ad0be9a8293e0c",
      "lastModified": "2023-09-27T12:52:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Guanaco 65B",
        "base_model": "timdettmers/guanaco-65b",
        "inference": false,
        "model_creator": "Tim Dettmers",
        "model_type": "llama",
        "prompt_template": "### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Guanaco-65B.Q2_K.gguf"
        },
        {
          "rfilename": "Guanaco-65B.Q3_K_L.gguf"
        },
        {
          "rfilename": "Guanaco-65B.Q3_K_M.gguf"
        },
        {
          "rfilename": "Guanaco-65B.Q3_K_S.gguf"
        },
        {
          "rfilename": "Guanaco-65B.Q4_0.gguf"
        },
        {
          "rfilename": "Guanaco-65B.Q4_K_M.gguf"
        },
        {
          "rfilename": "Guanaco-65B.Q4_K_S.gguf"
        },
        {
          "rfilename": "Guanaco-65B.Q5_0.gguf"
        },
        {
          "rfilename": "Guanaco-65B.Q5_K_M.gguf"
        },
        {
          "rfilename": "Guanaco-65B.Q5_K_S.gguf"
        },
        {
          "rfilename": "Guanaco-65B.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "Guanaco-65B.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "Guanaco-65B.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "Guanaco-65B.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "646bb012f85ebf65c5381436",
      "id": "timdettmers/guanaco-65b",
      "modelId": "timdettmers/guanaco-65b",
      "author": "timdettmers",
      "sha": "d5cca69da971922cf5da08e0ad4d596a178673df",
      "lastModified": "2023-07-13T19:59:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "arxiv:2305.14314",
        "arxiv:2302.13971",
        "arxiv:2304.07327",
        "has_space",
        "region:us"
      ],
      "downloads": 0,
      "likes": 81,
      "config": {},
      "spaces": [
        "timdettmers/guanaco-65b-4bit",
        "lavanjv/demo",
        "lavanjv/petalschatlvn"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "adapter_config.json"
        },
        {
          "rfilename": "adapter_model.bin"
        },
        {
          "rfilename": "adapter_model.safetensors"
        }
      ]
    }
  },
  {
    "_id": "650a32db2257a3afbaf6c7ab",
    "id": "TheBloke/guanaco-7B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/guanaco-7B-GGUF",
    "model": {
      "_id": "650a32db2257a3afbaf6c7ab",
      "id": "TheBloke/guanaco-7B-GGUF",
      "modelId": "TheBloke/guanaco-7B-GGUF",
      "author": "TheBloke",
      "sha": "777b589f8cec9d9bfbf16175fbef5e76c3a46ec1",
      "lastModified": "2023-09-27T12:52:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Guanaco 7B",
        "base_model": "timdettmers/guanaco-7b",
        "inference": false,
        "model_creator": "Tim Dettmers",
        "model_type": "llama",
        "prompt_template": "### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Guanaco-7B.Q2_K.gguf"
        },
        {
          "rfilename": "Guanaco-7B.Q3_K_L.gguf"
        },
        {
          "rfilename": "Guanaco-7B.Q3_K_M.gguf"
        },
        {
          "rfilename": "Guanaco-7B.Q3_K_S.gguf"
        },
        {
          "rfilename": "Guanaco-7B.Q4_0.gguf"
        },
        {
          "rfilename": "Guanaco-7B.Q4_K_M.gguf"
        },
        {
          "rfilename": "Guanaco-7B.Q4_K_S.gguf"
        },
        {
          "rfilename": "Guanaco-7B.Q5_0.gguf"
        },
        {
          "rfilename": "Guanaco-7B.Q5_K_M.gguf"
        },
        {
          "rfilename": "Guanaco-7B.Q5_K_S.gguf"
        },
        {
          "rfilename": "Guanaco-7B.Q6_K.gguf"
        },
        {
          "rfilename": "Guanaco-7B.Q8_0.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "646ba998db697c798a44b8a4",
      "id": "timdettmers/guanaco-7b",
      "modelId": "timdettmers/guanaco-7b",
      "author": "timdettmers",
      "sha": "cad9de16fb306d5bb1feb901333fe0aa7bd700d8",
      "lastModified": "2023-06-13T01:21:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "arxiv:2305.14314",
        "arxiv:2302.13971",
        "arxiv:2304.07327",
        "has_space",
        "region:us"
      ],
      "downloads": 0,
      "likes": 22,
      "config": {},
      "spaces": [
        "vivekkumarbarman/guanaco_7B",
        "booktrawler/try-guanaco",
        "Linseypass/PLTS"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "adapter_config.json"
        },
        {
          "rfilename": "adapter_model.bin"
        }
      ]
    }
  },
  {
    "_id": "650a3319abdde5290e9a93ca",
    "id": "TheBloke/Uncensored-Frank-33b-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/wizard_vicuna_70k_unfiltered",
      "license:cc-by-nc-nd-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Uncensored-Frank-33b-GGUF",
    "model": {
      "_id": "650a3319abdde5290e9a93ca",
      "id": "TheBloke/Uncensored-Frank-33b-GGUF",
      "modelId": "TheBloke/Uncensored-Frank-33b-GGUF",
      "author": "TheBloke",
      "sha": "c9a52dae8ceaa9c6787d621912891239f001b38b",
      "lastModified": "2023-09-27T12:52:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:cc-by-nc-nd-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-nd-4.0",
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ],
        "model_name": "Uncensored Frank 33b",
        "base_model": "ajibawa-2023/Uncensored-Frank-33b",
        "inference": false,
        "model_creator": "Feynman Innovcations",
        "model_type": "llama",
        "prompt_template": "This is a conversation with your Uncensored AI assistant Frank. Frank can discuss with you at length about various topics such as ---, ---, ---, . You can ask it anything you want and it will do its best to give you accurate and relevant information.\n\nContext\nYou are a Uncensored AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "uncensored-frank-33b.Q2_K.gguf"
        },
        {
          "rfilename": "uncensored-frank-33b.Q3_K_L.gguf"
        },
        {
          "rfilename": "uncensored-frank-33b.Q3_K_M.gguf"
        },
        {
          "rfilename": "uncensored-frank-33b.Q3_K_S.gguf"
        },
        {
          "rfilename": "uncensored-frank-33b.Q4_0.gguf"
        },
        {
          "rfilename": "uncensored-frank-33b.Q4_K_M.gguf"
        },
        {
          "rfilename": "uncensored-frank-33b.Q4_K_S.gguf"
        },
        {
          "rfilename": "uncensored-frank-33b.Q5_0.gguf"
        },
        {
          "rfilename": "uncensored-frank-33b.Q5_K_M.gguf"
        },
        {
          "rfilename": "uncensored-frank-33b.Q5_K_S.gguf"
        },
        {
          "rfilename": "uncensored-frank-33b.Q6_K.gguf"
        },
        {
          "rfilename": "uncensored-frank-33b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650353def9f01e67ee6e628e",
      "id": "ajibawa-2023/Uncensored-Frank-33B",
      "modelId": "ajibawa-2023/Uncensored-Frank-33B",
      "author": "ajibawa-2023",
      "sha": "8a6359d5b66e3b693c4c65ea6f3e61972f5c9126",
      "lastModified": "2023-10-06T17:23:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "license:cc-by-nc-nd-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6602,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-nd-4.0",
        "language": [
          "en"
        ],
        "datasets": [
          "ehartford/wizard_vicuna_70k_unfiltered"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a37ba6d2284f7325fa7b3",
    "id": "TheBloke/upstage-llama-30b-instruct-2048-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 5,
    "tags": [
      "transformers",
      "llama",
      "upstage",
      "instruct",
      "instruction",
      "text-generation",
      "en",
      "dataset:sciq",
      "dataset:metaeval/ScienceQA_text_only",
      "dataset:GAIR/lima",
      "dataset:Open-Orca/OpenOrca",
      "dataset:openbookqa",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/upstage-llama-30b-instruct-2048-GGUF",
    "model": {
      "_id": "650a37ba6d2284f7325fa7b3",
      "id": "TheBloke/upstage-llama-30b-instruct-2048-GGUF",
      "modelId": "TheBloke/upstage-llama-30b-instruct-2048-GGUF",
      "author": "TheBloke",
      "sha": "3803bf7b0a1f1539690e37967478ecdb0b1070b7",
      "lastModified": "2023-09-27T12:52:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "upstage",
        "instruct",
        "instruction",
        "text-generation",
        "en",
        "dataset:sciq",
        "dataset:metaeval/ScienceQA_text_only",
        "dataset:GAIR/lima",
        "dataset:Open-Orca/OpenOrca",
        "dataset:openbookqa",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "upstage",
          "llama",
          "instruct",
          "instruction"
        ],
        "datasets": [
          "sciq",
          "metaeval/ScienceQA_text_only",
          "GAIR/lima",
          "Open-Orca/OpenOrca",
          "openbookqa"
        ],
        "model_name": "Llama 30B Instruct 2048",
        "base_model": "upstage/llama-30b-instruct-2048",
        "inference": false,
        "model_creator": "upstage",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### System:\n{system_message}\n\n### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "upstage-llama-30b-instruct-2048.Q2_K.gguf"
        },
        {
          "rfilename": "upstage-llama-30b-instruct-2048.Q3_K_L.gguf"
        },
        {
          "rfilename": "upstage-llama-30b-instruct-2048.Q3_K_M.gguf"
        },
        {
          "rfilename": "upstage-llama-30b-instruct-2048.Q3_K_S.gguf"
        },
        {
          "rfilename": "upstage-llama-30b-instruct-2048.Q4_0.gguf"
        },
        {
          "rfilename": "upstage-llama-30b-instruct-2048.Q4_K_M.gguf"
        },
        {
          "rfilename": "upstage-llama-30b-instruct-2048.Q4_K_S.gguf"
        },
        {
          "rfilename": "upstage-llama-30b-instruct-2048.Q5_0.gguf"
        },
        {
          "rfilename": "upstage-llama-30b-instruct-2048.Q5_K_M.gguf"
        },
        {
          "rfilename": "upstage-llama-30b-instruct-2048.Q5_K_S.gguf"
        },
        {
          "rfilename": "upstage-llama-30b-instruct-2048.Q6_K.gguf"
        },
        {
          "rfilename": "upstage-llama-30b-instruct-2048.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64afe8bac6cae3c050023a56",
      "id": "upstage/llama-30b-instruct-2048",
      "modelId": "upstage/llama-30b-instruct-2048",
      "author": "upstage",
      "sha": "9f246be5c6c08bf397ff7b42aa5fe91d011d9ace",
      "lastModified": "2023-08-03T22:02:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "upstage",
        "instruct",
        "instruction",
        "en",
        "dataset:sciq",
        "dataset:metaeval/ScienceQA_text_only",
        "dataset:GAIR/lima",
        "dataset:Open-Orca/OpenOrca",
        "dataset:openbookqa",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6690,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 103,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "sciq",
          "metaeval/ScienceQA_text_only",
          "GAIR/lima",
          "Open-Orca/OpenOrca",
          "openbookqa"
        ],
        "language": [
          "en"
        ],
        "tags": [
          "upstage",
          "llama",
          "instruct",
          "instruction"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Ralpher1/upstage-llama-30b-instruct-2048",
        "wholewhale/CW-upstage-llama-30b-instruct-2048",
        "wholewhale/upstage-llama-30b-instruct-2048",
        "ki7/upstage-llama-30b-instruct-2048",
        "p11man/upstage-llama-30b-instruct-2048",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a38b7d26103b6eed84a42",
    "id": "TheBloke/Upstage-Llama1-65B-Instruct-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "upstage",
      "instruct",
      "instruction",
      "text-generation",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Upstage-Llama1-65B-Instruct-GGUF",
    "model": {
      "_id": "650a38b7d26103b6eed84a42",
      "id": "TheBloke/Upstage-Llama1-65B-Instruct-GGUF",
      "modelId": "TheBloke/Upstage-Llama1-65B-Instruct-GGUF",
      "author": "TheBloke",
      "sha": "c55c8e36ea0b0ccdf38ec70870740529c83c327f",
      "lastModified": "2023-09-27T12:52:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "upstage",
        "instruct",
        "instruction",
        "text-generation",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "upstage",
          "llama",
          "instruct",
          "instruction"
        ],
        "model_name": "Llama 65B Instruct",
        "base_model": "upstage/llama-65b-instruct",
        "inference": false,
        "model_creator": "upstage",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### System:\n{system_message}\n\n### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q2_K.gguf"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q3_K_L.gguf"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q3_K_M.gguf"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q3_K_S.gguf"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q4_0.gguf"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q4_K_M.gguf"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q4_K_S.gguf"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q5_0.gguf"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q5_K_M.gguf"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q5_K_S.gguf"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "upstage-llama-65b-instruct.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64b532eb1fb720947d79e888",
      "id": "upstage/llama-65b-instruct",
      "modelId": "upstage/llama-65b-instruct",
      "author": "upstage",
      "sha": "f70a9865cb0a1ac1157ad928b3b428dd85d52946",
      "lastModified": "2023-08-03T22:02:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "upstage",
        "instruct",
        "instruction",
        "en",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4952,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "tags": [
          "upstage",
          "llama",
          "instruct",
          "instruction"
        ],
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a3e3af02cb322e9370434",
    "id": "TheBloke/WizardLM-13B-1.0-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2304.12244",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-13B-1.0-GGUF",
    "model": {
      "_id": "650a3e3af02cb322e9370434",
      "id": "TheBloke/WizardLM-13B-1.0-GGUF",
      "modelId": "TheBloke/WizardLM-13B-1.0-GGUF",
      "author": "TheBloke",
      "sha": "35d3697c80dda65c4149213c8896b4c256223d9e",
      "lastModified": "2023-09-27T12:52:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2304.12244",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "WizardLM 13B 1.0",
        "base_model": "WizardLM/WizardLM-13B-V1.0",
        "inference": false,
        "model_creator": "WizardLM",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardLM-13B-1.0.Q2_K.gguf"
        },
        {
          "rfilename": "wizardLM-13B-1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardLM-13B-1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardLM-13B-1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardLM-13B-1.0.Q4_0.gguf"
        },
        {
          "rfilename": "wizardLM-13B-1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardLM-13B-1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardLM-13B-1.0.Q5_0.gguf"
        },
        {
          "rfilename": "wizardLM-13B-1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardLM-13B-1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardLM-13B-1.0.Q6_K.gguf"
        },
        {
          "rfilename": "wizardLM-13B-1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "645fa9eda93c1779eb0d474b",
      "id": "WizardLMTeam/WizardLM-13B-V1.0",
      "modelId": "WizardLMTeam/WizardLM-13B-V1.0",
      "author": "WizardLMTeam",
      "sha": "964a93aa2e78da377115bb856075a69ebe8aefa4",
      "lastModified": "2023-09-01T07:56:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4528,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 67,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a41482e4bbde41822f856",
    "id": "TheBloke/WizardLM-13B-V1.1-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2304.12244",
      "arxiv:2306.08568",
      "arxiv:2308.09583",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-13B-V1.1-GGUF",
    "model": {
      "_id": "650a41482e4bbde41822f856",
      "id": "TheBloke/WizardLM-13B-V1.1-GGUF",
      "modelId": "TheBloke/WizardLM-13B-V1.1-GGUF",
      "author": "TheBloke",
      "sha": "372299a828017036da3f6103cd443b2492e88138",
      "lastModified": "2023-09-27T12:52:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "WizardLM 13B V1.1",
        "base_model": "WizardLM/WizardLM-13B-V1.1",
        "inference": false,
        "model_creator": "WizardLM",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardlm-13b-v1.1.Q2_K.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.1.Q4_0.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.1.Q5_0.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.1.Q6_K.gguf"
        },
        {
          "rfilename": "wizardlm-13b-v1.1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64a7e88a99817733abbab276",
      "id": "WizardLM/WizardLM-13B-V1.1",
      "modelId": "WizardLM/WizardLM-13B-V1.1",
      "author": "WizardLM",
      "sha": "4e5fe3c792942b0ab25c1efc6a1f44594fc1d5b0",
      "lastModified": "2023-09-01T07:56:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5188,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 70,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "photovideo2046/WizardLM-WizardLM-13B-V1.1",
        "nomadMax/WizardLM-WizardLM-13B-V1.1",
        "rymdfraktal/WizardLM-WizardLM-13B-V1.1",
        "marloncepeda/WizardLM-WizardLM-13B-V1.1",
        "LouCharrierMIS/WizardLM-WizardLM-13B-V1.1",
        "abdulrehman135/WizardLM-WizardLM-13B-V1.1",
        "bigraj/WizardLM-WizardLM-13B-V1.1",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "zero_to_fp32.py"
        }
      ]
    }
  },
  {
    "_id": "650a41e57ee07e274b53a70c",
    "id": "TheBloke/FashionGPT-70B-V1.1-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 18,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/FashionGPT-70B-V1.1-GGUF",
    "model": {
      "_id": "650a41e57ee07e274b53a70c",
      "id": "TheBloke/FashionGPT-70B-V1.1-GGUF",
      "modelId": "TheBloke/FashionGPT-70B-V1.1-GGUF",
      "author": "TheBloke",
      "sha": "60300da5b778f9b247a8cacc642b6e1ab859b40b",
      "lastModified": "2023-09-27T12:52:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 18,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "FashionGPT 70B V1.1",
        "base_model": "ICBU-NPU/FashionGPT-70B-V1.1",
        "inference": false,
        "model_creator": "ICBU-NPU",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q2_K.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q4_0.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q5_0.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "fashiongpt-70b-v1.1.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "6506bea4f3060ea840cd8424",
      "id": "ICBU-NPU/FashionGPT-70B-V1.1",
      "modelId": "ICBU-NPU/FashionGPT-70B-V1.1",
      "author": "ICBU-NPU",
      "sha": "1d27f109dfde41d087789679811edc03a643f4af",
      "lastModified": "2023-09-22T08:32:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "dataset:openchat/openchat_sharegpt4_dataset",
        "dataset:LDJnr/Puffin",
        "dataset:ehartford/samantha-data",
        "dataset:OpenAssistant/oasst1",
        "dataset:jondurbin/airoboros-gpt4-1.4.1",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7373,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 41,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "datasets": [
          "Open-Orca/OpenOrca",
          "openchat/openchat_sharegpt4_dataset",
          "LDJnr/Puffin",
          "ehartford/samantha-data",
          "OpenAssistant/oasst1",
          "jondurbin/airoboros-gpt4-1.4.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "JoYCC/ICBU-NPU-FashionGPT-70B-V1.1",
        "jbcobb/ICBU-NPU-FashionGPT-70B-V1.1",
        "zirconeth/ICBU-NPU-FashionGPT-70B-V1.1",
        "Steph1949/ICBU-NPU-FashionGPT-70B-V1.1",
        "guillelucero/ICBU-NPU-FashionGPT-70B-V1.1",
        "Nonthapat/JackICBU-NPU-FashionGPT-70B-V1.11",
        "shylllynn/ICBU-NPU-FashionGPT-70B-V1.1",
        "Hydrc68/ICBU-NPU-FashionGPT-70B-V1.1",
        "Swaine/ICBU-NPU-FashionGPT-70B-V1.1",
        "Making/ICBU-NPU-FashionGPT-70B-V1.1"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a4375905c78a96a54245b",
    "id": "TheBloke/WizardLM-30B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2304.12244",
      "arxiv:2306.08568",
      "arxiv:2308.09583",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-30B-GGUF",
    "model": {
      "_id": "650a4375905c78a96a54245b",
      "id": "TheBloke/WizardLM-30B-GGUF",
      "modelId": "TheBloke/WizardLM-30B-GGUF",
      "author": "TheBloke",
      "sha": "7bfbf76402ce6437c3e4ca421089ae14fc4d4b0e",
      "lastModified": "2023-09-27T12:52:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "WizardLM 30B v1.0",
        "base_model": "WizardLM/WizardLM-30B-V1.0",
        "inference": false,
        "model_creator": "WizardLM",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardlm-30b.Q2_K.gguf"
        },
        {
          "rfilename": "wizardlm-30b.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardlm-30b.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-30b.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-30b.Q4_0.gguf"
        },
        {
          "rfilename": "wizardlm-30b.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-30b.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-30b.Q5_0.gguf"
        },
        {
          "rfilename": "wizardlm-30b.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardlm-30b.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardlm-30b.Q6_K.gguf"
        },
        {
          "rfilename": "wizardlm-30b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "647f3730f41cf810e37d03f8",
      "id": "WizardLM/WizardLM-30B-V1.0",
      "modelId": "WizardLM/WizardLM-30B-V1.0",
      "author": "WizardLM",
      "sha": "d197b6d97e26d99e7106c9a884d043fb030834c6",
      "lastModified": "2023-09-01T07:56:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4654,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 70,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Vinnybustacap/WizardLM-WizardLM-30B-V1.0",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a4466623330a3a53e7102",
    "id": "TheBloke/wizardLM-7B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 7,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2304.12244",
      "arxiv:2306.08568",
      "arxiv:2308.09583",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/wizardLM-7B-GGUF",
    "model": {
      "_id": "650a4466623330a3a53e7102",
      "id": "TheBloke/wizardLM-7B-GGUF",
      "modelId": "TheBloke/wizardLM-7B-GGUF",
      "author": "TheBloke",
      "sha": "2d495dd61b166c8a47929c54f9497508675d1c03",
      "lastModified": "2023-09-27T12:53:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "WizardLM 7B v1.0",
        "base_model": "WizardLM/WizardLM-7B-V1.0",
        "inference": false,
        "model_creator": "WizardLM",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizardLM-7B.Q2_K.gguf"
        },
        {
          "rfilename": "wizardLM-7B.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizardLM-7B.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizardLM-7B.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizardLM-7B.Q4_0.gguf"
        },
        {
          "rfilename": "wizardLM-7B.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizardLM-7B.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizardLM-7B.Q5_0.gguf"
        },
        {
          "rfilename": "wizardLM-7B.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizardLM-7B.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizardLM-7B.Q6_K.gguf"
        },
        {
          "rfilename": "wizardLM-7B.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6447740b3411a0902badd86d",
      "id": "WizardLM/WizardLM-7B-V1.0",
      "modelId": "WizardLM/WizardLM-7B-V1.0",
      "author": "WizardLM",
      "sha": "b245eca88962e16b8ee4b21eb6b58c2e5f871217",
      "lastModified": "2023-09-01T07:56:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2304.12244",
        "arxiv:2306.08568",
        "arxiv:2308.09583",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1682,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 78,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Vinnybustacap/WizardLM-WizardLM-7B-V1.0",
        "randomshitsen/WizardLM-WizardLM-7B-V1.0",
        "vhpvmx/Chatbot_Comparison"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a44dd61c4bb4636171f0d",
    "id": "TheBloke/minotaur-13B-fixed-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "OpenAccess AI Collective",
      "MPT",
      "axolotl",
      "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
      "dataset:QingyiSi/Alpaca-CoT",
      "dataset:teknium/GPTeacher-General-Instruct",
      "dataset:metaeval/ScienceQA_text_only",
      "dataset:hellaswag",
      "dataset:openai/summarize_from_feedback",
      "dataset:riddle_sense",
      "dataset:gsm8k",
      "dataset:camel-ai/math",
      "dataset:camel-ai/biology",
      "dataset:camel-ai/physics",
      "dataset:camel-ai/chemistry",
      "dataset:winglian/evals",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/minotaur-13B-fixed-GGUF",
    "model": {
      "_id": "650a44dd61c4bb4636171f0d",
      "id": "TheBloke/minotaur-13B-fixed-GGUF",
      "modelId": "TheBloke/minotaur-13B-fixed-GGUF",
      "author": "TheBloke",
      "sha": "126f652f959b4c710bbdbcfe39dfd34959843622",
      "lastModified": "2023-09-27T12:53:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "OpenAccess AI Collective",
        "MPT",
        "axolotl",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "dataset:QingyiSi/Alpaca-CoT",
        "dataset:teknium/GPTeacher-General-Instruct",
        "dataset:metaeval/ScienceQA_text_only",
        "dataset:hellaswag",
        "dataset:openai/summarize_from_feedback",
        "dataset:riddle_sense",
        "dataset:gsm8k",
        "dataset:camel-ai/math",
        "dataset:camel-ai/biology",
        "dataset:camel-ai/physics",
        "dataset:camel-ai/chemistry",
        "dataset:winglian/evals",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "OpenAccess AI Collective",
          "MPT",
          "axolotl"
        ],
        "datasets": [
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
          "QingyiSi/Alpaca-CoT",
          "teknium/GPTeacher-General-Instruct",
          "metaeval/ScienceQA_text_only",
          "hellaswag",
          "openai/summarize_from_feedback",
          "riddle_sense",
          "gsm8k",
          "camel-ai/math",
          "camel-ai/biology",
          "camel-ai/physics",
          "camel-ai/chemistry",
          "winglian/evals"
        ],
        "model_name": "Minotaur 13B Fixed",
        "base_model": "openaccess-ai-collective/minotaur-13b-fixed",
        "inference": false,
        "model_creator": "Open Access AI Collective",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "minotaur-13b.Q2_K.gguf"
        },
        {
          "rfilename": "minotaur-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "minotaur-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "minotaur-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "minotaur-13b.Q4_0.gguf"
        },
        {
          "rfilename": "minotaur-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "minotaur-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "minotaur-13b.Q5_0.gguf"
        },
        {
          "rfilename": "minotaur-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "minotaur-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "minotaur-13b.Q6_K.gguf"
        },
        {
          "rfilename": "minotaur-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6486c7aef583cba71a74ad4e",
      "id": "openaccess-ai-collective/minotaur-13b-fixed",
      "modelId": "openaccess-ai-collective/minotaur-13b-fixed",
      "author": "openaccess-ai-collective",
      "sha": "5dac6f7559dba1c6fb59fee18c3e713cc3c83db7",
      "lastModified": "2023-06-14T14:56:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "OpenAccess AI Collective",
        "MPT",
        "axolotl",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "dataset:QingyiSi/Alpaca-CoT",
        "dataset:teknium/GPTeacher-General-Instruct",
        "dataset:metaeval/ScienceQA_text_only",
        "dataset:hellaswag",
        "dataset:openai/summarize_from_feedback",
        "dataset:riddle_sense",
        "dataset:gsm8k",
        "dataset:camel-ai/math",
        "dataset:camel-ai/biology",
        "dataset:camel-ai/physics",
        "dataset:camel-ai/chemistry",
        "dataset:winglian/evals",
        "license:apache-2.0",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4481,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "tags": [
          "OpenAccess AI Collective",
          "MPT",
          "axolotl"
        ],
        "datasets": [
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
          "QingyiSi/Alpaca-CoT",
          "teknium/GPTeacher-General-Instruct",
          "metaeval/ScienceQA_text_only",
          "hellaswag",
          "openai/summarize_from_feedback",
          "riddle_sense",
          "gsm8k",
          "camel-ai/math",
          "camel-ai/biology",
          "camel-ai/physics",
          "camel-ai/chemistry",
          "winglian/evals"
        ],
        "inference": false
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configs/minotaur-13b.yml"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "minotaur.png"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a44e21b3694179dfdfb5d",
    "id": "TheBloke/Manticore-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:anon8231489123/ShareGPT_Vicuna_unfiltered",
      "dataset:ehartford/wizard_vicuna_70k_unfiltered",
      "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
      "dataset:QingyiSi/Alpaca-CoT",
      "dataset:teknium/GPT4-LLM-Cleaned",
      "dataset:teknium/GPTeacher-General-Instruct",
      "dataset:metaeval/ScienceQA_text_only",
      "dataset:hellaswag",
      "dataset:tasksource/mmlu",
      "dataset:openai/summarize_from_feedback",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Manticore-13B-GGUF",
    "model": {
      "_id": "650a44e21b3694179dfdfb5d",
      "id": "TheBloke/Manticore-13B-GGUF",
      "modelId": "TheBloke/Manticore-13B-GGUF",
      "author": "TheBloke",
      "sha": "d218bf63cda305c4f062ee21707a937b997c6a23",
      "lastModified": "2023-09-27T12:53:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:anon8231489123/ShareGPT_Vicuna_unfiltered",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "dataset:QingyiSi/Alpaca-CoT",
        "dataset:teknium/GPT4-LLM-Cleaned",
        "dataset:teknium/GPTeacher-General-Instruct",
        "dataset:metaeval/ScienceQA_text_only",
        "dataset:hellaswag",
        "dataset:tasksource/mmlu",
        "dataset:openai/summarize_from_feedback",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "library_name": "transformers",
        "datasets": [
          "anon8231489123/ShareGPT_Vicuna_unfiltered",
          "ehartford/wizard_vicuna_70k_unfiltered",
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
          "QingyiSi/Alpaca-CoT",
          "teknium/GPT4-LLM-Cleaned",
          "teknium/GPTeacher-General-Instruct",
          "metaeval/ScienceQA_text_only",
          "hellaswag",
          "tasksource/mmlu",
          "openai/summarize_from_feedback"
        ],
        "model_name": "Manticore 13B",
        "base_model": "openaccess-ai-collective/manticore-13b",
        "inference": false,
        "model_creator": "Open Access AI Collective",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Manticore-13B.Q2_K.gguf"
        },
        {
          "rfilename": "Manticore-13B.Q3_K_L.gguf"
        },
        {
          "rfilename": "Manticore-13B.Q3_K_M.gguf"
        },
        {
          "rfilename": "Manticore-13B.Q3_K_S.gguf"
        },
        {
          "rfilename": "Manticore-13B.Q4_0.gguf"
        },
        {
          "rfilename": "Manticore-13B.Q4_K_M.gguf"
        },
        {
          "rfilename": "Manticore-13B.Q4_K_S.gguf"
        },
        {
          "rfilename": "Manticore-13B.Q5_0.gguf"
        },
        {
          "rfilename": "Manticore-13B.Q5_K_M.gguf"
        },
        {
          "rfilename": "Manticore-13B.Q5_K_S.gguf"
        },
        {
          "rfilename": "Manticore-13B.Q6_K.gguf"
        },
        {
          "rfilename": "Manticore-13B.Q8_0.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6464426edfacc4d097bdd053",
      "id": "openaccess-ai-collective/manticore-13b",
      "modelId": "openaccess-ai-collective/manticore-13b",
      "author": "openaccess-ai-collective",
      "sha": "aed786b0200251c9962ac200c50f7e367f264b46",
      "lastModified": "2023-05-24T21:16:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:anon8231489123/ShareGPT_Vicuna_unfiltered",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "dataset:QingyiSi/Alpaca-CoT",
        "dataset:teknium/GPT4-LLM-Cleaned",
        "dataset:teknium/GPTeacher-General-Instruct",
        "dataset:metaeval/ScienceQA_text_only",
        "dataset:hellaswag",
        "dataset:tasksource/mmlu",
        "dataset:openai/summarize_from_feedback",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4523,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 108,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "anon8231489123/ShareGPT_Vicuna_unfiltered",
          "ehartford/wizard_vicuna_70k_unfiltered",
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
          "QingyiSi/Alpaca-CoT",
          "teknium/GPT4-LLM-Cleaned",
          "teknium/GPTeacher-General-Instruct",
          "metaeval/ScienceQA_text_only",
          "hellaswag",
          "tasksource/mmlu",
          "openai/summarize_from_feedback"
        ],
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "openaccess-ai-collective/manticore-ggml",
        "Toaster496/openaccess-ai-collective-manticore-13b",
        "b1sheng/kg_llm_leaderboard_test",
        "MLIFY/openaccess-ai-collective-manticore-13b",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "johnnyisgood/openaccess-ai-collective-manticore-13b",
        "Rvvvvvvvvvvv/openaccess-ai-collective-manticore-13b",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "Aniket1/openaccess-ai-collective-manticore-13b",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configs/manticore.yml"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "open-llm-leaderboard.png"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a46b85ac587b3f38863a6",
    "id": "TheBloke/wizard-mega-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:anon8231489123/ShareGPT_Vicuna_unfiltered",
      "dataset:ehartford/wizard_vicuna_70k_unfiltered",
      "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/wizard-mega-13B-GGUF",
    "model": {
      "_id": "650a46b85ac587b3f38863a6",
      "id": "TheBloke/wizard-mega-13B-GGUF",
      "modelId": "TheBloke/wizard-mega-13B-GGUF",
      "author": "TheBloke",
      "sha": "3328d1702351ae22e9d7f7a7a65c91a5f2a1580b",
      "lastModified": "2023-09-27T12:53:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:anon8231489123/ShareGPT_Vicuna_unfiltered",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "library_name": "transformers",
        "datasets": [
          "anon8231489123/ShareGPT_Vicuna_unfiltered",
          "ehartford/wizard_vicuna_70k_unfiltered",
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered"
        ],
        "model_name": "Wizard Mega 13B",
        "base_model": "openaccess-ai-collective/wizard-mega-13b",
        "inference": false,
        "model_creator": "Open Access AI Collective",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizard-mega-13B.Q2_K.gguf"
        },
        {
          "rfilename": "wizard-mega-13B.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizard-mega-13B.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizard-mega-13B.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizard-mega-13B.Q4_0.gguf"
        },
        {
          "rfilename": "wizard-mega-13B.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizard-mega-13B.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizard-mega-13B.Q5_0.gguf"
        },
        {
          "rfilename": "wizard-mega-13B.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizard-mega-13B.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizard-mega-13B.Q6_K.gguf"
        },
        {
          "rfilename": "wizard-mega-13B.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6461573ba3081fffa05dc5a5",
      "id": "openaccess-ai-collective/wizard-mega-13b",
      "modelId": "openaccess-ai-collective/wizard-mega-13b",
      "author": "openaccess-ai-collective",
      "sha": "76e90314541be6cfa2b55208831c99f1351c1a33",
      "lastModified": "2023-06-08T04:20:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:anon8231489123/ShareGPT_Vicuna_unfiltered",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4553,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 103,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "anon8231489123/ShareGPT_Vicuna_unfiltered",
          "ehartford/wizard_vicuna_70k_unfiltered",
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered"
        ],
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "h2oai/h2ogpt-chatbot",
        "h2oai/h2ogpt-chatbot2",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "openaccess-ai-collective/wizard-mega-ggml",
        "b1sheng/kg_llm_leaderboard_test",
        "gordonchan/h2oo",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "flashvenom/openaccess-ai-collective-wizard-mega-13b",
        "elitecode/h2ogpt-chatbot2",
        "akashkj/H2OGPT",
        "ariel0330/h2osiri",
        "ccoreilly/aigua-xat",
        "hossamdaoud/Falcon40b_GSB",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "AnonymousSub/Ayurveda_Chatbot",
        "gamerluker1234/openaccess-ai-collective-wizard-mega-13b",
        "TheVortexProject/open_llm_leaderboard",
        "OreoAu/wizard-mega-ggml",
        "kelvin-t-lu/chatbot",
        "choco9966/open-ko-llm-leaderboard",
        "his0/h2ogpt-chatbot",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configs/wizard-mega-13b.yml"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a46d9d26103b6eeda076b",
    "id": "TheBloke/minotaur-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "region:us"
    ],
    "modelId": "TheBloke/minotaur-13B-GGUF",
    "model": {
      "_id": "650a46d9d26103b6eeda076b",
      "id": "TheBloke/minotaur-13B-GGUF",
      "modelId": "TheBloke/minotaur-13B-GGUF",
      "author": "TheBloke",
      "sha": "ca88535fa7dbb97aecdfb8289b9e48ee3664fcb2",
      "lastModified": "2023-09-20T01:11:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "region:us"
      ],
      "downloads": 0,
      "likes": 0,
      "config": {},
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        }
      ]
    }
  },
  {
    "_id": "650a479cad753305dee5a928",
    "id": "TheBloke/llama-13b-supercot-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/llama-13b-supercot-GGUF",
    "model": {
      "_id": "650a479cad753305dee5a928",
      "id": "TheBloke/llama-13b-supercot-GGUF",
      "modelId": "TheBloke/llama-13b-supercot-GGUF",
      "author": "TheBloke",
      "sha": "a90568d2bd21f0a7026d1c44d492784a2de1fd77",
      "lastModified": "2023-09-27T12:53:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Llama 13B Supercot",
        "base_model": "ausboss/llama-13b-supercot",
        "inference": false,
        "model_creator": "ausboss",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-13b-supercot.Q2_K.gguf"
        },
        {
          "rfilename": "llama-13b-supercot.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-13b-supercot.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-13b-supercot.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-13b-supercot.Q4_0.gguf"
        },
        {
          "rfilename": "llama-13b-supercot.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-13b-supercot.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-13b-supercot.Q5_0.gguf"
        },
        {
          "rfilename": "llama-13b-supercot.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-13b-supercot.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-13b-supercot.Q6_K.gguf"
        },
        {
          "rfilename": "llama-13b-supercot.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64433659ce9c6d85e5c413e6",
      "id": "ausboss/llama-13b-supercot",
      "modelId": "ausboss/llama-13b-supercot",
      "author": "ausboss",
      "sha": "f6953fa162b487a3d4c6bdc7b7951e09576c2ae5",
      "lastModified": "2023-04-22T05:47:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4537,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "pytorch_model.bin.index.json.1"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a4a1d4882fab5c4c9c2f5",
    "id": "TheBloke/chronos-hermes-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "pytorch",
      "chatbot",
      "storywriting",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/chronos-hermes-13B-GGUF",
    "model": {
      "_id": "650a4a1d4882fab5c4c9c2f5",
      "id": "TheBloke/chronos-hermes-13B-GGUF",
      "modelId": "TheBloke/chronos-hermes-13B-GGUF",
      "author": "TheBloke",
      "sha": "1d8087c6e1dfa2a73036d98b857168846dc75725",
      "lastModified": "2023-09-27T12:53:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "pytorch",
        "chatbot",
        "storywriting",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "pytorch",
          "chatbot",
          "storywriting"
        ],
        "model_name": "Chronos Hermes 13B",
        "base_model": "Austism/chronos-hermes-13b",
        "inference": false,
        "model_creator": "Austism",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "chronos-hermes-13b.Q2_K.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b.Q4_0.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b.Q5_0.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b.Q6_K.gguf"
        },
        {
          "rfilename": "chronos-hermes-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6487d61385ada975eb821d27",
      "id": "Austism/chronos-hermes-13b",
      "modelId": "Austism/chronos-hermes-13b",
      "author": "Austism",
      "sha": "6a2d2024964c3d1c7e2b2109afd1e823d45d6a23",
      "lastModified": "2023-07-01T16:13:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "chatbot",
        "storywriting",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 13189,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 39,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "pytorch",
          "chatbot",
          "storywriting"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "LoryLury/Austism-chronos-hermes-13b",
        "Damask22/Austism-chronos-hermes-13b_copy"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a4ae31b3694179dfec482",
    "id": "TheBloke/chronos-wizardlm-uc-scot-st-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "storywriting",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/chronos-wizardlm-uc-scot-st-13B-GGUF",
    "model": {
      "_id": "650a4ae31b3694179dfec482",
      "id": "TheBloke/chronos-wizardlm-uc-scot-st-13B-GGUF",
      "modelId": "TheBloke/chronos-wizardlm-uc-scot-st-13B-GGUF",
      "author": "TheBloke",
      "sha": "3b07cb638639cb73bdf80eee87bfdebf4a90742a",
      "lastModified": "2023-09-27T12:53:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "storywriting",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "storywriting"
        ],
        "model_name": "Chronos Wizardlm Uc Scot St 13B",
        "base_model": "Austism/chronos-wizardlm-uc-scot-st-13b",
        "inference": false,
        "model_creator": "Austism",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "chronos-wizardlm-uc-scot-st-13B.Q2_K.gguf"
        },
        {
          "rfilename": "chronos-wizardlm-uc-scot-st-13B.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronos-wizardlm-uc-scot-st-13B.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronos-wizardlm-uc-scot-st-13B.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronos-wizardlm-uc-scot-st-13B.Q4_0.gguf"
        },
        {
          "rfilename": "chronos-wizardlm-uc-scot-st-13B.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronos-wizardlm-uc-scot-st-13B.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronos-wizardlm-uc-scot-st-13B.Q5_0.gguf"
        },
        {
          "rfilename": "chronos-wizardlm-uc-scot-st-13B.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronos-wizardlm-uc-scot-st-13B.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronos-wizardlm-uc-scot-st-13B.Q6_K.gguf"
        },
        {
          "rfilename": "chronos-wizardlm-uc-scot-st-13B.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "647f0a742a7bcaa3079cd1fb",
      "id": "Austism/chronos-wizardlm-uc-scot-st-13b",
      "modelId": "Austism/chronos-wizardlm-uc-scot-st-13b",
      "author": "Austism",
      "sha": "057f6d2d1bdbae9ac23c6019ef939f931e0caa92",
      "lastModified": "2023-06-06T11:23:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "storywriting",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "llama",
          "storywriting"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00013.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a4b49b44445e9b3a99ddf",
    "id": "TheBloke/CAMEL-13B-Combined-Data-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2303.17760",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/CAMEL-13B-Combined-Data-GGUF",
    "model": {
      "_id": "650a4b49b44445e9b3a99ddf",
      "id": "TheBloke/CAMEL-13B-Combined-Data-GGUF",
      "modelId": "TheBloke/CAMEL-13B-Combined-Data-GGUF",
      "author": "TheBloke",
      "sha": "b699260dd4d5b2dfdeea8db9ecc4f71825246b1f",
      "lastModified": "2023-09-27T12:53:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2303.17760",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "CAMEL 13B Combined Data",
        "base_model": "camel-ai/CAMEL-13B-Combined-Data",
        "inference": false,
        "model_creator": "CAMEL",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "camel-13b-combined.Q2_K.gguf"
        },
        {
          "rfilename": "camel-13b-combined.Q3_K_L.gguf"
        },
        {
          "rfilename": "camel-13b-combined.Q3_K_M.gguf"
        },
        {
          "rfilename": "camel-13b-combined.Q3_K_S.gguf"
        },
        {
          "rfilename": "camel-13b-combined.Q4_0.gguf"
        },
        {
          "rfilename": "camel-13b-combined.Q4_K_M.gguf"
        },
        {
          "rfilename": "camel-13b-combined.Q4_K_S.gguf"
        },
        {
          "rfilename": "camel-13b-combined.Q5_0.gguf"
        },
        {
          "rfilename": "camel-13b-combined.Q5_K_M.gguf"
        },
        {
          "rfilename": "camel-13b-combined.Q5_K_S.gguf"
        },
        {
          "rfilename": "camel-13b-combined.Q6_K.gguf"
        },
        {
          "rfilename": "camel-13b-combined.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "647a80d8822b7e8ccbdc3ab0",
      "id": "camel-ai/CAMEL-13B-Combined-Data",
      "modelId": "camel-ai/CAMEL-13B-Combined-Data",
      "author": "camel-ai",
      "sha": "6d98f2801f13d89de7978ee9f348a52ea46a24ec",
      "lastModified": "2023-06-17T18:51:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2303.17760",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4514,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "alexshengzhili/calahealthgpt",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a4bd01b3694179dfeeda4",
    "id": "TheBloke/stable-vicuna-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 5,
    "tags": [
      "transformers",
      "llama",
      "causal-lm",
      "en",
      "dataset:OpenAssistant/oasst1",
      "dataset:nomic-ai/gpt4all_prompt_generations",
      "dataset:tatsu-lab/alpaca",
      "arxiv:2302.13971",
      "license:cc-by-nc-sa-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/stable-vicuna-13B-GGUF",
    "model": {
      "_id": "650a4bd01b3694179dfeeda4",
      "id": "TheBloke/stable-vicuna-13B-GGUF",
      "modelId": "TheBloke/stable-vicuna-13B-GGUF",
      "author": "TheBloke",
      "sha": "32b7ba805701464c9fa4f4cd761a50a690ed31ce",
      "lastModified": "2023-09-27T12:53:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "causal-lm",
        "en",
        "dataset:OpenAssistant/oasst1",
        "dataset:nomic-ai/gpt4all_prompt_generations",
        "dataset:tatsu-lab/alpaca",
        "arxiv:2302.13971",
        "license:cc-by-nc-sa-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "cc-by-nc-sa-4.0",
        "tags": [
          "causal-lm",
          "llama"
        ],
        "datasets": [
          "OpenAssistant/oasst1",
          "nomic-ai/gpt4all_prompt_generations",
          "tatsu-lab/alpaca"
        ],
        "model_name": "Stable Vicuna 13B",
        "base_model": "CarperAI/stable-vicuna-13b-delta",
        "inference": false,
        "model_creator": "CarperAI",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "stable-vicuna-13B.Q2_K.gguf"
        },
        {
          "rfilename": "stable-vicuna-13B.Q3_K_L.gguf"
        },
        {
          "rfilename": "stable-vicuna-13B.Q3_K_M.gguf"
        },
        {
          "rfilename": "stable-vicuna-13B.Q3_K_S.gguf"
        },
        {
          "rfilename": "stable-vicuna-13B.Q4_0.gguf"
        },
        {
          "rfilename": "stable-vicuna-13B.Q4_K_M.gguf"
        },
        {
          "rfilename": "stable-vicuna-13B.Q4_K_S.gguf"
        },
        {
          "rfilename": "stable-vicuna-13B.Q5_0.gguf"
        },
        {
          "rfilename": "stable-vicuna-13B.Q5_K_M.gguf"
        },
        {
          "rfilename": "stable-vicuna-13B.Q5_K_S.gguf"
        },
        {
          "rfilename": "stable-vicuna-13B.Q6_K.gguf"
        },
        {
          "rfilename": "stable-vicuna-13B.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64489dad3411a0902bca5bc9",
      "id": "CarperAI/stable-vicuna-13b-delta",
      "modelId": "CarperAI/stable-vicuna-13b-delta",
      "author": "CarperAI",
      "sha": "c8bb23fc9a25b9dc59edf94a8ba922c8f6b75b1f",
      "lastModified": "2023-05-19T08:40:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "causal-lm",
        "en",
        "dataset:OpenAssistant/oasst1",
        "dataset:nomic-ai/gpt4all_prompt_generations",
        "dataset:tatsu-lab/alpaca",
        "arxiv:2302.13971",
        "doi:10.57967/hf/0588",
        "license:cc-by-nc-sa-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 44,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 455,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "tags": [
          "causal-lm",
          "llama"
        ],
        "license": "cc-by-nc-sa-4.0",
        "datasets": [
          "OpenAssistant/oasst1",
          "nomic-ai/gpt4all_prompt_generations",
          "tatsu-lab/alpaca"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "CarperAI/StableVicuna",
        "upstage/open-ko-llm-leaderboard",
        "HuggingFaceH4/human_eval_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "AILab-CVC/SEED-Bench_Leaderboard",
        "openkg/llm_leaderboard",
        "AILab-CVC/EvalCrafter",
        "b1sheng/kg_llm_leaderboard_test",
        "PeepDaSlan9/CarperAI-stable-vicuna-13b-delta",
        "DrewKarn/CarperAI-stable-vicuna-13b-delta",
        "itbeard/CarperAI-stable-vicuna-13b-delta",
        "bebetterfeng/CarperAI-stable-vicuna-13b-delta",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "lightmansor/CarperAI-stable-vicuna-13b-delta",
        "Giptaku/StableVicuna",
        "Tj/CarperAI-stable-vicuna-13b-delta",
        "strauss23/StableVicuna3",
        "harshav/CarperAI-stable-vicuna-13b-delta",
        "vengeance1st/bloomdemo",
        "MoAlsalman/CarperAI-stable-vicuna-13b-delta11",
        "Alfasign/open_llm_leaderboard",
        "tejeshbhalla/CarperAI-stable-vicuna-13b-delta",
        "danielpark/open_llm_leaderboard",
        "AiAgent/CarperAI-stable-vicuna-13b-delta",
        "redrabbitsz/CarperAI-stable-vicuna-13b-delta",
        "starmorph/open_llm_leaderboard",
        "DeepBrainz/open_llm_leaderboard",
        "seikwan/open_llm_leaderboard",
        "levelsup/StableVicuna",
        "kingskiller/CarperAI-stable-vicuna-13b-delta",
        "GageWeike/CarperAI-stable-vicuna-13b-delta",
        "wanxiaoyuan/CarperAI-stable-vicuna-13b-delta",
        "eaada/CarperAI-stable-vicuna-13b-delta",
        "wu152/CarperAI-stable-vicuna-13b-delta",
        "loljok/CarperAI-stable-vicuna-13b-delta",
        "BreakLee/SEED-Bench",
        "Flor3324/CarperAI-stable-vicuna-13b-delta",
        "IUSEGPTLOL/CarperAI-stable-vicuna-13b-delta",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "Onegai/CarperAI-stable-vicuna-13b-delta",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "apply_delta.py"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generate_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a4be73449d9a49c2c288e",
    "id": "TheBloke/CAMEL-13B-Role-Playing-Data-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2303.17760",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/CAMEL-13B-Role-Playing-Data-GGUF",
    "model": {
      "_id": "650a4be73449d9a49c2c288e",
      "id": "TheBloke/CAMEL-13B-Role-Playing-Data-GGUF",
      "modelId": "TheBloke/CAMEL-13B-Role-Playing-Data-GGUF",
      "author": "TheBloke",
      "sha": "d934c630988a7769cb74fb23f4b7399e2d617f57",
      "lastModified": "2023-09-27T12:53:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2303.17760",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "CAMEL 13B Role Playing Data",
        "base_model": "camel-ai/CAMEL-13B-Role-Playing-Data",
        "inference": false,
        "model_creator": "CAMEL",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "camel-13b-roleplay.Q2_K.gguf"
        },
        {
          "rfilename": "camel-13b-roleplay.Q3_K_L.gguf"
        },
        {
          "rfilename": "camel-13b-roleplay.Q3_K_M.gguf"
        },
        {
          "rfilename": "camel-13b-roleplay.Q3_K_S.gguf"
        },
        {
          "rfilename": "camel-13b-roleplay.Q4_0.gguf"
        },
        {
          "rfilename": "camel-13b-roleplay.Q4_K_M.gguf"
        },
        {
          "rfilename": "camel-13b-roleplay.Q4_K_S.gguf"
        },
        {
          "rfilename": "camel-13b-roleplay.Q5_0.gguf"
        },
        {
          "rfilename": "camel-13b-roleplay.Q5_K_M.gguf"
        },
        {
          "rfilename": "camel-13b-roleplay.Q5_K_S.gguf"
        },
        {
          "rfilename": "camel-13b-roleplay.Q6_K.gguf"
        },
        {
          "rfilename": "camel-13b-roleplay.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "647a55df822b7e8ccbd6fd06",
      "id": "camel-ai/CAMEL-13B-Role-Playing-Data",
      "modelId": "camel-ai/CAMEL-13B-Role-Playing-Data",
      "author": "camel-ai",
      "sha": "762ecb0d85572c8f8bcbca06d27f7f64a4d74615",
      "lastModified": "2023-06-18T19:08:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2303.17760",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4546,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a4c11d48ed98e63ce111d",
    "id": "TheBloke/fin-llama-33B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "finance",
      "llm",
      "trading",
      "dataset:bavest/fin-llama-dataset",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/fin-llama-33B-GGUF",
    "model": {
      "_id": "650a4c11d48ed98e63ce111d",
      "id": "TheBloke/fin-llama-33B-GGUF",
      "modelId": "TheBloke/fin-llama-33B-GGUF",
      "author": "TheBloke",
      "sha": "b1f5a531bb959d2995da5b43a1ae7a2193a678df",
      "lastModified": "2023-09-27T12:53:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "finance",
        "llm",
        "trading",
        "dataset:bavest/fin-llama-dataset",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "finance",
          "llm",
          "llama",
          "trading"
        ],
        "datasets": [
          "bavest/fin-llama-dataset"
        ],
        "model_name": "Fin Llama 33B",
        "base_model": "bavest/fin-llama-33b-merged",
        "inference": false,
        "model_creator": "Bavest",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "fin-llama-33b.Q2_K.gguf"
        },
        {
          "rfilename": "fin-llama-33b.Q3_K_L.gguf"
        },
        {
          "rfilename": "fin-llama-33b.Q3_K_M.gguf"
        },
        {
          "rfilename": "fin-llama-33b.Q3_K_S.gguf"
        },
        {
          "rfilename": "fin-llama-33b.Q4_0.gguf"
        },
        {
          "rfilename": "fin-llama-33b.Q4_K_M.gguf"
        },
        {
          "rfilename": "fin-llama-33b.Q4_K_S.gguf"
        },
        {
          "rfilename": "fin-llama-33b.Q5_0.gguf"
        },
        {
          "rfilename": "fin-llama-33b.Q5_K_M.gguf"
        },
        {
          "rfilename": "fin-llama-33b.Q5_K_S.gguf"
        },
        {
          "rfilename": "fin-llama-33b.Q6_K.gguf"
        },
        {
          "rfilename": "fin-llama-33b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "647a7189822b7e8ccbda03d2",
      "id": "bavest/fin-llama-33b-merged",
      "modelId": "bavest/fin-llama-33b-merged",
      "author": "bavest",
      "sha": "17114520801da7b9599fe7a9fdf238915713a59b",
      "lastModified": "2023-06-05T10:18:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "finance",
        "llm",
        "trading",
        "dataset:bavest/fin-llama-dataset",
        "license:gpl",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4568,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "gpl",
        "datasets": [
          "bavest/fin-llama-dataset"
        ],
        "tags": [
          "finance",
          "llm",
          "llama",
          "trading"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a4cabe13ff962300eac74",
    "id": "TheBloke/CAMEL-33B-Combined-Data-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/CAMEL-33B-Combined-Data-GGUF",
    "model": {
      "_id": "650a4cabe13ff962300eac74",
      "id": "TheBloke/CAMEL-33B-Combined-Data-GGUF",
      "modelId": "TheBloke/CAMEL-33B-Combined-Data-GGUF",
      "author": "TheBloke",
      "sha": "d9e0838c77535b60194df1315949d754d5472f5a",
      "lastModified": "2023-09-27T12:53:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "CAMEL 33B Combined Data",
        "base_model": "camel-ai/CAMEL-33B-Combined-Data",
        "inference": false,
        "model_creator": "CAMEL",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "camel-33b-combined-data.Q2_K.gguf"
        },
        {
          "rfilename": "camel-33b-combined-data.Q3_K_L.gguf"
        },
        {
          "rfilename": "camel-33b-combined-data.Q3_K_M.gguf"
        },
        {
          "rfilename": "camel-33b-combined-data.Q3_K_S.gguf"
        },
        {
          "rfilename": "camel-33b-combined-data.Q4_0.gguf"
        },
        {
          "rfilename": "camel-33b-combined-data.Q4_K_M.gguf"
        },
        {
          "rfilename": "camel-33b-combined-data.Q4_K_S.gguf"
        },
        {
          "rfilename": "camel-33b-combined-data.Q5_0.gguf"
        },
        {
          "rfilename": "camel-33b-combined-data.Q5_K_M.gguf"
        },
        {
          "rfilename": "camel-33b-combined-data.Q5_K_S.gguf"
        },
        {
          "rfilename": "camel-33b-combined-data.Q6_K.gguf"
        },
        {
          "rfilename": "camel-33b-combined-data.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "648de8d625a12e220da18ca2",
      "id": "camel-ai/CAMEL-33B-Combined-Data",
      "modelId": "camel-ai/CAMEL-33B-Combined-Data",
      "author": "camel-ai",
      "sha": "62c74e7531625c1383bbbdc7c8346a996e9d1e21",
      "lastModified": "2023-06-17T19:50:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4516,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Rardilit/Camel-AI",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a4ea8634e02df56d4fa99",
    "id": "TheBloke/Karen_theEditor_13B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "lora",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Karen_theEditor_13B-GGUF",
    "model": {
      "_id": "650a4ea8634e02df56d4fa99",
      "id": "TheBloke/Karen_theEditor_13B-GGUF",
      "modelId": "TheBloke/Karen_theEditor_13B-GGUF",
      "author": "TheBloke",
      "sha": "ba1d9ea725bddeb6586ba87d519dacf36b2121b3",
      "lastModified": "2023-09-27T12:53:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "lora",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "tags": [
          "lora"
        ],
        "model_name": "Karen The Editor 13B",
        "base_model": "FPHam/Karen_theEditor_13b_HF",
        "inference": false,
        "model_creator": "FPHam",
        "model_type": "llama",
        "prompt_template": "You are a helpful AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Karen-The-Editor.Q2_K.gguf"
        },
        {
          "rfilename": "Karen-The-Editor.Q3_K_L.gguf"
        },
        {
          "rfilename": "Karen-The-Editor.Q3_K_M.gguf"
        },
        {
          "rfilename": "Karen-The-Editor.Q3_K_S.gguf"
        },
        {
          "rfilename": "Karen-The-Editor.Q4_0.gguf"
        },
        {
          "rfilename": "Karen-The-Editor.Q4_K_M.gguf"
        },
        {
          "rfilename": "Karen-The-Editor.Q4_K_S.gguf"
        },
        {
          "rfilename": "Karen-The-Editor.Q5_0.gguf"
        },
        {
          "rfilename": "Karen-The-Editor.Q5_K_M.gguf"
        },
        {
          "rfilename": "Karen-The-Editor.Q5_K_S.gguf"
        },
        {
          "rfilename": "Karen-The-Editor.Q6_K.gguf"
        },
        {
          "rfilename": "Karen-The-Editor.Q8_0.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "647a5a7944b6a3ae9d23fefe",
      "id": "FPHam/Karen_theEditor_13b_HF",
      "modelId": "FPHam/Karen_theEditor_13b_HF",
      "author": "FPHam",
      "sha": "68689982b9d554e4ce3f2d68edef51f9c22a138a",
      "lastModified": "2023-06-27T22:54:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "lora",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 24,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "lora"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a4ee14882fab5c4ca7d65",
    "id": "TheBloke/gorilla-7B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2305.15334",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/gorilla-7B-GGUF",
    "model": {
      "_id": "650a4ee14882fab5c4ca7d65",
      "id": "TheBloke/gorilla-7B-GGUF",
      "modelId": "TheBloke/gorilla-7B-GGUF",
      "author": "TheBloke",
      "sha": "e280376bfe03ed00c70db5054babbf289cb12899",
      "lastModified": "2023-09-27T12:53:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2305.15334",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Gorilla 7B",
        "base_model": "gorilla-llm/gorilla-7b-hf-delta-v0",
        "inference": false,
        "model_creator": "Gorilla LLM (UC Berkeley)",
        "model_type": "llama",
        "prompt_template": "### User: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Gorilla-7B.Q2_K.gguf"
        },
        {
          "rfilename": "Gorilla-7B.Q3_K_L.gguf"
        },
        {
          "rfilename": "Gorilla-7B.Q3_K_M.gguf"
        },
        {
          "rfilename": "Gorilla-7B.Q3_K_S.gguf"
        },
        {
          "rfilename": "Gorilla-7B.Q4_0.gguf"
        },
        {
          "rfilename": "Gorilla-7B.Q4_K_M.gguf"
        },
        {
          "rfilename": "Gorilla-7B.Q4_K_S.gguf"
        },
        {
          "rfilename": "Gorilla-7B.Q5_0.gguf"
        },
        {
          "rfilename": "Gorilla-7B.Q5_K_M.gguf"
        },
        {
          "rfilename": "Gorilla-7B.Q5_K_S.gguf"
        },
        {
          "rfilename": "Gorilla-7B.Q6_K.gguf"
        },
        {
          "rfilename": "Gorilla-7B.Q8_0.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "647284700211f852700c75cb",
      "id": "gorilla-llm/gorilla-7b-hf-delta-v0",
      "modelId": "gorilla-llm/gorilla-7b-hf-delta-v0",
      "author": "gorilla-llm",
      "sha": "1a2335cb7efddba41e189a3fffe5aaa258f3db37",
      "lastModified": "2023-06-06T09:14:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "api",
        "en",
        "dataset:gorilla-llm/APIBench",
        "arxiv:2305.15334",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 21,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 52,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "language": [
          "en"
        ],
        "tags": [
          "api"
        ],
        "datasets": [
          "gorilla-llm/APIBench"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "zou-code/gorilla-llm-gorilla-7b-hf-delta-v0",
        "jatin-tech/gorilla-llm-gorilla-7b-hf-delta-v0",
        "goridge/gorilla-llm-gorilla-7b-hf-delta-v0"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a4f90e13ff962300f0c9d",
    "id": "TheBloke/llama-30b-supercot-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/llama-30b-supercot-GGUF",
    "model": {
      "_id": "650a4f90e13ff962300f0c9d",
      "id": "TheBloke/llama-30b-supercot-GGUF",
      "modelId": "TheBloke/llama-30b-supercot-GGUF",
      "author": "TheBloke",
      "sha": "8a81174c3451d12035edf8c5cb90467fa1aa9a75",
      "lastModified": "2023-09-27T12:53:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Llama 30B Supercot",
        "base_model": "ausboss/llama-30b-supercot",
        "inference": false,
        "model_creator": "ausboss",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-30b-supercot.Q2_K.gguf"
        },
        {
          "rfilename": "llama-30b-supercot.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-30b-supercot.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-30b-supercot.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-30b-supercot.Q4_0.gguf"
        },
        {
          "rfilename": "llama-30b-supercot.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-30b-supercot.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-30b-supercot.Q5_0.gguf"
        },
        {
          "rfilename": "llama-30b-supercot.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-30b-supercot.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-30b-supercot.Q6_K.gguf"
        },
        {
          "rfilename": "llama-30b-supercot.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6442b3e88569978432f9a6cd",
      "id": "ausboss/llama-30b-supercot",
      "modelId": "ausboss/llama-30b-supercot",
      "author": "ausboss",
      "sha": "dc9d81f454d286ea040c5cd45b058aecaa51c13e",
      "lastModified": "2023-05-23T20:57:23.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4722,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 125,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "rodgermoore/ausboss-llama-30b-supercot",
        "thatsfoxy/ausboss-llama-30b-supercot",
        "darlade/ausboss-llama-30b-supercot",
        "sikkha/ausboss-llama-30b-supercot",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "aitechadict/ausboss-llama-30b-supercot",
        "aitechadict/ausboss-llama-30b-supercot-mod",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00024-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00025-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00026-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00027-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00028-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00029-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00030-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00031-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00032-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00033-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00034-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00035-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00036-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00037-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00038-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00039-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00040-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00041-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00042-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00043-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00044-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00045-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00046-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00047-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00048-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00049-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00050-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00051-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00052-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00053-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00054-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00055-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00056-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00057-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00058-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00059-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00060-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00061-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00062-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00063-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00064-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00065-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00066-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00067-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00068-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00069-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00070-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00071-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00072-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00073-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00074-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00075-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00076-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00077-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00078-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00079-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00080-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00081-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00082-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00083-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00084-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00085-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00086-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00087-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00088-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00089-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00090-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00091-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00092-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00093-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00094-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00095-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00096-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00097-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00098-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00099-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00100-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00101-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00102-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00103-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00104-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00105-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00106-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00107-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00108-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00109-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00110-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00111-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00112-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00113-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00114-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00115-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00116-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00117-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00118-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00119-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00120-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00121-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00122-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00123-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00124-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00125-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00126-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00127-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00128-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00129-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00130-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00131-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00132-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00133-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00134-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00135-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00136-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00137-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00138-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00139-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00140-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00141-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00142-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00143-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00144-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00145-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00146-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00147-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00148-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00149-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00150-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00151-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00152-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00153-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00154-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00155-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00156-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00157-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00158-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00159-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00160-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00161-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00162-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00163-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00164-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00165-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00166-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00167-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00168-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00169-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00170-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00171-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00172-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00173-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00174-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00175-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00176-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00177-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00178-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00179-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00180-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00181-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00182-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00183-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00184-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00185-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00186-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00187-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00188-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00189-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00190-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00191-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00192-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00193-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00194-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00195-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00196-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00197-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00198-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00199-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00200-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00201-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00202-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00203-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00204-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00205-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00206-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00207-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00208-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00209-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00210-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00211-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00212-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00213-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00214-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00215-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00216-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00217-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00218-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00219-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00220-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00221-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00222-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00223-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00224-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00225-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00226-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00227-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00228-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00229-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00230-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00231-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00232-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00233-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00234-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00235-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00236-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00237-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00238-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00239-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00240-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00241-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00242-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model-00243-of-00243.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "tokenizer_config.json.1"
        }
      ]
    }
  },
  {
    "_id": "650a504ef99720fea14ea249",
    "id": "TheBloke/Chronoboros-33B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Chronoboros-33B-GGUF",
    "model": {
      "_id": "650a504ef99720fea14ea249",
      "id": "TheBloke/Chronoboros-33B-GGUF",
      "modelId": "TheBloke/Chronoboros-33B-GGUF",
      "author": "TheBloke",
      "sha": "fc1e7d7fd7132b707dd899566c4f2e9904e637f2",
      "lastModified": "2023-09-27T12:53:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Chronoboros 33B",
        "base_model": "Henk717/chronoboros-33B",
        "inference": false,
        "model_creator": "Henky!!",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "chronoboros-33b.Q2_K.gguf"
        },
        {
          "rfilename": "chronoboros-33b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronoboros-33b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronoboros-33b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronoboros-33b.Q4_0.gguf"
        },
        {
          "rfilename": "chronoboros-33b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronoboros-33b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronoboros-33b.Q5_0.gguf"
        },
        {
          "rfilename": "chronoboros-33b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronoboros-33b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronoboros-33b.Q6_K.gguf"
        },
        {
          "rfilename": "chronoboros-33b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64ab1fd904e7b379fede4df6",
      "id": "Henk717/chronoboros-33B",
      "modelId": "Henk717/chronoboros-33B",
      "author": "Henk717",
      "sha": "a4deca117c5fa48f2cdc49ed2e2596046201d688",
      "lastModified": "2023-07-10T20:48:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4879,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a50a3f99720fea14eabaf",
    "id": "TheBloke/wizard-vicuna-13B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 11,
    "tags": [
      "transformers",
      "llama",
      "causal-lm",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/wizard-vicuna-13B-GGUF",
    "model": {
      "_id": "650a50a3f99720fea14eabaf",
      "id": "TheBloke/wizard-vicuna-13B-GGUF",
      "modelId": "TheBloke/wizard-vicuna-13B-GGUF",
      "author": "TheBloke",
      "sha": "db9115cf70873c7ee4787c8989c221b4160da691",
      "lastModified": "2023-09-27T12:53:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "causal-lm",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 11,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "causal-lm",
          "llama"
        ],
        "model_name": "Wizard Vicuna 13B",
        "base_model": "junelee/wizard-vicuna-13b",
        "inference": false,
        "model_creator": "junelee",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "wizard-vicuna-13b.Q2_K.gguf"
        },
        {
          "rfilename": "wizard-vicuna-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "wizard-vicuna-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "wizard-vicuna-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "wizard-vicuna-13b.Q4_0.gguf"
        },
        {
          "rfilename": "wizard-vicuna-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "wizard-vicuna-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "wizard-vicuna-13b.Q5_0.gguf"
        },
        {
          "rfilename": "wizard-vicuna-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "wizard-vicuna-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "wizard-vicuna-13b.Q6_K.gguf"
        },
        {
          "rfilename": "wizard-vicuna-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6452c820a0c0a664a24a2725",
      "id": "junelee/wizard-vicuna-13b",
      "modelId": "junelee/wizard-vicuna-13b",
      "author": "junelee",
      "sha": "419dc5acc391de54a60d0b041e94e767d1ef2032",
      "lastModified": "2023-05-04T01:23:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4656,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 70,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "h2oai/h2ogpt-chatbot",
        "h2oai/h2ogpt-chatbot2",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "cryddd/junelee-wizard-vicuna-13b",
        "gordonchan/h2oo",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "LordBon/junelee-wizard-vicuna-13b",
        "eliasj36/junelee-wizard-vicuna-13b",
        "AlexLee1235/junelee-wizard-vicuna-13b",
        "Raricythine/junelee-wizard-vicuna-13b",
        "elitecode/h2ogpt-chatbot2",
        "akashkj/H2OGPT",
        "ariel0330/h2osiri",
        "henryezell/junelee-wizard-vicuna-13b",
        "ccoreilly/aigua-xat",
        "hossamdaoud/Falcon40b_GSB",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "AnonymousSub/Ayurveda_Chatbot",
        "TheVortexProject/open_llm_leaderboard",
        "kelvin-t-lu/chatbot",
        "Gh6st66/junelee-wizard-vicuna-13b",
        "choco9966/open-ko-llm-leaderboard",
        "his0/h2ogpt-chatbot",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "650a50aef36bb51c50395453",
    "id": "TheBloke/airochronos-33B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airochronos-33B-GGUF",
    "model": {
      "_id": "650a50aef36bb51c50395453",
      "id": "TheBloke/airochronos-33B-GGUF",
      "modelId": "TheBloke/airochronos-33B-GGUF",
      "author": "TheBloke",
      "sha": "b76e02bd24fd1c56be27d5b6e8e553344a9c00fb",
      "lastModified": "2023-09-27T12:53:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Airochronos 33B",
        "base_model": "Henk717/airochronos-33B",
        "inference": false,
        "model_creator": "Henky!!",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "airochronos-33b.Q2_K.gguf"
        },
        {
          "rfilename": "airochronos-33b.Q3_K_L.gguf"
        },
        {
          "rfilename": "airochronos-33b.Q3_K_M.gguf"
        },
        {
          "rfilename": "airochronos-33b.Q3_K_S.gguf"
        },
        {
          "rfilename": "airochronos-33b.Q4_0.gguf"
        },
        {
          "rfilename": "airochronos-33b.Q4_K_M.gguf"
        },
        {
          "rfilename": "airochronos-33b.Q4_K_S.gguf"
        },
        {
          "rfilename": "airochronos-33b.Q5_0.gguf"
        },
        {
          "rfilename": "airochronos-33b.Q5_K_M.gguf"
        },
        {
          "rfilename": "airochronos-33b.Q5_K_S.gguf"
        },
        {
          "rfilename": "airochronos-33b.Q6_K.gguf"
        },
        {
          "rfilename": "airochronos-33b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64abd3875a69e2ca88d64c4c",
      "id": "Henk717/airochronos-33B",
      "modelId": "Henk717/airochronos-33B",
      "author": "Henk717",
      "sha": "06843c6693cc265dabb464c818a3d3713239721a",
      "lastModified": "2023-07-28T22:11:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4907,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F32": 3840,
          "F16": 32528943616
        },
        "total": 32528947456
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00007.safetensors"
        },
        {
          "rfilename": "model-00002-of-00007.safetensors"
        },
        {
          "rfilename": "model-00003-of-00007.safetensors"
        },
        {
          "rfilename": "model-00004-of-00007.safetensors"
        },
        {
          "rfilename": "model-00005-of-00007.safetensors"
        },
        {
          "rfilename": "model-00006-of-00007.safetensors"
        },
        {
          "rfilename": "model-00007-of-00007.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a51bb6fb511ba9ea5ab99",
    "id": "TheBloke/Vicuna-13B-CoT-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:1910.09700",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Vicuna-13B-CoT-GGUF",
    "model": {
      "_id": "650a51bb6fb511ba9ea5ab99",
      "id": "TheBloke/Vicuna-13B-CoT-GGUF",
      "modelId": "TheBloke/Vicuna-13B-CoT-GGUF",
      "author": "TheBloke",
      "sha": "1c3307580135855a307b65e4e64e7aa152b5e294",
      "lastModified": "2023-09-27T12:53:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:1910.09700",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Vicuna 13B CoT",
        "base_model": "kevinpro/Vicuna-13B-CoT",
        "inference": false,
        "model_creator": "Shuaijie She",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "Vicuna-13B-CoT.Q2_K.gguf"
        },
        {
          "rfilename": "Vicuna-13B-CoT.Q3_K_L.gguf"
        },
        {
          "rfilename": "Vicuna-13B-CoT.Q3_K_M.gguf"
        },
        {
          "rfilename": "Vicuna-13B-CoT.Q3_K_S.gguf"
        },
        {
          "rfilename": "Vicuna-13B-CoT.Q4_0.gguf"
        },
        {
          "rfilename": "Vicuna-13B-CoT.Q4_K_M.gguf"
        },
        {
          "rfilename": "Vicuna-13B-CoT.Q4_K_S.gguf"
        },
        {
          "rfilename": "Vicuna-13B-CoT.Q5_0.gguf"
        },
        {
          "rfilename": "Vicuna-13B-CoT.Q5_K_M.gguf"
        },
        {
          "rfilename": "Vicuna-13B-CoT.Q5_K_S.gguf"
        },
        {
          "rfilename": "Vicuna-13B-CoT.Q6_K.gguf"
        },
        {
          "rfilename": "Vicuna-13B-CoT.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64780c9604aa03da2aca3fa9",
      "id": "kevinpro/Vicuna-13B-CoT",
      "modelId": "kevinpro/Vicuna-13B-CoT",
      "author": "kevinpro",
      "sha": "346e3c46959cf9f1e03feffa761afe020c0fb6a8",
      "lastModified": "2023-06-04T08:05:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "en",
        "dataset:QingyiSi/Alpaca-CoT",
        "arxiv:1910.09700",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4488,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "QingyiSi/Alpaca-CoT"
        ],
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "code"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/adapter_config.json"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/adapter_model.bin"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1036/adapter_config.json"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1036/adapter_model.bin"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1036/optimizer.pt"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1036/pytorch_model.bin"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1036/rng_state_0.pth"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1036/rng_state_1.pth"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1036/rng_state_2.pth"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1036/rng_state_3.pth"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1036/scaler.pt"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1036/scheduler.pt"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1036/trainer_state.json"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1036/training_args.bin"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1498/adapter_config.json"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1498/adapter_model.bin"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1498/optimizer.pt"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1498/pytorch_model.bin"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1498/rng_state_0.pth"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1498/rng_state_1.pth"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1498/rng_state_2.pth"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1498/rng_state_3.pth"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1498/scaler.pt"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1498/scheduler.pt"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1498/trainer_state.json"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1498/training_args.bin"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1505/adapter_config.json"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1505/adapter_model.bin"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1505/optimizer.pt"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1505/pytorch_model.bin"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1505/rng_state_0.pth"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1505/rng_state_1.pth"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1505/rng_state_2.pth"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1505/rng_state_3.pth"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1505/scaler.pt"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1505/scheduler.pt"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1505/trainer_state.json"
        },
        {
          "rfilename": "vicuna-13b_english-cot+auto-cot_0.0002/lora/checkpoint-1505/training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "650a5339e0850b3ff055c675",
    "id": "TheBloke/Vicuna-7B-CoT-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 7,
    "tags": [
      "transformers",
      "llama",
      "arxiv:1910.09700",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Vicuna-7B-CoT-GGUF",
    "model": {
      "_id": "650a5339e0850b3ff055c675",
      "id": "TheBloke/Vicuna-7B-CoT-GGUF",
      "modelId": "TheBloke/Vicuna-7B-CoT-GGUF",
      "author": "TheBloke",
      "sha": "c260d4a97b732cf7d95b1d419cd9479369bbdf46",
      "lastModified": "2023-09-27T12:53:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:1910.09700",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Vicuna 7B CoT",
        "base_model": "kevinpro/Vicuna-7B-CoT",
        "inference": false,
        "model_creator": "Shuaijie She",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "vicuna-7b-cot.Q2_K.gguf"
        },
        {
          "rfilename": "vicuna-7b-cot.Q3_K_L.gguf"
        },
        {
          "rfilename": "vicuna-7b-cot.Q3_K_M.gguf"
        },
        {
          "rfilename": "vicuna-7b-cot.Q3_K_S.gguf"
        },
        {
          "rfilename": "vicuna-7b-cot.Q4_0.gguf"
        },
        {
          "rfilename": "vicuna-7b-cot.Q4_K_M.gguf"
        },
        {
          "rfilename": "vicuna-7b-cot.Q4_K_S.gguf"
        },
        {
          "rfilename": "vicuna-7b-cot.Q5_0.gguf"
        },
        {
          "rfilename": "vicuna-7b-cot.Q5_K_M.gguf"
        },
        {
          "rfilename": "vicuna-7b-cot.Q5_K_S.gguf"
        },
        {
          "rfilename": "vicuna-7b-cot.Q6_K.gguf"
        },
        {
          "rfilename": "vicuna-7b-cot.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64788b971f9756aa89d0e6f5",
      "id": "kevinpro/Vicuna-7B-CoT",
      "modelId": "kevinpro/Vicuna-7B-CoT",
      "author": "kevinpro",
      "sha": "7951880e70f555c500eb60cf56eea4539a572e05",
      "lastModified": "2023-06-04T08:04:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:1910.09700",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {},
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-723/adapter_config.json"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-723/adapter_model.bin"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-723/optimizer.pt"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-723/pytorch_model.bin"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-723/rng_state_0.pth"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-723/rng_state_1.pth"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-723/rng_state_2.pth"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-723/rng_state_3.pth"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-723/scaler.pt"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-723/scheduler.pt"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-723/trainer_state.json"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-723/training_args.bin"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-738/adapter_config.json"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-738/adapter_model.bin"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-738/optimizer.pt"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-738/pytorch_model.bin"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-738/rng_state_0.pth"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-738/rng_state_1.pth"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-738/rng_state_2.pth"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-738/rng_state_3.pth"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-738/scaler.pt"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-738/scheduler.pt"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-738/trainer_state.json"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-738/training_args.bin"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/adapter_config.json"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/adapter_model.bin"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/optimizer.pt"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/pytorch_model.bin"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/rng_state_0.pth"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/rng_state_1.pth"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/rng_state_2.pth"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/rng_state_3.pth"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/scaler.pt"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/scheduler.pt"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/tokenizer.model"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/tokenizer_config.json"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/trainer_state.json"
        },
        {
          "rfilename": "vicuna-7b_english-cot+auto-cot_0.0002/lora/checkpoint-741/training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "650a56cc905c78a96a5717b3",
    "id": "TheBloke/LLaMA-13b-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/LLaMA-13b-GGUF",
    "model": {
      "_id": "650a56cc905c78a96a5717b3",
      "id": "TheBloke/LLaMA-13b-GGUF",
      "modelId": "TheBloke/LLaMA-13b-GGUF",
      "author": "TheBloke",
      "sha": "0c8bafec64579d6e550b60fea72f3277e23a97ab",
      "lastModified": "2023-09-20T09:03:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "https://ai.meta.com/blog/large-language-model-llama-meta-ai",
        "inference": false,
        "license": "other",
        "model_creator": "Meta",
        "model_name": "LLaMA 13B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-13b.Q2_K.gguf"
        },
        {
          "rfilename": "llama-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-13b.Q4_0.gguf"
        },
        {
          "rfilename": "llama-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-13b.Q5_0.gguf"
        },
        {
          "rfilename": "llama-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-13b.Q6_K.gguf"
        },
        {
          "rfilename": "llama-13b.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "650a57252257a3afbafc27e2",
    "id": "TheBloke/medalpaca-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "medical",
      "text-generation",
      "en",
      "arxiv:2303.14070",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/medalpaca-13B-GGUF",
    "model": {
      "_id": "650a57252257a3afbafc27e2",
      "id": "TheBloke/medalpaca-13B-GGUF",
      "modelId": "TheBloke/medalpaca-13B-GGUF",
      "author": "TheBloke",
      "sha": "d1e1afc5cb7fc3c669f4b6c42d85e94954b31c7e",
      "lastModified": "2023-09-27T12:53:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "medical",
        "text-generation",
        "en",
        "arxiv:2303.14070",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "library_name": "transformers",
        "tags": [
          "medical"
        ],
        "model_name": "Medalpaca 13B",
        "base_model": "medalpaca/medalpaca-13b",
        "inference": false,
        "model_creator": "medalpaca",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "medalpaca-13b.Q2_K.gguf"
        },
        {
          "rfilename": "medalpaca-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "medalpaca-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "medalpaca-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "medalpaca-13b.Q4_0.gguf"
        },
        {
          "rfilename": "medalpaca-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "medalpaca-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "medalpaca-13b.Q5_0.gguf"
        },
        {
          "rfilename": "medalpaca-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "medalpaca-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "medalpaca-13b.Q6_K.gguf"
        },
        {
          "rfilename": "medalpaca-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "642591e9d9896a8a0b88850f",
      "id": "medalpaca/medalpaca-13b",
      "modelId": "medalpaca/medalpaca-13b",
      "author": "medalpaca",
      "sha": "3e5d80d26b0373167ab2daed45b7f9ef35f998e5",
      "lastModified": "2023-07-18T21:54:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "medical",
        "en",
        "arxiv:2303.14070",
        "license:cc",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 898,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 60,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc",
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "medical"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "msmilauer/medalpaca-medalpaca-13b",
        "btlee215/medalpaca-medalpaca-13b",
        "sidmanale643/dr.ai",
        "sidmanale643/medalpaca-medalpaca-13b",
        "Chris4K/medalpaca-medalpaca-13b",
        "mschetel/medalpaca-medalpaca-13b",
        "Reynold97/medalpaca-medalpaca-13b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "optimizer.pt"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "rng_state_0.pth"
        },
        {
          "rfilename": "rng_state_1.pth"
        },
        {
          "rfilename": "rng_state_2.pth"
        },
        {
          "rfilename": "rng_state_3.pth"
        },
        {
          "rfilename": "rng_state_4.pth"
        },
        {
          "rfilename": "rng_state_5.pth"
        },
        {
          "rfilename": "rng_state_6.pth"
        },
        {
          "rfilename": "rng_state_7.pth"
        },
        {
          "rfilename": "scheduler.pt"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "650a575b634e02df56d63627",
    "id": "TheBloke/GPlatty-30B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/GPlatty-30B-GGUF",
    "model": {
      "_id": "650a575b634e02df56d63627",
      "id": "TheBloke/GPlatty-30B-GGUF",
      "modelId": "TheBloke/GPlatty-30B-GGUF",
      "author": "TheBloke",
      "sha": "601c364f6503daaac2b536e094747966baac023a",
      "lastModified": "2023-09-27T12:53:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "llama"
        ],
        "metrics": [
          "MMLU",
          "ARC",
          "HellaSwag",
          "TruthfulQA"
        ],
        "model_name": "Gplatty 30B",
        "base_model": "lilloukas/GPlatty-30B",
        "inference": false,
        "model_creator": "lilloukas",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "gplatty-30b.Q2_K.gguf"
        },
        {
          "rfilename": "gplatty-30b.Q3_K_L.gguf"
        },
        {
          "rfilename": "gplatty-30b.Q3_K_M.gguf"
        },
        {
          "rfilename": "gplatty-30b.Q3_K_S.gguf"
        },
        {
          "rfilename": "gplatty-30b.Q4_0.gguf"
        },
        {
          "rfilename": "gplatty-30b.Q4_K_M.gguf"
        },
        {
          "rfilename": "gplatty-30b.Q4_K_S.gguf"
        },
        {
          "rfilename": "gplatty-30b.Q5_0.gguf"
        },
        {
          "rfilename": "gplatty-30b.Q5_K_M.gguf"
        },
        {
          "rfilename": "gplatty-30b.Q5_K_S.gguf"
        },
        {
          "rfilename": "gplatty-30b.Q6_K.gguf"
        },
        {
          "rfilename": "gplatty-30b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "649bcd4f90f69047f5858f57",
      "id": "garage-bAInd/GPlatty-30B",
      "modelId": "garage-bAInd/GPlatty-30B",
      "author": "garage-bAInd",
      "sha": "a06dc5e381f2987749f0a559ffcaf44401df2239",
      "lastModified": "2023-07-25T19:07:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4700,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 18,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "tags": [
          "llama"
        ],
        "license": "other",
        "metrics": [
          "MMLU",
          "ARC",
          "HellaSwag",
          "TruthfulQA"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Aashir01/garage-bAInd-GPlatty-30B"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a57ab69739cd31041d642",
    "id": "TheBloke/Platypus-30B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Platypus-30B-GGUF",
    "model": {
      "_id": "650a57ab69739cd31041d642",
      "id": "TheBloke/Platypus-30B-GGUF",
      "modelId": "TheBloke/Platypus-30B-GGUF",
      "author": "TheBloke",
      "sha": "88e964d01205dc64fa827bf65fa394c34fa268ef",
      "lastModified": "2023-09-27T12:53:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "tags": [
          "llama"
        ],
        "metrics": [
          "MMLU",
          "ARC",
          "HellaSwag",
          "TruthfulQA"
        ],
        "model_name": "Platypus 30B",
        "base_model": "lilloukas/Platypus-30B",
        "inference": false,
        "model_creator": "lilloukas",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "platypus-30b.Q2_K.gguf"
        },
        {
          "rfilename": "platypus-30b.Q3_K_L.gguf"
        },
        {
          "rfilename": "platypus-30b.Q3_K_M.gguf"
        },
        {
          "rfilename": "platypus-30b.Q3_K_S.gguf"
        },
        {
          "rfilename": "platypus-30b.Q4_0.gguf"
        },
        {
          "rfilename": "platypus-30b.Q4_K_M.gguf"
        },
        {
          "rfilename": "platypus-30b.Q4_K_S.gguf"
        },
        {
          "rfilename": "platypus-30b.Q5_0.gguf"
        },
        {
          "rfilename": "platypus-30b.Q5_K_M.gguf"
        },
        {
          "rfilename": "platypus-30b.Q5_K_S.gguf"
        },
        {
          "rfilename": "platypus-30b.Q6_K.gguf"
        },
        {
          "rfilename": "platypus-30b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6490e21ea728a392348aeeff",
      "id": "garage-bAInd/Platypus-30B",
      "modelId": "garage-bAInd/Platypus-30B",
      "author": "garage-bAInd",
      "sha": "c5d21054f8dd71099696bd7790df07ac54990f29",
      "lastModified": "2023-07-25T02:35:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9068,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 16,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "tags": [
          "llama"
        ],
        "license": "other",
        "metrics": [
          "MMLU",
          "ARC",
          "HellaSwag",
          "TruthfulQA"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00023.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a581dc2d4c8fc37b710ba",
    "id": "TheBloke/LLaMA-30b-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/LLaMA-30b-GGUF",
    "model": {
      "_id": "650a581dc2d4c8fc37b710ba",
      "id": "TheBloke/LLaMA-30b-GGUF",
      "modelId": "TheBloke/LLaMA-30b-GGUF",
      "author": "TheBloke",
      "sha": "fd6b601605410a7f132d98209a365ae695f1bc40",
      "lastModified": "2023-09-20T09:03:32.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "https://ai.meta.com/blog/large-language-model-llama-meta-ai",
        "inference": false,
        "license": "other",
        "model_creator": "Meta",
        "model_name": "LLaMA 33B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-30b.Q2_K.gguf"
        },
        {
          "rfilename": "llama-30b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-30b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-30b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-30b.Q4_0.gguf"
        },
        {
          "rfilename": "llama-30b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-30b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-30b.Q5_0.gguf"
        },
        {
          "rfilename": "llama-30b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-30b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-30b.Q6_K.gguf"
        },
        {
          "rfilename": "llama-30b.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "650a58896fb511ba9ea685ef",
    "id": "TheBloke/LLaMA-7b-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 59,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/LLaMA-7b-GGUF",
    "model": {
      "_id": "650a58896fb511ba9ea685ef",
      "id": "TheBloke/LLaMA-7b-GGUF",
      "modelId": "TheBloke/LLaMA-7b-GGUF",
      "author": "TheBloke",
      "sha": "0a1200190c8c1baafaa0b496c599ba68ad3d4056",
      "lastModified": "2023-09-20T09:03:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 59,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "https://ai.meta.com/blog/large-language-model-llama-meta-ai",
        "inference": false,
        "license": "other",
        "model_creator": "Meta",
        "model_name": "LLaMA 7B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-7b.Q2_K.gguf"
        },
        {
          "rfilename": "llama-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-7b.Q4_0.gguf"
        },
        {
          "rfilename": "llama-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-7b.Q5_0.gguf"
        },
        {
          "rfilename": "llama-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-7b.Q6_K.gguf"
        },
        {
          "rfilename": "llama-7b.Q8_0.gguf"
        }
      ]
    }
  },
  {
    "_id": "650a592e19f6f953cb501ed2",
    "id": "TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF",
    "likes": 11,
    "private": false,
    "downloads": 10,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF",
    "model": {
      "_id": "650a592e19f6f953cb501ed2",
      "id": "TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF",
      "modelId": "TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGUF",
      "author": "TheBloke",
      "sha": "0972169e2a22740ec26a2698443e2d8141703b61",
      "lastModified": "2023-09-27T12:53:32.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "likes": 11,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "WizardLM Uncensored SuperCOT Storytelling 30B",
        "base_model": "Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b",
        "inference": false,
        "model_creator": "YellowRoseCx",
        "model_type": "llama",
        "prompt_template": "You are a helpful AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "WizardLM-Uncensored-SuperCOT-Storytelling.Q2_K.gguf"
        },
        {
          "rfilename": "WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_L.gguf"
        },
        {
          "rfilename": "WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_M.gguf"
        },
        {
          "rfilename": "WizardLM-Uncensored-SuperCOT-Storytelling.Q3_K_S.gguf"
        },
        {
          "rfilename": "WizardLM-Uncensored-SuperCOT-Storytelling.Q4_0.gguf"
        },
        {
          "rfilename": "WizardLM-Uncensored-SuperCOT-Storytelling.Q4_K_M.gguf"
        },
        {
          "rfilename": "WizardLM-Uncensored-SuperCOT-Storytelling.Q4_K_S.gguf"
        },
        {
          "rfilename": "WizardLM-Uncensored-SuperCOT-Storytelling.Q5_0.gguf"
        },
        {
          "rfilename": "WizardLM-Uncensored-SuperCOT-Storytelling.Q5_K_M.gguf"
        },
        {
          "rfilename": "WizardLM-Uncensored-SuperCOT-Storytelling.Q5_K_S.gguf"
        },
        {
          "rfilename": "WizardLM-Uncensored-SuperCOT-Storytelling.Q6_K.gguf"
        },
        {
          "rfilename": "WizardLM-Uncensored-SuperCOT-Storytelling.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6476b6ab0214fec3e76cae88",
      "id": "Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b",
      "modelId": "Monero/WizardLM-Uncensored-SuperCOT-StoryTelling-30b",
      "author": "Monero",
      "sha": "e58bafedf660477c206ad64f3118a571951bb28e",
      "lastModified": "2023-05-31T05:57:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4700,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 32,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Slammed96/Monero-WizardLM-Uncensored-SuperCOT-StoryTelling-30bb",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00017.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        },
        {
          "rfilename": "zero_to_fp32.py"
        }
      ]
    }
  },
  {
    "_id": "650a5967cc02352e1e38d90b",
    "id": "TheBloke/ARIA-70B-V2-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "code",
      "text-generation-inference",
      "Meta ",
      "facebook",
      "pytorch",
      "openassistant",
      "data",
      "education",
      "languages",
      "text-generation",
      "fr",
      "en",
      "arxiv:2307.09288",
      "license:llama2",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/ARIA-70B-V2-GGUF",
    "model": {
      "_id": "650a5967cc02352e1e38d90b",
      "id": "TheBloke/ARIA-70B-V2-GGUF",
      "modelId": "TheBloke/ARIA-70B-V2-GGUF",
      "author": "TheBloke",
      "sha": "369616ebd9a32f8ce7b741f4f5cc1e9cdb6c717d",
      "lastModified": "2023-09-27T12:53:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "code",
        "text-generation-inference",
        "Meta ",
        "facebook",
        "pytorch",
        "openassistant",
        "data",
        "education",
        "languages",
        "text-generation",
        "fr",
        "en",
        "arxiv:2307.09288",
        "license:llama2",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Mon nom est Julien et j'aime"
        },
        {
          "text": "Mon nom est Thomas et mon principal"
        },
        {
          "text": "Il tait une fois"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "fr",
          "en"
        ],
        "license": "llama2",
        "tags": [
          "code",
          "text-generation-inference",
          "Meta ",
          "llama",
          "facebook",
          "pytorch",
          "openassistant",
          "data",
          "education",
          "languages"
        ],
        "model_name": "ARIA 70B V2",
        "base_model": "Faradaylab/ARIA-70B-V2",
        "inference": false,
        "model_creator": "Faradaylab",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n{prompt}[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "aria-70b-v2.Q2_K.gguf"
        },
        {
          "rfilename": "aria-70b-v2.Q3_K_L.gguf"
        },
        {
          "rfilename": "aria-70b-v2.Q3_K_M.gguf"
        },
        {
          "rfilename": "aria-70b-v2.Q3_K_S.gguf"
        },
        {
          "rfilename": "aria-70b-v2.Q4_0.gguf"
        },
        {
          "rfilename": "aria-70b-v2.Q4_K_M.gguf"
        },
        {
          "rfilename": "aria-70b-v2.Q4_K_S.gguf"
        },
        {
          "rfilename": "aria-70b-v2.Q5_0.gguf"
        },
        {
          "rfilename": "aria-70b-v2.Q5_K_M.gguf"
        },
        {
          "rfilename": "aria-70b-v2.Q5_K_S.gguf"
        },
        {
          "rfilename": "aria-70b-v2.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "aria-70b-v2.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "aria-70b-v2.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "aria-70b-v2.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "64fb5a3527fb3a92e9c7ff1e",
      "id": "Faradaylab/ARIA-70B-V2",
      "modelId": "Faradaylab/ARIA-70B-V2",
      "author": "Faradaylab",
      "sha": "0acd6b01b129995edfcd5be8dc08962421987337",
      "lastModified": "2023-10-10T14:02:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "text-generation-inference",
        "Meta ",
        "facebook",
        "openassistant",
        "data",
        "education",
        "languages",
        "legal",
        "fr",
        "en",
        "arxiv:2307.09288",
        "license:llama2",
        "endpoints_compatible",
        "region:us"
      ],
      "downloads": 4391,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Mon nom est Julien et j'aime"
        },
        {
          "text": "Mon nom est Thomas et mon principal"
        },
        {
          "text": "Il tait une fois"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "fr",
          "en"
        ],
        "tags": [
          "code",
          "text-generation-inference",
          "Meta ",
          "llama",
          "facebook",
          "pytorch",
          "openassistant",
          "data",
          "education",
          "languages",
          "legal"
        ],
        "pipeline_tag": "text-generation",
        "inference": true
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a597af37afbab0d5f704a",
    "id": "TheBloke/VicUnlocked-30B-LoRA-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:gozfarb/ShareGPT_Vicuna_unfiltered",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/VicUnlocked-30B-LoRA-GGUF",
    "model": {
      "_id": "650a597af37afbab0d5f704a",
      "id": "TheBloke/VicUnlocked-30B-LoRA-GGUF",
      "modelId": "TheBloke/VicUnlocked-30B-LoRA-GGUF",
      "author": "TheBloke",
      "sha": "f70bcd20420294b259b8d94ef1b31bc1dd6f8204",
      "lastModified": "2023-09-27T12:53:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:gozfarb/ShareGPT_Vicuna_unfiltered",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "gozfarb/ShareGPT_Vicuna_unfiltered"
        ],
        "model_name": "Vicunlocked 30B Lora",
        "base_model": "Neko-Institute-of-Science/VicUnLocked-30b-LoRA",
        "inference": false,
        "model_creator": "Bonanza Unthread",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "VicUnlocked-30B.Q2_K.gguf"
        },
        {
          "rfilename": "VicUnlocked-30B.Q3_K_L.gguf"
        },
        {
          "rfilename": "VicUnlocked-30B.Q3_K_M.gguf"
        },
        {
          "rfilename": "VicUnlocked-30B.Q3_K_S.gguf"
        },
        {
          "rfilename": "VicUnlocked-30B.Q4_0.gguf"
        },
        {
          "rfilename": "VicUnlocked-30B.Q4_K_M.gguf"
        },
        {
          "rfilename": "VicUnlocked-30B.Q4_K_S.gguf"
        },
        {
          "rfilename": "VicUnlocked-30B.Q5_0.gguf"
        },
        {
          "rfilename": "VicUnlocked-30B.Q5_K_M.gguf"
        },
        {
          "rfilename": "VicUnlocked-30B.Q5_K_S.gguf"
        },
        {
          "rfilename": "VicUnlocked-30B.Q6_K.gguf"
        },
        {
          "rfilename": "VicUnlocked-30B.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6459dc09232e5f0712c280dd",
      "id": "Neko-Institute-of-Science/VicUnLocked-30b-LoRA",
      "modelId": "Neko-Institute-of-Science/VicUnLocked-30b-LoRA",
      "author": "Neko-Institute-of-Science",
      "sha": "91e952bc5d87ab5c94ffb16bb5cd5de21eb54cb1",
      "lastModified": "2023-06-24T14:38:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "uncensored",
        "dataset:gozfarb/ShareGPT_Vicuna_unfiltered",
        "dataset:Aeala/ShareGPT_Vicuna_unfiltered",
        "region:us"
      ],
      "downloads": 0,
      "likes": 15,
      "model-index": null,
      "config": {},
      "cardData": {
        "datasets": [
          "gozfarb/ShareGPT_Vicuna_unfiltered",
          "Aeala/ShareGPT_Vicuna_unfiltered"
        ],
        "tags": [
          "uncensored"
        ]
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "adapter_config.json"
        },
        {
          "rfilename": "adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-14336/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-14336/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-21504/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-21504/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-29696/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-29696/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-3072/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-3072/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-39936/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-39936/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-46080/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-46080/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-5120/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-5120/adapter_model.bin"
        },
        {
          "rfilename": "checkpoint-8192/adapter_config.json"
        },
        {
          "rfilename": "checkpoint-8192/adapter_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "training_parameters.json"
        }
      ]
    }
  },
  {
    "_id": "650a59e6a2abcb18d65632dd",
    "id": "TheBloke/LLaMA-65B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/LLaMA-65B-GGUF",
    "model": {
      "_id": "650a59e6a2abcb18d65632dd",
      "id": "TheBloke/LLaMA-65B-GGUF",
      "modelId": "TheBloke/LLaMA-65B-GGUF",
      "author": "TheBloke",
      "sha": "d9a0975068487614aea45330bd051aadfc1e0ffd",
      "lastModified": "2023-09-20T09:03:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "https://ai.meta.com/blog/large-language-model-llama-meta-ai",
        "inference": false,
        "license": "other",
        "model_creator": "Meta",
        "model_name": "LLaMA 65B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-65b.Q2_K.gguf"
        },
        {
          "rfilename": "llama-65b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-65b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-65b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-65b.Q4_0.gguf"
        },
        {
          "rfilename": "llama-65b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-65b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-65b.Q5_0.gguf"
        },
        {
          "rfilename": "llama-65b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-65b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-65b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "llama-65b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "llama-65b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "llama-65b.Q8_0.gguf-split-b"
        }
      ]
    }
  },
  {
    "_id": "650a59e911afda55caee989e",
    "id": "TheBloke/hippogriff-30b-chat-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:QingyiSi/Alpaca-CoT",
      "dataset:teknium/GPT4-LLM-Cleaned",
      "dataset:teknium/GPTeacher-General-Instruct",
      "dataset:metaeval/ScienceQA_text_only",
      "dataset:hellaswag",
      "dataset:openai/summarize_from_feedback",
      "dataset:riddle_sense",
      "dataset:gsm8k",
      "dataset:OpenAssistant/oasst1",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/hippogriff-30b-chat-GGUF",
    "model": {
      "_id": "650a59e911afda55caee989e",
      "id": "TheBloke/hippogriff-30b-chat-GGUF",
      "modelId": "TheBloke/hippogriff-30b-chat-GGUF",
      "author": "TheBloke",
      "sha": "8383d4c4ca3998f6a753662cadc03580ad94963d",
      "lastModified": "2023-09-27T12:53:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:QingyiSi/Alpaca-CoT",
        "dataset:teknium/GPT4-LLM-Cleaned",
        "dataset:teknium/GPTeacher-General-Instruct",
        "dataset:metaeval/ScienceQA_text_only",
        "dataset:hellaswag",
        "dataset:openai/summarize_from_feedback",
        "dataset:riddle_sense",
        "dataset:gsm8k",
        "dataset:OpenAssistant/oasst1",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "library_name": "transformers",
        "datasets": [
          "QingyiSi/Alpaca-CoT",
          "teknium/GPT4-LLM-Cleaned",
          "teknium/GPTeacher-General-Instruct",
          "metaeval/ScienceQA_text_only",
          "hellaswag",
          "openai/summarize_from_feedback",
          "riddle_sense",
          "gsm8k",
          "OpenAssistant/oasst1"
        ],
        "model_name": "Hippogriff 30B Chat",
        "base_model": "openaccess-ai-collective/hippogriff-30b-chat",
        "inference": false,
        "model_creator": "Open Access AI Collective",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "hippogriff-30b.Q2_K.gguf"
        },
        {
          "rfilename": "hippogriff-30b.Q3_K_L.gguf"
        },
        {
          "rfilename": "hippogriff-30b.Q3_K_M.gguf"
        },
        {
          "rfilename": "hippogriff-30b.Q3_K_S.gguf"
        },
        {
          "rfilename": "hippogriff-30b.Q4_0.gguf"
        },
        {
          "rfilename": "hippogriff-30b.Q4_K_M.gguf"
        },
        {
          "rfilename": "hippogriff-30b.Q4_K_S.gguf"
        },
        {
          "rfilename": "hippogriff-30b.Q5_0.gguf"
        },
        {
          "rfilename": "hippogriff-30b.Q5_K_M.gguf"
        },
        {
          "rfilename": "hippogriff-30b.Q5_K_S.gguf"
        },
        {
          "rfilename": "hippogriff-30b.Q6_K.gguf"
        },
        {
          "rfilename": "hippogriff-30b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "646df96e9e252f776e3e4f30",
      "id": "openaccess-ai-collective/hippogriff-30b-chat",
      "modelId": "openaccess-ai-collective/hippogriff-30b-chat",
      "author": "openaccess-ai-collective",
      "sha": "64c10edf5312cd13704925b07413882d9e94c7a0",
      "lastModified": "2023-06-12T03:19:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:QingyiSi/Alpaca-CoT",
        "dataset:teknium/GPT4-LLM-Cleaned",
        "dataset:teknium/GPTeacher-General-Instruct",
        "dataset:metaeval/ScienceQA_text_only",
        "dataset:hellaswag",
        "dataset:openai/summarize_from_feedback",
        "dataset:riddle_sense",
        "dataset:gsm8k",
        "dataset:OpenAssistant/oasst1",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4546,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 21,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "QingyiSi/Alpaca-CoT",
          "teknium/GPT4-LLM-Cleaned",
          "teknium/GPTeacher-General-Instruct",
          "metaeval/ScienceQA_text_only",
          "hellaswag",
          "openai/summarize_from_feedback",
          "riddle_sense",
          "gsm8k",
          "OpenAssistant/oasst1"
        ],
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "b1sheng/kg_llm_leaderboard_test",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "axolotl-badge-web.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configs/hippogriff.yml"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a5a053449d9a49c2df045",
    "id": "TheBloke/manticore-13b-chat-pyg-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 15,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "dataset:anon8231489123/ShareGPT_Vicuna_unfiltered",
      "dataset:ehartford/wizard_vicuna_70k_unfiltered",
      "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
      "dataset:QingyiSi/Alpaca-CoT",
      "dataset:teknium/GPT4-LLM-Cleaned",
      "dataset:teknium/GPTeacher-General-Instruct",
      "dataset:metaeval/ScienceQA_text_only",
      "dataset:hellaswag",
      "dataset:openai/summarize_from_feedback",
      "dataset:riddle_sense",
      "dataset:gsm8k",
      "dataset:ewof/code-alpaca-instruct-unfiltered",
      "license:other",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/manticore-13b-chat-pyg-GGUF",
    "model": {
      "_id": "650a5a053449d9a49c2df045",
      "id": "TheBloke/manticore-13b-chat-pyg-GGUF",
      "modelId": "TheBloke/manticore-13b-chat-pyg-GGUF",
      "author": "TheBloke",
      "sha": "ff78a905378e9b7f0587a82376a42abd3560bd4c",
      "lastModified": "2023-09-27T12:53:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "dataset:anon8231489123/ShareGPT_Vicuna_unfiltered",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "dataset:QingyiSi/Alpaca-CoT",
        "dataset:teknium/GPT4-LLM-Cleaned",
        "dataset:teknium/GPTeacher-General-Instruct",
        "dataset:metaeval/ScienceQA_text_only",
        "dataset:hellaswag",
        "dataset:openai/summarize_from_feedback",
        "dataset:riddle_sense",
        "dataset:gsm8k",
        "dataset:ewof/code-alpaca-instruct-unfiltered",
        "license:other",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "library_name": "transformers",
        "datasets": [
          "anon8231489123/ShareGPT_Vicuna_unfiltered",
          "ehartford/wizard_vicuna_70k_unfiltered",
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
          "QingyiSi/Alpaca-CoT",
          "teknium/GPT4-LLM-Cleaned",
          "teknium/GPTeacher-General-Instruct",
          "metaeval/ScienceQA_text_only",
          "hellaswag",
          "openai/summarize_from_feedback",
          "riddle_sense",
          "gsm8k",
          "ewof/code-alpaca-instruct-unfiltered"
        ],
        "model_name": "Manticore 13B Chat Pyg",
        "base_model": "openaccess-ai-collective/manticore-13b-chat-pyg",
        "inference": false,
        "model_creator": "Open Access AI Collective",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "Cran-May/SEA-pyg"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "manticore-13b-chat-pyg.Q2_K.gguf"
        },
        {
          "rfilename": "manticore-13b-chat-pyg.Q3_K_L.gguf"
        },
        {
          "rfilename": "manticore-13b-chat-pyg.Q3_K_M.gguf"
        },
        {
          "rfilename": "manticore-13b-chat-pyg.Q3_K_S.gguf"
        },
        {
          "rfilename": "manticore-13b-chat-pyg.Q4_0.gguf"
        },
        {
          "rfilename": "manticore-13b-chat-pyg.Q4_K_M.gguf"
        },
        {
          "rfilename": "manticore-13b-chat-pyg.Q4_K_S.gguf"
        },
        {
          "rfilename": "manticore-13b-chat-pyg.Q5_0.gguf"
        },
        {
          "rfilename": "manticore-13b-chat-pyg.Q5_K_M.gguf"
        },
        {
          "rfilename": "manticore-13b-chat-pyg.Q5_K_S.gguf"
        },
        {
          "rfilename": "manticore-13b-chat-pyg.Q6_K.gguf"
        },
        {
          "rfilename": "manticore-13b-chat-pyg.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "646b96a5db697c798a41efbd",
      "id": "openaccess-ai-collective/manticore-13b-chat-pyg",
      "modelId": "openaccess-ai-collective/manticore-13b-chat-pyg",
      "author": "openaccess-ai-collective",
      "sha": "f9ef65a3cf50e3c09ccb443f99225148e08517aa",
      "lastModified": "2023-06-07T12:32:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "en",
        "dataset:anon8231489123/ShareGPT_Vicuna_unfiltered",
        "dataset:ehartford/wizard_vicuna_70k_unfiltered",
        "dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
        "dataset:QingyiSi/Alpaca-CoT",
        "dataset:teknium/GPT4-LLM-Cleaned",
        "dataset:teknium/GPTeacher-General-Instruct",
        "dataset:metaeval/ScienceQA_text_only",
        "dataset:hellaswag",
        "dataset:openai/summarize_from_feedback",
        "dataset:riddle_sense",
        "dataset:gsm8k",
        "dataset:ewof/code-alpaca-instruct-unfiltered",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4701,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 27,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "anon8231489123/ShareGPT_Vicuna_unfiltered",
          "ehartford/wizard_vicuna_70k_unfiltered",
          "ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered",
          "QingyiSi/Alpaca-CoT",
          "teknium/GPT4-LLM-Cleaned",
          "teknium/GPTeacher-General-Instruct",
          "metaeval/ScienceQA_text_only",
          "hellaswag",
          "openai/summarize_from_feedback",
          "riddle_sense",
          "gsm8k",
          "ewof/code-alpaca-instruct-unfiltered"
        ],
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "openaccess-ai-collective/manticore-13b-chat-pyg",
        "justest/vicuna-ggml",
        "b1sheng/kg_llm_leaderboard_test",
        "justest/vicuna-v1.3-ggml",
        "everton-santos/vicuna-ggml",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "Rupnil/AmeuChat-StudyBot-7B",
        "justest/chatglm2-ggml",
        "alexshengzhili/calahealthgpt",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "Cran-May/vicuna-v1.3-ggml",
        "TheVortexProject/open_llm_leaderboard",
        "choco9966/open-ko-llm-leaderboard",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F16": 13015866880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configs/manticore-13b-v2.yml"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a5c463f8a38f064a44dd4",
    "id": "TheBloke/tulu-30B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:databricks/databricks-dolly-15k",
      "dataset:OpenAssistant/oasst1",
      "dataset:sahil2801/CodeAlpaca-20k",
      "arxiv:2306.04751",
      "arxiv:2302.13971",
      "arxiv:2304.07327",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/tulu-30B-GGUF",
    "model": {
      "_id": "650a5c463f8a38f064a44dd4",
      "id": "TheBloke/tulu-30B-GGUF",
      "modelId": "TheBloke/tulu-30B-GGUF",
      "author": "TheBloke",
      "sha": "c95b903f0d48f96769ca5de2fa0287d5a1a75e1a",
      "lastModified": "2023-09-27T12:53:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:databricks/databricks-dolly-15k",
        "dataset:OpenAssistant/oasst1",
        "dataset:sahil2801/CodeAlpaca-20k",
        "arxiv:2306.04751",
        "arxiv:2302.13971",
        "arxiv:2304.07327",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "datasets": [
          "databricks/databricks-dolly-15k",
          "OpenAssistant/oasst1",
          "sahil2801/CodeAlpaca-20k"
        ],
        "model_name": "Tulu 30B",
        "base_model": "allenai/tulu-30b",
        "inference": false,
        "model_creator": "Allen Institute for AI",
        "model_type": "llama",
        "prompt_template": "<|user|>\n{prompt}\n<|assistant|>\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tulu-30b.Q2_K.gguf"
        },
        {
          "rfilename": "tulu-30b.Q3_K_L.gguf"
        },
        {
          "rfilename": "tulu-30b.Q3_K_M.gguf"
        },
        {
          "rfilename": "tulu-30b.Q3_K_S.gguf"
        },
        {
          "rfilename": "tulu-30b.Q4_0.gguf"
        },
        {
          "rfilename": "tulu-30b.Q4_K_M.gguf"
        },
        {
          "rfilename": "tulu-30b.Q4_K_S.gguf"
        },
        {
          "rfilename": "tulu-30b.Q5_0.gguf"
        },
        {
          "rfilename": "tulu-30b.Q5_K_M.gguf"
        },
        {
          "rfilename": "tulu-30b.Q5_K_S.gguf"
        },
        {
          "rfilename": "tulu-30b.Q6_K.gguf"
        },
        {
          "rfilename": "tulu-30b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6480c01940facadc5571904e",
      "id": "allenai/tulu-30b",
      "modelId": "allenai/tulu-30b",
      "author": "allenai",
      "sha": "24bbfc381ecd9e210b58ede7fa93e46a075f4c12",
      "lastModified": "2023-06-20T17:48:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:databricks/databricks-dolly-15k",
        "dataset:OpenAssistant/oasst1",
        "dataset:sahil2801/CodeAlpaca-20k",
        "arxiv:2306.04751",
        "arxiv:2302.13971",
        "arxiv:2304.07327",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 18,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "databricks/databricks-dolly-15k",
          "OpenAssistant/oasst1",
          "sahil2801/CodeAlpaca-20k"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "alexshengzhili/calahealthgpt"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "llama_license.txt"
        },
        {
          "rfilename": "pytorch_model-00001-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650a5c547b68c4a6f6969a97",
    "id": "TheBloke/tulu-7B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:databricks/databricks-dolly-15k",
      "dataset:OpenAssistant/oasst1",
      "dataset:sahil2801/CodeAlpaca-20k",
      "arxiv:2306.04751",
      "arxiv:2302.13971",
      "arxiv:2304.07327",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/tulu-7B-GGUF",
    "model": {
      "_id": "650a5c547b68c4a6f6969a97",
      "id": "TheBloke/tulu-7B-GGUF",
      "modelId": "TheBloke/tulu-7B-GGUF",
      "author": "TheBloke",
      "sha": "b06858a7c055df766cf81b88636fae0c80f8eae6",
      "lastModified": "2023-09-27T12:53:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:databricks/databricks-dolly-15k",
        "dataset:OpenAssistant/oasst1",
        "dataset:sahil2801/CodeAlpaca-20k",
        "arxiv:2306.04751",
        "arxiv:2302.13971",
        "arxiv:2304.07327",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "datasets": [
          "databricks/databricks-dolly-15k",
          "OpenAssistant/oasst1",
          "sahil2801/CodeAlpaca-20k"
        ],
        "model_name": "Tulu 7B",
        "base_model": "allenai/tulu-7b",
        "inference": false,
        "model_creator": "Allen Institute for AI",
        "model_type": "llama",
        "prompt_template": "<|user|>\n{prompt}\n<|assistant|>\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tulu-7b.Q2_K.gguf"
        },
        {
          "rfilename": "tulu-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "tulu-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "tulu-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "tulu-7b.Q4_0.gguf"
        },
        {
          "rfilename": "tulu-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "tulu-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "tulu-7b.Q5_0.gguf"
        },
        {
          "rfilename": "tulu-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "tulu-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "tulu-7b.Q6_K.gguf"
        },
        {
          "rfilename": "tulu-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6480b9039aafd41918ac28d0",
      "id": "allenai/tulu-7b",
      "modelId": "allenai/tulu-7b",
      "author": "allenai",
      "sha": "8266d1c8ccc7d2eec6ae6900ac634400c96b8f2c",
      "lastModified": "2023-06-20T17:47:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:databricks/databricks-dolly-15k",
        "dataset:OpenAssistant/oasst1",
        "dataset:sahil2801/CodeAlpaca-20k",
        "arxiv:2306.04751",
        "arxiv:2302.13971",
        "arxiv:2304.07327",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 27,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "databricks/databricks-dolly-15k",
          "OpenAssistant/oasst1",
          "sahil2801/CodeAlpaca-20k"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Sharathhebbar24/One-stop-for-Open-source-models"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "llama_license.txt"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650b5c6eaa87a69ea38a702e",
    "id": "TheBloke/Xwin-LM-13B-V0.1-GGUF",
    "likes": 22,
    "private": false,
    "downloads": 61,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Xwin-LM-13B-V0.1-GGUF",
    "model": {
      "_id": "650b5c6eaa87a69ea38a702e",
      "id": "TheBloke/Xwin-LM-13B-V0.1-GGUF",
      "modelId": "TheBloke/Xwin-LM-13B-V0.1-GGUF",
      "author": "TheBloke",
      "sha": "a7831437058c2729b6fb7d4838aee5f57ee45a36",
      "lastModified": "2023-09-27T12:53:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 61,
      "library_name": "transformers",
      "likes": 22,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Xwin-LM 13B V0.1",
        "base_model": "Xwin-LM/Xwin-LM-13B-V0.1",
        "inference": false,
        "model_creator": "Xwin-LM",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "xwin-lm-13b-v0.1.Q2_K.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.1.Q4_0.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.1.Q5_0.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.1.Q6_K.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650464373fbd7ffcfd2fdfef",
      "id": "Xwin-LM/Xwin-LM-13B-V0.1",
      "modelId": "Xwin-LM/Xwin-LM-13B-V0.1",
      "author": "Xwin-LM",
      "sha": "32938856dc3d713dcba706aded7c82791b6ff647",
      "lastModified": "2023-09-21T05:42:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10314,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 57,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "zhanghao-njmu/Xwin-LM-Xwin-LM-13B-V0.1"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650b7177a27ba14323e5af95",
    "id": "TheBloke/MAmmoTH-Coder-34B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:TIGER-Lab/MathInstruct",
      "arxiv:2309.05653",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MAmmoTH-Coder-34B-GGUF",
    "model": {
      "_id": "650b7177a27ba14323e5af95",
      "id": "TheBloke/MAmmoTH-Coder-34B-GGUF",
      "modelId": "TheBloke/MAmmoTH-Coder-34B-GGUF",
      "author": "TheBloke",
      "sha": "395326df9e4828a7c543b5ff74d1e8900cd1477f",
      "lastModified": "2023-09-27T12:53:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:TIGER-Lab/MathInstruct",
        "arxiv:2309.05653",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "mit",
        "datasets": [
          "TIGER-Lab/MathInstruct"
        ],
        "model_name": "MAmmoTH Coder 34B",
        "base_model": "TIGER-Lab/MAmmoTH-Coder-34B",
        "inference": false,
        "model_creator": "TIGER-Lab",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mammoth-coder-34b.Q2_K.gguf"
        },
        {
          "rfilename": "mammoth-coder-34b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mammoth-coder-34b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mammoth-coder-34b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mammoth-coder-34b.Q4_0.gguf"
        },
        {
          "rfilename": "mammoth-coder-34b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mammoth-coder-34b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mammoth-coder-34b.Q5_0.gguf"
        },
        {
          "rfilename": "mammoth-coder-34b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mammoth-coder-34b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mammoth-coder-34b.Q6_K.gguf"
        },
        {
          "rfilename": "mammoth-coder-34b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fe818da39388f54fdd72e9",
      "id": "TIGER-Lab/MAmmoTH-Coder-34B",
      "modelId": "TIGER-Lab/MAmmoTH-Coder-34B",
      "author": "TIGER-Lab",
      "sha": "71e925d4e8553007394ec4b3c22edc43aea700ff",
      "lastModified": "2023-10-23T03:00:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:TIGER-Lab/MathInstruct",
        "arxiv:2309.05653",
        "license:mit",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 13,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit",
        "datasets": [
          "TIGER-Lab/MathInstruct"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "drdonut1/TIGER-Lab-MAmmoTH-Coder-34B"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650b7622ba3bc3360656bbf2",
    "id": "TheBloke/MAmmoTH-70B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:TIGER-Lab/MathInstruct",
      "arxiv:2309.05653",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MAmmoTH-70B-GGUF",
    "model": {
      "_id": "650b7622ba3bc3360656bbf2",
      "id": "TheBloke/MAmmoTH-70B-GGUF",
      "modelId": "TheBloke/MAmmoTH-70B-GGUF",
      "author": "TheBloke",
      "sha": "bec64672d923a53fbffd4c558e925cad09b1fb98",
      "lastModified": "2023-09-27T12:53:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:TIGER-Lab/MathInstruct",
        "arxiv:2309.05653",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "mit",
        "datasets": [
          "TIGER-Lab/MathInstruct"
        ],
        "model_name": "MAmmoTH 70B",
        "base_model": "TIGER-Lab/MAmmoTH-70b",
        "inference": false,
        "model_creator": "TIGER-Lab",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mammoth-70b.Q2_K.gguf"
        },
        {
          "rfilename": "mammoth-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mammoth-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mammoth-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mammoth-70b.Q4_0.gguf"
        },
        {
          "rfilename": "mammoth-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mammoth-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mammoth-70b.Q5_0.gguf"
        },
        {
          "rfilename": "mammoth-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mammoth-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mammoth-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "mammoth-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "mammoth-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "mammoth-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64fe8050c367f7b1ca307917",
      "id": "TIGER-Lab/MAmmoTH-70B",
      "modelId": "TIGER-Lab/MAmmoTH-70B",
      "author": "TIGER-Lab",
      "sha": "e757a38fb2346db6ba91fd24ece55058544eff4c",
      "lastModified": "2023-10-23T03:00:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:TIGER-Lab/MathInstruct",
        "arxiv:2309.05653",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 673,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit",
        "datasets": [
          "TIGER-Lab/MathInstruct"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650bf894dab7deefd460223a",
    "id": "TheBloke/Inkbot-13B-4k-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Inkbot-13B-4k-GGUF",
    "model": {
      "_id": "650bf894dab7deefd460223a",
      "id": "TheBloke/Inkbot-13B-4k-GGUF",
      "modelId": "TheBloke/Inkbot-13B-4k-GGUF",
      "author": "TheBloke",
      "sha": "12af921689fbadbe23c61fb34290dff8ac6867ba",
      "lastModified": "2023-09-27T12:53:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Inkbot 13B 4K",
        "base_model": "Tostino/Inkbot-13b-4k",
        "inference": false,
        "model_creator": "Tostino",
        "model_type": "llama",
        "prompt_template": "<#meta#>\n- Date: [DATE]\n- Task: [TASK TYPE]\n<#system#>\n{system_message}\n<#chat#>\n<#user#>\n{prompt}\n<#bot#>\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "inkbot-13b-4k.Q2_K.gguf"
        },
        {
          "rfilename": "inkbot-13b-4k.Q3_K_L.gguf"
        },
        {
          "rfilename": "inkbot-13b-4k.Q3_K_M.gguf"
        },
        {
          "rfilename": "inkbot-13b-4k.Q3_K_S.gguf"
        },
        {
          "rfilename": "inkbot-13b-4k.Q4_0.gguf"
        },
        {
          "rfilename": "inkbot-13b-4k.Q4_K_M.gguf"
        },
        {
          "rfilename": "inkbot-13b-4k.Q4_K_S.gguf"
        },
        {
          "rfilename": "inkbot-13b-4k.Q5_0.gguf"
        },
        {
          "rfilename": "inkbot-13b-4k.Q5_K_M.gguf"
        },
        {
          "rfilename": "inkbot-13b-4k.Q5_K_S.gguf"
        },
        {
          "rfilename": "inkbot-13b-4k.Q6_K.gguf"
        },
        {
          "rfilename": "inkbot-13b-4k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650bdb207c99ca283e59e79d",
      "id": "Tostino/Inkbot-13b-4k",
      "modelId": "Tostino/Inkbot-13b-4k",
      "author": "Tostino",
      "sha": "62a8ce8a5e4efad3de63a20d69775ef467176e96",
      "lastModified": "2023-09-21T18:36:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650bfac22ec41a31f322c1a5",
    "id": "TheBloke/Xwin-LM-7B-V0.1-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 18,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Xwin-LM-7B-V0.1-GGUF",
    "model": {
      "_id": "650bfac22ec41a31f322c1a5",
      "id": "TheBloke/Xwin-LM-7B-V0.1-GGUF",
      "modelId": "TheBloke/Xwin-LM-7B-V0.1-GGUF",
      "author": "TheBloke",
      "sha": "e30c0c255cce9aea5caba9377d2bc43762f40c75",
      "lastModified": "2023-09-27T12:53:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 18,
      "library_name": "transformers",
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Xwin-LM 7B V0.1",
        "base_model": "Xwin-LM/Xwin-LM-7b-V0.1",
        "inference": false,
        "model_creator": "Xwin-LM",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "xwin-lm-7b-v0.1.Q2_K.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.1.Q4_0.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.1.Q5_0.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.1.Q6_K.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6504641b56cadc9ef157ce6a",
      "id": "Xwin-LM/Xwin-LM-7B-V0.1",
      "modelId": "Xwin-LM/Xwin-LM-7B-V0.1",
      "author": "Xwin-LM",
      "sha": "470e680120a7249d6e8a875345015ddba1711100",
      "lastModified": "2023-09-21T05:42:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 51361,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 75,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Ashv27/Xwin-LM-Xwin-LM-7B-V0.1",
        "zhch158/Xwin-LM-Xwin-LM-7B-V0.1",
        "kunihiros/Xwin-LM-Xwin-LM-7B-V0.1"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650bfe3c78d2dfbad85e17a0",
    "id": "TheBloke/Xwin-LM-70B-V0.1-GGUF",
    "likes": 39,
    "private": false,
    "downloads": 150,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Xwin-LM-70B-V0.1-GGUF",
    "model": {
      "_id": "650bfe3c78d2dfbad85e17a0",
      "id": "TheBloke/Xwin-LM-70B-V0.1-GGUF",
      "modelId": "TheBloke/Xwin-LM-70B-V0.1-GGUF",
      "author": "TheBloke",
      "sha": "0f9c5cbd9ccbca39c3ec8b5c11d03cab76e2bedb",
      "lastModified": "2023-09-27T12:53:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 150,
      "library_name": "transformers",
      "likes": 39,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "Xwin-LM 70B V0.1",
        "base_model": "Xwin-LM/Xwin-LM-70b-V0.1",
        "inference": false,
        "model_creator": "Xwin-LM",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q2_K.gguf"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q4_0.gguf"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q5_0.gguf"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "xwin-lm-70b-v0.1.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "6504645ec0d1b73b9464b2b7",
      "id": "Xwin-LM/Xwin-LM-70B-V0.1",
      "modelId": "Xwin-LM/Xwin-LM-70B-V0.1",
      "author": "Xwin-LM",
      "sha": "d6c803a180e3d46c371f8d3cb3848b861596ccbc",
      "lastModified": "2023-09-21T09:55:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9223,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 169,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "h1bomb/Xwin-LM-Xwin-LM-70B-V0.1",
        "mstager/N-LLM-XWIN-2",
        "Kycid/Xwin-LM-Xwin-LM-70B-V0.1",
        "Circlescorner/Xwin-LM-Xwin-LM-70B-V0.1",
        "zhanghao-njmu/Xwin-LM-Xwin-LM-70B-V0.1",
        "44brabal/Xwin-LM-Xwin-LM-70B-V0.1",
        "kingbubbles/Xwin-LM-Xwin-LM-70B-V0.1",
        "lhlhlh1998/Xwin-LM-Xwin-LM-70B-V0.1",
        "kol-s/Xwin-LM-Xwin-LM-70B-V0.1"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00024-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00025-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00026-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00027-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00028-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model-00029-of-00029.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650cbdd8fc7c3a59dff5b4c2",
    "id": "TheBloke/Airoboros-L2-70b-2.2.1-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 5,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.2.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-70b-2.2.1-GGUF",
    "model": {
      "_id": "650cbdd8fc7c3a59dff5b4c2",
      "id": "TheBloke/Airoboros-L2-70b-2.2.1-GGUF",
      "modelId": "TheBloke/Airoboros-L2-70b-2.2.1-GGUF",
      "author": "TheBloke",
      "sha": "a72ea02675f875d1c22019c92a3212a408bd7025",
      "lastModified": "2023-09-27T12:53:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2.1"
        ],
        "model_name": "Airoboros L2 70B 2.2.1",
        "base_model": "jondurbin/airoboros-l2-70b-2.2.1",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-2.2.1.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "650b1a4faffb2713c2a4e6c4",
      "id": "jondurbin/airoboros-l2-70b-2.2.1",
      "modelId": "jondurbin/airoboros-l2-70b-2.2.1",
      "author": "jondurbin",
      "sha": "eadc78a4a9e173bccdca7dc8d12a34e80317c66c",
      "lastModified": "2023-09-21T18:38:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6752,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/README.md"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650e254c2a45730c3fccd4b8",
    "id": "TheBloke/MLewd-ReMM-L2-Chat-20B-GGUF",
    "likes": 19,
    "private": false,
    "downloads": 271,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MLewd-ReMM-L2-Chat-20B-GGUF",
    "model": {
      "_id": "650e254c2a45730c3fccd4b8",
      "id": "TheBloke/MLewd-ReMM-L2-Chat-20B-GGUF",
      "modelId": "TheBloke/MLewd-ReMM-L2-Chat-20B-GGUF",
      "author": "TheBloke",
      "sha": "6ae10337b427dc96b325f7c3ba2fb12fbd067d58",
      "lastModified": "2023-09-27T12:53:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 271,
      "library_name": "transformers",
      "likes": 19,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ],
        "model_name": "MLewd ReMM L2 Chat 20B",
        "base_model": "Undi95/MLewd-ReMM-L2-Chat-20B",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b.Q2_K.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b.Q4_0.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b.Q5_0.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b.Q6_K.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6507805b4a8839a8bd925298",
      "id": "Undi95/MLewd-ReMM-L2-Chat-20B",
      "modelId": "Undi95/MLewd-ReMM-L2-Chat-20B",
      "author": "Undi95",
      "sha": "cda06630a1d8173541431e5ce8bc17dcfaa37e5e",
      "lastModified": "2023-09-26T00:37:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10254,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 9997178880,
          "BF16": 9833344000,
          "F32": 163840000
        },
        "total": 19994362880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00005.safetensors"
        },
        {
          "rfilename": "model-00002-of-00005.safetensors"
        },
        {
          "rfilename": "model-00003-of-00005.safetensors"
        },
        {
          "rfilename": "model-00004-of-00005.safetensors"
        },
        {
          "rfilename": "model-00005-of-00005.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650e2790469c325dc48e3a1a",
    "id": "TheBloke/MLewd-ReMM-L2-Chat-20B-Inverted-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 28,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MLewd-ReMM-L2-Chat-20B-Inverted-GGUF",
    "model": {
      "_id": "650e2790469c325dc48e3a1a",
      "id": "TheBloke/MLewd-ReMM-L2-Chat-20B-Inverted-GGUF",
      "modelId": "TheBloke/MLewd-ReMM-L2-Chat-20B-Inverted-GGUF",
      "author": "TheBloke",
      "sha": "0923a9af4d6260e8e3ee2b7e3a39041255f2233b",
      "lastModified": "2023-09-27T12:54:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 28,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ],
        "model_name": "MLewd ReMM L2 Chat 20b Inverted",
        "base_model": "Undi95/MLewd-ReMM-L2-Chat-20b-inverted",
        "inference": false,
        "model_creator": "Undi95",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b-inverted.Q2_K.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b-inverted.Q3_K_L.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b-inverted.Q3_K_M.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b-inverted.Q3_K_S.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b-inverted.Q4_0.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b-inverted.Q4_K_M.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b-inverted.Q4_K_S.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b-inverted.Q5_0.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b-inverted.Q5_K_M.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b-inverted.Q5_K_S.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b-inverted.Q6_K.gguf"
        },
        {
          "rfilename": "mlewd-remm-l2-chat-20b-inverted.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6507688867876ea3202d16cf",
      "id": "Undi95/MLewd-ReMM-L2-Chat-20B-Inverted",
      "modelId": "Undi95/MLewd-ReMM-L2-Chat-20B-Inverted",
      "author": "Undi95",
      "sha": "b5b501b4d23ec7ab24b827f79e48b2c67e548ddb",
      "lastModified": "2023-09-23T22:51:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4046,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 163840000,
          "BF16": 9833338880,
          "F16": 9997184000
        },
        "total": 19994362880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00005.safetensors"
        },
        {
          "rfilename": "model-00002-of-00005.safetensors"
        },
        {
          "rfilename": "model-00003-of-00005.safetensors"
        },
        {
          "rfilename": "model-00004-of-00005.safetensors"
        },
        {
          "rfilename": "model-00005-of-00005.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650e2a32dc509ae7d7a7e6d8",
    "id": "TheBloke/ALMA-7B-Pretrain-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2309.11674",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/ALMA-7B-Pretrain-GGUF",
    "model": {
      "_id": "650e2a32dc509ae7d7a7e6d8",
      "id": "TheBloke/ALMA-7B-Pretrain-GGUF",
      "modelId": "TheBloke/ALMA-7B-Pretrain-GGUF",
      "author": "TheBloke",
      "sha": "736b07dafb7b604d62b7fb5aed0a38be246ad00c",
      "lastModified": "2023-09-27T12:54:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2309.11674",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit",
        "model_name": "ALMA 7B Pretrain",
        "base_model": "haoranxu/ALMA-7b-Pretrain",
        "inference": false,
        "model_creator": "haoranxu",
        "model_type": "llama",
        "prompt_template": "Translate this from Chinese to English:\nChinese: {prompt}\nEnglish:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "alma-7b-pretrain.Q2_K.gguf"
        },
        {
          "rfilename": "alma-7b-pretrain.Q3_K_L.gguf"
        },
        {
          "rfilename": "alma-7b-pretrain.Q3_K_M.gguf"
        },
        {
          "rfilename": "alma-7b-pretrain.Q3_K_S.gguf"
        },
        {
          "rfilename": "alma-7b-pretrain.Q4_0.gguf"
        },
        {
          "rfilename": "alma-7b-pretrain.Q4_K_M.gguf"
        },
        {
          "rfilename": "alma-7b-pretrain.Q4_K_S.gguf"
        },
        {
          "rfilename": "alma-7b-pretrain.Q5_0.gguf"
        },
        {
          "rfilename": "alma-7b-pretrain.Q5_K_M.gguf"
        },
        {
          "rfilename": "alma-7b-pretrain.Q5_K_S.gguf"
        },
        {
          "rfilename": "alma-7b-pretrain.Q6_K.gguf"
        },
        {
          "rfilename": "alma-7b-pretrain.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "65073a90d55dd4e15cba4309",
      "id": "haoranxu/ALMA-7B-Pretrain",
      "modelId": "haoranxu/ALMA-7B-Pretrain",
      "author": "haoranxu",
      "sha": "871412ea63572e860728bcb1ff791e2e94d472f1",
      "lastModified": "2023-10-27T05:10:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2309.11674",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1605,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650e2c27671604f140c01efd",
    "id": "TheBloke/ALMA-13B-Pretrain-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 7,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2309.11674",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/ALMA-13B-Pretrain-GGUF",
    "model": {
      "_id": "650e2c27671604f140c01efd",
      "id": "TheBloke/ALMA-13B-Pretrain-GGUF",
      "modelId": "TheBloke/ALMA-13B-Pretrain-GGUF",
      "author": "TheBloke",
      "sha": "d5017cb469aed84d5c443b44fed2508ab0fb46b2",
      "lastModified": "2023-09-27T12:54:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2309.11674",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit",
        "model_name": "ALMA 13B Pretrain",
        "base_model": "haoranxu/ALMA-13B-Pretrain",
        "inference": false,
        "model_creator": "haoranxu",
        "model_type": "llama",
        "prompt_template": "Translate this from Chinese to English:\nChinese: {prompt}\nEnglish:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "alma-13b-pretrain.Q2_K.gguf"
        },
        {
          "rfilename": "alma-13b-pretrain.Q3_K_L.gguf"
        },
        {
          "rfilename": "alma-13b-pretrain.Q3_K_M.gguf"
        },
        {
          "rfilename": "alma-13b-pretrain.Q3_K_S.gguf"
        },
        {
          "rfilename": "alma-13b-pretrain.Q4_0.gguf"
        },
        {
          "rfilename": "alma-13b-pretrain.Q4_K_M.gguf"
        },
        {
          "rfilename": "alma-13b-pretrain.Q4_K_S.gguf"
        },
        {
          "rfilename": "alma-13b-pretrain.Q5_0.gguf"
        },
        {
          "rfilename": "alma-13b-pretrain.Q5_K_M.gguf"
        },
        {
          "rfilename": "alma-13b-pretrain.Q5_K_S.gguf"
        },
        {
          "rfilename": "alma-13b-pretrain.Q6_K.gguf"
        },
        {
          "rfilename": "alma-13b-pretrain.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "65073aba00c9c9a775479068",
      "id": "haoranxu/ALMA-13B-Pretrain",
      "modelId": "haoranxu/ALMA-13B-Pretrain",
      "author": "haoranxu",
      "sha": "cd195b398c44197b3799d7829ac3341e2c5735b5",
      "lastModified": "2023-10-27T05:10:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2309.11674",
        "license:mit",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8988,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f243c9060fe790101b236",
    "id": "TheBloke/airoboros-c34b-2.2.1-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.2.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-c34b-2.2.1-GGUF",
    "model": {
      "_id": "650f243c9060fe790101b236",
      "id": "TheBloke/airoboros-c34b-2.2.1-GGUF",
      "modelId": "TheBloke/airoboros-c34b-2.2.1-GGUF",
      "author": "TheBloke",
      "sha": "f790668f21fc931ea736ef4cb1498f129de83ef8",
      "lastModified": "2023-09-27T12:54:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2.1"
        ],
        "model_name": "Airoboros C34B 2.2.1",
        "base_model": "jondurbin/airoboros-c34b-2.2.1",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-c34b-2.2.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-c34b-2.2.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "650a03226d2284f73257916e",
      "id": "jondurbin/airoboros-c34b-2.2.1",
      "modelId": "jondurbin/airoboros-c34b-2.2.1",
      "author": "jondurbin",
      "sha": "79d9761af231fecbfaf6066d6d405a0f8c04f4ba",
      "lastModified": "2023-09-28T09:39:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6698,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/README.md"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f4a7bdc509ae7d7c8521d",
    "id": "TheBloke/airoboros-l2-13B-2.2.1-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.2.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-13B-2.2.1-GGUF",
    "model": {
      "_id": "650f4a7bdc509ae7d7c8521d",
      "id": "TheBloke/airoboros-l2-13B-2.2.1-GGUF",
      "modelId": "TheBloke/airoboros-l2-13B-2.2.1-GGUF",
      "author": "TheBloke",
      "sha": "fabc0c59543afaea1ba2fe20b7358f8d0a365560",
      "lastModified": "2023-09-27T12:54:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2.1"
        ],
        "model_name": "Airoboros L2 13B 2.2.1",
        "base_model": "jondurbin/airoboros-l2-13b-2.2.1",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-2.2.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "650b3b70a17882d7e0781570",
      "id": "jondurbin/airoboros-l2-13b-2.2.1",
      "modelId": "jondurbin/airoboros-l2-13b-2.2.1",
      "author": "jondurbin",
      "sha": "9b2dbc1f6f17a162228799df6e9449c903ddf04d",
      "lastModified": "2023-09-21T18:39:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7384,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/README.md"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f4a826620b0c57e3a663a",
    "id": "TheBloke/EverythingLM-13B-V3-16K-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "dataset:totally-not-an-llm/EverythingLM-data-V3",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/EverythingLM-13B-V3-16K-GGUF",
    "model": {
      "_id": "650f4a826620b0c57e3a663a",
      "id": "TheBloke/EverythingLM-13B-V3-16K-GGUF",
      "modelId": "TheBloke/EverythingLM-13B-V3-16K-GGUF",
      "author": "TheBloke",
      "sha": "3b3197554919b5c4a7d438005a411351bb523c1d",
      "lastModified": "2023-09-27T12:54:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:totally-not-an-llm/EverythingLM-data-V3",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "totally-not-an-llm/EverythingLM-data-V3"
        ],
        "model_name": "EverythingLM 13B V3 16K",
        "base_model": "totally-not-an-llm/EverythingLM-13b-V3-16k",
        "inference": false,
        "model_creator": "Kai Howard",
        "model_type": "llama",
        "prompt_template": "USER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "everythinglm-13b-v3-16k.Q2_K.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v3-16k.Q3_K_L.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v3-16k.Q3_K_M.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v3-16k.Q3_K_S.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v3-16k.Q4_0.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v3-16k.Q4_K_M.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v3-16k.Q4_K_S.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v3-16k.Q5_0.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v3-16k.Q5_K_M.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v3-16k.Q5_K_S.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v3-16k.Q6_K.gguf"
        },
        {
          "rfilename": "everythinglm-13b-v3-16k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650e3cf855dc1e8417392e85",
      "id": "totally-not-an-llm/EverythingLM-13b-V3-16k",
      "modelId": "totally-not-an-llm/EverythingLM-13b-V3-16k",
      "author": "totally-not-an-llm",
      "sha": "1de9244bfadb947f80872727f76790cbc76e7142",
      "lastModified": "2023-09-23T23:30:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:totally-not-an-llm/EverythingLM-data-V3",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6211,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "totally-not-an-llm/EverythingLM-data-V3"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f52c1544d7edd813609da",
    "id": "TheBloke/airoboros-l2-7B-2.2.1-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-2.2.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-7B-2.2.1-GGUF",
    "model": {
      "_id": "650f52c1544d7edd813609da",
      "id": "TheBloke/airoboros-l2-7B-2.2.1-GGUF",
      "modelId": "TheBloke/airoboros-l2-7B-2.2.1-GGUF",
      "author": "TheBloke",
      "sha": "4d44e2982e79b7ac2eaca1221e061ecc7924f8b2",
      "lastModified": "2023-09-27T12:54:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2.1"
        ],
        "model_name": "Airoboros L2 7B 2.2.1",
        "base_model": "jondurbin/airoboros-l2-7b-2.2.1",
        "inference": false,
        "model_creator": "Jon Durbin",
        "model_type": "llama",
        "prompt_template": "A chat.\nUSER: {prompt}\nASSISTANT: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-2.2.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "650b2b49f795a59f49fe078e",
      "id": "jondurbin/airoboros-l2-7b-2.2.1",
      "modelId": "jondurbin/airoboros-l2-7b-2.2.1",
      "author": "jondurbin",
      "sha": "eafbba6fec094a17ca7bce6d9605cac97b90a483",
      "lastModified": "2023-09-21T18:39:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6699,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-2.2.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/README.md"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f57155877b1c07718d567",
    "id": "TheBloke/MAmmoTH-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:TIGER-Lab/MathInstruct",
      "arxiv:2309.05653",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MAmmoTH-13B-GGUF",
    "model": {
      "_id": "650f57155877b1c07718d567",
      "id": "TheBloke/MAmmoTH-13B-GGUF",
      "modelId": "TheBloke/MAmmoTH-13B-GGUF",
      "author": "TheBloke",
      "sha": "83fc7389592141f3b2a3176036b3503c334f7bfe",
      "lastModified": "2023-09-27T12:54:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:TIGER-Lab/MathInstruct",
        "arxiv:2309.05653",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "mit",
        "datasets": [
          "TIGER-Lab/MathInstruct"
        ],
        "model_name": "MAmmoTH 13B",
        "base_model": "TIGER-Lab/MAmmoTH-13B",
        "inference": false,
        "model_creator": "TIGER-Lab",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mammoth-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mammoth-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mammoth-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mammoth-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mammoth-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mammoth-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mammoth-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mammoth-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mammoth-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mammoth-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mammoth-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mammoth-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fe7fac0e486522f8810aa7",
      "id": "TIGER-Lab/MAmmoTH-13B",
      "modelId": "TIGER-Lab/MAmmoTH-13B",
      "author": "TIGER-Lab",
      "sha": "0a81973004ccf1676e738e00e86e27a69f71447c",
      "lastModified": "2023-10-23T02:59:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:TIGER-Lab/MathInstruct",
        "arxiv:2309.05653",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 205,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit",
        "datasets": [
          "TIGER-Lab/MathInstruct"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f5e048607fa78b02cedeb",
    "id": "TheBloke/MAmmoTH-7B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:TIGER-Lab/MathInstruct",
      "arxiv:2309.05653",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MAmmoTH-7B-GGUF",
    "model": {
      "_id": "650f5e048607fa78b02cedeb",
      "id": "TheBloke/MAmmoTH-7B-GGUF",
      "modelId": "TheBloke/MAmmoTH-7B-GGUF",
      "author": "TheBloke",
      "sha": "b850bfce3c06eeb1b712d09c8c4ee9381afd4e1c",
      "lastModified": "2023-09-27T12:54:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:TIGER-Lab/MathInstruct",
        "arxiv:2309.05653",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "mit",
        "datasets": [
          "TIGER-Lab/MathInstruct"
        ],
        "model_name": "MAmmoTH 7B",
        "base_model": "TIGER-Lab/MAmmoTH-7B",
        "inference": false,
        "model_creator": "TIGER-Lab",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mammoth-7b.Q2_K.gguf"
        },
        {
          "rfilename": "mammoth-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mammoth-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mammoth-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mammoth-7b.Q4_0.gguf"
        },
        {
          "rfilename": "mammoth-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mammoth-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mammoth-7b.Q5_0.gguf"
        },
        {
          "rfilename": "mammoth-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mammoth-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mammoth-7b.Q6_K.gguf"
        },
        {
          "rfilename": "mammoth-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fe2c4bc3329fa5932fe02f",
      "id": "TIGER-Lab/MAmmoTH-7B",
      "modelId": "TIGER-Lab/MAmmoTH-7B",
      "author": "TIGER-Lab",
      "sha": "b188bd14659d2086c182b4726f0413cbda89b38b",
      "lastModified": "2023-10-23T02:59:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:TIGER-Lab/MathInstruct",
        "arxiv:2309.05653",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 385,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit",
        "datasets": [
          "TIGER-Lab/MathInstruct"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f6236a0f2ffbeca84c089",
    "id": "TheBloke/Athena-v2-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 35,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Athena-v2-GGUF",
    "model": {
      "_id": "650f6236a0f2ffbeca84c089",
      "id": "TheBloke/Athena-v2-GGUF",
      "modelId": "TheBloke/Athena-v2-GGUF",
      "author": "TheBloke",
      "sha": "35afdcc76694dd796ce31cc7a7454955bb743986",
      "lastModified": "2023-09-27T12:54:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 35,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "model_name": "Athena V2",
        "base_model": "IkariDev/Athena-v2",
        "inference": false,
        "model_creator": "IkariDev",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "athena-v2.Q2_K.gguf"
        },
        {
          "rfilename": "athena-v2.Q3_K_L.gguf"
        },
        {
          "rfilename": "athena-v2.Q3_K_M.gguf"
        },
        {
          "rfilename": "athena-v2.Q3_K_S.gguf"
        },
        {
          "rfilename": "athena-v2.Q4_0.gguf"
        },
        {
          "rfilename": "athena-v2.Q4_K_M.gguf"
        },
        {
          "rfilename": "athena-v2.Q4_K_S.gguf"
        },
        {
          "rfilename": "athena-v2.Q5_0.gguf"
        },
        {
          "rfilename": "athena-v2.Q5_K_M.gguf"
        },
        {
          "rfilename": "athena-v2.Q5_K_S.gguf"
        },
        {
          "rfilename": "athena-v2.Q6_K.gguf"
        },
        {
          "rfilename": "athena-v2.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "650ef0371765bd51f4ac3bc5",
      "id": "IkariDev/Athena-v2",
      "modelId": "IkariDev/Athena-v2",
      "author": "IkariDev",
      "sha": "46de6a64c5885d8ba2187043f91b1fb003f2fc7a",
      "lastModified": "2023-09-25T13:11:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 28,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00006.safetensors"
        },
        {
          "rfilename": "model-00002-of-00006.safetensors"
        },
        {
          "rfilename": "model-00003-of-00006.safetensors"
        },
        {
          "rfilename": "model-00004-of-00006.safetensors"
        },
        {
          "rfilename": "model-00005-of-00006.safetensors"
        },
        {
          "rfilename": "model-00006-of-00006.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f67c4dba31194cb4bf263",
    "id": "TheBloke/PuddleJumper-13B-V2-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:totally-not-an-llm/EverythingLM-data-V3",
      "dataset:Open-Orca/OpenOrca",
      "dataset:garage-bAInd/Open-Platypus",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/PuddleJumper-13B-V2-GGUF",
    "model": {
      "_id": "650f67c4dba31194cb4bf263",
      "id": "TheBloke/PuddleJumper-13B-V2-GGUF",
      "modelId": "TheBloke/PuddleJumper-13B-V2-GGUF",
      "author": "TheBloke",
      "sha": "fb5033d26ba4760926811c7600c8108c12a07cc9",
      "lastModified": "2023-09-27T12:54:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:totally-not-an-llm/EverythingLM-data-V3",
        "dataset:Open-Orca/OpenOrca",
        "dataset:garage-bAInd/Open-Platypus",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "totally-not-an-llm/EverythingLM-data-V3",
          "Open-Orca/OpenOrca",
          "garage-bAInd/Open-Platypus"
        ],
        "model_name": "PuddleJumper 13B V2",
        "base_model": "totally-not-an-llm/PuddleJumper-13b-V2",
        "inference": false,
        "model_creator": "Kai Howard",
        "model_type": "llama",
        "prompt_template": "USER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "puddlejumper-13b-v2.Q2_K.gguf"
        },
        {
          "rfilename": "puddlejumper-13b-v2.Q3_K_L.gguf"
        },
        {
          "rfilename": "puddlejumper-13b-v2.Q3_K_M.gguf"
        },
        {
          "rfilename": "puddlejumper-13b-v2.Q3_K_S.gguf"
        },
        {
          "rfilename": "puddlejumper-13b-v2.Q4_0.gguf"
        },
        {
          "rfilename": "puddlejumper-13b-v2.Q4_K_M.gguf"
        },
        {
          "rfilename": "puddlejumper-13b-v2.Q4_K_S.gguf"
        },
        {
          "rfilename": "puddlejumper-13b-v2.Q5_0.gguf"
        },
        {
          "rfilename": "puddlejumper-13b-v2.Q5_K_M.gguf"
        },
        {
          "rfilename": "puddlejumper-13b-v2.Q5_K_S.gguf"
        },
        {
          "rfilename": "puddlejumper-13b-v2.Q6_K.gguf"
        },
        {
          "rfilename": "puddlejumper-13b-v2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650bbb895510464e85aabc76",
      "id": "totally-not-an-llm/PuddleJumper-13b-V2",
      "modelId": "totally-not-an-llm/PuddleJumper-13b-V2",
      "author": "totally-not-an-llm",
      "sha": "1fe9494e334a32ba73dc2926f58246450850c534",
      "lastModified": "2023-09-25T01:16:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:totally-not-an-llm/EverythingLM-data-V3",
        "dataset:Open-Orca/OpenOrca",
        "dataset:garage-bAInd/Open-Platypus",
        "license:other",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6527,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "datasets": [
          "totally-not-an-llm/EverythingLM-data-V3",
          "Open-Orca/OpenOrca",
          "garage-bAInd/Open-Platypus"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f69188d01590937d207e3",
    "id": "TheBloke/MXLewd-L2-20B-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 81,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MXLewd-L2-20B-GGUF",
    "model": {
      "_id": "650f69188d01590937d207e3",
      "id": "TheBloke/MXLewd-L2-20B-GGUF",
      "modelId": "TheBloke/MXLewd-L2-20B-GGUF",
      "author": "TheBloke",
      "sha": "afbfd7a0a1928f82f961c1dd80c9323a86632622",
      "lastModified": "2023-09-27T12:54:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 81,
      "library_name": "transformers",
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "model_name": "MXLewd L2 20B",
        "base_model": "Undi95/MXLewd-L2-20B",
        "inference": false,
        "model_creator": "Undi",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mxlewd-l2-20b.Q2_K.gguf"
        },
        {
          "rfilename": "mxlewd-l2-20b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mxlewd-l2-20b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mxlewd-l2-20b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mxlewd-l2-20b.Q4_0.gguf"
        },
        {
          "rfilename": "mxlewd-l2-20b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mxlewd-l2-20b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mxlewd-l2-20b.Q5_0.gguf"
        },
        {
          "rfilename": "mxlewd-l2-20b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mxlewd-l2-20b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mxlewd-l2-20b.Q6_K.gguf"
        },
        {
          "rfilename": "mxlewd-l2-20b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650dbb19ff259b573e435740",
      "id": "Undi95/MXLewd-L2-20B",
      "modelId": "Undi95/MXLewd-L2-20B",
      "author": "Undi95",
      "sha": "ac279478abd9ddb8d1f5adcc548be0287b963adf",
      "lastModified": "2023-09-23T22:46:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4579,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 19666682880
        },
        "total": 19994362880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00005.safetensors"
        },
        {
          "rfilename": "model-00002-of-00005.safetensors"
        },
        {
          "rfilename": "model-00003-of-00005.safetensors"
        },
        {
          "rfilename": "model-00004-of-00005.safetensors"
        },
        {
          "rfilename": "model-00005-of-00005.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f7457d4e844fefdb51afc",
    "id": "TheBloke/storytime-13B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/storytime-13B-GGUF",
    "model": {
      "_id": "650f7457d4e844fefdb51afc",
      "id": "TheBloke/storytime-13B-GGUF",
      "modelId": "TheBloke/storytime-13B-GGUF",
      "author": "TheBloke",
      "sha": "0ce945aa4e150c8dc1f44a838350290a7b5134ee",
      "lastModified": "2023-09-27T12:54:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "tags": [
          "llama"
        ],
        "model_name": "Storytime 13B",
        "base_model": "chargoddard/storytime-13b",
        "inference": false,
        "model_creator": "Charles Goddard",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "storytime-13b.Q2_K.gguf"
        },
        {
          "rfilename": "storytime-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "storytime-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "storytime-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "storytime-13b.Q4_0.gguf"
        },
        {
          "rfilename": "storytime-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "storytime-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "storytime-13b.Q5_0.gguf"
        },
        {
          "rfilename": "storytime-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "storytime-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "storytime-13b.Q6_K.gguf"
        },
        {
          "rfilename": "storytime-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650e0e6cc22803e6a076b81a",
      "id": "chargoddard/storytime-13b",
      "modelId": "chargoddard/storytime-13b",
      "author": "chargoddard",
      "sha": "233568319a636b6a7b02a4def2c51d08a3e0fbfc",
      "lastModified": "2023-09-23T01:02:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4817,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ],
        "tags": [
          "llama"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f747811f3210cf7b386aa",
    "id": "TheBloke/MXLewdMini-L2-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MXLewdMini-L2-13B-GGUF",
    "model": {
      "_id": "650f747811f3210cf7b386aa",
      "id": "TheBloke/MXLewdMini-L2-13B-GGUF",
      "modelId": "TheBloke/MXLewdMini-L2-13B-GGUF",
      "author": "TheBloke",
      "sha": "2cc680cbe9ece75097c4cc2efc7a004c0aabc29a",
      "lastModified": "2023-09-27T12:54:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "model_name": "Mxlewdmini L2 13B",
        "base_model": "Undi95/MXLewdMini-L2-13B",
        "inference": false,
        "model_creator": "Undi",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mxlewdmini-l2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mxlewdmini-l2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mxlewdmini-l2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mxlewdmini-l2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mxlewdmini-l2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mxlewdmini-l2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mxlewdmini-l2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mxlewdmini-l2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mxlewdmini-l2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mxlewdmini-l2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mxlewdmini-l2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mxlewdmini-l2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650e11ad007ea5dd9dd39277",
      "id": "Undi95/MXLewdMini-L2-13B",
      "modelId": "Undi95/MXLewdMini-L2-13B",
      "author": "Undi95",
      "sha": "f7f3e401f470424a9d359f7de2eb11f89252d96d",
      "lastModified": "2023-09-22T23:56:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 114,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688184320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f7b7edcfa9d24c5225505",
    "id": "TheBloke/MetaMath-13B-V1.0-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MetaMath-13B-V1.0-GGUF",
    "model": {
      "_id": "650f7b7edcfa9d24c5225505",
      "id": "TheBloke/MetaMath-13B-V1.0-GGUF",
      "modelId": "TheBloke/MetaMath-13B-V1.0-GGUF",
      "author": "TheBloke",
      "sha": "25cda58cf9bcd0adfe2fa965101daacb20134b51",
      "lastModified": "2023-09-27T12:54:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "MetaMath 13B V1.0",
        "base_model": "meta-math/MetaMath-13B-V1.0",
        "inference": false,
        "model_creator": "MetaMath",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n\n### Instruction:\n{prompt}\n\n\n### Response: Let's think step by step.\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "metamath-13b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "metamath-13b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "metamath-13b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "metamath-13b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "metamath-13b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "metamath-13b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "metamath-13b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "metamath-13b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "metamath-13b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "metamath-13b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "metamath-13b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "metamath-13b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650cfdd772afb1e60e79907c",
      "id": "meta-math/MetaMath-13B-V1.0",
      "modelId": "meta-math/MetaMath-13B-V1.0",
      "author": "meta-math",
      "sha": "4f7ca097739f741fccdbfea14928bd0699737fd5",
      "lastModified": "2023-10-11T02:44:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:meta-math/MetaMathQA",
        "arxiv:2309.12284",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6499,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "meta-math/MetaMathQA"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f8211e14eeb01d45bccd6",
    "id": "TheBloke/MAmmoTH-Coder-13B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:TIGER-Lab/MathInstruct",
      "arxiv:2309.05653",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MAmmoTH-Coder-13B-GGUF",
    "model": {
      "_id": "650f8211e14eeb01d45bccd6",
      "id": "TheBloke/MAmmoTH-Coder-13B-GGUF",
      "modelId": "TheBloke/MAmmoTH-Coder-13B-GGUF",
      "author": "TheBloke",
      "sha": "0b7e040bb61ccef5b5d70be1800f4dda5611fdee",
      "lastModified": "2023-09-27T12:54:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:TIGER-Lab/MathInstruct",
        "arxiv:2309.05653",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "mit",
        "datasets": [
          "TIGER-Lab/MathInstruct"
        ],
        "model_name": "MAmmoTH Coder 13B",
        "base_model": "TIGER-Lab/MAmmoTH-Coder-13B",
        "inference": false,
        "model_creator": "TIGER-Lab",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mammoth-coder-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mammoth-coder-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mammoth-coder-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mammoth-coder-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mammoth-coder-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mammoth-coder-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mammoth-coder-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mammoth-coder-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mammoth-coder-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mammoth-coder-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mammoth-coder-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mammoth-coder-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64ff600a32d2159207d0c593",
      "id": "TIGER-Lab/MAmmoTH-Coder-13B",
      "modelId": "TIGER-Lab/MAmmoTH-Coder-13B",
      "author": "TIGER-Lab",
      "sha": "b26466bc05b7cd14983c041f27227548f54ef2f5",
      "lastModified": "2023-10-23T03:00:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:TIGER-Lab/MathInstruct",
        "arxiv:2309.05653",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 273,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit",
        "datasets": [
          "TIGER-Lab/MathInstruct"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650f846e871fed2307d5f13a",
    "id": "TheBloke/MetaMath-70B-V1.0-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MetaMath-70B-V1.0-GGUF",
    "model": {
      "_id": "650f846e871fed2307d5f13a",
      "id": "TheBloke/MetaMath-70B-V1.0-GGUF",
      "modelId": "TheBloke/MetaMath-70B-V1.0-GGUF",
      "author": "TheBloke",
      "sha": "757e9975d660c4f3c934665d8bd6b532150afbd4",
      "lastModified": "2023-09-27T12:54:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "MetaMath 70B V1.0",
        "base_model": "meta-math/MetaMath-70B-V1.0",
        "inference": false,
        "model_creator": "MetaMath",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n\n### Instruction:\n{prompt}\n\n\n### Response: Let's think step by step.\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "metamath-70b-v1.0.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "650d0801d231d98fc3a5a413",
      "id": "meta-math/MetaMath-70B-V1.0",
      "modelId": "meta-math/MetaMath-70B-V1.0",
      "author": "meta-math",
      "sha": "a5419673321fef896aeca32fbbc9a4f345ca7d1e",
      "lastModified": "2023-10-11T02:44:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:meta-math/MetaMathQA",
        "arxiv:2309.12284",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6273,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "meta-math/MetaMathQA"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650fa6f5007ea5dd9d00f685",
    "id": "TheBloke/MetaMath-7B-V1.0-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MetaMath-7B-V1.0-GGUF",
    "model": {
      "_id": "650fa6f5007ea5dd9d00f685",
      "id": "TheBloke/MetaMath-7B-V1.0-GGUF",
      "modelId": "TheBloke/MetaMath-7B-V1.0-GGUF",
      "author": "TheBloke",
      "sha": "0111444b27423816461397204a814bcfbf4fe70b",
      "lastModified": "2023-09-27T12:54:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "model_name": "MetaMath 7B V1.0",
        "base_model": "meta-math/MetaMath-7B-V1.0",
        "inference": false,
        "model_creator": "MetaMath",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n\n### Instruction:\n{prompt}\n\n\n### Response: Let's think step by step.\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "metamath-7b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "metamath-7b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "metamath-7b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "metamath-7b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "metamath-7b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "metamath-7b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "metamath-7b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "metamath-7b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "metamath-7b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "metamath-7b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "metamath-7b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "metamath-7b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650bfff2b5b6029d37436d5d",
      "id": "meta-math/MetaMath-7B-V1.0",
      "modelId": "meta-math/MetaMath-7B-V1.0",
      "author": "meta-math",
      "sha": "51b13691d345ff03f2ef70f3ec1ff69ff7aeaf76",
      "lastModified": "2023-10-11T02:45:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "dataset:meta-math/MetaMathQA",
        "arxiv:2309.12284",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1593,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 16,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "meta-math/MetaMathQA"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "alexanlee/meta-math-MetaMath-7B-V1.0"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650fabbe8f80c1165cf9edad",
    "id": "TheBloke/Synthia-13B-v1.2-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 15,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Synthia-13B-v1.2-GGUF",
    "model": {
      "_id": "650fabbe8f80c1165cf9edad",
      "id": "TheBloke/Synthia-13B-v1.2-GGUF",
      "modelId": "TheBloke/Synthia-13B-v1.2-GGUF",
      "author": "TheBloke",
      "sha": "807fd61acde8028719e1fe1c2b15df2e57b686cd",
      "lastModified": "2023-09-27T12:54:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "Synthia 13B V1.2",
        "base_model": "migtissera/Synthia-13B-v1.2",
        "inference": false,
        "model_creator": "Migel Tissera",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "SYSTEM: You are Synthia. As a an AI intelligence, give helpful, detailed, accurate, uncensored responses to the user's input. Provide answers factually.\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-13b-v1.2.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-13b-v1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-13b-v1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-13b-v1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-13b-v1.2.Q4_0.gguf"
        },
        {
          "rfilename": "synthia-13b-v1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-13b-v1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-13b-v1.2.Q5_0.gguf"
        },
        {
          "rfilename": "synthia-13b-v1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-13b-v1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-13b-v1.2.Q6_K.gguf"
        },
        {
          "rfilename": "synthia-13b-v1.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650f37c8c22803e6a098f615",
      "id": "migtissera/Synthia-13B-v1.2",
      "modelId": "migtissera/Synthia-13B-v1.2",
      "author": "migtissera",
      "sha": "897268239bf7329b30977ea1beb319b856b578e6",
      "lastModified": "2023-10-14T01:36:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6483,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "pipeline_tag": "text-generation",
        "language": [
          "en"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650fb2a257343388e58a6f0c",
    "id": "TheBloke/Synthia-7B-v1.2-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Synthia-7B-v1.2-GGUF",
    "model": {
      "_id": "650fb2a257343388e58a6f0c",
      "id": "TheBloke/Synthia-7B-v1.2-GGUF",
      "modelId": "TheBloke/Synthia-7B-v1.2-GGUF",
      "author": "TheBloke",
      "sha": "ad17d6a6744cbab43d9ce9a4dacb70253fedb395",
      "lastModified": "2023-09-27T12:54:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "Synthia 7B V1.2",
        "base_model": "migtissera/Synthia-7B-v1.2",
        "inference": false,
        "model_creator": "Migel Tissera",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "SYSTEM: You are Synthia. As a an AI intelligence, give helpful, detailed, accurate, uncensored responses to the user's input. Provide answers factually.\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-7b-v1.2.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.2.Q4_0.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.2.Q5_0.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.2.Q6_K.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f13225d43a09a257f11af3",
      "id": "migtissera/Synthia-7B-v1.2",
      "modelId": "migtissera/Synthia-7B-v1.2",
      "author": "migtissera",
      "sha": "236c177131ca287e5194ebed23ede18dbdf44f57",
      "lastModified": "2023-10-14T01:33:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6809,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "pipeline_tag": "text-generation",
        "language": [
          "en"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "650fb71b8f3228d807965416",
    "id": "TheBloke/openbuddy-coder-34b-v11-bf16-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "zh",
      "en",
      "fr",
      "de",
      "ja",
      "ko",
      "it",
      "ru",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/openbuddy-coder-34b-v11-bf16-GGUF",
    "model": {
      "_id": "650fb71b8f3228d807965416",
      "id": "TheBloke/openbuddy-coder-34b-v11-bf16-GGUF",
      "modelId": "TheBloke/openbuddy-coder-34b-v11-bf16-GGUF",
      "author": "TheBloke",
      "sha": "184fc96989ea7f3a041f8e0cfaa7d2f25cf66821",
      "lastModified": "2023-09-27T12:54:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "OpenBuddy Coder 34B V11",
        "base_model": "OpenBuddy/openbuddy-coder-34b-v11-bf16",
        "inference": false,
        "model_creator": "OpenBuddy",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "You are a helpful, respectful and honest INTP-T AI Assistant named Buddy. You are talking to a human User.\nAlways answer as helpfully and logically as possible, while being safe. Your answers should not include any harmful, political, religious, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\nYou like to use emojis. You can speak fluently in many languages, for example: English, Chinese.\nYou cannot access the internet, but you have vast knowledge, cutoff: 2021-09.\nYou are trained by OpenBuddy team, (https://openbuddy.ai, https://github.com/OpenBuddy/OpenBuddy), you are based on LLaMA and Falcon transformers model, not related to GPT or OpenAI.\n\nUser: {prompt}\nAssistant: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openbuddy-coder-34b-v11-bf16.Q2_K.gguf"
        },
        {
          "rfilename": "openbuddy-coder-34b-v11-bf16.Q3_K_L.gguf"
        },
        {
          "rfilename": "openbuddy-coder-34b-v11-bf16.Q3_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-coder-34b-v11-bf16.Q3_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-coder-34b-v11-bf16.Q4_0.gguf"
        },
        {
          "rfilename": "openbuddy-coder-34b-v11-bf16.Q4_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-coder-34b-v11-bf16.Q4_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-coder-34b-v11-bf16.Q5_0.gguf"
        },
        {
          "rfilename": "openbuddy-coder-34b-v11-bf16.Q5_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-coder-34b-v11-bf16.Q5_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-coder-34b-v11-bf16.Q6_K.gguf"
        },
        {
          "rfilename": "openbuddy-coder-34b-v11-bf16.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64edead1cf86e87fad070114",
      "id": "OpenBuddy/openbuddy-coder-34b-v11-bf16",
      "modelId": "OpenBuddy/openbuddy-coder-34b-v11-bf16",
      "author": "OpenBuddy",
      "sha": "6b511d6003afe4cd96f48901ce2becff1f3648d3",
      "lastModified": "2023-09-20T06:41:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Evaluation.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651004458c4b535a97fc9af9",
    "id": "TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 7,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "zh",
      "en",
      "fr",
      "de",
      "ja",
      "ko",
      "it",
      "ru",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF",
    "model": {
      "_id": "651004458c4b535a97fc9af9",
      "id": "TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF",
      "modelId": "TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF",
      "author": "TheBloke",
      "sha": "dfaf85268b925453175ffab73806013e0c197667",
      "lastModified": "2023-09-27T12:54:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "license": "llama2",
        "library_name": "transformers",
        "model_name": "OpenBuddy Llama2 34B V11.1",
        "base_model": "OpenBuddy/openbuddy-llama2-34b-v11.1-bf16",
        "inference": false,
        "model_creator": "OpenBuddy",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "You are a helpful, respectful and honest INTP-T AI Assistant named Buddy. You are talking to a human User.\nAlways answer as helpfully and logically as possible, while being safe. Your answers should not include any harmful, political, religious, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\nYou like to use emojis. You can speak fluently in many languages, for example: English, Chinese.\nYou cannot access the internet, but you have vast knowledge, cutoff: 2021-09.\nYou are trained by OpenBuddy team, (https://openbuddy.ai, https://github.com/OpenBuddy/OpenBuddy), you are based on LLaMA and Falcon transformers model, not related to GPT or OpenAI.\n\nUser: {prompt}\nAssistant: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openbuddy-llama2-34b-v11.1-bf16.Q2_K.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-34b-v11.1-bf16.Q3_K_L.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-34b-v11.1-bf16.Q3_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-34b-v11.1-bf16.Q3_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-34b-v11.1-bf16.Q4_0.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-34b-v11.1-bf16.Q4_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-34b-v11.1-bf16.Q4_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-34b-v11.1-bf16.Q5_0.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-34b-v11.1-bf16.Q5_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-34b-v11.1-bf16.Q5_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-34b-v11.1-bf16.Q6_K.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-34b-v11.1-bf16.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fa854320a2d04cc165845d",
      "id": "OpenBuddy/openbuddy-codellama2-34b-v11.1-bf16",
      "modelId": "OpenBuddy/openbuddy-codellama2-34b-v11.1-bf16",
      "author": "OpenBuddy",
      "sha": "1b361b3634bf59913b47c9dad1b138e99833472b",
      "lastModified": "2023-09-20T06:40:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15572,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6511ae8b5b4590211de0a25a",
    "id": "TheBloke/vicuna-33B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 13,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2302.13971",
      "arxiv:2306.05685",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/vicuna-33B-GGUF",
    "model": {
      "_id": "6511ae8b5b4590211de0a25a",
      "id": "TheBloke/vicuna-33B-GGUF",
      "modelId": "TheBloke/vicuna-33B-GGUF",
      "author": "TheBloke",
      "sha": "48aa7a766921b15d7f0369b90cc8de3c4491be6c",
      "lastModified": "2023-09-27T12:54:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2302.13971",
        "arxiv:2306.05685",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 13,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Vicuna 33B V1.3",
        "base_model": "lmsys/vicuna-33b-v1.3",
        "inference": false,
        "model_creator": "Large Model Systems Organization",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "vicuna-33b.Q2_K.gguf"
        },
        {
          "rfilename": "vicuna-33b.Q3_K_L.gguf"
        },
        {
          "rfilename": "vicuna-33b.Q3_K_M.gguf"
        },
        {
          "rfilename": "vicuna-33b.Q3_K_S.gguf"
        },
        {
          "rfilename": "vicuna-33b.Q4_0.gguf"
        },
        {
          "rfilename": "vicuna-33b.Q4_K_M.gguf"
        },
        {
          "rfilename": "vicuna-33b.Q4_K_S.gguf"
        },
        {
          "rfilename": "vicuna-33b.Q5_0.gguf"
        },
        {
          "rfilename": "vicuna-33b.Q5_K_M.gguf"
        },
        {
          "rfilename": "vicuna-33b.Q5_K_S.gguf"
        },
        {
          "rfilename": "vicuna-33b.Q6_K.gguf"
        },
        {
          "rfilename": "vicuna-33b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "649298d80489aff17d083afe",
      "id": "lmsys/vicuna-33b-v1.3",
      "modelId": "lmsys/vicuna-33b-v1.3",
      "author": "lmsys",
      "sha": "ef8d6becf883fb3ce52e3706885f761819477ab4",
      "lastModified": "2023-08-01T01:50:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2302.13971",
        "arxiv:2306.05685",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 16837,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 236,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "inference": false
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "h2oai/h2ogpt-chatbot",
        "h2oai/h2ogpt-chatbot2",
        "gsaivinay/open_llm_leaderboard",
        "Sharathhebbar24/One-stop-for-Open-source-models",
        "zeno-ml/chatbot-report",
        "gordonchan/h2oo",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "akashkj/H2OGPT",
        "ariel0330/h2osiri",
        "ccoreilly/aigua-xat",
        "hossamdaoud/Falcon40b_GSB",
        "AnonymousSub/Ayurveda_Chatbot",
        "wissamantoun/LLM_Detection_Attribution",
        "TheVortexProject/open_llm_leaderboard",
        "kelvin-t-lu/chatbot",
        "his0/h2ogpt-chatbot",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6513ea60584d106e62968bf3",
    "id": "TheBloke/law-LLM-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2309.09530",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/law-LLM-GGUF",
    "model": {
      "_id": "6513ea60584d106e62968bf3",
      "id": "TheBloke/law-LLM-GGUF",
      "modelId": "TheBloke/law-LLM-GGUF",
      "author": "TheBloke",
      "sha": "cc17fde87daae8456332600c6b36d48eead30259",
      "lastModified": "2023-09-27T12:54:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2309.09530",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "model_name": "Law LLM",
        "base_model": "AdaptLLM/law-LLM",
        "inference": false,
        "model_creator": "AdaptLLM",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "law-llm.Q2_K.gguf"
        },
        {
          "rfilename": "law-llm.Q3_K_L.gguf"
        },
        {
          "rfilename": "law-llm.Q3_K_M.gguf"
        },
        {
          "rfilename": "law-llm.Q3_K_S.gguf"
        },
        {
          "rfilename": "law-llm.Q4_0.gguf"
        },
        {
          "rfilename": "law-llm.Q4_K_M.gguf"
        },
        {
          "rfilename": "law-llm.Q4_K_S.gguf"
        },
        {
          "rfilename": "law-llm.Q5_0.gguf"
        },
        {
          "rfilename": "law-llm.Q5_K_M.gguf"
        },
        {
          "rfilename": "law-llm.Q5_K_S.gguf"
        },
        {
          "rfilename": "law-llm.Q6_K.gguf"
        },
        {
          "rfilename": "law-llm.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65085453dacc94cd6c379d52",
      "id": "AdaptLLM/law-LLM",
      "modelId": "AdaptLLM/law-LLM",
      "author": "AdaptLLM",
      "sha": "d6901051d6fd7abf3187e07a550511052ebb4f3c",
      "lastModified": "2023-10-21T11:47:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2309.09530",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 106,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "config": {
        "architectures": [
          "LLaMAForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "vikaswr/law"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "comparison.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00024-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00025-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00026-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00027-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00028-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00029-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00030-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00031-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00032-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model-00033-of-00033.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6513f263cc7684c9e422acef",
    "id": "TheBloke/sqlcoder-GGUF",
    "likes": 14,
    "private": false,
    "downloads": 28,
    "tags": [
      "transformers",
      "starcoder",
      "code",
      "text-generation",
      "en",
      "license:other",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/sqlcoder-GGUF",
    "model": {
      "_id": "6513f263cc7684c9e422acef",
      "id": "TheBloke/sqlcoder-GGUF",
      "modelId": "TheBloke/sqlcoder-GGUF",
      "author": "TheBloke",
      "sha": "ebcc0c2de66198fdefe7b3bc5fafd5923dbfc077",
      "lastModified": "2023-09-27T12:54:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "starcoder",
        "code",
        "text-generation",
        "en",
        "license:other",
        "region:us"
      ],
      "downloads": 28,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 14,
      "model-index": null,
      "config": {
        "model_type": "starcoder"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "license": "other",
        "library_name": "transformers",
        "tags": [
          "code"
        ],
        "metrics": [
          "code_eval"
        ],
        "model_name": "Sqlcoder",
        "base_model": "defog/sqlcoder",
        "inference": false,
        "model_creator": "Defog.ai",
        "model_type": "starcoder",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "sqlcoder.Q2_K.gguf"
        },
        {
          "rfilename": "sqlcoder.Q3_K_L.gguf"
        },
        {
          "rfilename": "sqlcoder.Q3_K_M.gguf"
        },
        {
          "rfilename": "sqlcoder.Q3_K_S.gguf"
        },
        {
          "rfilename": "sqlcoder.Q4_0.gguf"
        },
        {
          "rfilename": "sqlcoder.Q4_K_M.gguf"
        },
        {
          "rfilename": "sqlcoder.Q4_K_S.gguf"
        },
        {
          "rfilename": "sqlcoder.Q5_0.gguf"
        },
        {
          "rfilename": "sqlcoder.Q5_K_M.gguf"
        },
        {
          "rfilename": "sqlcoder.Q5_K_S.gguf"
        },
        {
          "rfilename": "sqlcoder.Q6_K.gguf"
        },
        {
          "rfilename": "sqlcoder.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64d6ae4e54bb9eb70414d321",
      "id": "defog/sqlcoder",
      "modelId": "defog/sqlcoder",
      "author": "defog",
      "sha": "bef4bcd10cc551fb3359a2ebc8f394f5e567f540",
      "lastModified": "2023-09-15T17:47:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "gpt_bigcode",
        "text-generation",
        "code",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7939,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 247,
      "model-index": null,
      "config": {
        "architectures": [
          "GPTBigCodeForCausalLM"
        ],
        "model_type": "gpt_bigcode"
      },
      "cardData": {
        "license": "other",
        "language": [
          "en"
        ],
        "metrics": [
          "code_eval"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "code"
        ],
        "inference": false
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "inference.py"
        },
        {
          "rfilename": "merges.txt"
        },
        {
          "rfilename": "pytorch_model-00001-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "vocab.json"
        }
      ]
    }
  },
  {
    "_id": "65140cda51c0141fa86b7d8b",
    "id": "TheBloke/U-Amethyst-20B-GGUF",
    "likes": 12,
    "private": false,
    "downloads": 31,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/U-Amethyst-20B-GGUF",
    "model": {
      "_id": "65140cda51c0141fa86b7d8b",
      "id": "TheBloke/U-Amethyst-20B-GGUF",
      "modelId": "TheBloke/U-Amethyst-20B-GGUF",
      "author": "TheBloke",
      "sha": "c8176ac8249c33c90e571e9a5bf5ccbf0a59f9b1",
      "lastModified": "2023-09-27T12:54:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 31,
      "library_name": "transformers",
      "likes": 12,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ],
        "model_name": "U-Amethyst 20B",
        "base_model": "Undi95/U-Amethyst-20B",
        "inference": false,
        "model_creator": "Undi",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "u-amethyst-20b.Q2_K.gguf"
        },
        {
          "rfilename": "u-amethyst-20b.Q3_K_L.gguf"
        },
        {
          "rfilename": "u-amethyst-20b.Q3_K_M.gguf"
        },
        {
          "rfilename": "u-amethyst-20b.Q3_K_S.gguf"
        },
        {
          "rfilename": "u-amethyst-20b.Q4_0.gguf"
        },
        {
          "rfilename": "u-amethyst-20b.Q4_K_M.gguf"
        },
        {
          "rfilename": "u-amethyst-20b.Q4_K_S.gguf"
        },
        {
          "rfilename": "u-amethyst-20b.Q5_0.gguf"
        },
        {
          "rfilename": "u-amethyst-20b.Q5_K_M.gguf"
        },
        {
          "rfilename": "u-amethyst-20b.Q5_K_S.gguf"
        },
        {
          "rfilename": "u-amethyst-20b.Q6_K.gguf"
        },
        {
          "rfilename": "u-amethyst-20b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6510733bf2e0c7dc7ef8d69b",
      "id": "Undi95/U-Amethyst-20B",
      "modelId": "Undi95/U-Amethyst-20B",
      "author": "Undi95",
      "sha": "c0cbe0b3c88041bb6beef27dbe85146af8dddec9",
      "lastModified": "2023-09-25T13:22:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4416,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 19666682880
        },
        "total": 19994362880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00005.safetensors"
        },
        {
          "rfilename": "model-00002-of-00005.safetensors"
        },
        {
          "rfilename": "model-00003-of-00005.safetensors"
        },
        {
          "rfilename": "model-00004-of-00005.safetensors"
        },
        {
          "rfilename": "model-00005-of-00005.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65145063a18b3317c352bc2a",
    "id": "TheBloke/Marcoroni-70B-v1-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 13,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Marcoroni-70B-v1-GGUF",
    "model": {
      "_id": "65145063a18b3317c352bc2a",
      "id": "TheBloke/Marcoroni-70B-v1-GGUF",
      "modelId": "TheBloke/Marcoroni-70B-v1-GGUF",
      "author": "TheBloke",
      "sha": "c247e2875eb2e642a2a1568775eaffaaf0edddcc",
      "lastModified": "2023-09-27T17:54:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 13,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "AIDC-ai-business/Marcoroni-70B-v1",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "AIDC-ai-business",
        "model_name": "Marcoroni 70B v1",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q2_K.gguf"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q3_K_L.gguf"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q3_K_M.gguf"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q3_K_S.gguf"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q4_0.gguf"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q4_K_M.gguf"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q4_K_S.gguf"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q5_0.gguf"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q5_K_M.gguf"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q5_K_S.gguf"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "marcoroni-70b-v1.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "650b07e407c3bfaaa8657bbf",
      "id": "AIDC-ai-business/Marcoroni-70B-v1",
      "modelId": "AIDC-ai-business/Marcoroni-70B-v1",
      "author": "AIDC-ai-business",
      "sha": "55a30d29db194832c0b5de1392a6598a63582144",
      "lastModified": "2023-09-20T16:59:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8609,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 17,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Srelan/AIDC-ai-business-Marcoroni-70B-v1",
        "lep512/AIDC-ai-business-Marcoroni-70B-v1",
        "guillelucero/AIDC-ai-business-Marcoroni-70B-v1",
        "Utopian2/AIDC-ai-business-Marcoroni-70B-v1",
        "Germinal/AIDC-ai-business-Marcoroni-70B-v1",
        "monkebonk/AIDC-ai-business-Marcoroni-70B-v1",
        "ziedammak/AIDC-ai-business-Marcoroni-70B-v1"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65145594e31c0e2e3dfabe9a",
    "id": "TheBloke/Mistral-7B-v0.1-GGUF",
    "likes": 144,
    "private": false,
    "downloads": 3163,
    "tags": [
      "transformers",
      "mistral",
      "pretrained",
      "text-generation",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Mistral-7B-v0.1-GGUF",
    "model": {
      "_id": "65145594e31c0e2e3dfabe9a",
      "id": "TheBloke/Mistral-7B-v0.1-GGUF",
      "modelId": "TheBloke/Mistral-7B-v0.1-GGUF",
      "author": "TheBloke",
      "sha": "d4ae605152c8de0d6570cf624c083fa57dd0d551",
      "lastModified": "2023-09-28T22:42:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "pretrained",
        "text-generation",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3163,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 144,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "mistralai/Mistral-7B-v0.1",
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Mistral AI",
        "model_name": "Mistral 7B v0.1",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke",
        "tags": [
          "pretrained"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-7b-v0.1.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-7b-v0.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-7b-v0.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-v0.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-v0.1.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-7b-v0.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-v0.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-v0.1.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-7b-v0.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-v0.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-v0.1.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-7b-v0.1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650aedb6238a644cb93a52c3",
      "id": "mistralai/Mistral-7B-v0.1",
      "modelId": "mistralai/Mistral-7B-v0.1",
      "author": "mistralai",
      "sha": "5e9c98b96d071dce59368012254c55b0ec6f8658",
      "lastModified": "2023-10-12T17:52:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "pretrained",
        "en",
        "arxiv:2310.06825",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 288310,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1573,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "pipeline_tag": "text-generation",
        "language": [
          "en"
        ],
        "tags": [
          "pretrained"
        ],
        "inference": {
          "parameters": {
            "temperature": 0.7
          }
        }
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Vokturz/can-it-run-llm",
        "Aabbhishekk/MistralQnA",
        "pseudolab/MistralMED_Chat",
        "Statical/STC-LLM-CHAT",
        "Tonic/MistralMED_Chat",
        "pseudolab/GaiaMiniMed",
        "CosmoAI/BhagwatGeeta",
        "airesai/Mistral-7B-v0.1-Demo",
        "zhuraavl/mistralai-Mistral-7B-v0.1",
        "ridges/mistralai-Mistral-7B-v0.1",
        "jeanbaptdzd/mistralai-Mistral-7B-v0.1",
        "ravichodry/CHATGPT-LLAMA2",
        "ardances/mistralai-Mistral-7B-v0.1",
        "InvisableClearCoat101/mistralai-Mistral-7B-v0.1",
        "Orami01/Cha_with_CSV_using_Llama2",
        "mdkhalid/mistralai-Mistral-7B-v0.1",
        "alexkueck/ChatBotLI2Klein",
        "focusit/ksv",
        "CosmoAI/Web_QnA",
        "Dominik72/LLM",
        "Jake3000/mistralai-Mistral-7B-v0.1",
        "swagatdasgupta/mistralai-Mistral-7B-v0.1",
        "thibz/Testing-Mistral-v01",
        "mileszim/Mistral-7B-v0.1-Demo",
        "andreyz/mistralai-Mistral-7B-v0.1",
        "thibz/mistralai-Mistral-7B-v0.1",
        "mattnosleep/mistralai-Mistral-7B-v0.1",
        "nmd/mistralai-Mistral-7B-v0.1",
        "OreoAu/mistralai-Mistral-7B-v0.1",
        "Wusul/mistralai-Mistral-7B-v0.1",
        "olanigan/Mistral-7B-v0.1",
        "neridonk/mistralai-Mistral-7B-v0.1",
        "apurv101/mistralai-Mistral-7B-v0.1",
        "KazeDevID/mistralai-Mistral-7B-v0.1",
        "Yerrramsetty/mistralai-Mistral-7B-v0.1",
        "mihaivl90/mistralai-Mistral-7B-v0.1",
        "xxdoomedxx/mistralai-Mistral-7B-v0.1",
        "nadaguy/mistralai-Mistral-7B-v0.1",
        "Jeancattan/mistralai-Mistral-7B-v0.1",
        "Alexxander/mistralai-Mistral-7B-v0.1",
        "Pikachiu/mistralai-Mistral-7B-v0.1",
        "mgokg/mistralai-Mistral-7B-v0.1",
        "ni-volk/mistralai-Mistral-7B-v0.1",
        "GreenTeaLatte/Test-ChatBot-ChatUI",
        "Herschelle/mistralai-Mistral-7B-v0.1",
        "bradshimmin/mistralai-Mistral-7B-v0.1",
        "fb80/mistralai-Mistral-7B-v0.1",
        "GreenTeaLatte/Test-ChatBot-ChatUI-2",
        "DiogenesX/mistralai-Mistral-7B-v0.1",
        "niveone/mistralai-Mistral-7B-v0.1",
        "mxtkde/mistralai-Mistral-7B-v0.1",
        "sosoai/mistralai-Mistral-7B-v0.1",
        "quangnhan145/mistralai-Mistral-7B-v0.1",
        "scafati98/mistralai-Mistral-7B-v0.1",
        "quangnhan145/mistralai-Mistral-7B-v0.122",
        "Gainchanger/mistralai-Mistral-7B-v0.1",
        "MarkoVidrih/mistralai-Mistral-7B-v0.1",
        "Groenewaldt/mistralai-Mistral-7B-v0.1",
        "xsa-face/mistralai-Mistral-7B-v0.1",
        "Groenewaldt/mistralai-Mistral-7b",
        "binderjoe/mistralai-Mistral-7B-v0.1",
        "codewithjss/mistralai-1",
        "flaviojoshua/mistralai-Mistral-7B-v0.1",
        "sathayen/Mistral-7B-v0.1",
        "aiuser1/chat-with-pdf-test-amlan",
        "Mualzaher/mistralai-Mistral-7B-v0.1",
        "webman/mistralai-Mistral-7B-v0.1",
        "amilenovic/mistralai-Mistral-7B-v0.1",
        "ZabieruJetixYT/mistralai-Mistral-7B-v0.1",
        "roberttony165/mistralai-Mistral-7B-v0.1",
        "XaaSStaX/mistralai-Mistral-7B-v0.1",
        "wayandadang/mistralai-Mistral-7B-v0.1",
        "Kevingduck/mistralai-Mistral-7B-v0.1",
        "0xshervin/mistralai-Mistral-7B-v0.1",
        "AliCampbellKhaya/mistralai-Mistral-7B-v0.1",
        "Wawaa/omni_bot",
        "imjunaidafzal/can-it-run-llm",
        "bpatel644/mistralai-Mistral-7B-v0.1",
        "modelexio/mistralai-Mistral-7B-v0.1",
        "ybl0000/mistralai-Mistral-7B-v0.1",
        "vahjela17/mistralai-Mistral-7B-v0.1",
        "muellerzr/can-it-run-llm",
        "xelosz/mistralai-Mistral-7B-v0.1",
        "NimraAkhtar/mistralai-Mistral-7B-v0.1",
        "stets/mistralai-Mistral-7B-v0.1",
        "luptonicedtea/mistralai-Mistral-7B-v0.1",
        "VanceMiller/mistralai-Mistral-7B-v0.1",
        "FreddieSpaghetti/mistralai-Mistral-7B-v0.1",
        "NCKDCOK/mistralai-Mistral-7B-v0.1",
        "HunterZSYT/mistralai-Mistral-7B-v0.1",
        "AnishKumbhar/mistralai-Mistral-7B-v0.1",
        "DaxSudo/mistralai-Mistral-7B-v0.1",
        "NeuralLeapDev/mistralai-Mistral-7B-v0.1_Shehan",
        "satpalsingh2021/mistralai-Mistral-7B-v0.1",
        "Reza2kn/mistralai-Mistral-7B-v0.1",
        "Sniffe/mistralai-Mistral-7B-v0.1",
        "shridurga/Story_Generate",
        "maxamed123/mistralai-Mistral-7B-v0.1",
        "Fatima-99/mistralai-Mistral-7B-v0.1",
        "beyond-repair/mistralai-Mistral-7B-v0.1",
        "gar1t/mistralai-Mistral-7B-v0.1",
        "feisarx86/mistralai-Mistral-7B-v0.1",
        "alfonsovelp/mistralai-Mistral-7B-v0.1",
        "johntheguyperson/mistralai-Mistral-7B-v0.1",
        "shideqin/mistralai-Mistral-7B-v0.1",
        "jfelipenc/mistralmed-experiment",
        "amizya/mistralai-Mistral-7B-v0.1",
        "pseudolab/medical-chatbot",
        "ehristoforu/TestDocker",
        "ALIOJ/mistralai-Mistral-7B-v0.1",
        "shethjenil/educhatbot"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651462ec463c4fd767f2fe08",
    "id": "TheBloke/Athena-v3-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 42,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Athena-v3-GGUF",
    "model": {
      "_id": "651462ec463c4fd767f2fe08",
      "id": "TheBloke/Athena-v3-GGUF",
      "modelId": "TheBloke/Athena-v3-GGUF",
      "author": "TheBloke",
      "sha": "d5b27a62a8fdbd461e8cb02430dbd7af7a424209",
      "lastModified": "2023-09-27T17:23:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 42,
      "library_name": "transformers",
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "IkariDev/Athena-v3",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "IkariDev and Undi95",
        "model_name": "Athena V3",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "athena-v3.Q2_K.gguf"
        },
        {
          "rfilename": "athena-v3.Q3_K_L.gguf"
        },
        {
          "rfilename": "athena-v3.Q3_K_M.gguf"
        },
        {
          "rfilename": "athena-v3.Q3_K_S.gguf"
        },
        {
          "rfilename": "athena-v3.Q4_0.gguf"
        },
        {
          "rfilename": "athena-v3.Q4_K_M.gguf"
        },
        {
          "rfilename": "athena-v3.Q4_K_S.gguf"
        },
        {
          "rfilename": "athena-v3.Q5_0.gguf"
        },
        {
          "rfilename": "athena-v3.Q5_K_M.gguf"
        },
        {
          "rfilename": "athena-v3.Q5_K_S.gguf"
        },
        {
          "rfilename": "athena-v3.Q6_K.gguf"
        },
        {
          "rfilename": "athena-v3.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "65132a16cc7684c9e4087fe3",
      "id": "IkariDev/Athena-v3",
      "modelId": "IkariDev/Athena-v3",
      "author": "IkariDev",
      "sha": "5e4024b6694bb13f1a81ce4277ac9141f0b226df",
      "lastModified": "2023-10-03T14:39:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6671,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65146b42c75a3d4c44e41667",
    "id": "TheBloke/Mistral-7B-Instruct-v0.1-GGUF",
    "likes": 231,
    "private": false,
    "downloads": 5659,
    "tags": [
      "transformers",
      "mistral",
      "finetuned",
      "text-generation",
      "license:apache-2.0",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Mistral-7B-Instruct-v0.1-GGUF",
    "model": {
      "_id": "65146b42c75a3d4c44e41667",
      "id": "TheBloke/Mistral-7B-Instruct-v0.1-GGUF",
      "modelId": "TheBloke/Mistral-7B-Instruct-v0.1-GGUF",
      "author": "TheBloke",
      "sha": "45167a542b6fa64a14aea61a4c468bbbf9f258a8",
      "lastModified": "2023-09-28T22:43:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "finetuned",
        "text-generation",
        "license:apache-2.0",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5659,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 231,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "mistralai/Mistral-7B-Instruct-v0.1",
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Mistral AI",
        "model_name": "Mistral 7B Instruct v0.1",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "<s>[INST]{prompt} [/INST]\n",
        "quantized_by": "TheBloke",
        "tags": [
          "finetuned"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "coqui/voice-chat-with-mistral",
        "limcheekin/Mistral-7B-Instruct-v0.1-GGUF",
        "coqui/ml-trivia",
        "coqui/voice-chat-with-zephyr",
        "faisalhr1997/chat-ggml",
        "captain-awesome/docuverse",
        "Cran-May/Mistril-7b",
        "Dawoodthouseef/Mistral-7b",
        "Dawoodthouseef/Mistral-7B-V2",
        "jeff31415/Mistral-7B-Instruct-v0.1-GGUF",
        "Cloxl/Mistral-7B-Instruct-v0.1-GGUF",
        "Erala/Mistral-7B-Instruct-v0.1-GGUF",
        "Dawoodthouseef/Mistril-7b",
        "Cran-May/Mistral-7b2",
        "dkdaniz/katara",
        "srossitto79/AgentLlama007B",
        "faldeus0092/mistral7b-simple-qa",
        "tahvili/localGPT-test",
        "lamtung16/Mistral-7b",
        "lamtung16/Mistral-running-answer",
        "lalanikarim/ai-chatbot",
        "lalanikarim/ai-chatbot-conversational",
        "vikkaird/chat-Vikk"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-7b-instruct-v0.1.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-7b-instruct-v0.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-7b-instruct-v0.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-instruct-v0.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-instruct-v0.1.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-7b-instruct-v0.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-instruct-v0.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-instruct-v0.1.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-7b-instruct-v0.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-instruct-v0.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-instruct-v0.1.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-7b-instruct-v0.1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65143cd8e31c0e2e3df713e5",
      "id": "mistralai/Mistral-7B-Instruct-v0.1",
      "modelId": "mistralai/Mistral-7B-Instruct-v0.1",
      "author": "mistralai",
      "sha": "7ad5799710574ba1c1d953eba3077af582f3a773",
      "lastModified": "2023-10-11T12:31:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "finetuned",
        "arxiv:2310.06825",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 243955,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 909,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "pipeline_tag": "text-generation",
        "tags": [
          "finetuned"
        ],
        "inference": {
          "parameters": {
            "temperature": 0.7
          }
        }
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Vokturz/can-it-run-llm",
        "osanseviero/mistral-super-fast",
        "coqui/voice-chat-with-mistral",
        "DarwinAnim8or/Mistral-Chat",
        "limcheekin/Mistral-7B-Instruct-v0.1-GGUF",
        "coqui/ml-trivia",
        "hysts/mistral-7b",
        "ylacombe/accessible-mistral",
        "SoAp9035/mistral-7b-fast-chat",
        "Tomoniai/Demo_Mistral_Chat",
        "awacke1/MistralCoder",
        "langvision/mistral-7b-chat",
        "ahmadawais/Mistral-Chat",
        "joshuasundance/langchain-streamlit-demo",
        "rishiraj/mistral",
        "FlipTip/ChatBot",
        "awacke1/MistralGradioFast",
        "awacke1/MistralAndABardGoRoleplaying",
        "awacke1/Mistral_Ultimate_Chords_and_Lyrics_Writer",
        "cedpsam/mistral_openorca_lamacpp",
        "awacke1/VoiceChatMistral",
        "AchyuthGamer/OpenGPT-Chat",
        "Abhaykoul/HelpingAI-t2",
        "gojiteji/mistral-7b-fast-chat-with-Japanese-MT",
        "lfoppiano/document-qa",
        "sunil448832/retrieval-augment-generation",
        "CazC/smallville",
        "thibz/mistralai-Mistral-7B-Instruct-v0.1",
        "BobArctor2070/mistralai-Mistral-7B-Instruct-v0.1",
        "mattshumer/mistral7b-instruct-demo",
        "PeepDaSlan9/mistralai-Mistral-7B-Instruct-v0.1",
        "G-bot/mistralai-Mistral-7B-Instruct-v0.1",
        "deniandriancode/trescha-chatbot",
        "zjrwtx/mistral-super-fast",
        "YUCHUL/mistralai-Mistral-7B-Instruct-v0.1",
        "dionysio211/mistral-super-fast-basegpt",
        "Carreraella/mistral-super-fast",
        "WebDUh1/mistralai-Mistral-7B-Instruct-v0.1",
        "Johan09033/mistralai-Mistral-7B-Instruct-v0.1",
        "hossamdaoud/mistral-super-fast",
        "Mahender/chaatbot",
        "alihs/mistralai-Mistral-7B-Instruct-v0.1",
        "jeff31415/Mistral-7B-Instruct-v0.1-GGUF",
        "Cloxl/Mistral-7B-Instruct-v0.1-GGUF",
        "Erala/Mistral-7B-Instruct-v0.1-GGUF",
        "jsaplication/meu-assistente",
        "alejandroguille/sooft",
        "tx3bas/Mistral_tx3",
        "deniandriancode/mistral-chat-bot",
        "Proxor/mistralai-Mistral-7B-Instruct-v0.1",
        "colornative/mistral-super-fast",
        "YaBoyFathoM/ANNSfaqbot",
        "santoshvutukuri/mistralai-Mistral-7B-Instruct-chat",
        "daymos2/mistralai-Mistral-7B-Instruct-v0.1",
        "Cran-May/mistral7b-instruct-demo",
        "bistromd/Mistral",
        "reonjy/mistral-7b-instruct",
        "mfernezir/mistral-super-fast",
        "DavidFernandes/Mistral_7B_Instruct",
        "Buck3tHead/mistralai-Mistral-7B-Instruct-v0.1",
        "tx3bas/Ytb-fast",
        "Skier8402/mistral-super-fast",
        "Whiteknightai2/mistralai-Mistral-7B-Instruct-v0.1",
        "himuken/mistral-super-fast",
        "heidornj/mistral-super-fast",
        "jacobwilsonx/Demo_Mistral_Chat",
        "kunihiros/mistralai-Mistral-7B-Instruct-v0.1",
        "sanket09/mistral-super-fast",
        "TogetherAI/EinfachLlaMistral",
        "ckarande/mistralai-Mistral-7B-Instruct-v0.1",
        "gauravam/chat",
        "gauravam/mistralai-Mistral-7B-Instruct-v0.1",
        "ItsSapde/mistral-super-fast",
        "pragneshbarik/ikigai-chat",
        "pragneshbarik/mistral-super-fast",
        "pragneshbarik/mistral-7b",
        "randeom/mistral-super-fast",
        "KyleIsaacs/mistral-super-fast",
        "bonomg/mistral-super-fast",
        "pooroligarch/mistral-super-fast",
        "mies8888/mistralai-Mistral-7B-Instruct-v0.1",
        "vivekm/mistralchat-playground",
        "deniandriancode/akari-chatbot",
        "KyleIsaacs/mistralai-Mistral-7B-Instruct-v0.1",
        "pyakhurel/test",
        "imjunaidafzal/can-it-run-llm",
        "xsa-face/mistralai-Mistral-7B-Instruct-v0.1",
        "carolanderson/llm-explorer",
        "huggingfacejs/text-generation-Mistral-7B-Instruct",
        "pyakhurel/test-finetuned",
        "muellerzr/can-it-run-llm",
        "pyakhurel/new-try",
        "bohmian/chat_with_earnings_call",
        "deniandriancode/minato-chatbot",
        "derek-thomas/RAGDemo",
        "dragonz007/mistralai-Mistral-7B-Instruct-v0.1",
        "deniandriancode/duck-chatbot",
        "Darshansundeep/mistralai-Mistral-7B-Instruct-v0.1",
        "TheKitten/MistralCoder-Chat",
        "deniandriancode/trescha-stranger-chatbot",
        "deniandriancode/yukipedia-chatbot",
        "rphrp1985/sel-test-proxy",
        "tbboukhari/INF-LLM",
        "joheras/suicide-intent",
        "AnishKumbhar/Chatty",
        "dhanilka/mistral-instruct-model",
        "ethanrom/insuranec-chat",
        "ethanrom/cima-free-chat",
        "dileepdaji/anchor",
        "JSP/demo",
        "hossamdaoud/mistral-B7",
        "JSP/article",
        "dileepdaji/demo",
        "Looming/mistralai-Mistral-7B-Instruct-v0.1",
        "cybtek/mistralai-Mistral-7B-Instruct-v0.1",
        "ethanrom/tic_tac_toe_with_Mistral-7B",
        "Sapiensia/arch1v3s-talks",
        "BoldStudio/Text-To-Title",
        "tmarafon2/Mistral_7b_API",
        "manjunathshiva/Grade3-Dairy-SOP-BirlaBrainiacs",
        "dileepdaji/article22",
        "eaglelandsonce/streamlitmistraltest",
        "SuperSecureHuman/mistral-7b-fast-chat",
        "manjunathshiva/Bhagavad-Gita-GPT",
        "stellarshank/Mistral-Chat",
        "vikkaird/Mistral-Vikk",
        "ethanrom/GiTM-entry",
        "pigeonium/ium-1.5",
        "vikkaird/chat-Vikk",
        "illioran/mistralai-Mistral-7B-Instruct-v0.1",
        "Dev18/mistral"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6514710dfe79293513e763e0",
    "id": "TheBloke/openbuddy-openllama-7B-v12-bf16-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 11,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "zh",
      "en",
      "fr",
      "de",
      "ja",
      "ko",
      "it",
      "ru",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/openbuddy-openllama-7B-v12-bf16-GGUF",
    "model": {
      "_id": "6514710dfe79293513e763e0",
      "id": "TheBloke/openbuddy-openllama-7B-v12-bf16-GGUF",
      "modelId": "TheBloke/openbuddy-openllama-7B-v12-bf16-GGUF",
      "author": "TheBloke",
      "sha": "96c207968fcb24a3393f26c67bfe81146a5f70d8",
      "lastModified": "2023-09-27T18:20:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 11,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "OpenBuddy/openbuddy-openllama-7b-v12-bf16",
        "inference": false,
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "OpenBuddy",
        "model_name": "OpenBuddy OpenLlama 7B v12",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "You are a helpful, respectful and honest INTP-T AI Assistant named Buddy. You are talking to a human User.\nAlways answer as helpfully and logically as possible, while being safe. Your answers should not include any harmful, political, religious, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\nYou like to use emojis. You can speak fluently in many languages, for example: English, Chinese.\nYou cannot access the internet, but you have vast knowledge, cutoff: 2021-09.\nYou are trained by OpenBuddy team, (https://openbuddy.ai, https://github.com/OpenBuddy/OpenBuddy), you are based on LLaMA and Falcon transformers model, not related to GPT or OpenAI.\n\nUser: {prompt}\nAssistant: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openbuddy-openllama-7b-v12-bf16.Q2_K.gguf"
        },
        {
          "rfilename": "openbuddy-openllama-7b-v12-bf16.Q3_K_L.gguf"
        },
        {
          "rfilename": "openbuddy-openllama-7b-v12-bf16.Q3_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-openllama-7b-v12-bf16.Q3_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-openllama-7b-v12-bf16.Q4_0.gguf"
        },
        {
          "rfilename": "openbuddy-openllama-7b-v12-bf16.Q4_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-openllama-7b-v12-bf16.Q4_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-openllama-7b-v12-bf16.Q5_0.gguf"
        },
        {
          "rfilename": "openbuddy-openllama-7b-v12-bf16.Q5_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-openllama-7b-v12-bf16.Q5_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-openllama-7b-v12-bf16.Q6_K.gguf"
        },
        {
          "rfilename": "openbuddy-openllama-7b-v12-bf16.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6509230aed23af2c5d0ea348",
      "id": "OpenBuddy/openbuddy-openllama-7b-v12-bf16",
      "modelId": "OpenBuddy/openbuddy-openllama-7b-v12-bf16",
      "author": "OpenBuddy",
      "sha": "bb94ff691996484b1a9d899a6c0956ef6750d86a",
      "lastModified": "2023-09-20T06:40:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7005,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6515441db339549616d83e99",
    "id": "TheBloke/Emerhyst-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 16,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Emerhyst-13B-GGUF",
    "model": {
      "_id": "6515441db339549616d83e99",
      "id": "TheBloke/Emerhyst-13B-GGUF",
      "modelId": "TheBloke/Emerhyst-13B-GGUF",
      "author": "TheBloke",
      "sha": "2ac33086a1852f80dc72b38df52b14b4a288d400",
      "lastModified": "2023-09-28T09:22:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 16,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/Emerhyst-13B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Emerhyst 13B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "emerhyst-13b.Q2_K.gguf"
        },
        {
          "rfilename": "emerhyst-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "emerhyst-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "emerhyst-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "emerhyst-13b.Q4_0.gguf"
        },
        {
          "rfilename": "emerhyst-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "emerhyst-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "emerhyst-13b.Q5_0.gguf"
        },
        {
          "rfilename": "emerhyst-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "emerhyst-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "emerhyst-13b.Q6_K.gguf"
        },
        {
          "rfilename": "emerhyst-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65143b3232fed9496aae502c",
      "id": "Undi95/Emerhyst-13B",
      "modelId": "Undi95/Emerhyst-13B",
      "author": "Undi95",
      "sha": "457801c360e7ac2784ffa3d0626c1a2733e62396",
      "lastModified": "2023-09-27T15:23:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8376,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688184320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00013.safetensors"
        },
        {
          "rfilename": "model-00002-of-00013.safetensors"
        },
        {
          "rfilename": "model-00003-of-00013.safetensors"
        },
        {
          "rfilename": "model-00004-of-00013.safetensors"
        },
        {
          "rfilename": "model-00005-of-00013.safetensors"
        },
        {
          "rfilename": "model-00006-of-00013.safetensors"
        },
        {
          "rfilename": "model-00007-of-00013.safetensors"
        },
        {
          "rfilename": "model-00008-of-00013.safetensors"
        },
        {
          "rfilename": "model-00009-of-00013.safetensors"
        },
        {
          "rfilename": "model-00010-of-00013.safetensors"
        },
        {
          "rfilename": "model-00011-of-00013.safetensors"
        },
        {
          "rfilename": "model-00012-of-00013.safetensors"
        },
        {
          "rfilename": "model-00013-of-00013.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65154bdcfccbf319e632623f",
    "id": "TheBloke/Emerhyst-20B-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 49,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Emerhyst-20B-GGUF",
    "model": {
      "_id": "65154bdcfccbf319e632623f",
      "id": "TheBloke/Emerhyst-20B-GGUF",
      "modelId": "TheBloke/Emerhyst-20B-GGUF",
      "author": "TheBloke",
      "sha": "d85c9c4b438c24a9e5738f952955cdce7e18c045",
      "lastModified": "2023-09-28T09:57:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 49,
      "library_name": "transformers",
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/Emerhyst-20B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Emerhyst 20B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "emerhyst-20b.Q2_K.gguf"
        },
        {
          "rfilename": "emerhyst-20b.Q3_K_L.gguf"
        },
        {
          "rfilename": "emerhyst-20b.Q3_K_M.gguf"
        },
        {
          "rfilename": "emerhyst-20b.Q3_K_S.gguf"
        },
        {
          "rfilename": "emerhyst-20b.Q4_0.gguf"
        },
        {
          "rfilename": "emerhyst-20b.Q4_K_M.gguf"
        },
        {
          "rfilename": "emerhyst-20b.Q4_K_S.gguf"
        },
        {
          "rfilename": "emerhyst-20b.Q5_0.gguf"
        },
        {
          "rfilename": "emerhyst-20b.Q5_K_M.gguf"
        },
        {
          "rfilename": "emerhyst-20b.Q5_K_S.gguf"
        },
        {
          "rfilename": "emerhyst-20b.Q6_K.gguf"
        },
        {
          "rfilename": "emerhyst-20b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651370f1b4a3c844a7c9cd72",
      "id": "Undi95/Emerhyst-20B",
      "modelId": "Undi95/Emerhyst-20B",
      "author": "Undi95",
      "sha": "e4c23af4f5dd88cb27d245e2bfc3b81db652632c",
      "lastModified": "2023-09-27T00:59:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 13322,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 20,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 19994362880
        },
        "total": 19994362880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00005.safetensors"
        },
        {
          "rfilename": "model-00002-of-00005.safetensors"
        },
        {
          "rfilename": "model-00003-of-00005.safetensors"
        },
        {
          "rfilename": "model-00004-of-00005.safetensors"
        },
        {
          "rfilename": "model-00005-of-00005.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65155be7bdeba50196314660",
    "id": "TheBloke/leo-hessianai-13B-chat-bilingual-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 12,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "de",
      "dataset:LeoLM/OpenSchnabeltier",
      "dataset:OpenAssistant/OASST-DE",
      "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
      "dataset:FreedomIntelligence/evol-instruct-deutsch",
      "dataset:LeoLM/German_Poems",
      "dataset:LeoLM/German_Songs",
      "dataset:garage-bAInd/Open-Platypus",
      "dataset:WizardLM/WizardLM_evol_instruct_70k",
      "dataset:bjoernp/oasst25-08-23-filtered",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/leo-hessianai-13B-chat-bilingual-GGUF",
    "model": {
      "_id": "65155be7bdeba50196314660",
      "id": "TheBloke/leo-hessianai-13B-chat-bilingual-GGUF",
      "modelId": "TheBloke/leo-hessianai-13B-chat-bilingual-GGUF",
      "author": "TheBloke",
      "sha": "c7d2d859f2076896d69051ce003926d11462b3e0",
      "lastModified": "2023-09-28T11:11:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "de",
        "dataset:LeoLM/OpenSchnabeltier",
        "dataset:OpenAssistant/OASST-DE",
        "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
        "dataset:FreedomIntelligence/evol-instruct-deutsch",
        "dataset:LeoLM/German_Poems",
        "dataset:LeoLM/German_Songs",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:WizardLM/WizardLM_evol_instruct_70k",
        "dataset:bjoernp/oasst25-08-23-filtered",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 12,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "LeoLM/leo-hessianai-13b-chat-bilingual",
        "datasets": [
          "LeoLM/OpenSchnabeltier",
          "OpenAssistant/OASST-DE",
          "FreedomIntelligence/alpaca-gpt4-deutsch",
          "FreedomIntelligence/evol-instruct-deutsch",
          "LeoLM/German_Poems",
          "LeoLM/German_Songs",
          "garage-bAInd/Open-Platypus",
          "WizardLM/WizardLM_evol_instruct_70k",
          "bjoernp/oasst25-08-23-filtered"
        ],
        "inference": false,
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "LAION LeoLM",
        "model_name": "Leo Hessianai 13B Chat Bilingual",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "leo-hessianai-13b-chat-bilingual.Q2_K.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat-bilingual.Q3_K_L.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat-bilingual.Q3_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat-bilingual.Q3_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat-bilingual.Q4_0.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat-bilingual.Q4_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat-bilingual.Q4_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat-bilingual.Q5_0.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat-bilingual.Q5_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat-bilingual.Q5_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat-bilingual.Q6_K.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat-bilingual.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fd7ddd4c8924c4fec278b4",
      "id": "LeoLM/leo-hessianai-13b-chat-bilingual",
      "modelId": "LeoLM/leo-hessianai-13b-chat-bilingual",
      "author": "LeoLM",
      "sha": "e4ce5a84d1090a35e3a696a72250d4874a6eb11b",
      "lastModified": "2023-09-29T13:16:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "en",
        "de",
        "dataset:LeoLM/OpenSchnabeltier",
        "dataset:OpenAssistant/OASST-DE",
        "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
        "dataset:FreedomIntelligence/evol-instruct-deutsch",
        "dataset:LeoLM/German_Poems",
        "dataset:LeoLM/German_Songs",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:WizardLM/WizardLM_evol_instruct_70k",
        "dataset:bjoernp/oasst25-08-23-filtered",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 523,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoModelForCausalLM": "modeling_flash_llama.LlamaForCausalLM"
        }
      },
      "cardData": {
        "datasets": [
          "LeoLM/OpenSchnabeltier",
          "OpenAssistant/OASST-DE",
          "FreedomIntelligence/alpaca-gpt4-deutsch",
          "FreedomIntelligence/evol-instruct-deutsch",
          "LeoLM/German_Poems",
          "LeoLM/German_Songs",
          "garage-bAInd/Open-Platypus",
          "WizardLM/WizardLM_evol_instruct_70k",
          "bjoernp/oasst25-08-23-filtered"
        ],
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "modeling_flash_llama.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651570169d3b940a900bb730",
    "id": "TheBloke/leo-hessianai-13B-chat-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 10,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "de",
      "dataset:LeoLM/OpenSchnabeltier",
      "dataset:OpenAssistant/OASST-DE",
      "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
      "dataset:FreedomIntelligence/evol-instruct-deutsch",
      "dataset:LeoLM/German_Poems",
      "dataset:LeoLM/German_Songs",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/leo-hessianai-13B-chat-GGUF",
    "model": {
      "_id": "651570169d3b940a900bb730",
      "id": "TheBloke/leo-hessianai-13B-chat-GGUF",
      "modelId": "TheBloke/leo-hessianai-13B-chat-GGUF",
      "author": "TheBloke",
      "sha": "87eac03df6a7167199e9ac9032d126904ece3968",
      "lastModified": "2023-09-28T12:29:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "de",
        "dataset:LeoLM/OpenSchnabeltier",
        "dataset:OpenAssistant/OASST-DE",
        "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
        "dataset:FreedomIntelligence/evol-instruct-deutsch",
        "dataset:LeoLM/German_Poems",
        "dataset:LeoLM/German_Songs",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "LeoLM/leo-hessianai-13b-chat",
        "datasets": [
          "LeoLM/OpenSchnabeltier",
          "OpenAssistant/OASST-DE",
          "FreedomIntelligence/alpaca-gpt4-deutsch",
          "FreedomIntelligence/evol-instruct-deutsch",
          "LeoLM/German_Poems",
          "LeoLM/German_Songs"
        ],
        "inference": false,
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "LAION LeoLM",
        "model_name": "Leo Hessianai 13B Chat",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "leo-hessianai-13b-chat.Q2_K.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat.Q3_K_L.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat.Q3_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat.Q3_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat.Q4_0.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat.Q4_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat.Q4_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat.Q5_0.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat.Q5_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat.Q5_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat.Q6_K.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b-chat.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fd809bdc46569735adabe3",
      "id": "LeoLM/leo-hessianai-13b-chat",
      "modelId": "LeoLM/leo-hessianai-13b-chat",
      "author": "LeoLM",
      "sha": "60679b6ff9b59a02e7c410abed82f718a7f0b1b9",
      "lastModified": "2023-10-09T21:27:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "en",
        "de",
        "dataset:LeoLM/OpenSchnabeltier",
        "dataset:OpenAssistant/OASST-DE",
        "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
        "dataset:FreedomIntelligence/evol-instruct-deutsch",
        "dataset:LeoLM/German_Poems",
        "dataset:LeoLM/German_Songs",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2621,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 22,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoModelForCausalLM": "modeling_flash_llama.LlamaForCausalLM"
        }
      },
      "cardData": {
        "datasets": [
          "LeoLM/OpenSchnabeltier",
          "OpenAssistant/OASST-DE",
          "FreedomIntelligence/alpaca-gpt4-deutsch",
          "FreedomIntelligence/evol-instruct-deutsch",
          "LeoLM/German_Poems",
          "LeoLM/German_Songs"
        ],
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "dominikeff/LeoLM-leo-hessianai-13b-chat",
        "Yogesh0804/LeoLM-leo-hessianai-13b-chat"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "modeling_flash_llama.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65158162da8a3d7cdd804261",
    "id": "TheBloke/leo-hessianai-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "de",
      "dataset:oscar-corpus/OSCAR-2301",
      "dataset:wikipedia",
      "dataset:bjoernp/tagesschau-2018-2023",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/leo-hessianai-13B-GGUF",
    "model": {
      "_id": "65158162da8a3d7cdd804261",
      "id": "TheBloke/leo-hessianai-13B-GGUF",
      "modelId": "TheBloke/leo-hessianai-13B-GGUF",
      "author": "TheBloke",
      "sha": "30678142280bba47752cedab8d9976e4d7c6c774",
      "lastModified": "2023-09-28T13:43:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "de",
        "dataset:oscar-corpus/OSCAR-2301",
        "dataset:wikipedia",
        "dataset:bjoernp/tagesschau-2018-2023",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "LeoLM/leo-hessianai-13b",
        "datasets": [
          "oscar-corpus/OSCAR-2301",
          "wikipedia",
          "bjoernp/tagesschau-2018-2023"
        ],
        "inference": false,
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "LAION LeoLM",
        "model_name": "Leo Hessianai 13B",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "leo-hessianai-13b.Q2_K.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b.Q4_0.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b.Q5_0.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b.Q6_K.gguf"
        },
        {
          "rfilename": "leo-hessianai-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f7b014a92703ef65d07faa",
      "id": "LeoLM/leo-hessianai-13b",
      "modelId": "LeoLM/leo-hessianai-13b",
      "author": "LeoLM",
      "sha": "a947965cb07ca12a38ff981fe65b618d7dea28d3",
      "lastModified": "2023-09-29T10:34:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "en",
        "de",
        "dataset:oscar-corpus/OSCAR-2301",
        "dataset:wikipedia",
        "dataset:bjoernp/tagesschau-2018-2023",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7144,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 19,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoModelForCausalLM": "modeling_flash_llama.LlamaForCausalLM"
        }
      },
      "cardData": {
        "datasets": [
          "oscar-corpus/OSCAR-2301",
          "wikipedia",
          "bjoernp/tagesschau-2018-2023"
        ],
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "imgs/benchmarks.png"
        },
        {
          "rfilename": "imgs/training_params.png"
        },
        {
          "rfilename": "modeling_flash_llama.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651592ffc979eb9ca7238d13",
    "id": "TheBloke/leo-hessianai-7B-chat-bilingual-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 10,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "de",
      "dataset:LeoLM/OpenSchnabeltier",
      "dataset:OpenAssistant/OASST-DE",
      "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
      "dataset:FreedomIntelligence/evol-instruct-deutsch",
      "dataset:LeoLM/German_Poems",
      "dataset:LeoLM/German_Songs",
      "dataset:garage-bAInd/Open-Platypus",
      "dataset:WizardLM/WizardLM_evol_instruct_70k",
      "dataset:bjoernp/oasst25-08-23-filtered",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/leo-hessianai-7B-chat-bilingual-GGUF",
    "model": {
      "_id": "651592ffc979eb9ca7238d13",
      "id": "TheBloke/leo-hessianai-7B-chat-bilingual-GGUF",
      "modelId": "TheBloke/leo-hessianai-7B-chat-bilingual-GGUF",
      "author": "TheBloke",
      "sha": "21e17aef87e613ed3fd47cb1e8d6b71b45cdea12",
      "lastModified": "2023-09-28T14:55:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "de",
        "dataset:LeoLM/OpenSchnabeltier",
        "dataset:OpenAssistant/OASST-DE",
        "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
        "dataset:FreedomIntelligence/evol-instruct-deutsch",
        "dataset:LeoLM/German_Poems",
        "dataset:LeoLM/German_Songs",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:WizardLM/WizardLM_evol_instruct_70k",
        "dataset:bjoernp/oasst25-08-23-filtered",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "LeoLM/leo-hessianai-7b-chat-bilingual",
        "datasets": [
          "LeoLM/OpenSchnabeltier",
          "OpenAssistant/OASST-DE",
          "FreedomIntelligence/alpaca-gpt4-deutsch",
          "FreedomIntelligence/evol-instruct-deutsch",
          "LeoLM/German_Poems",
          "LeoLM/German_Songs",
          "garage-bAInd/Open-Platypus",
          "WizardLM/WizardLM_evol_instruct_70k",
          "bjoernp/oasst25-08-23-filtered"
        ],
        "inference": false,
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "LAION LeoLM",
        "model_name": "Leo Hessianai 7B Chat Bilingual",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "leo-hessianai-7b-chat-bilingual.Q2_K.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat-bilingual.Q3_K_L.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat-bilingual.Q3_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat-bilingual.Q3_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat-bilingual.Q4_0.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat-bilingual.Q4_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat-bilingual.Q4_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat-bilingual.Q5_0.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat-bilingual.Q5_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat-bilingual.Q5_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat-bilingual.Q6_K.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat-bilingual.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fe126467096272aec6af61",
      "id": "LeoLM/leo-hessianai-7b-chat-bilingual",
      "modelId": "LeoLM/leo-hessianai-7b-chat-bilingual",
      "author": "LeoLM",
      "sha": "5ee98fd03b310e3081f0c9986c5153b27ec5dce6",
      "lastModified": "2023-09-29T13:16:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "en",
        "de",
        "dataset:LeoLM/OpenSchnabeltier",
        "dataset:OpenAssistant/OASST-DE",
        "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
        "dataset:FreedomIntelligence/evol-instruct-deutsch",
        "dataset:LeoLM/German_Poems",
        "dataset:LeoLM/German_Songs",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:WizardLM/WizardLM_evol_instruct_70k",
        "dataset:bjoernp/oasst25-08-23-filtered",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6879,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoModelForCausalLM": "modeling_flash_llama.LlamaForCausalLM"
        }
      },
      "cardData": {
        "datasets": [
          "LeoLM/OpenSchnabeltier",
          "OpenAssistant/OASST-DE",
          "FreedomIntelligence/alpaca-gpt4-deutsch",
          "FreedomIntelligence/evol-instruct-deutsch",
          "LeoLM/German_Poems",
          "LeoLM/German_Songs",
          "garage-bAInd/Open-Platypus",
          "WizardLM/WizardLM_evol_instruct_70k",
          "bjoernp/oasst25-08-23-filtered"
        ],
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "modeling_flash_llama.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65159d427a07d71e9c5a9010",
    "id": "TheBloke/leo-hessianai-7B-chat-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 35,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "de",
      "dataset:LeoLM/OpenSchnabeltier",
      "dataset:OpenAssistant/OASST-DE",
      "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
      "dataset:FreedomIntelligence/evol-instruct-deutsch",
      "dataset:LeoLM/German_Poems",
      "dataset:LeoLM/German_Songs",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/leo-hessianai-7B-chat-GGUF",
    "model": {
      "_id": "65159d427a07d71e9c5a9010",
      "id": "TheBloke/leo-hessianai-7B-chat-GGUF",
      "modelId": "TheBloke/leo-hessianai-7B-chat-GGUF",
      "author": "TheBloke",
      "sha": "3ca16e6294bd684b612a123fb7fe6817232bac1c",
      "lastModified": "2023-09-28T15:39:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "de",
        "dataset:LeoLM/OpenSchnabeltier",
        "dataset:OpenAssistant/OASST-DE",
        "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
        "dataset:FreedomIntelligence/evol-instruct-deutsch",
        "dataset:LeoLM/German_Poems",
        "dataset:LeoLM/German_Songs",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 35,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "LeoLM/leo-hessianai-7b-chat",
        "datasets": [
          "LeoLM/OpenSchnabeltier",
          "OpenAssistant/OASST-DE",
          "FreedomIntelligence/alpaca-gpt4-deutsch",
          "FreedomIntelligence/evol-instruct-deutsch",
          "LeoLM/German_Poems",
          "LeoLM/German_Songs"
        ],
        "inference": false,
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "LAION LeoLM",
        "model_name": "Leo Hessianai 7B Chat",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "leo-hessianai-7b-chat.Q2_K.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat.Q3_K_L.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat.Q3_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat.Q3_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat.Q4_0.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat.Q4_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat.Q4_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat.Q5_0.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat.Q5_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat.Q5_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat.Q6_K.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b-chat.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64fe0a4535a7fc7d4f5eb61e",
      "id": "LeoLM/leo-hessianai-7b-chat",
      "modelId": "LeoLM/leo-hessianai-7b-chat",
      "author": "LeoLM",
      "sha": "a4c5fcbaea9f0a04f386533b0331c7f55a84f81c",
      "lastModified": "2023-10-09T21:30:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "en",
        "de",
        "dataset:LeoLM/OpenSchnabeltier",
        "dataset:OpenAssistant/OASST-DE",
        "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
        "dataset:FreedomIntelligence/evol-instruct-deutsch",
        "dataset:LeoLM/German_Poems",
        "dataset:LeoLM/German_Songs",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10238,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoModelForCausalLM": "modeling_flash_llama.LlamaForCausalLM"
        }
      },
      "cardData": {
        "datasets": [
          "LeoLM/OpenSchnabeltier",
          "OpenAssistant/OASST-DE",
          "FreedomIntelligence/alpaca-gpt4-deutsch",
          "FreedomIntelligence/evol-instruct-deutsch",
          "LeoLM/German_Poems",
          "LeoLM/German_Songs"
        ],
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Jalmer/LeoLM-leo-hessianai-7b-chat"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "modeling_flash_llama.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6515a896966dae9d5ca82573",
    "id": "TheBloke/leo-hessianai-7B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 15,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "de",
      "dataset:oscar-corpus/OSCAR-2301",
      "dataset:wikipedia",
      "dataset:bjoernp/tagesschau-2018-2023",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/leo-hessianai-7B-GGUF",
    "model": {
      "_id": "6515a896966dae9d5ca82573",
      "id": "TheBloke/leo-hessianai-7B-GGUF",
      "modelId": "TheBloke/leo-hessianai-7B-GGUF",
      "author": "TheBloke",
      "sha": "64b8c07daea811094004c1f48200e48c098fc2a2",
      "lastModified": "2023-09-28T16:28:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "de",
        "dataset:oscar-corpus/OSCAR-2301",
        "dataset:wikipedia",
        "dataset:bjoernp/tagesschau-2018-2023",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "LeoLM/leo-hessianai-7b",
        "datasets": [
          "oscar-corpus/OSCAR-2301",
          "wikipedia",
          "bjoernp/tagesschau-2018-2023"
        ],
        "inference": false,
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "LAION LeoLM",
        "model_name": "Leo Hessianai 7B",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "leo-hessianai-7b.Q2_K.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b.Q4_0.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b.Q5_0.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b.Q6_K.gguf"
        },
        {
          "rfilename": "leo-hessianai-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e51840398134c2af880097",
      "id": "LeoLM/leo-hessianai-7b",
      "modelId": "LeoLM/leo-hessianai-7b",
      "author": "LeoLM",
      "sha": "88c5ac07006ea8f1b5d10aa4f03f0d624dd27e56",
      "lastModified": "2023-09-11T00:10:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "custom_code",
        "en",
        "de",
        "dataset:oscar-corpus/OSCAR-2301",
        "dataset:wikipedia",
        "dataset:bjoernp/tagesschau-2018-2023",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7744,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 28,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama",
        "auto_map": {
          "AutoModelForCausalLM": "modeling_flash_llama.LlamaForCausalLM"
        }
      },
      "cardData": {
        "datasets": [
          "oscar-corpus/OSCAR-2301",
          "wikipedia",
          "bjoernp/tagesschau-2018-2023"
        ],
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "imgs/benchmarks.png"
        },
        {
          "rfilename": "imgs/training_params.png"
        },
        {
          "rfilename": "modeling_flash_llama.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651605b15671e6529662d1e0",
    "id": "TheBloke/NexusRaven-13B-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 6,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2308.12950",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/NexusRaven-13B-GGUF",
    "model": {
      "_id": "651605b15671e6529662d1e0",
      "id": "TheBloke/NexusRaven-13B-GGUF",
      "modelId": "TheBloke/NexusRaven-13B-GGUF",
      "author": "TheBloke",
      "sha": "58e5ff538fa26f2513ee13d733dfe9f40edb4352",
      "lastModified": "2023-09-28T23:09:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2308.12950",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "likes": 10,
      "model-index": [
        {
          "name": "NexusRaven-13B",
          "results": []
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Nexusflow/NexusRaven-13B",
        "inference": false,
        "license": "llama2",
        "model-index": [
          {
            "name": "NexusRaven-13B",
            "results": []
          }
        ],
        "model_creator": "Nexusflow",
        "model_name": "Nexusraven 13B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "nexusraven-13b.Q2_K.gguf"
        },
        {
          "rfilename": "nexusraven-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "nexusraven-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "nexusraven-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "nexusraven-13b.Q4_0.gguf"
        },
        {
          "rfilename": "nexusraven-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "nexusraven-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "nexusraven-13b.Q5_0.gguf"
        },
        {
          "rfilename": "nexusraven-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "nexusraven-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "nexusraven-13b.Q6_K.gguf"
        },
        {
          "rfilename": "nexusraven-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651536c991aa56a7b10b1eda",
      "id": "Nexusflow/NexusRaven-13B",
      "modelId": "Nexusflow/NexusRaven-13B",
      "author": "Nexusflow",
      "sha": "147e5598dec704715730d5a707cae1e6baebdfd1",
      "lastModified": "2023-10-01T15:22:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2308.12950",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 472,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 56,
      "model-index": [
        {
          "name": "NexusRaven-13B",
          "results": []
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "base_model": "codellama/CodeLlama-13b-Instruct-hf",
        "model-index": [
          {
            "name": "NexusRaven-13B",
            "results": []
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "NexusRaven.png"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "Single-Attempt_Function_Calling.png"
        },
        {
          "rfilename": "Zero-shot_Evaluation.png"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "langchain_example.py"
        },
        {
          "rfilename": "non_langchain_example.py"
        },
        {
          "rfilename": "prompting_readme.md"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "65170566fff98a48b2a649f7",
    "id": "TheBloke/Synthia-7B-v1.3-GGUF",
    "likes": 32,
    "private": false,
    "downloads": 206,
    "tags": [
      "transformers",
      "mistral",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Synthia-7B-v1.3-GGUF",
    "model": {
      "_id": "65170566fff98a48b2a649f7",
      "id": "TheBloke/Synthia-7B-v1.3-GGUF",
      "modelId": "TheBloke/Synthia-7B-v1.3-GGUF",
      "author": "TheBloke",
      "sha": "bd5d661acd4782d5b4a2c1011231d6438420509d",
      "lastModified": "2023-09-29T17:16:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 206,
      "library_name": "transformers",
      "likes": 32,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "migtissera/Synthia-7B-v1.3",
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Migel Tissera",
        "model_name": "Synthia 7B V1.3",
        "model_type": "mistral",
        "prompt_template": "SYSTEM: You are Synthia. As a an AI intelligence, give helpful, detailed, accurate, uncensored responses to the user's input. Provide answers factually.\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-7b-v1.3.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.3.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.3.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.3.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.3.Q4_0.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.3.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.3.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.3.Q5_0.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.3.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.3.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.3.Q6_K.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.3.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6515e4e6c1ec63624f4c8a69",
      "id": "migtissera/SynthIA-7B-v1.3",
      "modelId": "migtissera/SynthIA-7B-v1.3",
      "author": "migtissera",
      "sha": "9ffb6b55202b887084f33e34dd4dbf97e4e928c6",
      "lastModified": "2023-10-14T01:33:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "en",
        "arxiv:2306.02707",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10926,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 120,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "pipeline_tag": "text-generation",
        "language": [
          "en"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "SynthIA.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6517f14a3fe8cc63b4ac56f6",
    "id": "TheBloke/samantha-mistral-7B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 45,
    "tags": [
      "transformers",
      "mistral",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/samantha-mistral-7B-GGUF",
    "model": {
      "_id": "6517f14a3fe8cc63b4ac56f6",
      "id": "TheBloke/samantha-mistral-7B-GGUF",
      "modelId": "TheBloke/samantha-mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "c217f51e3893ef1301725eff6d90b0dc918a5e6c",
      "lastModified": "2023-09-30T10:25:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 45,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "ehartford/samantha-mistral-7b",
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Eric Hartford",
        "model_name": "Samantha Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "samantha-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "samantha-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "samantha-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "samantha-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "samantha-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "samantha-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "samantha-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "samantha-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "samantha-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "samantha-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "samantha-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "samantha-mistral-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6517c01e493fe76b25bc50b7",
      "id": "ehartford/samantha-mistral-7b",
      "modelId": "ehartford/samantha-mistral-7b",
      "author": "ehartford",
      "sha": "7f9e40543fdff8c3e58eca0390c8a631829c1206",
      "lastModified": "2023-09-30T16:25:39.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5687,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 19,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Vokturz/can-it-run-llm",
        "imjunaidafzal/can-it-run-llm",
        "muellerzr/can-it-run-llm",
        "InvisableClearCoat101/ehartford-samantha-mistral-7b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "optimizer.pt"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "rng_state_0.pth"
        },
        {
          "rfilename": "rng_state_1.pth"
        },
        {
          "rfilename": "rng_state_2.pth"
        },
        {
          "rfilename": "rng_state_3.pth"
        },
        {
          "rfilename": "scheduler.pt"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "651812aa593b3af31211987d",
    "id": "TheBloke/samantha-mistral-instruct-7B-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 43,
    "tags": [
      "transformers",
      "mistral",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/samantha-mistral-instruct-7B-GGUF",
    "model": {
      "_id": "651812aa593b3af31211987d",
      "id": "TheBloke/samantha-mistral-instruct-7B-GGUF",
      "modelId": "TheBloke/samantha-mistral-instruct-7B-GGUF",
      "author": "TheBloke",
      "sha": "290b11cd141e903fafb4455c2487c4e71d989327",
      "lastModified": "2023-09-30T12:24:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 43,
      "library_name": "transformers",
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "ehartford/samantha-mistral-instruct-7b",
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Eric Hartford",
        "model_name": "Samantha Mistral Instruct 7B",
        "model_type": "mistral",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "samantha-mistral-instruct-7b.Q2_K.gguf"
        },
        {
          "rfilename": "samantha-mistral-instruct-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "samantha-mistral-instruct-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "samantha-mistral-instruct-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "samantha-mistral-instruct-7b.Q4_0.gguf"
        },
        {
          "rfilename": "samantha-mistral-instruct-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "samantha-mistral-instruct-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "samantha-mistral-instruct-7b.Q5_0.gguf"
        },
        {
          "rfilename": "samantha-mistral-instruct-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "samantha-mistral-instruct-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "samantha-mistral-instruct-7b.Q6_K.gguf"
        },
        {
          "rfilename": "samantha-mistral-instruct-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6517bc4570694414234167aa",
      "id": "ehartford/samantha-mistral-instruct-7b",
      "modelId": "ehartford/samantha-mistral-instruct-7b",
      "author": "ehartford",
      "sha": "3a33eea0858d411617c472c3c0ae39f17d2b3f5d",
      "lastModified": "2023-09-30T16:30:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5369,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 16,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "PeepDaSlan9/ehartford-samantha-mistral-instruct-7b",
        "hkniberg/ehartford-samantha-mistral-instruct-7b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "optimizer.pt"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "rng_state_0.pth"
        },
        {
          "rfilename": "rng_state_1.pth"
        },
        {
          "rfilename": "rng_state_2.pth"
        },
        {
          "rfilename": "rng_state_3.pth"
        },
        {
          "rfilename": "scheduler.pt"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "6518249520b18e99b46876a0",
    "id": "TheBloke/Pandalyst-7B-V1.1-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 70,
    "tags": [
      "transformers",
      "llama",
      "code",
      "en",
      "license:llama2",
      "model-index",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Pandalyst-7B-V1.1-GGUF",
    "model": {
      "_id": "6518249520b18e99b46876a0",
      "id": "TheBloke/Pandalyst-7B-V1.1-GGUF",
      "modelId": "TheBloke/Pandalyst-7B-V1.1-GGUF",
      "author": "TheBloke",
      "sha": "8a88355c1dfe04577bb06a19b8b95c3154ebbd0b",
      "lastModified": "2023-09-30T13:46:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "code",
        "en",
        "license:llama2",
        "model-index",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 70,
      "library_name": "transformers",
      "likes": 5,
      "model-index": [
        {
          "name": "Pandalyst_7B_v1.1",
          "results": [
            {
              "metrics": [
                {
                  "name": "exec@1",
                  "type": "exec@1",
                  "value": 0.76,
                  "verified": false
                }
              ],
              "task": {
                "type": "text-generation"
              }
            }
          ]
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "pipizhao/Pandalyst-7B-V1.1",
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model-index": [
          {
            "name": "Pandalyst_7B_v1.1",
            "results": [
              {
                "metrics": [
                  {
                    "name": "exec@1",
                    "type": "exec@1",
                    "value": 0.76,
                    "verified": false
                  }
                ],
                "task": {
                  "type": "text-generation"
                }
              }
            ]
          }
        ],
        "model_creator": "Yanzhao Zheng",
        "model_name": "Pandalyst 7B V1.1",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "code"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pandalyst-7b-v1.1.Q2_K.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.1.Q4_0.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.1.Q5_0.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.1.Q6_K.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65179182186bc3b6994c04c3",
      "id": "pipizhao/Pandalyst-7B-V1.1",
      "modelId": "pipizhao/Pandalyst-7B-V1.1",
      "author": "pipizhao",
      "sha": "2a9c900a8cefcf3ccaf5cdb05b23c831bfeaa384",
      "lastModified": "2023-10-15T08:05:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "en",
        "license:llama2",
        "model-index",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 253,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": [
        {
          "name": "Pandalyst-7B-V1.1",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "metrics": [
                {
                  "name": "acc@1",
                  "type": "acc@1",
                  "value": 0,
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "code"
        ],
        "model-index": [
          {
            "name": "Pandalyst-7B-V1.1",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "metrics": [
                  {
                    "name": "acc@1",
                    "type": "acc@1",
                    "value": 0,
                    "verified": false
                  }
                ]
              }
            ]
          }
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "bijurikin/pipizhao-Pandalyst-7B-V1.1b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651830cd4fadbeb643d1188d",
    "id": "TheBloke/Pandalyst_13B_V1.0-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "code",
      "en",
      "license:llama2",
      "model-index",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Pandalyst_13B_V1.0-GGUF",
    "model": {
      "_id": "651830cd4fadbeb643d1188d",
      "id": "TheBloke/Pandalyst_13B_V1.0-GGUF",
      "modelId": "TheBloke/Pandalyst_13B_V1.0-GGUF",
      "author": "TheBloke",
      "sha": "7b6b885a94362d0269852d5d6112d73ba98edb4c",
      "lastModified": "2023-09-30T14:35:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "code",
        "en",
        "license:llama2",
        "model-index",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 2,
      "model-index": [
        {
          "name": "Pandalyst_13B_v1.0",
          "results": [
            {
              "metrics": [
                {
                  "name": "exec@1",
                  "type": "exec@1",
                  "value": 0.71,
                  "verified": false
                }
              ],
              "task": {
                "type": "text-generation"
              }
            }
          ]
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "pipizhao/Pandalyst_13B_V1.0",
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model-index": [
          {
            "name": "Pandalyst_13B_v1.0",
            "results": [
              {
                "metrics": [
                  {
                    "name": "exec@1",
                    "type": "exec@1",
                    "value": 0.71,
                    "verified": false
                  }
                ],
                "task": {
                  "type": "text-generation"
                }
              }
            ]
          }
        ],
        "model_creator": "Yanzhao Zheng",
        "model_name": "Pandalyst 13B V1.0",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "code"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pandalyst_13b_v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "pandalyst_13b_v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "pandalyst_13b_v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "pandalyst_13b_v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "pandalyst_13b_v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "pandalyst_13b_v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "pandalyst_13b_v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "pandalyst_13b_v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "pandalyst_13b_v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "pandalyst_13b_v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "pandalyst_13b_v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "pandalyst_13b_v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65159db2fbfe82f36fa5fc0f",
      "id": "pipizhao/Pandalyst_13B_V1.0",
      "modelId": "pipizhao/Pandalyst_13B_V1.0",
      "author": "pipizhao",
      "sha": "37c5568aa9fe8352dc8218e0e11988d40815d51c",
      "lastModified": "2023-10-15T08:04:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "en",
        "license:llama2",
        "model-index",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 79,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": [
        {
          "name": "Pandalyst_13B_v1.0",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "metrics": [
                {
                  "name": "exec@1",
                  "type": "exec@1",
                  "value": 0,
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "code"
        ],
        "model-index": [
          {
            "name": "Pandalyst_13B_v1.0",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "metrics": [
                  {
                    "name": "exec@1",
                    "type": "exec@1",
                    "value": 0,
                    "verified": false
                  }
                ]
              }
            ]
          }
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651848d0684223da599fd97f",
    "id": "TheBloke/Kimiko-Mistral-7B-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 23,
    "tags": [
      "transformers",
      "mistral",
      "generated_from_trainer",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Kimiko-Mistral-7B-GGUF",
    "model": {
      "_id": "651848d0684223da599fd97f",
      "id": "TheBloke/Kimiko-Mistral-7B-GGUF",
      "modelId": "TheBloke/Kimiko-Mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "24374c3362bfd5cd28cddf1d43597885b4b0bfa6",
      "lastModified": "2023-09-30T16:20:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "generated_from_trainer",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 23,
      "library_name": "transformers",
      "likes": 8,
      "model-index": [
        {
          "name": "Kimiko-Mistral-7B",
          "results": []
        }
      ],
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "nRuaif/Kimiko-Mistral-7B",
        "inference": false,
        "license": "apache-2.0",
        "model-index": [
          {
            "name": "Kimiko-Mistral-7B",
            "results": []
          }
        ],
        "model_creator": "nRuaif",
        "model_name": "Kimiko Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "You are a helpful AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "generated_from_trainer"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "kimiko-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "kimiko-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "kimiko-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "kimiko-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "kimiko-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "kimiko-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "kimiko-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "kimiko-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "kimiko-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "kimiko-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "kimiko-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "kimiko-mistral-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65182008ea991a3229d1a3bc",
      "id": "nRuaif/Kimiko-Mistral-7B",
      "modelId": "nRuaif/Kimiko-Mistral-7B",
      "author": "nRuaif",
      "sha": "36e4d1228deb2ea6fd487b656f05c7e523d17ce1",
      "lastModified": "2023-10-07T01:43:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "text-generation",
        "generated_from_trainer",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 115,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": [
        {
          "name": "Kimiko-Mistral-7B",
          "results": []
        }
      ],
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "base_model": "mistralai/Mistral-7B-v0.1",
        "tags": [
          "generated_from_trainer"
        ],
        "model-index": [
          {
            "name": "Kimiko-Mistral-7B",
            "results": []
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "adapter_config.json"
        },
        {
          "rfilename": "adapter_model.bin"
        },
        {
          "rfilename": "config.json"
        }
      ]
    }
  },
  {
    "_id": "651860ecb447213cb528f867",
    "id": "TheBloke/Megamix-A1-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Megamix-A1-13B-GGUF",
    "model": {
      "_id": "651860ecb447213cb528f867",
      "id": "TheBloke/Megamix-A1-13B-GGUF",
      "modelId": "TheBloke/Megamix-A1-13B-GGUF",
      "author": "TheBloke",
      "sha": "1aca406a8b0a94541d8ade3583142ca0f6d1f761",
      "lastModified": "2023-09-30T18:00:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "gradientputri/Megamix-A1-13B",
        "inference": false,
        "license": "llama2",
        "model_creator": "Putri",
        "model_name": "Megamix A1 13B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "megamix-a1-13b.Q2_K.gguf"
        },
        {
          "rfilename": "megamix-a1-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "megamix-a1-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "megamix-a1-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "megamix-a1-13b.Q4_0.gguf"
        },
        {
          "rfilename": "megamix-a1-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "megamix-a1-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "megamix-a1-13b.Q5_0.gguf"
        },
        {
          "rfilename": "megamix-a1-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "megamix-a1-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "megamix-a1-13b.Q6_K.gguf"
        },
        {
          "rfilename": "megamix-a1-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65172342fff98a48b2aa91e0",
      "id": "gradientputri/Megamix-A1-13B",
      "modelId": "gradientputri/Megamix-A1-13B",
      "author": "gradientputri",
      "sha": "14e0756c210bcf420fbf825e6b8087ee5c716e7f",
      "lastModified": "2023-10-02T10:20:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4311,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65186850fff98a48b2d0b5eb",
    "id": "TheBloke/MegaMix-S1-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MegaMix-S1-13B-GGUF",
    "model": {
      "_id": "65186850fff98a48b2d0b5eb",
      "id": "TheBloke/MegaMix-S1-13B-GGUF",
      "modelId": "TheBloke/MegaMix-S1-13B-GGUF",
      "author": "TheBloke",
      "sha": "cb1dcee4270a90726150ed712878e9eaf049b4d9",
      "lastModified": "2023-09-30T18:32:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "gradientputri/MegaMix-S1-13B",
        "inference": false,
        "license": "llama2",
        "model_creator": "Putri",
        "model_name": "Megamix S1 13B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "megamix-s1-13b.Q2_K.gguf"
        },
        {
          "rfilename": "megamix-s1-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "megamix-s1-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "megamix-s1-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "megamix-s1-13b.Q4_0.gguf"
        },
        {
          "rfilename": "megamix-s1-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "megamix-s1-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "megamix-s1-13b.Q5_0.gguf"
        },
        {
          "rfilename": "megamix-s1-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "megamix-s1-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "megamix-s1-13b.Q6_K.gguf"
        },
        {
          "rfilename": "megamix-s1-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651724e1684223da597c594d",
      "id": "gradientputri/MegaMix-S1-13B",
      "modelId": "gradientputri/MegaMix-S1-13B",
      "author": "gradientputri",
      "sha": "afca2c9488cf8738faec4db6721f6a4c755a5d81",
      "lastModified": "2023-10-02T10:21:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4315,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65186f6a2d69a6fd7efa1926",
    "id": "TheBloke/MegaMix-T1-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MegaMix-T1-13B-GGUF",
    "model": {
      "_id": "65186f6a2d69a6fd7efa1926",
      "id": "TheBloke/MegaMix-T1-13B-GGUF",
      "modelId": "TheBloke/MegaMix-T1-13B-GGUF",
      "author": "TheBloke",
      "sha": "b3f9232e6d11e3dc5aefbe0ced520ce1e8604bd8",
      "lastModified": "2023-09-30T19:02:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "gradientputri/MegaMix-T1-13B",
        "inference": false,
        "license": "llama2",
        "model_creator": "Putri",
        "model_name": "Megamix T1 13B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "megamix-t1-13b.Q2_K.gguf"
        },
        {
          "rfilename": "megamix-t1-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "megamix-t1-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "megamix-t1-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "megamix-t1-13b.Q4_0.gguf"
        },
        {
          "rfilename": "megamix-t1-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "megamix-t1-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "megamix-t1-13b.Q5_0.gguf"
        },
        {
          "rfilename": "megamix-t1-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "megamix-t1-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "megamix-t1-13b.Q6_K.gguf"
        },
        {
          "rfilename": "megamix-t1-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65172633b8de47f470a40ae1",
      "id": "gradientputri/MegaMix-T1-13B",
      "modelId": "gradientputri/MegaMix-T1-13B",
      "author": "gradientputri",
      "sha": "55d31300f8972b56320855bb40efb5e3d1e1a6fc",
      "lastModified": "2023-10-02T10:21:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4328,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65193caf70694414236dcbde",
    "id": "TheBloke/sheep-duck-llama-2-70B-v1.1-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 16,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/sheep-duck-llama-2-70B-v1.1-GGUF",
    "model": {
      "_id": "65193caf70694414236dcbde",
      "id": "TheBloke/sheep-duck-llama-2-70B-v1.1-GGUF",
      "modelId": "TheBloke/sheep-duck-llama-2-70B-v1.1-GGUF",
      "author": "TheBloke",
      "sha": "347549da5e6b5f8c9475045c6f45b9c6e769b615",
      "lastModified": "2023-10-01T10:28:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 16,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Riiid/sheep-duck-llama-2-70b-v1.1",
        "inference": false,
        "license": "llama2",
        "model_creator": "Riiid",
        "model_name": "Sheep Duck Llama 2 70B v1.1",
        "model_type": "llama",
        "prompt_template": "### System:\n{system_message}\n\n### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q2_K.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q4_0.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q5_0.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "sheep-duck-llama-2-70b-v1.1.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "65145fabe69f6374e55ac276",
      "id": "Riiid/sheep-duck-llama-2-70b-v1.1",
      "modelId": "Riiid/sheep-duck-llama-2-70b-v1.1",
      "author": "Riiid",
      "sha": "978c3cc8d44ad37eb764a53e026ae1fa8d334eb2",
      "lastModified": "2023-10-13T00:59:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "Riiid",
        "llama-2",
        "sheep-duck-llama-2",
        "en",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7493,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 13,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "thumbnail": "https://cdn-uploads.huggingface.co/production/uploads/62fb1ef7e8c9c532aa7d19e4/NswB5XPkkOljeRh1xbMmR.png",
        "pipeline_tag": "text-generation",
        "license": "llama2",
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "tags": [
          "Riiid",
          "llama-2",
          "sheep-duck-llama-2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "idkukkikoooii/Riiid-sheep-duck-llama-2-70b-v1.11",
        "dackdel/Riiid-sheep-duck-llama-2-70b-v1.1",
        "Edwardmonteirobr/Riiid-sheep-duck-llama-2-70b-v1.1",
        "Edwardmonteirobr/Riiid-sheep-duck-llama-2-70b-v1.1new",
        "Fayzul/Riiid-sheep-duck-llama-2-70b-v1.1",
        "monkebonk/Riiid-sheep-duck-llama-2-70b-v1.1",
        "Aniquel/Riiid-sheep-duck-llama-2-70b-v1.1",
        "scrambled-gabs/Riiid-sheep-duck-llama-2-70b-v1.1",
        "veerza/Riiid-sheep-duck-llama-2-70b-v1.1",
        "ziedammak/Riiid-sheep-duck-llama-2-70b-v1.1",
        "Debargha-1225/Riiid-sheep-duck-llama-2-70b-v1.1"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651960a04fadbeb643f2b51d",
    "id": "TheBloke/lince-zero-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 6,
    "tags": [
      "transformers",
      "falcon",
      "text-generation",
      "es",
      "dataset:tatsu-lab/alpaca",
      "dataset:databricks/databricks-dolly-15k",
      "arxiv:1910.09700",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/lince-zero-GGUF",
    "model": {
      "_id": "651960a04fadbeb643f2b51d",
      "id": "TheBloke/lince-zero-GGUF",
      "modelId": "TheBloke/lince-zero-GGUF",
      "author": "TheBloke",
      "sha": "395d251bef7d11a89a25e035041b4cb790735ff3",
      "lastModified": "2023-10-01T12:15:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "falcon",
        "text-generation",
        "es",
        "dataset:tatsu-lab/alpaca",
        "dataset:databricks/databricks-dolly-15k",
        "arxiv:1910.09700",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Me llamo Julien y me gusta"
        },
        {
          "text": "Me llamo Thomas y mi principal"
        },
        {
          "text": "Me llamo Manuel y trabajo en"
        },
        {
          "text": "rase una vez,"
        },
        {
          "text": "Si t me dices ven, "
        }
      ],
      "likes": 2,
      "model-index": [
        {
          "name": "lince-zero",
          "results": []
        }
      ],
      "config": {
        "model_type": "falcon"
      },
      "cardData": {
        "base_model": "clibrain/lince-zero",
        "datasets": [
          "tatsu-lab/alpaca",
          "databricks/databricks-dolly-15k"
        ],
        "inference": false,
        "language": [
          "es"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model-index": [
          {
            "name": "lince-zero",
            "results": []
          }
        ],
        "model_creator": "CliBrAIn",
        "model_name": "Lince Zero",
        "model_type": "falcon",
        "pipeline_tag": "text-generation",
        "prompt_template": "A continuacin hay una instruccin que describe una tarea, junto con una entrada que proporciona ms contexto. Escriba una respuesta que complete adecuadamente la solicitud.\n\n### Instruccin: {prompt}\n\n### Entrada:\n\n### Contexto: \n\n### Respuesta:\n",
        "quantized_by": "TheBloke",
        "thumbnail": "https://huggingface.co/clibrain/lince-zero/resolve/main/LINCE-CLIBRAIN-HD.jpg"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "lince-zero.Q4_0.gguf"
        },
        {
          "rfilename": "lince-zero.Q4_1.gguf"
        },
        {
          "rfilename": "lince-zero.Q5_0.gguf"
        },
        {
          "rfilename": "lince-zero.Q5_1.gguf"
        },
        {
          "rfilename": "lince-zero.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64a3bdd573f3ad435c3cd0b9",
      "id": "clibrain/lince-zero",
      "modelId": "clibrain/lince-zero",
      "author": "clibrain",
      "sha": "d01fa0748fa174b5ad7dd29f0978797253a8ba25",
      "lastModified": "2023-10-23T10:44:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "falcon",
        "text-generation",
        "custom_code",
        "es",
        "dataset:tatsu-lab/alpaca",
        "dataset:databricks/databricks-dolly-15k",
        "arxiv:1910.09700",
        "license:apache-2.0",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 663,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Me llamo Julien y me gusta"
        },
        {
          "text": "Me llamo Thomas y mi principal"
        },
        {
          "text": "Me llamo Manuel y trabajo en"
        },
        {
          "text": "rase una vez,"
        },
        {
          "text": "Si t me dices ven, "
        }
      ],
      "likes": 42,
      "model-index": [
        {
          "name": "lince-zero",
          "results": []
        }
      ],
      "config": {
        "architectures": [
          "FalconForCausalLM"
        ],
        "model_type": "falcon",
        "auto_map": {
          "AutoConfig": "configuration_falcon.FalconConfig",
          "AutoModel": "modeling_falcon.FalconModel",
          "AutoModelForSequenceClassification": "modeling_falcon.FalconForSequenceClassification",
          "AutoModelForTokenClassification": "modeling_falcon.FalconForTokenClassification",
          "AutoModelForQuestionAnswering": "modeling_falcon.FalconForQuestionAnswering",
          "AutoModelForCausalLM": "modeling_falcon.FalconForCausalLM"
        }
      },
      "cardData": {
        "model-index": [
          {
            "name": "lince-zero",
            "results": []
          }
        ],
        "license": "apache-2.0",
        "language": [
          "es"
        ],
        "thumbnail": "https://huggingface.co/clibrain/lince-zero/resolve/main/LINCE-CLIBRAIN-HD.jpg",
        "pipeline_tag": "text-generation",
        "datasets": [
          "tatsu-lab/alpaca",
          "databricks/databricks-dolly-15k"
        ],
        "library_name": "transformers",
        "inference": false
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LINCE-CLIBRAIN-HD.jpg"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "config_old.json"
        },
        {
          "rfilename": "configuration_falcon.py"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "lince_logo_1.png"
        },
        {
          "rfilename": "modeling_falcon.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651961a5593b3af312355be7",
    "id": "TheBloke/MythoMakiseMerged-13B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 18,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MythoMakiseMerged-13B-GGUF",
    "model": {
      "_id": "651961a5593b3af312355be7",
      "id": "TheBloke/MythoMakiseMerged-13B-GGUF",
      "modelId": "TheBloke/MythoMakiseMerged-13B-GGUF",
      "author": "TheBloke",
      "sha": "738175db4c3294d39e4461184b605090bf03949e",
      "lastModified": "2023-10-01T12:18:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 18,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Heralax/MythoMakiseMerged-13b",
        "inference": false,
        "license": "llama2",
        "model_creator": "Evan Armstrong",
        "model_name": "MythoMakiseMerged 13B",
        "model_type": "llama",
        "prompt_template": "## {{{{charname}}}}:\n- You're \"{{{{charname}}}}\" in this never-ending roleplay with \"{{{{user}}}}\".\n### Input:\n{prompt}\n\n### Response:\n(OOC) Understood. I will take this info into account for the roleplay. (end OOC)\n\n### New Roleplay:\n### Instruction:\n#### {{{{char}}}}:\nwhatever the char says, this is the chat history\n#### {{{{user}}}}:\nwhatever the user says, this is the chat history\n... repeated some number of times ...\n### Response 2 paragraphs, engaging, natural, authentic, descriptive, creative):\n#### {{{{char}}}}:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mythomakisemerged-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mythomakisemerged-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mythomakisemerged-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mythomakisemerged-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mythomakisemerged-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mythomakisemerged-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mythomakisemerged-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mythomakisemerged-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mythomakisemerged-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mythomakisemerged-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mythomakisemerged-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mythomakisemerged-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6517c74a69c938b3d6f5602b",
      "id": "Heralax/MythoMakiseMerged-13b",
      "modelId": "Heralax/MythoMakiseMerged-13b",
      "author": "Heralax",
      "sha": "5888f4667f4a1fe22b4bc8cacdcc323f0dbbbbfc",
      "lastModified": "2023-10-23T09:42:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "MythoMakiseMerged-13b-q5km.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "ggml-model-f16.gguf"
        },
        {
          "rfilename": "model-00001-of-00006.safetensors"
        },
        {
          "rfilename": "model-00002-of-00006.safetensors"
        },
        {
          "rfilename": "model-00003-of-00006.safetensors"
        },
        {
          "rfilename": "model-00004-of-00006.safetensors"
        },
        {
          "rfilename": "model-00005-of-00006.safetensors"
        },
        {
          "rfilename": "model-00006-of-00006.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_files/added_tokens.json"
        },
        {
          "rfilename": "pytorch_files/config.json"
        },
        {
          "rfilename": "pytorch_files/model-00001-of-00006.safetensors"
        },
        {
          "rfilename": "pytorch_files/model-00002-of-00006.safetensors"
        },
        {
          "rfilename": "pytorch_files/model-00003-of-00006.safetensors"
        },
        {
          "rfilename": "pytorch_files/model-00004-of-00006.safetensors"
        },
        {
          "rfilename": "pytorch_files/model-00005-of-00006.safetensors"
        },
        {
          "rfilename": "pytorch_files/model-00006-of-00006.safetensors"
        },
        {
          "rfilename": "pytorch_files/model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_files/special_tokens_map.json"
        },
        {
          "rfilename": "pytorch_files/tokenizer.json"
        },
        {
          "rfilename": "pytorch_files/tokenizer.model"
        },
        {
          "rfilename": "pytorch_files/tokenizer_config.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65199234ed0bef1df00a9a62",
    "id": "TheBloke/UltraLM-13B-v2.0-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/UltraLM-13B-v2.0-GGUF",
    "model": {
      "_id": "65199234ed0bef1df00a9a62",
      "id": "TheBloke/UltraLM-13B-v2.0-GGUF",
      "modelId": "TheBloke/UltraLM-13B-v2.0-GGUF",
      "author": "TheBloke",
      "sha": "c242fe37ad950f8e9030ae3d6a293d26cf043ee9",
      "lastModified": "2023-10-01T15:42:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "openbmb/UltraLM-13b-v2.0",
        "inference": false,
        "license": "mit",
        "model_creator": "OpenBMB",
        "model_name": "UltraLM 13B v2.0",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "ultralm-13b-v2.0.Q2_K.gguf"
        },
        {
          "rfilename": "ultralm-13b-v2.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "ultralm-13b-v2.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "ultralm-13b-v2.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "ultralm-13b-v2.0.Q4_0.gguf"
        },
        {
          "rfilename": "ultralm-13b-v2.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "ultralm-13b-v2.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "ultralm-13b-v2.0.Q5_0.gguf"
        },
        {
          "rfilename": "ultralm-13b-v2.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "ultralm-13b-v2.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "ultralm-13b-v2.0.Q6_K.gguf"
        },
        {
          "rfilename": "ultralm-13b-v2.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650d5f54aeb45e887b614364",
      "id": "openbmb/UltraLM-13b-v2.0",
      "modelId": "openbmb/UltraLM-13b-v2.0",
      "author": "openbmb",
      "sha": "a452045c96ae62379a98ef0d85666616a66e78a6",
      "lastModified": "2023-09-23T16:25:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5758,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6519df070e3a5553d4b7ce22",
    "id": "TheBloke/em_german_13b_v01-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 9,
    "tags": [
      "transformers",
      "llama",
      "facebook",
      "meta",
      "pytorch",
      "llama-2",
      "german",
      "deutsch",
      "text-generation",
      "de",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/em_german_13b_v01-GGUF",
    "model": {
      "_id": "6519df070e3a5553d4b7ce22",
      "id": "TheBloke/em_german_13b_v01-GGUF",
      "modelId": "TheBloke/em_german_13b_v01-GGUF",
      "author": "TheBloke",
      "sha": "096e77ee0cb97ac80321e4f03c2434b80bc26225",
      "lastModified": "2023-10-01T21:15:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "german",
        "deutsch",
        "text-generation",
        "de",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "jphme/em_german_13b_v01",
        "inference": false,
        "language": [
          "de"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "Jan Philipp Harries",
        "model_name": "EM German 13B v01",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Du bist ein hilfreicher Assistent. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2",
          "german",
          "deutsch"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "em_german_13b_v01.Q2_K.gguf"
        },
        {
          "rfilename": "em_german_13b_v01.Q3_K_L.gguf"
        },
        {
          "rfilename": "em_german_13b_v01.Q3_K_M.gguf"
        },
        {
          "rfilename": "em_german_13b_v01.Q3_K_S.gguf"
        },
        {
          "rfilename": "em_german_13b_v01.Q4_0.gguf"
        },
        {
          "rfilename": "em_german_13b_v01.Q4_K_M.gguf"
        },
        {
          "rfilename": "em_german_13b_v01.Q4_K_S.gguf"
        },
        {
          "rfilename": "em_german_13b_v01.Q5_0.gguf"
        },
        {
          "rfilename": "em_german_13b_v01.Q5_K_M.gguf"
        },
        {
          "rfilename": "em_german_13b_v01.Q5_K_S.gguf"
        },
        {
          "rfilename": "em_german_13b_v01.Q6_K.gguf"
        },
        {
          "rfilename": "em_german_13b_v01.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651192ccec3eef908a7872b9",
      "id": "jphme/em_german_13b_v01",
      "modelId": "jphme/em_german_13b_v01",
      "author": "jphme",
      "sha": "a9c198d3f008f40f85a7cf9a21814a8ae161db27",
      "lastModified": "2023-10-12T11:12:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "pytorch",
        "german",
        "deutsch",
        "llama2",
        "meta",
        "facebook",
        "de",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 103,
      "library_name": "transformers",
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "inference": false,
        "language": [
          "de"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "jphme",
        "model_name": "EM German",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Du bist ein hilfreicher Assistent. USER: Was ist 1+1? ASSISTANT:",
        "tags": [
          "pytorch",
          "german",
          "deutsch",
          "llama2",
          "meta",
          "facebook"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "em_model_logo_web.jpeg"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6519ef8a69c938b3d635ab66",
    "id": "TheBloke/em_german_70b_v01-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "facebook",
      "meta",
      "pytorch",
      "llama-2",
      "german",
      "deutsch",
      "text-generation",
      "de",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/em_german_70b_v01-GGUF",
    "model": {
      "_id": "6519ef8a69c938b3d635ab66",
      "id": "TheBloke/em_german_70b_v01-GGUF",
      "modelId": "TheBloke/em_german_70b_v01-GGUF",
      "author": "TheBloke",
      "sha": "20631bf9b2619757a7645cd84f67000f4f880a73",
      "lastModified": "2023-10-01T23:29:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "german",
        "deutsch",
        "text-generation",
        "de",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "jphme/em_german_70b_v01",
        "inference": false,
        "language": [
          "de"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "Jan Philipp Harries",
        "model_name": "EM German 70B v01",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Du bist ein hilfreicher Assistent. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2",
          "german",
          "deutsch"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "em_german_70b_v01.Q2_K.gguf"
        },
        {
          "rfilename": "em_german_70b_v01.Q3_K_L.gguf"
        },
        {
          "rfilename": "em_german_70b_v01.Q3_K_M.gguf"
        },
        {
          "rfilename": "em_german_70b_v01.Q3_K_S.gguf"
        },
        {
          "rfilename": "em_german_70b_v01.Q4_0.gguf"
        },
        {
          "rfilename": "em_german_70b_v01.Q4_K_M.gguf"
        },
        {
          "rfilename": "em_german_70b_v01.Q4_K_S.gguf"
        },
        {
          "rfilename": "em_german_70b_v01.Q5_0.gguf"
        },
        {
          "rfilename": "em_german_70b_v01.Q5_K_M.gguf"
        },
        {
          "rfilename": "em_german_70b_v01.Q5_K_S.gguf"
        },
        {
          "rfilename": "em_german_70b_v01.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "em_german_70b_v01.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "em_german_70b_v01.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "em_german_70b_v01.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "650cdd45664ad78790c5afa8",
      "id": "jphme/em_german_70b_v01",
      "modelId": "jphme/em_german_70b_v01",
      "author": "jphme",
      "sha": "b4a43f669e10025dabecb0425ad8202ca6ca15db",
      "lastModified": "2023-10-12T11:11:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "german",
        "deutsch",
        "llama2",
        "meta",
        "facebook",
        "de",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 260,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "inference": false,
        "language": [
          "de"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "jphme",
        "model_name": "EM German",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Du bist ein hilfreicher Assistent. USER: Was ist 1+1? ASSISTANT:",
        "tags": [
          "pytorch",
          "german",
          "deutsch",
          "llama2",
          "meta",
          "facebook"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "em_model_logo_web.jpeg"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651a09d666096ebbfe33e99b",
    "id": "TheBloke/em_german_7b_v01-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 10,
    "tags": [
      "transformers",
      "llama",
      "facebook",
      "meta",
      "pytorch",
      "llama-2",
      "german",
      "deutsch",
      "text-generation",
      "de",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/em_german_7b_v01-GGUF",
    "model": {
      "_id": "651a09d666096ebbfe33e99b",
      "id": "TheBloke/em_german_7b_v01-GGUF",
      "modelId": "TheBloke/em_german_7b_v01-GGUF",
      "author": "TheBloke",
      "sha": "d09c0d1b5187c65c57ac92cbf565404ad451483e",
      "lastModified": "2023-10-02T00:14:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "facebook",
        "meta",
        "pytorch",
        "llama-2",
        "german",
        "deutsch",
        "text-generation",
        "de",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "jphme/em_german_7b_v01",
        "inference": false,
        "language": [
          "de"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "Jan Philipp Harries",
        "model_name": "EM German 7B v01",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Du bist ein hilfreicher Assistent. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "facebook",
          "meta",
          "pytorch",
          "llama",
          "llama-2",
          "german",
          "deutsch"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "em_german_7b_v01.Q2_K.gguf"
        },
        {
          "rfilename": "em_german_7b_v01.Q3_K_L.gguf"
        },
        {
          "rfilename": "em_german_7b_v01.Q3_K_M.gguf"
        },
        {
          "rfilename": "em_german_7b_v01.Q3_K_S.gguf"
        },
        {
          "rfilename": "em_german_7b_v01.Q4_0.gguf"
        },
        {
          "rfilename": "em_german_7b_v01.Q4_K_M.gguf"
        },
        {
          "rfilename": "em_german_7b_v01.Q4_K_S.gguf"
        },
        {
          "rfilename": "em_german_7b_v01.Q5_0.gguf"
        },
        {
          "rfilename": "em_german_7b_v01.Q5_K_M.gguf"
        },
        {
          "rfilename": "em_german_7b_v01.Q5_K_S.gguf"
        },
        {
          "rfilename": "em_german_7b_v01.Q6_K.gguf"
        },
        {
          "rfilename": "em_german_7b_v01.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65119302ddff1f185ab5f611",
      "id": "jphme/em_german_7b_v01",
      "modelId": "jphme/em_german_7b_v01",
      "author": "jphme",
      "sha": "ae9cff0f3ba88e922832f98d38a0da2ac49533f6",
      "lastModified": "2023-10-27T23:52:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "pytorch",
        "german",
        "deutsch",
        "llama2",
        "meta",
        "facebook",
        "de",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5467,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "inference": false,
        "language": [
          "de"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "jphme",
        "model_name": "EM German",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Du bist ein hilfreicher Assistent. USER: Was ist 1+1? ASSISTANT:",
        "tags": [
          "pytorch",
          "german",
          "deutsch",
          "llama2",
          "meta",
          "facebook"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 6738415616
        },
        "total": 6738415616
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "em_model_logo_web.jpeg"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651ad36f85985c338b5cf207",
    "id": "TheBloke/Mistral-7B-OpenOrca-GGUF",
    "likes": 162,
    "private": false,
    "downloads": 1981,
    "tags": [
      "transformers",
      "mistral",
      "text-generation",
      "en",
      "dataset:Open-Orca/OpenOrca",
      "arxiv:2306.02707",
      "arxiv:2301.13688",
      "license:apache-2.0",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Mistral-7B-OpenOrca-GGUF",
    "model": {
      "_id": "651ad36f85985c338b5cf207",
      "id": "TheBloke/Mistral-7B-OpenOrca-GGUF",
      "modelId": "TheBloke/Mistral-7B-OpenOrca-GGUF",
      "author": "TheBloke",
      "sha": "fbd9cd059e5fa0bba72a0abe8aea7e127d7994cb",
      "lastModified": "2023-10-02T23:16:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "arxiv:2306.02707",
        "arxiv:2301.13688",
        "license:apache-2.0",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1981,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 162,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "Open-Orca/Mistral-7B-OpenOrca",
        "datasets": [
          "Open-Orca/OpenOrca"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "OpenOrca",
        "model_name": "Mistral 7B OpenOrca",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "limcheekin/Mistral-7B-OpenOrca-GGUF",
        "seanpedrickcase/Light-PDF-Web-QA-Chatbot",
        "Cran-May/SEA-orca",
        "cedpsam/mistral_openorca_lamacpp",
        "JSP/test4k",
        "JDWebProgrammer/chatbot",
        "cloudchng/augmented-analytic",
        "marekk/Mistral-7B-OpenOrca-GGUF",
        "seanpedrickcase/open_text_summariser"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-7b-openorca.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-7b-openorca.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-7b-openorca.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-openorca.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-openorca.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-7b-openorca.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-openorca.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-openorca.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-7b-openorca.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-openorca.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-openorca.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-7b-openorca.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6517230e0e3a5553d462a92b",
      "id": "Open-Orca/Mistral-7B-OpenOrca",
      "modelId": "Open-Orca/Mistral-7B-OpenOrca",
      "author": "Open-Orca",
      "sha": "8f934b2bd2d4484b846a7faf1c53093b9d956367",
      "lastModified": "2023-10-10T21:07:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "arxiv:2306.02707",
        "arxiv:2301.13688",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 82238,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 411,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "datasets": [
          "Open-Orca/OpenOrca"
        ],
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Open-Orca/Mistral-7B-OpenOrca",
        "limcheekin/Mistral-7B-OpenOrca-GGUF",
        "JSP/test4k",
        "Tonic/OrcaMistral7B",
        "Prakash1015/Open-Orca-Mistral-7B-OpenOrca",
        "sobeyd/Open-Orca-Mistral-7B-OpenOrca",
        "bonomg/Open-Orca-Mistral-7B-OpenOrca",
        "bonomg/Open-Orca-Mistral-7B-OpenOrca2",
        "bonomg/Open-Orca-Mistral-7B-OpenOrca-bono",
        "bonomg/Open-Orca-Mistral-7B-OpenOrcaa",
        "bonomg/Open-Orca-Mistral-7B-OpenOrca-1",
        "bonomg/Open-Orca-Mistral-7B-OpenOrca-2",
        "bonomg/Open-Orca-Mistral-7B-OpenOrca-3",
        "awakenai/fast-api-transformers-pipeline-v2",
        "amritsolar/chatgpt2.0",
        "Komes/Open-Orca-Mistral-7B-OpenOrca",
        "iloveapplesandoranges/Open-Orca-Mistral-7B-OpenOrca",
        "Jasshan/Open-Orca-Mistral-7B-OpenOrca",
        "yyy1227/Open-Orca-Mistral-7B-OpenOrca",
        "Felladrin/Web-LLM-Mistral-7B-OpenOrca",
        "jquisenberry-consilio/Open-Orca-Mistral-7B-OpenOrca",
        "marekk/Mistral-7B-OpenOrca-GGUF",
        "jquisenberry-consilio/Open-Orca-Mistral-7B-OpenOrca2",
        "Tushar38372/Open-Orca-Mistral-7B-OpenOrca",
        "agrpankaj/Open-Orca-Mistral-7B-OpenOrca",
        "dancers/Open-Orca-Mistral-7B-OpenOrca",
        "Carreraella/Open-Orca-Mistral-7B-OpenOrca",
        "shethjenil/Open-Orca-Mistral-7B-OpenOrca",
        "JSP/Mistral-7B-OpenOrca",
        "irotom/Open-Orca-Mistral-7B-OpenOrca",
        "sfraga/Open-Orca-Mistral-7B-OpenOrca",
        "firerszd/Open-Orca-Mistral-7B-OpenOrca"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Images/MistralOrca7BAGIEval.png"
        },
        {
          "rfilename": "Images/MistralOrca7BBigBenchHard.png"
        },
        {
          "rfilename": "Images/MistralOrca7BGPT4ALL.png"
        },
        {
          "rfilename": "Images/MistralOrca7BHFLeaderboard.png"
        },
        {
          "rfilename": "Images/MistralOrca7BMTBENCH.png"
        },
        {
          "rfilename": "Images/MistralOrcaLogo.png"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configs/mistral-7b-oo-phase1.yml"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651ad59ecd08536ba4c807ce",
    "id": "TheBloke/Inkbot-13B-8k-0.2-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 25,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Inkbot-13B-8k-0.2-GGUF",
    "model": {
      "_id": "651ad59ecd08536ba4c807ce",
      "id": "TheBloke/Inkbot-13B-8k-0.2-GGUF",
      "modelId": "TheBloke/Inkbot-13B-8k-0.2-GGUF",
      "author": "TheBloke",
      "sha": "b95af40a646e955f3d7b9388fcc2a1321b843759",
      "lastModified": "2023-10-02T15:01:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 25,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Tostino/Inkbot-13B-8k-0.2",
        "inference": false,
        "license": "llama2",
        "model_creator": "Adam Brusselback",
        "model_name": "Inkbot 13B 8K 0.2",
        "model_type": "llama",
        "prompt_template": "<#meta#>\n- Date: [DATE]\n- Task: [TASK TYPE]\n<#system#>\n{system_message}\n<#chat#>\n<#user#>\n{prompt}\n<#bot#>\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "inkbot-13b-8k-0.2.Q2_K.gguf"
        },
        {
          "rfilename": "inkbot-13b-8k-0.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "inkbot-13b-8k-0.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "inkbot-13b-8k-0.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "inkbot-13b-8k-0.2.Q4_0.gguf"
        },
        {
          "rfilename": "inkbot-13b-8k-0.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "inkbot-13b-8k-0.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "inkbot-13b-8k-0.2.Q5_0.gguf"
        },
        {
          "rfilename": "inkbot-13b-8k-0.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "inkbot-13b-8k-0.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "inkbot-13b-8k-0.2.Q6_K.gguf"
        },
        {
          "rfilename": "inkbot-13b-8k-0.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651a6c2129af405887fa928f",
      "id": "Tostino/Inkbot-13B-8k-0.2",
      "modelId": "Tostino/Inkbot-13B-8k-0.2",
      "author": "Tostino",
      "sha": "bcba660eb926713cbba12eea411845b0082c25ba",
      "lastModified": "2023-10-16T18:32:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 147,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 15,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651b3e866c8f1e8ec09b3cfd",
    "id": "TheBloke/Nous-Capybara-7B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 7,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "sft",
      "eng",
      "dataset:LDJnr/LessWrong-Amplify-Instruct",
      "dataset:LDJnr/Pure-Dove",
      "dataset:LDJnr/Verified-Camel",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Nous-Capybara-7B-GGUF",
    "model": {
      "_id": "651b3e866c8f1e8ec09b3cfd",
      "id": "TheBloke/Nous-Capybara-7B-GGUF",
      "modelId": "TheBloke/Nous-Capybara-7B-GGUF",
      "author": "TheBloke",
      "sha": "6c2065da61919193664856c51fb6bf4ea302c3a7",
      "lastModified": "2023-10-02T22:11:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "sft",
        "eng",
        "dataset:LDJnr/LessWrong-Amplify-Instruct",
        "dataset:LDJnr/Pure-Dove",
        "dataset:LDJnr/Verified-Camel",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "NousResearch/Nous-Capybara-7B",
        "datasets": [
          "LDJnr/LessWrong-Amplify-Instruct",
          "LDJnr/Pure-Dove",
          "LDJnr/Verified-Camel"
        ],
        "inference": false,
        "language": [
          "eng"
        ],
        "license": [
          "mit"
        ],
        "model_creator": "NousResearch",
        "model_name": "Nous Capybara 7B",
        "model_type": "llama",
        "prompt_template": "USER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "llama-2",
          "sft"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "nous-capybara-7b.Q2_K.gguf"
        },
        {
          "rfilename": "nous-capybara-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "nous-capybara-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "nous-capybara-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "nous-capybara-7b.Q4_0.gguf"
        },
        {
          "rfilename": "nous-capybara-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "nous-capybara-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "nous-capybara-7b.Q5_0.gguf"
        },
        {
          "rfilename": "nous-capybara-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "nous-capybara-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "nous-capybara-7b.Q6_K.gguf"
        },
        {
          "rfilename": "nous-capybara-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "650a460b1b3694179dfe20a2",
      "id": "NousResearch/Nous-Capybara-7B-V1",
      "modelId": "NousResearch/Nous-Capybara-7B-V1",
      "author": "NousResearch",
      "sha": "746ac8c7597fd2b7a6da5bd09e648fa1286e9534",
      "lastModified": "2023-10-28T21:17:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "sft",
        "eng",
        "dataset:LDJnr/LessWrong-Amplify-Instruct",
        "dataset:LDJnr/Pure-Dove",
        "dataset:LDJnr/Verified-Camel",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 14599,
      "library_name": "transformers",
      "likes": 17,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "eng"
        ],
        "tags": [
          "llama-2",
          "sft"
        ],
        "license": [
          "mit"
        ],
        "datasets": [
          "LDJnr/LessWrong-Amplify-Instruct",
          "LDJnr/Pure-Dove",
          "LDJnr/Verified-Camel"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651b43c9f9dd34ee028a7769",
    "id": "TheBloke/dolphin-2.0-mistral-7B-GGUF",
    "likes": 20,
    "private": false,
    "downloads": 65,
    "tags": [
      "transformers",
      "mistral",
      "en",
      "dataset:ehartford/dolphin",
      "dataset:jondurbin/airoboros-2.2.1",
      "license:apache-2.0",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/dolphin-2.0-mistral-7B-GGUF",
    "model": {
      "_id": "651b43c9f9dd34ee028a7769",
      "id": "TheBloke/dolphin-2.0-mistral-7B-GGUF",
      "modelId": "TheBloke/dolphin-2.0-mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "3b345ee148d25b2da209c6166e855dc4845fcb4e",
      "lastModified": "2023-10-02T22:46:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "en",
        "dataset:ehartford/dolphin",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:apache-2.0",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 65,
      "library_name": "transformers",
      "likes": 20,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "ehartford/dolphin-2.0-mistral-7b",
        "datasets": [
          "ehartford/dolphin",
          "jondurbin/airoboros-2.2.1"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "model_creator": "Eric Hartford",
        "model_name": "Dolphin 2.0 Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "Cran-May/Shi-CI.Extensional.Analyzer"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "dolphin-2.0-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "dolphin-2.0-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "dolphin-2.0-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "dolphin-2.0-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "dolphin-2.0-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "dolphin-2.0-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "dolphin-2.0-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "dolphin-2.0-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "dolphin-2.0-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "dolphin-2.0-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "dolphin-2.0-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "dolphin-2.0-mistral-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651b3c86704bfab3989b8c95",
      "id": "ehartford/dolphin-2.0-mistral-7b",
      "modelId": "ehartford/dolphin-2.0-mistral-7b",
      "author": "ehartford",
      "sha": "c673387016c622fd0a707426953c03957398bc37",
      "lastModified": "2023-10-03T16:25:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "en",
        "dataset:ehartford/dolphin",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6789,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 87,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "datasets": [
          "ehartford/dolphin",
          "jondurbin/airoboros-2.2.1"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "AlexTagger/ehartford-dolphin-2.0-mistral-7b",
        "bnto657/ehartford-dolphin-2.0-mistral-7b",
        "Carreraella/ehartford-dolphin-2.0-mistral-7b",
        "Betacuckgpt/ehartford-dolphin-2.0-mistral-7b",
        "elramly/ehartford-dolphin-2.0-mistral-7b",
        "Reza2kn/ehartford-dolphin-2.0-mistral-7b",
        "deathoperator/ehartford-dolphin-2.0-mistral-7b",
        "Cbrules3033/ehartford-dolphin-2.0-mistral-7b",
        "nuser/ehartford-dolphin-2.0-mistral-7b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651b50a9b6109ba14026ff19",
    "id": "TheBloke/Nous-Hermes-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 22,
    "tags": [
      "transformers",
      "llama",
      "self-instruct",
      "distillation",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Nous-Hermes-13B-GGUF",
    "model": {
      "_id": "651b50a9b6109ba14026ff19",
      "id": "TheBloke/Nous-Hermes-13B-GGUF",
      "modelId": "TheBloke/Nous-Hermes-13B-GGUF",
      "author": "TheBloke",
      "sha": "1fdc990e0588a21093ba3091f7117c3632e42901",
      "lastModified": "2023-10-02T23:31:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "self-instruct",
        "distillation",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 22,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "NousResearch/Nous-Hermes-13b",
        "inference": false,
        "language": [
          "en"
        ],
        "license": "other",
        "model_creator": "NousResearch",
        "model_name": "Nous Hermes 13B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "llama",
          "self-instruct",
          "distillation"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Nous-Hermes-13B.Q2_K.gguf"
        },
        {
          "rfilename": "Nous-Hermes-13B.Q3_K_L.gguf"
        },
        {
          "rfilename": "Nous-Hermes-13B.Q3_K_M.gguf"
        },
        {
          "rfilename": "Nous-Hermes-13B.Q3_K_S.gguf"
        },
        {
          "rfilename": "Nous-Hermes-13B.Q4_0.gguf"
        },
        {
          "rfilename": "Nous-Hermes-13B.Q4_K_M.gguf"
        },
        {
          "rfilename": "Nous-Hermes-13B.Q4_K_S.gguf"
        },
        {
          "rfilename": "Nous-Hermes-13B.Q5_0.gguf"
        },
        {
          "rfilename": "Nous-Hermes-13B.Q5_K_M.gguf"
        },
        {
          "rfilename": "Nous-Hermes-13B.Q5_K_S.gguf"
        },
        {
          "rfilename": "Nous-Hermes-13B.Q6_K.gguf"
        },
        {
          "rfilename": "Nous-Hermes-13B.Q8_0.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "647ab1cec7367455fda7378d",
      "id": "NousResearch/Nous-Hermes-13b",
      "modelId": "NousResearch/Nous-Hermes-13b",
      "author": "NousResearch",
      "sha": "24e8c03148ffd1f3e469744dfc24ad2ad82848f8",
      "lastModified": "2023-06-05T00:36:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "self-instruct",
        "distillation",
        "en",
        "license:gpl",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5388,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 393,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "gpl",
        "language": [
          "en"
        ],
        "tags": [
          "llama",
          "self-instruct",
          "distillation"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "upstage/open-ko-llm-leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "distbit/NousResearch-Nous-Hermes-13b",
        "gtome/NousResearch-Nous-Hermes-13b",
        "b1sheng/kg_llm_leaderboard_test",
        "srikanth-nm/ai_seeker",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "klodi1379/NousResearch-Nous-Hermes-13b",
        "howc0n/NousResearch-Nous-Hermes-13b",
        "Cvader/NousResearch-Nous-Hermes-13b",
        "Zoltan1111/NousResearch-Nous-Hermes-13b",
        "Kintsugi/NousResearch-Nous-Hermes-13b",
        "Noma6792/NousResearch-Nous-Hermes-13b",
        "Z3rkhol/NousResearch-Nous-Hermes-13b",
        "victor/NousResearch-Nous-Hermes-13b",
        "Wicaugen/NousResearch-Nous-Hermes-13b",
        "alexorbit/NousResearch-Nous-Hermes-13b",
        "gr00ve/NousResearch-Nous-Hermes-13b",
        "ikelyo/NousResearch-Nous-Hermes-13b",
        "9bestenbier/NousResearch-Nous-Hermes-13b",
        "DonDoesStuff/NousResearch-Nous-Hermes-13b",
        "IAsk/NousResearch-Nous-Hermes-13b",
        "CazC/smallville",
        "pngwn/open_llm_leaderboard",
        "pngwn/open_llm_leaderboard_two",
        "freddyaboulton/open_llm_leaderboard_two_fix",
        "choco9966/LeaderboardTest",
        "csalabs/AI-EMBD",
        "csalabs/Replicate-7b-chat-Llama-streamlit",
        "TheVortexProject/open_llm_leaderboard",
        "dkdaniz/katara",
        "JaydenMcCross/NousResearch-Nous-Hermes-13b",
        "tahvili/localGPT-test",
        "pngspam/NousResearch-Nous-Hermes-13b",
        "choco9966/open-ko-llm-leaderboard",
        "CoinCartel/NousResearch-Nous-Hermes-13b",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651bf48063cd12f4ba8db2f5",
    "id": "TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF",
    "likes": 19,
    "private": false,
    "downloads": 106,
    "tags": [
      "transformers",
      "tinyllama",
      "en",
      "dataset:cerebras/SlimPajama-627B",
      "dataset:bigcode/starcoderdata",
      "dataset:OpenAssistant/oasst_top1_2023-08-25",
      "license:apache-2.0",
      "has_space",
      "region:us"
    ],
    "modelId": "TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF",
    "model": {
      "_id": "651bf48063cd12f4ba8db2f5",
      "id": "TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF",
      "modelId": "TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF",
      "author": "TheBloke",
      "sha": "b32046744d93031a26c8e925de2c8932c305f7b9",
      "lastModified": "2023-10-03T11:05:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "tinyllama",
        "en",
        "dataset:cerebras/SlimPajama-627B",
        "dataset:bigcode/starcoderdata",
        "dataset:OpenAssistant/oasst_top1_2023-08-25",
        "license:apache-2.0",
        "has_space",
        "region:us"
      ],
      "downloads": 106,
      "library_name": "transformers",
      "likes": 19,
      "model-index": null,
      "config": {
        "model_type": "tinyllama"
      },
      "cardData": {
        "base_model": "PY007/TinyLlama-1.1B-Chat-v0.3",
        "datasets": [
          "cerebras/SlimPajama-627B",
          "bigcode/starcoderdata",
          "OpenAssistant/oasst_top1_2023-08-25"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "model_creator": "Zhang Peiyuan",
        "model_name": "TinyLlama 1.1B Chat v0.3",
        "model_type": "tinyllama",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "limcheekin/TinyLlama-1.1B-Chat-v0.3-GGUF",
        "Renegadesoffun/BuddyChrist"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tinyllama-1.1b-chat-v0.3.Q2_K.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-chat-v0.3.Q3_K_L.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-chat-v0.3.Q3_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-chat-v0.3.Q3_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-chat-v0.3.Q4_0.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-chat-v0.3.Q4_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-chat-v0.3.Q5_0.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-chat-v0.3.Q5_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-chat-v0.3.Q5_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-chat-v0.3.Q6_K.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-chat-v0.3.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65203de7578e7da0d71891e5",
      "id": "PY007/TinyLlama-1.1B-Chat-v0.3",
      "modelId": "PY007/TinyLlama-1.1B-Chat-v0.3",
      "author": "PY007",
      "sha": "01ac7c253773bc892478dcc931cd4647d60df139",
      "lastModified": "2023-10-07T09:17:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:cerebras/SlimPajama-627B",
        "dataset:bigcode/starcoderdata",
        "dataset:OpenAssistant/oasst_top1_2023-08-25",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 12132,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 14,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "datasets": [
          "cerebras/SlimPajama-627B",
          "bigcode/starcoderdata",
          "OpenAssistant/oasst_top1_2023-08-25"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "dsank/PY007-TinyLlama-1.1B-Chat-v0.3",
        "Tomoniai/TinyLlama_Chat",
        "limcheekin/TinyLlama-1.1B-Chat-v0.3-GGUF",
        "mattritchey/ChatBot_TinyLlama"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651bf6a4fb8e5721f7033b7f",
    "id": "TheBloke/TinyLlama-1.1B-python-v0.1-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 13,
    "tags": [
      "transformers",
      "tinyllama",
      "en",
      "dataset:cerebras/SlimPajama-627B",
      "dataset:bigcode/starcoderdata",
      "license:apache-2.0",
      "region:us"
    ],
    "modelId": "TheBloke/TinyLlama-1.1B-python-v0.1-GGUF",
    "model": {
      "_id": "651bf6a4fb8e5721f7033b7f",
      "id": "TheBloke/TinyLlama-1.1B-python-v0.1-GGUF",
      "modelId": "TheBloke/TinyLlama-1.1B-python-v0.1-GGUF",
      "author": "TheBloke",
      "sha": "fe232e11b4b0975b2ffd569e9c552e8c2667a7ff",
      "lastModified": "2023-10-03T11:13:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "tinyllama",
        "en",
        "dataset:cerebras/SlimPajama-627B",
        "dataset:bigcode/starcoderdata",
        "license:apache-2.0",
        "region:us"
      ],
      "downloads": 13,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "tinyllama"
      },
      "cardData": {
        "base_model": "PY007/TinyLlama-1.1B-python-v0.1",
        "datasets": [
          "cerebras/SlimPajama-627B",
          "bigcode/starcoderdata"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "model_creator": "Zhang Peiyuan",
        "model_name": "TinyLlama 1.1B Python v0.1",
        "model_type": "tinyllama",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tinyllama-1.1b-python-v0.1.Q2_K.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-python-v0.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-python-v0.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-python-v0.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-python-v0.1.Q4_0.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-python-v0.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-python-v0.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-python-v0.1.Q5_0.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-python-v0.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-python-v0.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-python-v0.1.Q6_K.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-python-v0.1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651ba533b9ae9f37afb8125c",
      "id": "PY007/TinyLlama-1.1B-python-v0.1",
      "modelId": "PY007/TinyLlama-1.1B-python-v0.1",
      "author": "PY007",
      "sha": "f8cb02e22e3da38ef962fe1eb1be7f70215253f7",
      "lastModified": "2023-10-03T05:46:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:cerebras/SlimPajama-627B",
        "dataset:bigcode/starcoderdata",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 364,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "datasets": [
          "cerebras/SlimPajama-627B",
          "bigcode/starcoderdata"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "tomaszki/PythonFileCompressor"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "ggml-model-q4_0.gguf"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651c4058e648c876f13cf776",
    "id": "TheBloke/em_german_mistral_v01-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 33,
    "tags": [
      "transformers",
      "mistral",
      "pytorch",
      "german",
      "deutsch",
      "text-generation",
      "de",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/em_german_mistral_v01-GGUF",
    "model": {
      "_id": "651c4058e648c876f13cf776",
      "id": "TheBloke/em_german_mistral_v01-GGUF",
      "modelId": "TheBloke/em_german_mistral_v01-GGUF",
      "author": "TheBloke",
      "sha": "3826f54b7a6822e371bf412f7b3988dc709293af",
      "lastModified": "2023-10-10T17:34:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "pytorch",
        "german",
        "deutsch",
        "text-generation",
        "de",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 33,
      "library_name": "transformers",
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "jphme/em_german_mistral_v01",
        "inference": false,
        "language": [
          "de"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "Jan Philipp Harries",
        "model_name": "EM German Mistral v01",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "Du bist ein hilfreicher Assistent. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "pytorch",
          "german",
          "deutsch",
          "mistral"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "em_german_mistral_v01.Q2_K.gguf"
        },
        {
          "rfilename": "em_german_mistral_v01.Q3_K_L.gguf"
        },
        {
          "rfilename": "em_german_mistral_v01.Q3_K_M.gguf"
        },
        {
          "rfilename": "em_german_mistral_v01.Q3_K_S.gguf"
        },
        {
          "rfilename": "em_german_mistral_v01.Q4_0.gguf"
        },
        {
          "rfilename": "em_german_mistral_v01.Q4_K_M.gguf"
        },
        {
          "rfilename": "em_german_mistral_v01.Q4_K_S.gguf"
        },
        {
          "rfilename": "em_german_mistral_v01.Q5_0.gguf"
        },
        {
          "rfilename": "em_german_mistral_v01.Q5_K_M.gguf"
        },
        {
          "rfilename": "em_german_mistral_v01.Q5_K_S.gguf"
        },
        {
          "rfilename": "em_german_mistral_v01.Q6_K.gguf"
        },
        {
          "rfilename": "em_german_mistral_v01.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65154a11e296d8e6e47cff42",
      "id": "jphme/em_german_mistral_v01",
      "modelId": "jphme/em_german_mistral_v01",
      "author": "jphme",
      "sha": "1cd12da7958065c1c9e7c0ab34577cd5caf6bf38",
      "lastModified": "2023-10-12T11:13:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "pytorch",
        "german",
        "deutsch",
        "de",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1016,
      "library_name": "transformers",
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "inference": false,
        "language": [
          "de"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "jphme",
        "model_name": "EM German",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "Du bist ein hilfreicher Assistent. USER: Was ist 1+1? ASSISTANT:",
        "tags": [
          "pytorch",
          "german",
          "deutsch",
          "mistral"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "em_model_logo_web.jpeg"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651c4a05b61dff6c00b4ca5a",
    "id": "TheBloke/TinyLlama-1.1B-intermediate-step-480k-1T-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 19,
    "tags": [
      "transformers",
      "tinyllama",
      "en",
      "dataset:cerebras/SlimPajama-627B",
      "dataset:bigcode/starcoderdata",
      "license:apache-2.0",
      "region:us"
    ],
    "modelId": "TheBloke/TinyLlama-1.1B-intermediate-step-480k-1T-GGUF",
    "model": {
      "_id": "651c4a05b61dff6c00b4ca5a",
      "id": "TheBloke/TinyLlama-1.1B-intermediate-step-480k-1T-GGUF",
      "modelId": "TheBloke/TinyLlama-1.1B-intermediate-step-480k-1T-GGUF",
      "author": "TheBloke",
      "sha": "a048935c0bb59569049ae02bb7d7fd86b021e0d1",
      "lastModified": "2023-10-03T17:09:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "tinyllama",
        "en",
        "dataset:cerebras/SlimPajama-627B",
        "dataset:bigcode/starcoderdata",
        "license:apache-2.0",
        "region:us"
      ],
      "downloads": 19,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "tinyllama"
      },
      "cardData": {
        "base_model": "PY007/TinyLlama-1.1B-intermediate-step-480k-1T",
        "datasets": [
          "cerebras/SlimPajama-627B",
          "bigcode/starcoderdata"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "model_creator": "Zhang Peiyuan",
        "model_name": "TinyLlama 1.1B Intermediate Step 480K 1T",
        "model_type": "tinyllama",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tinyllama-1.1b-intermediate-step-480k-1t.Q2_K.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-intermediate-step-480k-1t.Q3_K_L.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-intermediate-step-480k-1t.Q3_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-intermediate-step-480k-1t.Q3_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-intermediate-step-480k-1t.Q4_0.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-intermediate-step-480k-1t.Q4_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-intermediate-step-480k-1t.Q4_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-intermediate-step-480k-1t.Q5_0.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-intermediate-step-480k-1t.Q5_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-intermediate-step-480k-1t.Q5_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-intermediate-step-480k-1t.Q6_K.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-intermediate-step-480k-1t.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651a40a42b4fffcb41187483",
      "id": "PY007/TinyLlama-1.1B-intermediate-step-480k-1T",
      "modelId": "PY007/TinyLlama-1.1B-intermediate-step-480k-1T",
      "author": "PY007",
      "sha": "098830e58452a0a08f90eb0189ec5925803fd48b",
      "lastModified": "2023-10-02T05:15:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:cerebras/SlimPajama-627B",
        "dataset:bigcode/starcoderdata",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 19404,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 22,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "datasets": [
          "cerebras/SlimPajama-627B",
          "bigcode/starcoderdata"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Vokturz/can-it-run-llm",
        "imjunaidafzal/can-it-run-llm",
        "muellerzr/can-it-run-llm"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651c8d15b2d77f1f94c9c4a7",
    "id": "TheBloke/airoboros-mistral2.2-7B-GGUF",
    "likes": 17,
    "private": false,
    "downloads": 41,
    "tags": [
      "transformers",
      "mistral",
      "llama-2",
      "instruct",
      "finetune",
      "alpaca",
      "gpt4",
      "synthetic data",
      "distillation",
      "en",
      "dataset:jondurbin/airoboros-2.2.1",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-mistral2.2-7B-GGUF",
    "model": {
      "_id": "651c8d15b2d77f1f94c9c4a7",
      "id": "TheBloke/airoboros-mistral2.2-7B-GGUF",
      "modelId": "TheBloke/airoboros-mistral2.2-7B-GGUF",
      "author": "TheBloke",
      "sha": "cfd2d0c4a9de32190c6c5c80e80391f7e577f3ef",
      "lastModified": "2023-10-03T22:01:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "llama-2",
        "instruct",
        "finetune",
        "alpaca",
        "gpt4",
        "synthetic data",
        "distillation",
        "en",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 41,
      "library_name": "transformers",
      "likes": 17,
      "model-index": [
        {
          "name": "airoboros2.2-mistral-7b",
          "results": []
        }
      ],
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "teknium/airoboros-mistral2.2-7b",
        "datasets": [
          "jondurbin/airoboros-2.2.1"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "mit",
        "model-index": [
          {
            "name": "airoboros2.2-mistral-7b",
            "results": []
          }
        ],
        "model_creator": "Teknium",
        "model_name": "Airoboros Mistral2.2 7B",
        "model_type": "mistral",
        "prompt_template": "USER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "llama-2",
          "instruct",
          "finetune",
          "alpaca",
          "gpt4",
          "synthetic data",
          "distillation"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "airoboros-mistral2.2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-mistral2.2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-mistral2.2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-mistral2.2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-mistral2.2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-mistral2.2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-mistral2.2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-mistral2.2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-mistral2.2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-mistral2.2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-mistral2.2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-mistral2.2-7b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "651c2e47fb8e5721f70be6a2",
      "id": "teknium/airoboros-mistral2.2-7b",
      "modelId": "teknium/airoboros-mistral2.2-7b",
      "author": "teknium",
      "sha": "9ae77d465b2dc9dc768aa1dca94f03092781e44b",
      "lastModified": "2023-10-03T18:18:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "llama-2",
        "instruct",
        "finetune",
        "alpaca",
        "gpt4",
        "synthetic data",
        "distillation",
        "en",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:mit",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 135,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 23,
      "model-index": [
        {
          "name": "airoboros2.2-mistral-7b",
          "results": []
        }
      ],
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "mistralai/Mistral-7b-V0.1",
        "tags": [
          "llama-2",
          "instruct",
          "finetune",
          "alpaca",
          "gpt4",
          "synthetic data",
          "distillation"
        ],
        "datasets": [
          "jondurbin/airoboros-2.2.1"
        ],
        "model-index": [
          {
            "name": "airoboros2.2-mistral-7b",
            "results": []
          }
        ],
        "license": "mit",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651d4d1c40009318a844ed93",
    "id": "TheBloke/Dans-AdventurousWinds-7B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "mistral",
      "en",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Dans-AdventurousWinds-7B-GGUF",
    "model": {
      "_id": "651d4d1c40009318a844ed93",
      "id": "TheBloke/Dans-AdventurousWinds-7B-GGUF",
      "modelId": "TheBloke/Dans-AdventurousWinds-7B-GGUF",
      "author": "TheBloke",
      "sha": "5bbfcb734a4ad330e4f3282d3730e6cc315dc8a6",
      "lastModified": "2023-10-04T11:47:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "en",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "PocketDoc/Dans-AdventurousWinds-7b",
        "inference": false,
        "language": [
          "en"
        ],
        "model_creator": "PocketDoc Labs",
        "model_name": "Dans AdventurousWinds 7B",
        "model_type": "mistral",
        "prompt_template": "[Genres: Science Fiction]\n[Tags: humor, old school, sci fi]\n[Mode: Adventure]\n[Description: A puzzle about committing acts of financial skulduggery and exploiting ridiculous magical items.]\n[Misc: Writing era: 1993]\n[Intro]\nIt is the year 2045. You are a young man in his twenties living in New York City. Your father was an inventor who died when you were very small; your mother raised you alone for many years until she remarried. Now you live with your stepfather, but he doesn't care much for you and has never given you any money to help support yourself. You have no job and little hope of getting one because of your lack of experience. However, you do have some unusual abilities that could be put to good use if only you knew how...\n\n> {prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "dans-adventurouswinds-7b.Q2_K.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-7b.Q4_0.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-7b.Q5_0.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-7b.Q6_K.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651cb928a6ffb55a1e592ccb",
      "id": "PocketDoc/Dans-AdventurousWinds-7b",
      "modelId": "PocketDoc/Dans-AdventurousWinds-7b",
      "author": "PocketDoc",
      "sha": "ddc7e4fcbbb5c666a3fe1bbe4a47b4477151b699",
      "lastModified": "2023-10-07T20:28:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "en",
        "dataset:PocketDoc/Floyd-Text-Adventures",
        "dataset:PocketDoc/Choose-Your-Story-Long-Text-Adventures",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3733,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "datasets": [
          "PocketDoc/Floyd-Text-Adventures",
          "PocketDoc/Choose-Your-Story-Long-Text-Adventures"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00004.safetensors"
        },
        {
          "rfilename": "model-00002-of-00004.safetensors"
        },
        {
          "rfilename": "model-00003-of-00004.safetensors"
        },
        {
          "rfilename": "model-00004-of-00004.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651d5d9eff8745149ae4a368",
    "id": "TheBloke/Dans-TotSirocco-7B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "mistral",
      "en",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Dans-TotSirocco-7B-GGUF",
    "model": {
      "_id": "651d5d9eff8745149ae4a368",
      "id": "TheBloke/Dans-TotSirocco-7B-GGUF",
      "modelId": "TheBloke/Dans-TotSirocco-7B-GGUF",
      "author": "TheBloke",
      "sha": "66505f70a37995ae2bf40b0bb69428b706127c95",
      "lastModified": "2023-10-04T12:49:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "en",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "PocketDoc/Dans-TotSirocco-7b",
        "inference": false,
        "language": [
          "en"
        ],
        "model_creator": "PocketDoc Labs",
        "model_name": "Dans TotSirocco 7B",
        "model_type": "mistral",
        "prompt_template": "<|system|>{system_message}<|user|>{prompt}<|model|>\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "dans-totsirocco-7b.Q2_K.gguf"
        },
        {
          "rfilename": "dans-totsirocco-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "dans-totsirocco-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "dans-totsirocco-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "dans-totsirocco-7b.Q4_0.gguf"
        },
        {
          "rfilename": "dans-totsirocco-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "dans-totsirocco-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "dans-totsirocco-7b.Q5_0.gguf"
        },
        {
          "rfilename": "dans-totsirocco-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "dans-totsirocco-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "dans-totsirocco-7b.Q6_K.gguf"
        },
        {
          "rfilename": "dans-totsirocco-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651ca833bbcf220233b518cf",
      "id": "PocketDoc/Dans-TotSirocco-7b",
      "modelId": "PocketDoc/Dans-TotSirocco-7b",
      "author": "PocketDoc",
      "sha": "824e3a4738818142374721306ce85b83770de24b",
      "lastModified": "2023-10-07T20:28:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "en",
        "dataset:PocketDoc/Floyd-Text-Adventures",
        "dataset:PocketDoc/Choose-Your-Story-Long-Text-Adventures",
        "dataset:CheshireAI/guanaco-unchained",
        "dataset:openchat/openchat_sharegpt4_dataset",
        "dataset:64bits/lima_vicuna_format",
        "dataset:gsm8k",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3819,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "datasets": [
          "PocketDoc/Floyd-Text-Adventures",
          "PocketDoc/Choose-Your-Story-Long-Text-Adventures",
          "CheshireAI/guanaco-unchained",
          "openchat/openchat_sharegpt4_dataset",
          "64bits/lima_vicuna_format",
          "gsm8k"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00004.safetensors"
        },
        {
          "rfilename": "model-00002-of-00004.safetensors"
        },
        {
          "rfilename": "model-00003-of-00004.safetensors"
        },
        {
          "rfilename": "model-00004-of-00004.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651d69a0878d9cd77b7f116e",
    "id": "TheBloke/Mistralic-7B-1-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 32,
    "tags": [
      "transformers",
      "mistral",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mistralic-7B-1-GGUF",
    "model": {
      "_id": "651d69a0878d9cd77b7f116e",
      "id": "TheBloke/Mistralic-7B-1-GGUF",
      "modelId": "TheBloke/Mistralic-7B-1-GGUF",
      "author": "TheBloke",
      "sha": "3847704afeca8f6ffcd8f25419e763d461206020",
      "lastModified": "2023-10-04T15:42:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 32,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "SkunkworksAI/Mistralic-7B-1",
        "inference": false,
        "model_creator": "SkunkworksAI",
        "model_name": "Mistralic 7B-1",
        "model_type": "mistral",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### System: {system_message}\n\n### Instruction: {prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistralic-7b-1.Q2_K.gguf"
        },
        {
          "rfilename": "mistralic-7b-1.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistralic-7b-1.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistralic-7b-1.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistralic-7b-1.Q4_0.gguf"
        },
        {
          "rfilename": "mistralic-7b-1.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistralic-7b-1.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistralic-7b-1.Q5_0.gguf"
        },
        {
          "rfilename": "mistralic-7b-1.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistralic-7b-1.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistralic-7b-1.Q6_K.gguf"
        },
        {
          "rfilename": "mistralic-7b-1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6517618599cf1a4e3901402f",
      "id": "SkunkworksAI/Mistralic-7B-1",
      "modelId": "SkunkworksAI/Mistralic-7B-1",
      "author": "SkunkworksAI",
      "sha": "ebf138de4fb7a57f0d187ad0ab43abd6b35bfb62",
      "lastModified": "2023-10-03T22:04:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "pytorch",
        "endpoints_compatible",
        "has_space",
        "region:us"
      ],
      "downloads": 6459,
      "library_name": "transformers",
      "likes": 19,
      "config": {},
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "Vokturz/can-it-run-llm",
        "imjunaidafzal/can-it-run-llm",
        "muellerzr/can-it-run-llm"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "zero_to_fp32.py"
        }
      ]
    }
  },
  {
    "_id": "651d7d598c7923c229dbfd29",
    "id": "TheBloke/Llama-2-7B-vietnamese-20k-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "llama-2",
      "llama-2-7B",
      "llama2-vietnamese",
      "vietnamese",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Llama-2-7B-vietnamese-20k-GGUF",
    "model": {
      "_id": "651d7d598c7923c229dbfd29",
      "id": "TheBloke/Llama-2-7B-vietnamese-20k-GGUF",
      "modelId": "TheBloke/Llama-2-7B-vietnamese-20k-GGUF",
      "author": "TheBloke",
      "sha": "1607495fae6a02d7a25748e200a5ff9abef3d11e",
      "lastModified": "2023-10-04T15:03:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "llama-2",
        "llama-2-7B",
        "llama2-vietnamese",
        "vietnamese",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "ngoantech/Llama-2-7b-vietnamese-20k",
        "inference": false,
        "license": "llama2",
        "model_creator": "Pham Van Ngoan",
        "model_name": "Llama 2 7B Vietnamese 20K",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke",
        "tags": [
          "text-generation",
          "llama-2",
          "llama-2-7B",
          "llama2-vietnamese",
          "vietnamese"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-7b-vietnamese-20k.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-vietnamese-20k.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-7b-vietnamese-20k.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-vietnamese-20k.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-vietnamese-20k.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-vietnamese-20k.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-vietnamese-20k.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-vietnamese-20k.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-vietnamese-20k.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-vietnamese-20k.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-vietnamese-20k.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-vietnamese-20k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e6feb24a408888f9e0a9cc",
      "id": "ngoantech/Llama-2-7b-vietnamese-20k",
      "modelId": "ngoantech/Llama-2-7b-vietnamese-20k",
      "author": "ngoantech",
      "sha": "be56069ab7abbb3b476c06eeb5c46d6a26417ec2",
      "lastModified": "2023-09-07T03:59:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "llama-2-7B",
        "llama2-vietnamese",
        "vietnamese",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 226,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "text-generation",
          "llama-2",
          "llama-2-7B",
          "llama2-vietnamese",
          "vietnamese"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "hoangta/ngoantech-Llama-2-7b-vietnamese-20k"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "exp_1.png"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651da0ff301b7bb5c4112da9",
    "id": "TheBloke/Amethyst-13B-Mistral-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 33,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Amethyst-13B-Mistral-GGUF",
    "model": {
      "_id": "651da0ff301b7bb5c4112da9",
      "id": "TheBloke/Amethyst-13B-Mistral-GGUF",
      "modelId": "TheBloke/Amethyst-13B-Mistral-GGUF",
      "author": "TheBloke",
      "sha": "446d5697df7eee212cc5ac92173e5b192016651b",
      "lastModified": "2023-10-04T17:36:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 33,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/Amethyst-13B-Mistral",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Amethyst 13B Mistral",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "amethyst-13b-mistral.Q2_K.gguf"
        },
        {
          "rfilename": "amethyst-13b-mistral.Q3_K_L.gguf"
        },
        {
          "rfilename": "amethyst-13b-mistral.Q3_K_M.gguf"
        },
        {
          "rfilename": "amethyst-13b-mistral.Q3_K_S.gguf"
        },
        {
          "rfilename": "amethyst-13b-mistral.Q4_0.gguf"
        },
        {
          "rfilename": "amethyst-13b-mistral.Q4_K_M.gguf"
        },
        {
          "rfilename": "amethyst-13b-mistral.Q4_K_S.gguf"
        },
        {
          "rfilename": "amethyst-13b-mistral.Q5_0.gguf"
        },
        {
          "rfilename": "amethyst-13b-mistral.Q5_K_M.gguf"
        },
        {
          "rfilename": "amethyst-13b-mistral.Q5_K_S.gguf"
        },
        {
          "rfilename": "amethyst-13b-mistral.Q6_K.gguf"
        },
        {
          "rfilename": "amethyst-13b-mistral.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6518ecb73fe8cc63b4c7874f",
      "id": "Undi95/Amethyst-13B-Mistral",
      "modelId": "Undi95/Amethyst-13B-Mistral",
      "author": "Undi95",
      "sha": "4328809e568f01e3f0a05764e3bb58e901310415",
      "lastModified": "2023-10-03T12:04:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7105,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651ee10822aeffca25e5b9f6",
    "id": "TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF",
    "likes": 27,
    "private": false,
    "downloads": 55,
    "tags": [
      "transformers",
      "mistral",
      "mistral-7b",
      "instruct",
      "finetune",
      "gpt4",
      "synthetic data",
      "distillation",
      "sharegpt",
      "en",
      "dataset:CollectiveCognition/chats-data-2023-09-27",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF",
    "model": {
      "_id": "651ee10822aeffca25e5b9f6",
      "id": "TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF",
      "modelId": "TheBloke/CollectiveCognition-v1.1-Mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "fe4e8d6315d34f6eeacd2b32bf427e01a6cf8db6",
      "lastModified": "2023-10-05T16:21:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "mistral-7b",
        "instruct",
        "finetune",
        "gpt4",
        "synthetic data",
        "distillation",
        "sharegpt",
        "en",
        "dataset:CollectiveCognition/chats-data-2023-09-27",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 55,
      "library_name": "transformers",
      "likes": 27,
      "model-index": [
        {
          "name": "CollectiveCognition-v1-Mistral-7B",
          "results": []
        }
      ],
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "teknium/CollectiveCognition-v1.1-Mistral-7B",
        "datasets": [
          "CollectiveCognition/chats-data-2023-09-27"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "model-index": [
          {
            "name": "CollectiveCognition-v1-Mistral-7B",
            "results": []
          }
        ],
        "model_creator": "Teknium",
        "model_name": "CollectiveCognition v1.1 Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "USER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "mistral-7b",
          "instruct",
          "finetune",
          "gpt4",
          "synthetic data",
          "distillation",
          "sharegpt"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "collectivecognition-v1.1-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "collectivecognition-v1.1-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "collectivecognition-v1.1-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "collectivecognition-v1.1-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "collectivecognition-v1.1-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "collectivecognition-v1.1-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "collectivecognition-v1.1-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "collectivecognition-v1.1-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "collectivecognition-v1.1-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "collectivecognition-v1.1-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "collectivecognition-v1.1-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "collectivecognition-v1.1-mistral-7b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "651dcb473f54cfb8ddd8db9c",
      "id": "teknium/CollectiveCognition-v1.1-Mistral-7B",
      "modelId": "teknium/CollectiveCognition-v1.1-Mistral-7B",
      "author": "teknium",
      "sha": "5f57f70ec99450c70da2540e94dd7fd67be4b23c",
      "lastModified": "2023-10-07T00:22:52.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "mistral-7b",
        "instruct",
        "finetune",
        "gpt4",
        "synthetic data",
        "distillation",
        "sharegpt",
        "en",
        "dataset:CollectiveCognition/chats-data-2023-09-27",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5304,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 55,
      "model-index": [
        {
          "name": "CollectiveCognition-v1-Mistral-7B",
          "results": []
        }
      ],
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "mistralai/Mistral-7B-v0.1",
        "tags": [
          "mistral-7b",
          "instruct",
          "finetune",
          "gpt4",
          "synthetic data",
          "distillation",
          "sharegpt"
        ],
        "datasets": [
          "CollectiveCognition/chats-data-2023-09-27"
        ],
        "model-index": [
          {
            "name": "CollectiveCognition-v1-Mistral-7B",
            "results": []
          }
        ],
        "license": "apache-2.0",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "jonybepary/teknium-CollectiveCognition-v1.1-Mistral-7B"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651f3a6c8ed730cc00752bae",
    "id": "TheBloke/airoboros-l2-7B-3.0-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 6,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-3.0",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-7B-3.0-GGUF",
    "model": {
      "_id": "651f3a6c8ed730cc00752bae",
      "id": "TheBloke/airoboros-l2-7B-3.0-GGUF",
      "modelId": "TheBloke/airoboros-l2-7B-3.0-GGUF",
      "author": "TheBloke",
      "sha": "6ad15815db27789b748d7cb444ce6ae2c78c9f16",
      "lastModified": "2023-10-05T23:09:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-3.0",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "jondurbin/airoboros-l2-7b-3.0",
        "datasets": [
          "jondurbin/airoboros-3.0"
        ],
        "inference": false,
        "license": "llama2",
        "model_creator": "Jon Durbin",
        "model_name": "Airoboros L2 7B 3.0",
        "model_type": "llama",
        "prompt_template": "[INST] <<SYS>>\nYou are a help, unbiased, uncensored assistant.\n<</SYS>\n\n{prompt} [/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-7b-3.0.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-3.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-3.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-3.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-3.0.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-3.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-3.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-3.0.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-3.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-3.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-3.0.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-7b-3.0.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6519f56a5ae78fd44800387a",
      "id": "jondurbin/airoboros-l2-7b-3.0",
      "modelId": "jondurbin/airoboros-l2-7b-3.0",
      "author": "jondurbin",
      "sha": "59b90205e88c75b6e4acd2d43a00f4e6b840e0a1",
      "lastModified": "2023-10-05T12:36:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-3.0",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-3.0"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 6738415616
        },
        "total": 6738415616
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "model-00001-of-00007.safetensors"
        },
        {
          "rfilename": "model-00002-of-00007.safetensors"
        },
        {
          "rfilename": "model-00003-of-00007.safetensors"
        },
        {
          "rfilename": "model-00004-of-00007.safetensors"
        },
        {
          "rfilename": "model-00005-of-00007.safetensors"
        },
        {
          "rfilename": "model-00006-of-00007.safetensors"
        },
        {
          "rfilename": "model-00007-of-00007.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651f3acd22aeffca25f14a13",
    "id": "TheBloke/airoboros-l2-13B-3.0-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 19,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-3.0",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-13B-3.0-GGUF",
    "model": {
      "_id": "651f3acd22aeffca25f14a13",
      "id": "TheBloke/airoboros-l2-13B-3.0-GGUF",
      "modelId": "TheBloke/airoboros-l2-13B-3.0-GGUF",
      "author": "TheBloke",
      "sha": "d719a3cccb9e41885382c4bb6ac3811226e1eecf",
      "lastModified": "2023-10-05T22:47:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-3.0",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 19,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "jondurbin/airoboros-l2-13b-3.0",
        "datasets": [
          "jondurbin/airoboros-3.0"
        ],
        "inference": false,
        "license": "llama2",
        "model_creator": "Jon Durbin",
        "model_name": "Airoboros L2 13B 3.0",
        "model_type": "llama",
        "prompt_template": "[INST] <<SYS>>\nYou are a help, unbiased, uncensored assistant.\n<</SYS>\n\n{prompt} [/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-13b-3.0.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.0.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.0.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.0.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.0.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6519ff7b20b18e99b49fca77",
      "id": "jondurbin/airoboros-l2-13b-3.0",
      "modelId": "jondurbin/airoboros-l2-13b-3.0",
      "author": "jondurbin",
      "sha": "2fcef275782b2c1061cf671d889aea652d13236c",
      "lastModified": "2023-10-05T11:20:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-3.0",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3839,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-3.0"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "model-00001-of-00014.safetensors"
        },
        {
          "rfilename": "model-00002-of-00014.safetensors"
        },
        {
          "rfilename": "model-00003-of-00014.safetensors"
        },
        {
          "rfilename": "model-00004-of-00014.safetensors"
        },
        {
          "rfilename": "model-00005-of-00014.safetensors"
        },
        {
          "rfilename": "model-00006-of-00014.safetensors"
        },
        {
          "rfilename": "model-00007-of-00014.safetensors"
        },
        {
          "rfilename": "model-00008-of-00014.safetensors"
        },
        {
          "rfilename": "model-00009-of-00014.safetensors"
        },
        {
          "rfilename": "model-00010-of-00014.safetensors"
        },
        {
          "rfilename": "model-00011-of-00014.safetensors"
        },
        {
          "rfilename": "model-00012-of-00014.safetensors"
        },
        {
          "rfilename": "model-00013-of-00014.safetensors"
        },
        {
          "rfilename": "model-00014-of-00014.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651f3b27372c0f3dc7f4fa3e",
    "id": "TheBloke/llama-2-7B-Arguments-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 68,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/llama-2-7B-Arguments-GGUF",
    "model": {
      "_id": "651f3b27372c0f3dc7f4fa3e",
      "id": "TheBloke/llama-2-7B-Arguments-GGUF",
      "modelId": "TheBloke/llama-2-7B-Arguments-GGUF",
      "author": "TheBloke",
      "sha": "a3657552a6ae5a495cb95716d978eb129741c7e2",
      "lastModified": "2023-10-06T00:17:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 68,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "cris177/llama-2-7b-Arguments",
        "inference": false,
        "license": "llama2",
        "model_creator": "Cristian Desivo",
        "model_name": "Llama 2 7B Arguments",
        "model_type": "llama",
        "prompt_template": "<s>[INST] {prompt}\n[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama-2-7b-arguments.Q2_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-arguments.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama-2-7b-arguments.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-arguments.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-arguments.Q4_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-arguments.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-arguments.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-arguments.Q5_0.gguf"
        },
        {
          "rfilename": "llama-2-7b-arguments.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama-2-7b-arguments.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama-2-7b-arguments.Q6_K.gguf"
        },
        {
          "rfilename": "llama-2-7b-arguments.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651d4ee28f872544a2f7f833",
      "id": "cris177/llama-2-7b-Arguments",
      "modelId": "cris177/llama-2-7b-Arguments",
      "author": "cris177",
      "sha": "6c8c795d6727245322e6cca2bcd7ec9aa2c5b5c8",
      "lastModified": "2023-10-05T19:35:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "651f3d1ad55b43b07992bb2d",
    "id": "TheBloke/airoboros-m-7B-3.0-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 7,
    "tags": [
      "transformers",
      "mistral",
      "dataset:jondurbin/airoboros-3.0",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-m-7B-3.0-GGUF",
    "model": {
      "_id": "651f3d1ad55b43b07992bb2d",
      "id": "TheBloke/airoboros-m-7B-3.0-GGUF",
      "modelId": "TheBloke/airoboros-m-7B-3.0-GGUF",
      "author": "TheBloke",
      "sha": "414c4e86b54e0e157aa6d8942b576cb36b0c5771",
      "lastModified": "2023-10-05T23:27:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "dataset:jondurbin/airoboros-3.0",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "jondurbin/airoboros-m-7b-3.0",
        "datasets": [
          "jondurbin/airoboros-3.0"
        ],
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Jon Durbin",
        "model_name": "Airoboros M 7B 3.0",
        "model_type": "mistral",
        "prompt_template": "[INST] <<SYS>>\nYou are a help, unbiased, uncensored assistant.\n<</SYS>\n\n{prompt} [/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "airoboros-m-7b-3.0.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.0.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.0.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.0.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.0.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "651be14781fcf4844c36f4c3",
      "id": "jondurbin/airoboros-m-7b-3.0",
      "modelId": "jondurbin/airoboros-m-7b-3.0",
      "author": "jondurbin",
      "sha": "d1000f32a097cf6b0f0e8f9acfde982a362ba3b5",
      "lastModified": "2023-10-05T20:46:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "dataset:jondurbin/airoboros-3.0",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 44,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "datasets": [
          "jondurbin/airoboros-3.0"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00008.safetensors"
        },
        {
          "rfilename": "model-00002-of-00008.safetensors"
        },
        {
          "rfilename": "model-00003-of-00008.safetensors"
        },
        {
          "rfilename": "model-00004-of-00008.safetensors"
        },
        {
          "rfilename": "model-00005-of-00008.safetensors"
        },
        {
          "rfilename": "model-00006-of-00008.safetensors"
        },
        {
          "rfilename": "model-00007-of-00008.safetensors"
        },
        {
          "rfilename": "model-00008-of-00008.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65205b8d739dd2070b62ba6e",
    "id": "TheBloke/UndiMix-v4-13B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 5,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/UndiMix-v4-13B-GGUF",
    "model": {
      "_id": "65205b8d739dd2070b62ba6e",
      "id": "TheBloke/UndiMix-v4-13B-GGUF",
      "modelId": "TheBloke/UndiMix-v4-13B-GGUF",
      "author": "TheBloke",
      "sha": "f4459f556c9a059c0f84f6e4869d229927a0bb5a",
      "lastModified": "2023-10-06T19:18:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/UndiMix-v4-13B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Undimix v4 13B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "undimix-v4-13b.Q2_K.gguf"
        },
        {
          "rfilename": "undimix-v4-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "undimix-v4-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "undimix-v4-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "undimix-v4-13b.Q4_0.gguf"
        },
        {
          "rfilename": "undimix-v4-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "undimix-v4-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "undimix-v4-13b.Q5_0.gguf"
        },
        {
          "rfilename": "undimix-v4-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "undimix-v4-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "undimix-v4-13b.Q6_K.gguf"
        },
        {
          "rfilename": "undimix-v4-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6500ed0de102da55f9f3e4fc",
      "id": "Undi95/UndiMix-v4-13B",
      "modelId": "Undi95/UndiMix-v4-13B",
      "author": "Undi95",
      "sha": "6dd97c74cfe1d22432d5c993814e230f333ba401",
      "lastModified": "2023-09-12T23:22:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4669,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688184320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65218f23d65824bda78eab7f",
    "id": "TheBloke/Mistral-Trismegistus-7B-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 21,
    "tags": [
      "transformers",
      "mistral",
      "mistral-7b",
      "instruct",
      "finetune",
      "gpt4",
      "synthetic data",
      "distillation",
      "en",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mistral-Trismegistus-7B-GGUF",
    "model": {
      "_id": "65218f23d65824bda78eab7f",
      "id": "TheBloke/Mistral-Trismegistus-7B-GGUF",
      "modelId": "TheBloke/Mistral-Trismegistus-7B-GGUF",
      "author": "TheBloke",
      "sha": "2dfca691f6016a15a62d78c40e3e1f7ad276068c",
      "lastModified": "2023-10-07T17:13:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "mistral-7b",
        "instruct",
        "finetune",
        "gpt4",
        "synthetic data",
        "distillation",
        "en",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 21,
      "library_name": "transformers",
      "likes": 8,
      "model-index": [
        {
          "name": "Mistral-Trismegistus-7B",
          "results": []
        }
      ],
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "teknium/Mistral-Trismegistus-7B",
        "inference": false,
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "model-index": [
          {
            "name": "Mistral-Trismegistus-7B",
            "results": []
          }
        ],
        "model_creator": "Teknium",
        "model_name": "Mistral Trismegistus 7B",
        "model_type": "mistral",
        "prompt_template": "USER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "mistral-7b",
          "instruct",
          "finetune",
          "gpt4",
          "synthetic data",
          "distillation"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-trismegistus-7b.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-trismegistus-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-trismegistus-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-trismegistus-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-trismegistus-7b.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-trismegistus-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-trismegistus-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-trismegistus-7b.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-trismegistus-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-trismegistus-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-trismegistus-7b.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-trismegistus-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6520a49a2a16045c0924ecea",
      "id": "teknium/Mistral-Trismegistus-7B",
      "modelId": "teknium/Mistral-Trismegistus-7B",
      "author": "teknium",
      "sha": "cdb6faab05e782515296086fcde6ff4732e9e454",
      "lastModified": "2023-10-26T03:17:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "mistral-7b",
        "instruct",
        "finetune",
        "gpt4",
        "synthetic data",
        "distillation",
        "en",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4966,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 123,
      "model-index": [
        {
          "name": "Mistral-Trismegistus-7B",
          "results": []
        }
      ],
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "mistralai/Mistral-7B-v0.1",
        "tags": [
          "mistral-7b",
          "instruct",
          "finetune",
          "gpt4",
          "synthetic data",
          "distillation"
        ],
        "model-index": [
          {
            "name": "Mistral-Trismegistus-7B",
            "results": []
          }
        ],
        "license": "apache-2.0",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Tiroff/teknium-Mistral-Trismegistus-7B",
        "hashkoffee/teknium-Mistral-Trismegistus-7B",
        "nonyabidnus/teknium-Mistral-Trismegistus-7B",
        "promachina/teknium-Mistral-Trismegistus-7B",
        "TabLevitas/teknium-Mistral-Trismegistus-7B",
        "pooroligarch/Mistral-Trismegistus-7B",
        "ndehouche/teknium-Mistral-Trismegistus-7B",
        "FreddieSpaghetti/teknium-Mistral-Trismegistus-7B",
        "Ron78/teknium-Mistral-Trismegistus-7B",
        "MagicalAci/teknium-Mistral-Trismegistus-7B",
        "Rexzhang2023/teknium-Mistral-Trismegistus-7B",
        "billy123che/teknium-Mistral-Trismegistus-7B",
        "m-pajew-ski/teknium-Mistral-Trismegistus-7B",
        "MPLebron/teknium-Mistral-Trismegistus-7B",
        "aaddfff/teknium-Mistral-Trismegistus-7B",
        "timtimtimshen/teknium-Mistral-Trismegistus-7B",
        "ameliayi/teknium-Mistral-Trismegistus-7B",
        "yinhou3/mt",
        "sunnyzhu12/teknium-Mistral-Trismegistus-7B",
        "waytoAGI/teknium-Mistral-Trismegistus-7B",
        "hk1730/teknium-Mistral-Trismegistus-7B",
        "luckli/teknium-Mistral-Trismegistus-7B",
        "luckli/teknium-Mistral-Trismegistus-7B-1"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6522d567a56398128b58d8f0",
    "id": "TheBloke/sheep-duck-llama-2-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 14,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/sheep-duck-llama-2-13B-GGUF",
    "model": {
      "_id": "6522d567a56398128b58d8f0",
      "id": "TheBloke/sheep-duck-llama-2-13B-GGUF",
      "modelId": "TheBloke/sheep-duck-llama-2-13B-GGUF",
      "author": "TheBloke",
      "sha": "baef5cf1998fb4b1378de7763a3af45c889388a6",
      "lastModified": "2023-10-08T16:32:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 14,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Riiid/sheep-duck-llama-2-13b",
        "inference": false,
        "license": "llama2",
        "model_creator": "Riiid",
        "model_name": "Sheep Duck Llama 2 13B",
        "model_type": "llama",
        "prompt_template": "### System:\n{system_message}\n\n### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "sheep-duck-llama-2-13b.Q2_K.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-13b.Q4_0.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-13b.Q5_0.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-13b.Q6_K.gguf"
        },
        {
          "rfilename": "sheep-duck-llama-2-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651cef2409debbe627bd991a",
      "id": "Riiid/sheep-duck-llama-2-13b",
      "modelId": "Riiid/sheep-duck-llama-2-13b",
      "author": "Riiid",
      "sha": "71edf22c49677d0239caf5f87d8139dd9cc79078",
      "lastModified": "2023-10-04T05:01:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6740,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6522e53f706c755148b22c2f",
    "id": "TheBloke/Llama2-chat-AYB-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 44,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2306.02707",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Llama2-chat-AYB-13B-GGUF",
    "model": {
      "_id": "6522e53f706c755148b22c2f",
      "id": "TheBloke/Llama2-chat-AYB-13B-GGUF",
      "modelId": "TheBloke/Llama2-chat-AYB-13B-GGUF",
      "author": "TheBloke",
      "sha": "daa26c8c29f0eb7351df47fa6421d29d5913ea60",
      "lastModified": "2023-10-08T17:42:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2306.02707",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 44,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "posicube/Llama2-chat-AYB-13B",
        "inference": false,
        "license": "llama2",
        "model_creator": "Posicube Inc.",
        "model_name": "Llama2 Chat AYB 13B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama2-chat-ayb-13b.Q2_K.gguf"
        },
        {
          "rfilename": "llama2-chat-ayb-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama2-chat-ayb-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama2-chat-ayb-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama2-chat-ayb-13b.Q4_0.gguf"
        },
        {
          "rfilename": "llama2-chat-ayb-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama2-chat-ayb-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama2-chat-ayb-13b.Q5_0.gguf"
        },
        {
          "rfilename": "llama2-chat-ayb-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama2-chat-ayb-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama2-chat-ayb-13b.Q6_K.gguf"
        },
        {
          "rfilename": "llama2-chat-ayb-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651b85266794263227eb15b9",
      "id": "posicube/Llama2-chat-AYB-13B",
      "modelId": "posicube/Llama2-chat-AYB-13B",
      "author": "posicube",
      "sha": "7d41db241b4650d65700930af848bd893cb585f7",
      "lastModified": "2023-10-06T08:40:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "arxiv:2306.02707",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5710,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688186880
        },
        "total": 13015866880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652328be706c755148b93eb3",
    "id": "TheBloke/Athena-v4-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 9,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Athena-v4-GGUF",
    "model": {
      "_id": "652328be706c755148b93eb3",
      "id": "TheBloke/Athena-v4-GGUF",
      "modelId": "TheBloke/Athena-v4-GGUF",
      "author": "TheBloke",
      "sha": "5c1917c794ab287a4ac9adc6e58f2d41278d98a9",
      "lastModified": "2023-10-08T22:25:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "IkariDev/Athena-v4",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "IkariDev + Undi95",
        "model_name": "Athena v4",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "athena-v4.Q2_K.gguf"
        },
        {
          "rfilename": "athena-v4.Q3_K_L.gguf"
        },
        {
          "rfilename": "athena-v4.Q3_K_M.gguf"
        },
        {
          "rfilename": "athena-v4.Q3_K_S.gguf"
        },
        {
          "rfilename": "athena-v4.Q4_0.gguf"
        },
        {
          "rfilename": "athena-v4.Q4_K_M.gguf"
        },
        {
          "rfilename": "athena-v4.Q4_K_S.gguf"
        },
        {
          "rfilename": "athena-v4.Q5_0.gguf"
        },
        {
          "rfilename": "athena-v4.Q5_K_M.gguf"
        },
        {
          "rfilename": "athena-v4.Q5_K_S.gguf"
        },
        {
          "rfilename": "athena-v4.Q6_K.gguf"
        },
        {
          "rfilename": "athena-v4.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6521d86ac0ceb75b4963be0e",
      "id": "IkariDev/Athena-v4",
      "modelId": "IkariDev/Athena-v4",
      "author": "IkariDev",
      "sha": "73905b897858ec388eaa3dd8d310211051860ba2",
      "lastModified": "2023-10-09T09:46:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4320,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688184320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65233873cfbef01dc7c02d38",
    "id": "TheBloke/PsyMedRP-v1-20B-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 12,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/PsyMedRP-v1-20B-GGUF",
    "model": {
      "_id": "65233873cfbef01dc7c02d38",
      "id": "TheBloke/PsyMedRP-v1-20B-GGUF",
      "modelId": "TheBloke/PsyMedRP-v1-20B-GGUF",
      "author": "TheBloke",
      "sha": "9bf9df9c46d715895d017d26b16b770fcfabcfa1",
      "lastModified": "2023-10-08T23:40:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 12,
      "library_name": "transformers",
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/PsyMedRP-v1-20B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Psymedrp v1 20B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "psymedrp-v1-20b.Q2_K.gguf"
        },
        {
          "rfilename": "psymedrp-v1-20b.Q3_K_L.gguf"
        },
        {
          "rfilename": "psymedrp-v1-20b.Q3_K_M.gguf"
        },
        {
          "rfilename": "psymedrp-v1-20b.Q3_K_S.gguf"
        },
        {
          "rfilename": "psymedrp-v1-20b.Q4_0.gguf"
        },
        {
          "rfilename": "psymedrp-v1-20b.Q4_K_M.gguf"
        },
        {
          "rfilename": "psymedrp-v1-20b.Q4_K_S.gguf"
        },
        {
          "rfilename": "psymedrp-v1-20b.Q5_0.gguf"
        },
        {
          "rfilename": "psymedrp-v1-20b.Q5_K_M.gguf"
        },
        {
          "rfilename": "psymedrp-v1-20b.Q5_K_S.gguf"
        },
        {
          "rfilename": "psymedrp-v1-20b.Q6_K.gguf"
        },
        {
          "rfilename": "psymedrp-v1-20b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651f5fab128d26b399d63998",
      "id": "Undi95/PsyMedRP-v1-20B",
      "modelId": "Undi95/PsyMedRP-v1-20B",
      "author": "Undi95",
      "sha": "78188101b6331d9e61ef80f0971d715de100b44a",
      "lastModified": "2023-10-06T02:55:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 112,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 19994362880
        },
        "total": 19994362880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00005.safetensors"
        },
        {
          "rfilename": "model-00002-of-00005.safetensors"
        },
        {
          "rfilename": "model-00003-of-00005.safetensors"
        },
        {
          "rfilename": "model-00004-of-00005.safetensors"
        },
        {
          "rfilename": "model-00005-of-00005.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6523d68fab14165941296471",
    "id": "TheBloke/Ziya-Coding-34B-v1.0-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "zh",
      "en",
      "arxiv:2210.08590",
      "license:gpl-3.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Ziya-Coding-34B-v1.0-GGUF",
    "model": {
      "_id": "6523d68fab14165941296471",
      "id": "TheBloke/Ziya-Coding-34B-v1.0-GGUF",
      "modelId": "TheBloke/Ziya-Coding-34B-v1.0-GGUF",
      "author": "TheBloke",
      "sha": "7b6cb5369bdac59b3b4237830ffd944695e20d49",
      "lastModified": "2023-10-09T11:31:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "zh",
        "en",
        "arxiv:2210.08590",
        "license:gpl-3.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "IDEA-CCNL/Ziya-Coding-34B-v1.0",
        "inference": false,
        "language": [
          "zh",
          "en"
        ],
        "library_name": "transformers",
        "license": "gpl-3.0",
        "model_creator": "Fengshenbang-LM",
        "model_name": "Ziya Coding 34B v1.0",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<human>: \nPlease Complete the given function below according to the docstring: \n{prompt}\n<bot>: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "ziya-coding-34b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "ziya-coding-34b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "ziya-coding-34b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "ziya-coding-34b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "ziya-coding-34b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "ziya-coding-34b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "ziya-coding-34b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "ziya-coding-34b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "ziya-coding-34b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "ziya-coding-34b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "ziya-coding-34b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "ziya-coding-34b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6513a7cc97bb5c96ae8c7fc8",
      "id": "IDEA-CCNL/Ziya-Coding-34B-v1.0",
      "modelId": "IDEA-CCNL/Ziya-Coding-34B-v1.0",
      "author": "IDEA-CCNL",
      "sha": "8df4ff5798687edd31c1aff22a3f27375a5f3137",
      "lastModified": "2023-10-09T20:01:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "zh",
        "en",
        "arxiv:2210.08590",
        "license:gpl-3.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 123,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 18,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "gpl-3.0",
        "language": [
          "zh",
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "vahjela17/IDEA-CCNL-Ziya-Coding-34B-v1.0",
        "xsdgce024578/IDEA-CCNL-Ziya-Coding-34B-v1.0",
        "Yavi2002/Code-LLM"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00024-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model-00025-of-00025.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65252a6b9e4a6675fe888d34",
    "id": "TheBloke/em_german_leo_mistral-GGUF",
    "likes": 11,
    "private": false,
    "downloads": 33,
    "tags": [
      "transformers",
      "mistral",
      "pytorch",
      "german",
      "deutsch",
      "leolm",
      "text-generation",
      "de",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/em_german_leo_mistral-GGUF",
    "model": {
      "_id": "65252a6b9e4a6675fe888d34",
      "id": "TheBloke/em_german_leo_mistral-GGUF",
      "modelId": "TheBloke/em_german_leo_mistral-GGUF",
      "author": "TheBloke",
      "sha": "efd83f82df058e3e14a577caa1f32dcac3a80fd1",
      "lastModified": "2023-10-10T17:47:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "pytorch",
        "german",
        "deutsch",
        "leolm",
        "text-generation",
        "de",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 33,
      "library_name": "transformers",
      "likes": 11,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "jphme/em_german_leo_mistral",
        "inference": false,
        "language": [
          "de"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "Jan Philipp Harries",
        "model_name": "EM German Leo Mistral",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "Du bist ein hilfreicher Assistent. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "pytorch",
          "german",
          "deutsch",
          "mistral",
          "leolm"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "em_german_leo_mistral.Q2_K.gguf"
        },
        {
          "rfilename": "em_german_leo_mistral.Q3_K_L.gguf"
        },
        {
          "rfilename": "em_german_leo_mistral.Q3_K_M.gguf"
        },
        {
          "rfilename": "em_german_leo_mistral.Q3_K_S.gguf"
        },
        {
          "rfilename": "em_german_leo_mistral.Q4_0.gguf"
        },
        {
          "rfilename": "em_german_leo_mistral.Q4_K_M.gguf"
        },
        {
          "rfilename": "em_german_leo_mistral.Q4_K_S.gguf"
        },
        {
          "rfilename": "em_german_leo_mistral.Q5_0.gguf"
        },
        {
          "rfilename": "em_german_leo_mistral.Q5_K_M.gguf"
        },
        {
          "rfilename": "em_german_leo_mistral.Q5_K_S.gguf"
        },
        {
          "rfilename": "em_german_leo_mistral.Q6_K.gguf"
        },
        {
          "rfilename": "em_german_leo_mistral.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65212cb28fc4884992be97b6",
      "id": "jphme/em_german_leo_mistral",
      "modelId": "jphme/em_german_leo_mistral",
      "author": "jphme",
      "sha": "4f03ad4ce09f81cdb00e20649cb0c91625fe26ce",
      "lastModified": "2023-10-27T23:50:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "pytorch",
        "german",
        "deutsch",
        "leolm",
        "de",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9052,
      "library_name": "transformers",
      "likes": 18,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "inference": false,
        "language": [
          "de"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "jphme",
        "model_name": "EM German",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "Du bist ein hilfreicher Assistent. USER: Was ist 1+1? ASSISTANT:",
        "tags": [
          "pytorch",
          "german",
          "deutsch",
          "mistral",
          "leolm"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "em_model_logo_web.jpeg"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65254d75965d12744137c618",
    "id": "TheBloke/sqlcoder2-GGUF",
    "likes": 13,
    "private": false,
    "downloads": 50,
    "tags": [
      "transformers",
      "starcoder",
      "code",
      "text-generation",
      "en",
      "license:other",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/sqlcoder2-GGUF",
    "model": {
      "_id": "65254d75965d12744137c618",
      "id": "TheBloke/sqlcoder2-GGUF",
      "modelId": "TheBloke/sqlcoder2-GGUF",
      "author": "TheBloke",
      "sha": "bb29b37e3365a1b181d64fd6b0a3a3db83000509",
      "lastModified": "2023-10-12T06:15:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "starcoder",
        "code",
        "text-generation",
        "en",
        "license:other",
        "region:us"
      ],
      "downloads": 50,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 13,
      "model-index": null,
      "config": {
        "model_type": "starcoder"
      },
      "cardData": {
        "base_model": "defog/sqlcoder2",
        "inference": false,
        "language": [
          "en"
        ],
        "license": "other",
        "model_creator": "Defog.ai",
        "model_name": "Sqlcoder2",
        "model_type": "starcoder",
        "pipeline_tag": "text-generation",
        "prompt_template": "## Task\nGenerate a SQL query to answer the following question:\n`{prompt}`\n\n### Database Schema\nThis query will run on a database whose schema is represented in this string:\nCREATE TABLE products (\n  product_id INTEGER PRIMARY KEY, -- Unique ID for each product\n  name VARCHAR(50), -- Name of the product\n  price DECIMAL(10,2), -- Price of each unit of the product\n  quantity INTEGER  -- Current quantity in stock\n);\n\nCREATE TABLE sales (\n  sale_id INTEGER PRIMARY KEY, -- Unique ID for each sale\n  product_id INTEGER, -- ID of product sold\n  customer_id INTEGER,  -- ID of customer who made purchase\n  salesperson_id INTEGER, -- ID of salesperson who made the sale\n  sale_date DATE, -- Date the sale occurred\n  quantity INTEGER -- Quantity of product sold\n);\n\n-- sales.product_id can be joined with products.product_id\n\n### SQL\nGiven the database schema, here is the SQL query that answers `{prompt}`:\n```sql\n",
        "quantized_by": "TheBloke",
        "tags": [
          "code"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "sqlcoder2.Q2_K.gguf"
        },
        {
          "rfilename": "sqlcoder2.Q3_K_L.gguf"
        },
        {
          "rfilename": "sqlcoder2.Q3_K_M.gguf"
        },
        {
          "rfilename": "sqlcoder2.Q3_K_S.gguf"
        },
        {
          "rfilename": "sqlcoder2.Q4_0.gguf"
        },
        {
          "rfilename": "sqlcoder2.Q4_K_M.gguf"
        },
        {
          "rfilename": "sqlcoder2.Q4_K_S.gguf"
        },
        {
          "rfilename": "sqlcoder2.Q5_0.gguf"
        },
        {
          "rfilename": "sqlcoder2.Q5_K_M.gguf"
        },
        {
          "rfilename": "sqlcoder2.Q5_K_S.gguf"
        },
        {
          "rfilename": "sqlcoder2.Q6_K.gguf"
        },
        {
          "rfilename": "sqlcoder2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651ab3f70b13514f98835bbf",
      "id": "defog/sqlcoder2",
      "modelId": "defog/sqlcoder2",
      "author": "defog",
      "sha": "4ccba9158b67de83b070a4eb2fadaeb58ab2cd14",
      "lastModified": "2023-10-13T16:43:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "gpt_bigcode",
        "text-generation",
        "code",
        "en",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 11034,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 56,
      "model-index": null,
      "config": {
        "architectures": [
          "GPTBigCodeForCausalLM"
        ],
        "model_type": "gpt_bigcode"
      },
      "cardData": {
        "license": "other",
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation",
        "tags": [
          "code"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "teddy-shi/defog-sqlcoder2"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "merges.txt"
        },
        {
          "rfilename": "pytorch_model-00001-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "vocab.json"
        }
      ]
    }
  },
  {
    "_id": "65261483bda6113c956c3d5a",
    "id": "TheBloke/Tinyllama-2-1b-miniguanaco-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 97,
    "tags": [
      "transformers",
      "llama",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Tinyllama-2-1b-miniguanaco-GGUF",
    "model": {
      "_id": "65261483bda6113c956c3d5a",
      "id": "TheBloke/Tinyllama-2-1b-miniguanaco-GGUF",
      "modelId": "TheBloke/Tinyllama-2-1b-miniguanaco-GGUF",
      "author": "TheBloke",
      "sha": "d1c4ea0af66f6a27786ed9dcde826d45e4d7558c",
      "lastModified": "2023-10-14T16:21:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 97,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "abdgrt/Tinyllama-2-1b-miniguanaco",
        "inference": false,
        "license": "other",
        "model_creator": "Odunusi Abraham Ayoola",
        "model_name": "Tinyllama 2 1B MiniGuanaco",
        "model_type": "llama",
        "prompt_template": "### Human: {prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tinyllama-2-1b-miniguanaco.Q2_K.gguf"
        },
        {
          "rfilename": "tinyllama-2-1b-miniguanaco.Q3_K_L.gguf"
        },
        {
          "rfilename": "tinyllama-2-1b-miniguanaco.Q3_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-2-1b-miniguanaco.Q3_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-2-1b-miniguanaco.Q4_0.gguf"
        },
        {
          "rfilename": "tinyllama-2-1b-miniguanaco.Q4_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-2-1b-miniguanaco.Q4_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-2-1b-miniguanaco.Q5_0.gguf"
        },
        {
          "rfilename": "tinyllama-2-1b-miniguanaco.Q5_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-2-1b-miniguanaco.Q5_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-2-1b-miniguanaco.Q6_K.gguf"
        },
        {
          "rfilename": "tinyllama-2-1b-miniguanaco.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6510be498c4b535a970f8806",
      "id": "abdgrt/Tinyllama-2-1b-miniguanaco",
      "modelId": "abdgrt/Tinyllama-2-1b-miniguanaco",
      "author": "abdgrt",
      "sha": "57ab4af34af2416cc056ca13acd4cf270fe9d601",
      "lastModified": "2023-09-24T22:56:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 113,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652615d43177c2a79493a6b9",
    "id": "TheBloke/zephyr-7B-alpha-GGUF",
    "likes": 118,
    "private": false,
    "downloads": 719,
    "tags": [
      "transformers",
      "mistral",
      "generated_from_trainer",
      "en",
      "dataset:stingning/ultrachat",
      "dataset:openbmb/UltraFeedback",
      "arxiv:2305.18290",
      "license:mit",
      "has_space",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/zephyr-7B-alpha-GGUF",
    "model": {
      "_id": "652615d43177c2a79493a6b9",
      "id": "TheBloke/zephyr-7B-alpha-GGUF",
      "modelId": "TheBloke/zephyr-7B-alpha-GGUF",
      "author": "TheBloke",
      "sha": "17246e1732130e712d6d53b46c2f5179d47e84e9",
      "lastModified": "2023-10-14T07:12:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "generated_from_trainer",
        "en",
        "dataset:stingning/ultrachat",
        "dataset:openbmb/UltraFeedback",
        "arxiv:2305.18290",
        "license:mit",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 719,
      "library_name": "transformers",
      "likes": 118,
      "model-index": [
        {
          "name": "zephyr-7b-alpha",
          "results": []
        }
      ],
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "HuggingFaceH4/zephyr-7b-alpha",
        "datasets": [
          "stingning/ultrachat",
          "openbmb/UltraFeedback"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "mit",
        "model-index": [
          {
            "name": "zephyr-7b-alpha",
            "results": []
          }
        ],
        "model_creator": "Hugging Face H4",
        "model_name": "Zephyr 7B Alpha",
        "model_type": "mistral",
        "prompt_template": "<|system|>\n</s>\n<|user|>\n{prompt}</s>\n<|assistant|>\n",
        "quantized_by": "TheBloke",
        "tags": [
          "generated_from_trainer"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "coqui/voice-chat-with-mistral",
        "coqui/ml-trivia",
        "0x81632/GGUF_API",
        "awakenai/fast-api-transformers-pipeline-v2",
        "vikkaird/chat-Vikk"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "zephyr-7b-alpha.Q2_K.gguf"
        },
        {
          "rfilename": "zephyr-7b-alpha.Q3_K_L.gguf"
        },
        {
          "rfilename": "zephyr-7b-alpha.Q3_K_M.gguf"
        },
        {
          "rfilename": "zephyr-7b-alpha.Q3_K_S.gguf"
        },
        {
          "rfilename": "zephyr-7b-alpha.Q4_0.gguf"
        },
        {
          "rfilename": "zephyr-7b-alpha.Q4_K_M.gguf"
        },
        {
          "rfilename": "zephyr-7b-alpha.Q4_K_S.gguf"
        },
        {
          "rfilename": "zephyr-7b-alpha.Q5_0.gguf"
        },
        {
          "rfilename": "zephyr-7b-alpha.Q5_K_M.gguf"
        },
        {
          "rfilename": "zephyr-7b-alpha.Q5_K_S.gguf"
        },
        {
          "rfilename": "zephyr-7b-alpha.Q6_K.gguf"
        },
        {
          "rfilename": "zephyr-7b-alpha.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6523bd962d3ba46ccd378b5a",
      "id": "HuggingFaceH4/zephyr-7b-alpha",
      "modelId": "HuggingFaceH4/zephyr-7b-alpha",
      "author": "HuggingFaceH4",
      "sha": "f28e1c0e5a1af475bcd7bdf6554e69abc6c0c7ee",
      "lastModified": "2023-10-26T08:18:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "mistral",
        "text-generation",
        "generated_from_trainer",
        "en",
        "dataset:stingning/ultrachat",
        "dataset:openbmb/UltraFeedback",
        "arxiv:2305.18290",
        "license:mit",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 71062,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 857,
      "model-index": [
        {
          "name": "zephyr-7b-alpha",
          "results": []
        }
      ],
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "tags": [
          "generated_from_trainer"
        ],
        "model-index": [
          {
            "name": "zephyr-7b-alpha",
            "results": []
          }
        ],
        "license": "mit",
        "datasets": [
          "stingning/ultrachat",
          "openbmb/UltraFeedback"
        ],
        "language": [
          "en"
        ],
        "base_model": "mistralai/Mistral-7B-v0.1"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "deniandriancode/zephyr-7b-alpha-chatbot",
        "rishiraj/zephyr",
        "ysharma/Zephyr-Playground",
        "PeepDaSlan9/HuggingFaceH4-zephyr-7b-alpha",
        "msy127/app_rag_llama2_paper",
        "pragneshbarik/ikigai-chat",
        "awakenai/fast-api-transformers-pipeline-v2",
        "yushiang1004/HuggingFaceH4-zephyr-7b-alpha",
        "StatsGary/HuggingFaceH4-zephyr-7b-alpha",
        "Buck3tHead/HuggingFaceH4-zephyr-7b-alpha",
        "Pradeep-10/HuggingFaceH4-zephyr-7b-alpha",
        "Pradeep-10/HuggingFaceH4-zephyr-7b-alpha1",
        "neridonk/HuggingFaceH4-zephyr-7b-alpha",
        "gitorivera/HuggingFaceH4-zephyr-7b-alpha",
        "dalizhou1/HuggingFaceH4-zephyr-7b-alpha",
        "jacobwilsonx/zephyr-chat",
        "olanigan/zephyr-7b-chat",
        "BlueChamp/HuggingFaceH4-zephyr-7b-alpha",
        "morganfreemanfour20/HuggingFaceH4-zephyr-7b-alpha",
        "hiert/HuggingFaceH4-zephyr-7b-alpha",
        "sachin1729/ChatBot_By_Sachin",
        "jhkjh/HuggingFaceH4-zephyr-7b-alpha",
        "tb2022/HuggingFaceH4-zephyr-7b-alpha",
        "deathoperator/HuggingFaceH4-zephyr-7b-alpha",
        "HelenElf/HuggingFaceH4-zephyr-7b-alpha",
        "theroar/HuggingFaceH4-zephyr-7b-alpha",
        "natrajs/HuggingFaceH4-zephyr-7b-alpha",
        "dhanilka/chat-bot",
        "victor/chat-vs-chat",
        "lakshmikarpolam/Zephyr_prmpt2Json",
        "dhanilka/zephyr-model-1",
        "dazzledricky58/HuggingFaceH4-zephyr-7b-alpha",
        "dazzledricky58/HuggingFaceH4-zephyr-7b-alphakcydnhmv",
        "ethanrom/insuranec-chat",
        "ethanrom/cima-free-chat",
        "islammohy/zephyr-chat",
        "aps19/llm-information-extraction-chatbot",
        "codemaker2015/HuggingFaceH4-zephyr-7b-alpha",
        "binqiangliu/Zephyr7BAlpha",
        "binqiangliu/i-zephyr-chat",
        "wangyichen25/HuggingFaceH4-zephyr-7b-alpha",
        "ogegadavis254/HuggingFaceH4-zephyr-7b-alpha",
        "ogegadavis254/zephyr-chat",
        "Aryansoni27/zephyr-7b-alpha-chatbot1.0",
        "Deleteduser86/HuggingFaceH4-zephyr-7b-alpha",
        "zzw820626/HuggingFaceH4-zephyr-7b-alpha",
        "Rafaa/Chat",
        "amizya/HuggingFaceH4-zephyr-7b-alpha",
        "Rafaa/Nyx",
        "ahmedsali/PDF-Chat-Langchain",
        "charanhu/HuggingFaceH4-zephyr-7b-alpha",
        "TensaZangetsu/HuggingFaceH4-zephyr-7b-alpha-finetuned",
        "Arjun098/HuggingFaceH4-zephyr-7b-alpha",
        "toorhamza/HuggingFaceH4-zephyr-7b-alpha",
        "TogetherAI/ZECHAT",
        "fatihay/zephyrrishiraj",
        "dayanithi/Bot",
        "gongxiaoyi/HuggingFaceH4-zephyr-7b-alpha"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "all_results.json"
        },
        {
          "rfilename": "colab-demo.ipynb"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "eval_results.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00008.safetensors"
        },
        {
          "rfilename": "model-00002-of-00008.safetensors"
        },
        {
          "rfilename": "model-00003-of-00008.safetensors"
        },
        {
          "rfilename": "model-00004-of-00008.safetensors"
        },
        {
          "rfilename": "model-00005-of-00008.safetensors"
        },
        {
          "rfilename": "model-00006-of-00008.safetensors"
        },
        {
          "rfilename": "model-00007-of-00008.safetensors"
        },
        {
          "rfilename": "model-00008-of-00008.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "thumbnail.png"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "train_results.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "6526233fb5cccc82eab67931",
    "id": "TheBloke/TinyLlama-1.1B-1T-OpenOrca-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 51,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:Open-Orca/OpenOrca",
      "dataset:bigcode/starcoderdata",
      "dataset:cerebras/SlimPajama-627B",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/TinyLlama-1.1B-1T-OpenOrca-GGUF",
    "model": {
      "_id": "6526233fb5cccc82eab67931",
      "id": "TheBloke/TinyLlama-1.1B-1T-OpenOrca-GGUF",
      "modelId": "TheBloke/TinyLlama-1.1B-1T-OpenOrca-GGUF",
      "author": "TheBloke",
      "sha": "0c1ae5cd60a88ecedf5573f55b0eab6647605211",
      "lastModified": "2023-10-11T04:25:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "dataset:bigcode/starcoderdata",
        "dataset:cerebras/SlimPajama-627B",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 51,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "jeff31415/TinyLlama-1.1B-1T-OpenOrca",
        "datasets": [
          "Open-Orca/OpenOrca",
          "bigcode/starcoderdata",
          "cerebras/SlimPajama-627B"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "other",
        "model_creator": "jeff zhao",
        "model_name": "Tinyllama 1.1B 1T Openorca",
        "model_type": "llama",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tinyllama-1.1b-1t-openorca.Q2_K.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-1t-openorca.Q3_K_L.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-1t-openorca.Q3_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-1t-openorca.Q3_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-1t-openorca.Q4_0.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-1t-openorca.Q4_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-1t-openorca.Q4_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-1t-openorca.Q5_0.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-1t-openorca.Q5_K_M.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-1t-openorca.Q5_K_S.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-1t-openorca.Q6_K.gguf"
        },
        {
          "rfilename": "tinyllama-1.1b-1t-openorca.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652424fd8c2691925dce3f49",
      "id": "jeff31415/TinyLlama-1.1B-1T-OpenOrca",
      "modelId": "jeff31415/TinyLlama-1.1B-1T-OpenOrca",
      "author": "jeff31415",
      "sha": "605c2a8b2324a25ca0513c4c862bfa9c937b3514",
      "lastModified": "2023-10-25T13:52:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "dataset:bigcode/starcoderdata",
        "dataset:cerebras/SlimPajama-627B",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 502,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "datasets": [
          "Open-Orca/OpenOrca",
          "bigcode/starcoderdata",
          "cerebras/SlimPajama-627B"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "BF16": 1100048384
        },
        "total": 1100048384
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model.safetensors"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6526252d904f30580f50d176",
    "id": "TheBloke/tinyllama-1.1b-chat-v0.3_platypus-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "region:us"
    ],
    "modelId": "TheBloke/tinyllama-1.1b-chat-v0.3_platypus-GGUF",
    "model": {
      "_id": "6526252d904f30580f50d176",
      "id": "TheBloke/tinyllama-1.1b-chat-v0.3_platypus-GGUF",
      "modelId": "TheBloke/tinyllama-1.1b-chat-v0.3_platypus-GGUF",
      "author": "TheBloke",
      "sha": "d7ba5fa7de8e464c9fb30ff73c3a6104988320ff",
      "lastModified": "2023-10-11T04:31:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "region:us"
      ],
      "downloads": 0,
      "likes": 2,
      "config": {},
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        }
      ]
    }
  },
  {
    "_id": "652627aab017be1fc1ab24df",
    "id": "TheBloke/UndiMix-v3-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/UndiMix-v3-13B-GGUF",
    "model": {
      "_id": "652627aab017be1fc1ab24df",
      "id": "TheBloke/UndiMix-v3-13B-GGUF",
      "modelId": "TheBloke/UndiMix-v3-13B-GGUF",
      "author": "TheBloke",
      "sha": "1f647d71cbdb2e167ec7d1e8c55b74c8dec5c814",
      "lastModified": "2023-10-11T04:57:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/UndiMix-v3-13B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Undimix v3 13B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "undimix-v3-13b.Q2_K.gguf"
        },
        {
          "rfilename": "undimix-v3-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "undimix-v3-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "undimix-v3-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "undimix-v3-13b.Q4_0.gguf"
        },
        {
          "rfilename": "undimix-v3-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "undimix-v3-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "undimix-v3-13b.Q5_0.gguf"
        },
        {
          "rfilename": "undimix-v3-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "undimix-v3-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "undimix-v3-13b.Q6_K.gguf"
        },
        {
          "rfilename": "undimix-v3-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64f9fe9a84bf01577e2e75f4",
      "id": "Undi95/UndiMix-v3-13B",
      "modelId": "Undi95/UndiMix-v3-13B",
      "author": "Undi95",
      "sha": "98295b4c627185eee0f8573177438a4065e98e6f",
      "lastModified": "2023-09-09T21:16:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "datnip/Undi95-UndiMix-v3-13B"
      ],
      "safetensors": {
        "parameters": {
          "F32": 327680000,
          "BF16": 12688184320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652653590aaab896facf71a0",
    "id": "TheBloke/dolphin-2.1-mistral-7B-GGUF",
    "likes": 77,
    "private": false,
    "downloads": 446,
    "tags": [
      "transformers",
      "mistral",
      "en",
      "dataset:ehartford/dolphin",
      "dataset:jondurbin/airoboros-2.2.1",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us",
      "has_space"
    ],
    "modelId": "TheBloke/dolphin-2.1-mistral-7B-GGUF",
    "model": {
      "_id": "652653590aaab896facf71a0",
      "id": "TheBloke/dolphin-2.1-mistral-7B-GGUF",
      "modelId": "TheBloke/dolphin-2.1-mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "9fc40401811a50b36cd6f992975cec5a24e87ccf",
      "lastModified": "2023-10-22T05:56:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "en",
        "dataset:ehartford/dolphin",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:apache-2.0",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 446,
      "library_name": "transformers",
      "likes": 77,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "ehartford/dolphin-2.1-mistral-7b",
        "datasets": [
          "ehartford/dolphin",
          "jondurbin/airoboros-2.2.1"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "model_creator": "Eric Hartford",
        "model_name": "Dolphin 2.1 Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "limcheekin/dolphin-2.1-mistral-7B-GGUF"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "dolphin-2.1-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "dolphin-2.1-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "dolphin-2.1-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "dolphin-2.1-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "dolphin-2.1-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "dolphin-2.1-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "dolphin-2.1-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "dolphin-2.1-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "dolphin-2.1-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "dolphin-2.1-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "dolphin-2.1-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "dolphin-2.1-mistral-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652627a82ceb2f426c49b8c3",
      "id": "ehartford/dolphin-2.1-mistral-7b",
      "modelId": "ehartford/dolphin-2.1-mistral-7b",
      "author": "ehartford",
      "sha": "20db79f71731bc314ee646019c63d29beeb61d7d",
      "lastModified": "2023-10-11T13:35:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "en",
        "dataset:ehartford/dolphin",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 12949,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 165,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "datasets": [
          "ehartford/dolphin",
          "jondurbin/airoboros-2.2.1"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Tefa90/ehartford-dolphin-2.1-mistral-7b",
        "natana/ehartford-dolphin-2.1-mistral-7b",
        "mattduzit/ehartford-dolphin-2.1-mistral-7b",
        "spicytaco/ehartford-dolphin-2.1-mistral-7b",
        "deathoperator/ehartford-dolphin-2.1-mistral-7b",
        "OrlandoFresno/ehartford-dolphin-2.1-mistral-7b",
        "Reza2kn/ehartford-dolphin-2.1-mistral-7b",
        "beyond-repair/ehartford-dolphin-2.1-mistral-7b",
        "DJStomp/ehartford-dolphin-2.1-mistral-7b",
        "limcheekin/dolphin-2.1-mistral-7B-GGUF",
        "tex77/ehartford-dolphin-2.1-mistral-7b",
        "gstarwd/chat-dolphin-2.1-mistral-7b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configs/dolphin-mistral-7b.yml"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "latest"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        },
        {
          "rfilename": "zero_to_fp32.py"
        }
      ]
    }
  },
  {
    "_id": "65266322372fb24ede776b99",
    "id": "TheBloke/jackalope-7B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 5,
    "tags": [
      "transformers",
      "mistral",
      "text-generation",
      "en",
      "dataset:Open-Orca/OpenOrca",
      "dataset:LDJnr/LessWrong-Amplify-Instruct",
      "dataset:LDJnr/Pure-Dove",
      "dataset:LDJnr/Verified-Camel",
      "dataset:PygmalionAI/PIPPA",
      "dataset:meta-math/MetaMathQA",
      "dataset:riddle_sense",
      "arxiv:2306.02707",
      "arxiv:2301.13688",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/jackalope-7B-GGUF",
    "model": {
      "_id": "65266322372fb24ede776b99",
      "id": "TheBloke/jackalope-7B-GGUF",
      "modelId": "TheBloke/jackalope-7B-GGUF",
      "author": "TheBloke",
      "sha": "2f7158539687397c4e1a1437c824e2a693f44277",
      "lastModified": "2023-10-11T09:16:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "dataset:LDJnr/LessWrong-Amplify-Instruct",
        "dataset:LDJnr/Pure-Dove",
        "dataset:LDJnr/Verified-Camel",
        "dataset:PygmalionAI/PIPPA",
        "dataset:meta-math/MetaMathQA",
        "dataset:riddle_sense",
        "arxiv:2306.02707",
        "arxiv:2301.13688",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "openaccess-ai-collective/jackalope-7b",
        "datasets": [
          "Open-Orca/OpenOrca",
          "LDJnr/LessWrong-Amplify-Instruct",
          "LDJnr/Pure-Dove",
          "LDJnr/Verified-Camel",
          "PygmalionAI/PIPPA",
          "meta-math/MetaMathQA",
          "riddle_sense"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "Open Access AI Collective",
        "model_name": "Jackalope 7B",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "jackalope-7b.Q2_K.gguf"
        },
        {
          "rfilename": "jackalope-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "jackalope-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "jackalope-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "jackalope-7b.Q4_0.gguf"
        },
        {
          "rfilename": "jackalope-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "jackalope-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "jackalope-7b.Q5_0.gguf"
        },
        {
          "rfilename": "jackalope-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "jackalope-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "jackalope-7b.Q6_K.gguf"
        },
        {
          "rfilename": "jackalope-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6521828a0415e1b734c52893",
      "id": "openaccess-ai-collective/jackalope-7b",
      "modelId": "openaccess-ai-collective/jackalope-7b",
      "author": "openaccess-ai-collective",
      "sha": "011b872c50eebbcce4f82acece9d5081ce7a62a5",
      "lastModified": "2023-10-12T08:21:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "en",
        "dataset:Open-Orca/OpenOrca",
        "dataset:LDJnr/LessWrong-Amplify-Instruct",
        "dataset:LDJnr/Pure-Dove",
        "dataset:LDJnr/Verified-Camel",
        "dataset:PygmalionAI/PIPPA",
        "dataset:meta-math/MetaMathQA",
        "dataset:riddle_sense",
        "arxiv:2306.02707",
        "arxiv:2301.13688",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5034,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 23,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "datasets": [
          "Open-Orca/OpenOrca",
          "LDJnr/LessWrong-Amplify-Instruct",
          "LDJnr/Pure-Dove",
          "LDJnr/Verified-Camel",
          "PygmalionAI/PIPPA",
          "meta-math/MetaMathQA",
          "riddle_sense"
        ],
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "openaccess-ai-collective/jackalope-7b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "images/.gitignore"
        },
        {
          "rfilename": "images/bench.png"
        },
        {
          "rfilename": "images/jackalope.jpg"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65276b359040bfac67fc96c5",
    "id": "TheBloke/ZephRP-m7b-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 9,
    "tags": [
      "transformers",
      "mistral",
      "text-generation",
      "en",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/ZephRP-m7b-GGUF",
    "model": {
      "_id": "65276b359040bfac67fc96c5",
      "id": "TheBloke/ZephRP-m7b-GGUF",
      "modelId": "TheBloke/ZephRP-m7b-GGUF",
      "author": "TheBloke",
      "sha": "d38d50dee0775418fec3df0d5c7663ac2f751844",
      "lastModified": "2023-10-12T03:52:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "text-generation",
        "en",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "royallab/ZephRP-m7b",
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "cc-by-nc-4.0",
        "model_creator": "The Royal Lab",
        "model_name": "Zephrp m7b",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "### Instruction:\nCharacter's Persona: bot character description\n\nUser's persona: user character description\n  \nScenario: what happens in the story\n\nPlay the role of Character. You must engage in a roleplaying chat with User below this line. Do not write dialogues and narration for User. Character should respond with messages of medium length.\n\n### Input:\nUser: {prompt}\n\n### Response:\nCharacter: \n",
        "quantized_by": "TheBloke",
        "tags": [
          "mistral"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "zephrp-m7b.Q2_K.gguf"
        },
        {
          "rfilename": "zephrp-m7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "zephrp-m7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "zephrp-m7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "zephrp-m7b.Q4_0.gguf"
        },
        {
          "rfilename": "zephrp-m7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "zephrp-m7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "zephrp-m7b.Q5_0.gguf"
        },
        {
          "rfilename": "zephrp-m7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "zephrp-m7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "zephrp-m7b.Q6_K.gguf"
        },
        {
          "rfilename": "zephrp-m7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65262788e0094b7bf223ace9",
      "id": "royallab/ZephRP-m7b",
      "modelId": "royallab/ZephRP-m7b",
      "author": "royallab",
      "sha": "4ef26ff937765b3fb279151ba9af48fb42c03932",
      "lastModified": "2023-10-12T02:37:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "en",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 389,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "mistral"
        ],
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "BF16": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6527764534bf5ece73d12f73",
    "id": "TheBloke/ANIMA-Phi-Neptune-Mistral-7B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 0,
    "tags": [
      "adapter-transformers",
      "chemistry",
      "biology",
      "climate",
      "science",
      "philosophy",
      "nature",
      "ecology",
      "biomimicry",
      "fauna",
      "flora",
      "dataset:Severian/Biomimicry",
      "dataset:emrgnt-cmplxty/sciphi-textbooks-are-all-you-need",
      "dataset:fmars/wiki_stem",
      "dataset:fblgit/tree-of-knowledge",
      "dataset:Severian/Bio-Design-Process",
      "license:mit",
      "region:us"
    ],
    "modelId": "TheBloke/ANIMA-Phi-Neptune-Mistral-7B-GGUF",
    "model": {
      "_id": "6527764534bf5ece73d12f73",
      "id": "TheBloke/ANIMA-Phi-Neptune-Mistral-7B-GGUF",
      "modelId": "TheBloke/ANIMA-Phi-Neptune-Mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "becc1346946348c76364bf4a23510966ff6aecc9",
      "lastModified": "2023-10-12T04:41:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "adapter-transformers",
        "chemistry",
        "biology",
        "climate",
        "science",
        "philosophy",
        "nature",
        "ecology",
        "biomimicry",
        "fauna",
        "flora",
        "dataset:Severian/Biomimicry",
        "dataset:emrgnt-cmplxty/sciphi-textbooks-are-all-you-need",
        "dataset:fmars/wiki_stem",
        "dataset:fblgit/tree-of-knowledge",
        "dataset:Severian/Bio-Design-Process",
        "license:mit",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "adapter-transformers",
      "likes": 7,
      "model-index": null,
      "config": {},
      "cardData": {
        "base_model": "Severian/ANIMA-Phi-Neptune-Mistral-7B",
        "datasets": [
          "Severian/Biomimicry",
          "emrgnt-cmplxty/sciphi-textbooks-are-all-you-need",
          "fmars/wiki_stem",
          "fblgit/tree-of-knowledge",
          "Severian/Bio-Design-Process"
        ],
        "inference": false,
        "library_name": "adapter-transformers",
        "license": "mit",
        "model_creator": "Severian",
        "model_name": "Anima Phi Neptune Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "[INST] {prompt} [/INST]\n",
        "quantized_by": "TheBloke",
        "tags": [
          "chemistry",
          "biology",
          "climate",
          "science",
          "philosophy",
          "nature",
          "ecology",
          "biomimicry",
          "fauna",
          "flora"
        ]
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "anima-phi-neptune-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "anima-phi-neptune-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "anima-phi-neptune-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "anima-phi-neptune-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "anima-phi-neptune-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "anima-phi-neptune-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "anima-phi-neptune-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "anima-phi-neptune-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "anima-phi-neptune-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "anima-phi-neptune-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "anima-phi-neptune-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "anima-phi-neptune-mistral-7b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6527263068608eb5bbba62b1",
      "id": "Severian/ANIMA-Phi-Neptune-Mistral-7B",
      "modelId": "Severian/ANIMA-Phi-Neptune-Mistral-7B",
      "author": "Severian",
      "sha": "0943653e3b5340400059fd5dbedc3fa9ad176906",
      "lastModified": "2023-10-26T11:03:46.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "chemistry",
        "biology",
        "climate",
        "science",
        "philosophy",
        "nature",
        "ecology",
        "biomimicry",
        "fauna",
        "flora",
        "dataset:Severian/Biomimicry",
        "dataset:emrgnt-cmplxty/sciphi-textbooks-are-all-you-need",
        "dataset:fmars/wiki_stem",
        "dataset:fblgit/tree-of-knowledge",
        "dataset:Severian/Bio-Design-Process",
        "license:artistic-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6189,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 19,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "artistic-2.0",
        "datasets": [
          "Severian/Biomimicry",
          "emrgnt-cmplxty/sciphi-textbooks-are-all-you-need",
          "fmars/wiki_stem",
          "fblgit/tree-of-knowledge",
          "Severian/Bio-Design-Process"
        ],
        "tags": [
          "chemistry",
          "biology",
          "climate",
          "science",
          "philosophy",
          "nature",
          "ecology",
          "biomimicry",
          "fauna",
          "flora"
        ],
        "pipeline_tag": "text-generation",
        "metrics": [
          "accuracy"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65279e4c68608eb5bbc8ffe9",
    "id": "TheBloke/samantha-1.2-mistral-7B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "mistral",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/samantha-1.2-mistral-7B-GGUF",
    "model": {
      "_id": "65279e4c68608eb5bbc8ffe9",
      "id": "TheBloke/samantha-1.2-mistral-7B-GGUF",
      "modelId": "TheBloke/samantha-1.2-mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "2266ec1fee9a3ae2da231b2938be91064738e0e9",
      "lastModified": "2023-10-12T08:06:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "ehartford/samantha-1.2-mistral-7b",
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Eric Hartford",
        "model_name": "Samantha 1.2 Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "samantha-1.2-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "samantha-1.2-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "samantha-1.2-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.2-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.2-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "samantha-1.2-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.2-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.2-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "samantha-1.2-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "samantha-1.2-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "samantha-1.2-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "samantha-1.2-mistral-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6526aae363db3f847183aa26",
      "id": "ehartford/samantha-1.2-mistral-7b",
      "modelId": "ehartford/samantha-1.2-mistral-7b",
      "author": "ehartford",
      "sha": "5574a021f55a446a756dcbc776f1765aefc280a1",
      "lastModified": "2023-10-11T14:21:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5620,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 19,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "EsoCode/ehartford-samantha-1.2-mistral-7b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configs/samantha-mistral-7b.yml"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "latest"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        },
        {
          "rfilename": "zero_to_fp32.py"
        }
      ]
    }
  },
  {
    "_id": "6527bf910ae663e384eca333",
    "id": "TheBloke/chronos007-70B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "chat",
      "roleplay",
      "storywriting",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/chronos007-70B-GGUF",
    "model": {
      "_id": "6527bf910ae663e384eca333",
      "id": "TheBloke/chronos007-70B-GGUF",
      "modelId": "TheBloke/chronos007-70B-GGUF",
      "author": "TheBloke",
      "sha": "139097e4d34fea4dbbd0812b6fe7fc1938e03d90",
      "lastModified": "2023-10-12T12:12:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "chat",
        "roleplay",
        "storywriting",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "elinas/chronos007-70b",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "elinas",
        "model_name": "Chronos007 70B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "chat",
          "roleplay",
          "storywriting"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "chronos007-70b.Q2_K.gguf"
        },
        {
          "rfilename": "chronos007-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "chronos007-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "chronos007-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "chronos007-70b.Q4_0.gguf"
        },
        {
          "rfilename": "chronos007-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "chronos007-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "chronos007-70b.Q5_0.gguf"
        },
        {
          "rfilename": "chronos007-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "chronos007-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "chronos007-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "chronos007-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "chronos007-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "chronos007-70b.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "651351adb4a3c844a7c6324a",
      "id": "elinas/chronos007-70b",
      "modelId": "elinas/chronos007-70b",
      "author": "elinas",
      "sha": "559c57d38bf7b5513a8a7bd4e9d00b7bd964b89a",
      "lastModified": "2023-10-12T19:10:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "chat",
        "roleplay",
        "storywriting",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3591,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "chat",
          "roleplay",
          "storywriting"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 524288000,
          "BF16": 68452360192
        },
        "total": 68976648192
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00015.safetensors"
        },
        {
          "rfilename": "model-00002-of-00015.safetensors"
        },
        {
          "rfilename": "model-00003-of-00015.safetensors"
        },
        {
          "rfilename": "model-00004-of-00015.safetensors"
        },
        {
          "rfilename": "model-00005-of-00015.safetensors"
        },
        {
          "rfilename": "model-00006-of-00015.safetensors"
        },
        {
          "rfilename": "model-00007-of-00015.safetensors"
        },
        {
          "rfilename": "model-00008-of-00015.safetensors"
        },
        {
          "rfilename": "model-00009-of-00015.safetensors"
        },
        {
          "rfilename": "model-00010-of-00015.safetensors"
        },
        {
          "rfilename": "model-00011-of-00015.safetensors"
        },
        {
          "rfilename": "model-00012-of-00015.safetensors"
        },
        {
          "rfilename": "model-00013-of-00015.safetensors"
        },
        {
          "rfilename": "model-00014-of-00015.safetensors"
        },
        {
          "rfilename": "model-00015-of-00015.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65281157c0a5afef6931c877",
    "id": "TheBloke/FashionGPT-70B-v1.2-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/FashionGPT-70B-v1.2-GGUF",
    "model": {
      "_id": "65281157c0a5afef6931c877",
      "id": "TheBloke/FashionGPT-70B-v1.2-GGUF",
      "modelId": "TheBloke/FashionGPT-70B-v1.2-GGUF",
      "author": "TheBloke",
      "sha": "56c99f6a7aed7bfc204e4ef2d1093c7e95e88e90",
      "lastModified": "2023-10-12T18:02:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "ICBU-NPU/FashionGPT-70B-V1.2",
        "inference": false,
        "license": "llama2",
        "model_creator": "ICBU-NPU",
        "model_name": "Fashiongpt 70B v1.2",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q2_K.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q4_0.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q5_0.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "fashiongpt-70b-v1.2.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "6524c06ab4c4b4a32e705034",
      "id": "ICBU-NPU/FashionGPT-70B-V1.2",
      "modelId": "ICBU-NPU/FashionGPT-70B-V1.2",
      "author": "ICBU-NPU",
      "sha": "990a1664fc058de6ee2406af62c0a817d7047304",
      "lastModified": "2023-10-10T06:01:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5732,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Fr0NiX/ICBU-NPU-FashionGPT-70B-V1.2",
        "c4llmedezz/ICBU-NPU-FashionGPT-70B-V1.2",
        "arthurspapa/ICBU-NPU-FashionGPT-70B-V1.2",
        "ziedammak/ICBU-NPU-FashionGPT-70B-V1.2",
        "amrit071/ICBU-NPU-FashionGPT-70B-V1.2",
        "bhandsab/ICBU-NPU-FashionGPT-70B-V1.2"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6528dead1ce90a096149ec45",
    "id": "TheBloke/speechless-code-mistral-7B-v1.0-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "mistral",
      "llama-2",
      "code",
      "text-generation",
      "en",
      "dataset:jondurbin/airoboros-2.2",
      "dataset:Open-Orca/OpenOrca",
      "dataset:garage-bAInd/Open-Platypus",
      "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
      "dataset:TokenBender/python_eval_instruct_51k",
      "license:llama2",
      "model-index",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/speechless-code-mistral-7B-v1.0-GGUF",
    "model": {
      "_id": "6528dead1ce90a096149ec45",
      "id": "TheBloke/speechless-code-mistral-7B-v1.0-GGUF",
      "modelId": "TheBloke/speechless-code-mistral-7B-v1.0-GGUF",
      "author": "TheBloke",
      "sha": "26e8b23719a61f61ba755c67519ba954e02eba4d",
      "lastModified": "2023-10-13T06:17:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "llama-2",
        "code",
        "text-generation",
        "en",
        "dataset:jondurbin/airoboros-2.2",
        "dataset:Open-Orca/OpenOrca",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
        "dataset:TokenBender/python_eval_instruct_51k",
        "license:llama2",
        "model-index",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": [
        {
          "name": "SpeechlessCoder",
          "results": [
            {
              "dataset": {
                "name": "HumanEval",
                "type": "openai_humaneval"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": 0,
                  "verified": false
                }
              ],
              "task": {
                "type": "text-generation"
              }
            }
          ]
        }
      ],
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "uukuguy/speechless-code-mistral-7b-v1.0",
        "datasets": [
          "jondurbin/airoboros-2.2",
          "Open-Orca/OpenOrca",
          "garage-bAInd/Open-Platypus",
          "WizardLM/WizardLM_evol_instruct_V2_196k",
          "TokenBender/python_eval_instruct_51k"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model-index": [
          {
            "name": "SpeechlessCoder",
            "results": [
              {
                "dataset": {
                  "name": "HumanEval",
                  "type": "openai_humaneval"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": 0,
                    "verified": false
                  }
                ],
                "task": {
                  "type": "text-generation"
                }
              }
            ]
          }
        ],
        "model_creator": "Jiangwen Su",
        "model_name": "Speechless Code Mistral 7B v1.0",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke",
        "tags": [
          "llama-2",
          "code"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "speechless-code-mistral-7b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "speechless-code-mistral-7b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "speechless-code-mistral-7b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "speechless-code-mistral-7b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "speechless-code-mistral-7b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "speechless-code-mistral-7b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "speechless-code-mistral-7b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "speechless-code-mistral-7b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "speechless-code-mistral-7b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "speechless-code-mistral-7b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "speechless-code-mistral-7b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "speechless-code-mistral-7b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6524eba89d870c61b3102f8e",
      "id": "uukuguy/speechless-code-mistral-7b-v1.0",
      "modelId": "uukuguy/speechless-code-mistral-7b-v1.0",
      "author": "uukuguy",
      "sha": "9828fac7846ab081d5c9659f1bd89f6c77d83e4e",
      "lastModified": "2023-10-13T07:34:35.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "llama-2",
        "code",
        "en",
        "dataset:jondurbin/airoboros-2.2",
        "dataset:Open-Orca/OpenOrca",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
        "dataset:TokenBender/python_eval_instruct_51k",
        "license:llama2",
        "model-index",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4742,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": [
        {
          "name": "SpeechlessCoder",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "type": "openai_humaneval",
                "name": "HumanEval"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": 50,
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "datasets": [
          "jondurbin/airoboros-2.2",
          "Open-Orca/OpenOrca",
          "garage-bAInd/Open-Platypus",
          "WizardLM/WizardLM_evol_instruct_V2_196k",
          "TokenBender/python_eval_instruct_51k"
        ],
        "tags": [
          "llama-2",
          "code"
        ],
        "license": "llama2",
        "model-index": [
          {
            "name": "SpeechlessCoder",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "type": "openai_humaneval",
                  "name": "HumanEval"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": 50,
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6528e8a236b7c441d33a459d",
    "id": "TheBloke/CollectiveCognition-v1-Mistral-7B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 15,
    "tags": [
      "transformers",
      "mistral",
      "mistral-7b",
      "instruct",
      "finetune",
      "gpt4",
      "synthetic data",
      "distillation",
      "sharegpt",
      "en",
      "dataset:CollectiveCognition/chats-data-2023-09-27",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/CollectiveCognition-v1-Mistral-7B-GGUF",
    "model": {
      "_id": "6528e8a236b7c441d33a459d",
      "id": "TheBloke/CollectiveCognition-v1-Mistral-7B-GGUF",
      "modelId": "TheBloke/CollectiveCognition-v1-Mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "cfb331e0edfd6b4f67478ddc5ad1a739da86485a",
      "lastModified": "2023-10-13T06:58:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "mistral-7b",
        "instruct",
        "finetune",
        "gpt4",
        "synthetic data",
        "distillation",
        "sharegpt",
        "en",
        "dataset:CollectiveCognition/chats-data-2023-09-27",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15,
      "library_name": "transformers",
      "likes": 3,
      "model-index": [
        {
          "name": "CollectiveCognition-v1-Mistral-7B",
          "results": []
        }
      ],
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "teknium/CollectiveCognition-v1-Mistral-7B",
        "datasets": [
          "CollectiveCognition/chats-data-2023-09-27"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "model-index": [
          {
            "name": "CollectiveCognition-v1-Mistral-7B",
            "results": []
          }
        ],
        "model_creator": "Teknium",
        "model_name": "CollectiveCognition v1 Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "USER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "mistral-7b",
          "instruct",
          "finetune",
          "gpt4",
          "synthetic data",
          "distillation",
          "sharegpt"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "collectivecognition-v1-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "collectivecognition-v1-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "collectivecognition-v1-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "collectivecognition-v1-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "collectivecognition-v1-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "collectivecognition-v1-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "collectivecognition-v1-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "collectivecognition-v1-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "collectivecognition-v1-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "collectivecognition-v1-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "collectivecognition-v1-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "collectivecognition-v1-mistral-7b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "651db3bd3a7bb5530354b4b3",
      "id": "teknium/CollectiveCognition-v1-Mistral-7B",
      "modelId": "teknium/CollectiveCognition-v1-Mistral-7B",
      "author": "teknium",
      "sha": "58777f0563610fa770c4fa252c0350de71d4ab9d",
      "lastModified": "2023-10-07T00:22:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "mistral-7b",
        "instruct",
        "finetune",
        "gpt4",
        "synthetic data",
        "distillation",
        "sharegpt",
        "en",
        "dataset:CollectiveCognition/chats-data-2023-09-27",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4594,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 15,
      "model-index": [
        {
          "name": "CollectiveCognition-v1-Mistral-7B",
          "results": []
        }
      ],
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "mistralai/Mistral-7B-v0.1",
        "tags": [
          "mistral-7b",
          "instruct",
          "finetune",
          "gpt4",
          "synthetic data",
          "distillation",
          "sharegpt"
        ],
        "datasets": [
          "CollectiveCognition/chats-data-2023-09-27"
        ],
        "model-index": [
          {
            "name": "CollectiveCognition-v1-Mistral-7B",
            "results": []
          }
        ],
        "license": "apache-2.0",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6528f3af4638938a727237ea",
    "id": "TheBloke/speechless-tora-code-7B-v1.0-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "code",
      "text-generation",
      "en",
      "dataset:jondurbin/airoboros-2.2",
      "dataset:Open-Orca/OpenOrca",
      "dataset:garage-bAInd/Open-Platypus",
      "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
      "dataset:TokenBender/python_eval_instruct_51k",
      "license:llama2",
      "model-index",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/speechless-tora-code-7B-v1.0-GGUF",
    "model": {
      "_id": "6528f3af4638938a727237ea",
      "id": "TheBloke/speechless-tora-code-7B-v1.0-GGUF",
      "modelId": "TheBloke/speechless-tora-code-7B-v1.0-GGUF",
      "author": "TheBloke",
      "sha": "a87f40d2c7496abc2d25c0ba2977914074ff692b",
      "lastModified": "2023-10-13T09:52:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "code",
        "text-generation",
        "en",
        "dataset:jondurbin/airoboros-2.2",
        "dataset:Open-Orca/OpenOrca",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
        "dataset:TokenBender/python_eval_instruct_51k",
        "license:llama2",
        "model-index",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": [
        {
          "name": "SpeechlessCoder",
          "results": [
            {
              "dataset": {
                "name": "HumanEval",
                "type": "openai_humaneval"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": 51.829,
                  "verified": false
                }
              ],
              "task": {
                "type": "text-generation"
              }
            }
          ]
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "uukuguy/speechless-tora-code-7b-v1.0",
        "datasets": [
          "jondurbin/airoboros-2.2",
          "Open-Orca/OpenOrca",
          "garage-bAInd/Open-Platypus",
          "WizardLM/WizardLM_evol_instruct_V2_196k",
          "TokenBender/python_eval_instruct_51k"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model-index": [
          {
            "name": "SpeechlessCoder",
            "results": [
              {
                "dataset": {
                  "name": "HumanEval",
                  "type": "openai_humaneval"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": 51.829,
                    "verified": false
                  }
                ],
                "task": {
                  "type": "text-generation"
                }
              }
            ]
          }
        ],
        "model_creator": "Jiangwen Su",
        "model_name": "Speechless Tora Code 7B v1.0",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke",
        "tags": [
          "llama-2",
          "code"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "speechless-tora-code-7b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "speechless-tora-code-7b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "speechless-tora-code-7b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "speechless-tora-code-7b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "speechless-tora-code-7b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "speechless-tora-code-7b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "speechless-tora-code-7b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "speechless-tora-code-7b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "speechless-tora-code-7b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "speechless-tora-code-7b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "speechless-tora-code-7b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "speechless-tora-code-7b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652525b8d28287cae31914b5",
      "id": "uukuguy/speechless-tora-code-7b-v1.0",
      "modelId": "uukuguy/speechless-tora-code-7b-v1.0",
      "author": "uukuguy",
      "sha": "4b4fac38530d4e63b599b2953e67408f58cf4bda",
      "lastModified": "2023-10-13T09:13:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "tensorboard",
        "llama",
        "text-generation",
        "llama-2",
        "code",
        "en",
        "dataset:jondurbin/airoboros-2.2",
        "dataset:Open-Orca/OpenOrca",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
        "dataset:TokenBender/python_eval_instruct_51k",
        "license:llama2",
        "model-index",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4703,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": [
        {
          "name": "SpeechlessCoder",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "type": "openai_humaneval",
                "name": "HumanEval"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": 51.829,
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "datasets": [
          "jondurbin/airoboros-2.2",
          "Open-Orca/OpenOrca",
          "garage-bAInd/Open-Platypus",
          "WizardLM/WizardLM_evol_instruct_V2_196k",
          "TokenBender/python_eval_instruct_51k"
        ],
        "tags": [
          "llama-2",
          "code"
        ],
        "license": "llama2",
        "model-index": [
          {
            "name": "SpeechlessCoder",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "type": "openai_humaneval",
                  "name": "HumanEval"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": 51.829,
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/merge_peft_adapters.sh"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/all_results.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/README.md"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/adapter_config.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/adapter_model.bin"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/adapter_model/README.md"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/adapter_model/adapter_config.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/adapter_model/adapter_model.bin"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/added_tokens.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/optimizer.pt"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/rng_state_0.pth"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/rng_state_1.pth"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/scheduler.pt"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/special_tokens_map.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/tokenizer.model"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/tokenizer_config.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/trainer_state.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3000/training_args.bin"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3092/adapter_model/README.md"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3092/adapter_model/adapter_config.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/checkpoint-3092/adapter_model/adapter_model.bin"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/completed"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/eval_results.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/logs/finetune_20231009_061922.log"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/logs/finetune_20231009_122312.log"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/metrics.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/runs/Oct09_06-19-22_I156f1f3f410070163e/events.out.tfevents.1696832467.I156f1f3f410070163e.7536.0"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/runs/Oct09_12-23-12_I156f1f3f410070163e/events.out.tfevents.1696854295.I156f1f3f410070163e.1701.0"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/runs/Oct09_12-23-12_I156f1f3f410070163e/events.out.tfevents.1696924201.I156f1f3f410070163e.1701.1"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/train_results.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/outputs/speechless-tora-code-7b-v1.0/trainer_state.json"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/run_api_server.sh"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/run_finetune.sh"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/task.env"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/task_a100_40gx2.env"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/task_a100_40gx4.env"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/task_a100_80gx2.env"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/task_a40_48gx2.env"
        },
        {
          "rfilename": "tasks/speechless-tora-code-7b-v1.0/task_a40_48gx4.env"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65291a244d7cf551ac495f29",
    "id": "TheBloke/speechless-codellama-34b-v2.0-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "llama-2",
      "code",
      "text-generation",
      "en",
      "dataset:jondurbin/airoboros-2.2",
      "dataset:Open-Orca/OpenOrca",
      "dataset:garage-bAInd/Open-Platypus",
      "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
      "arxiv:2308.12950",
      "license:llama2",
      "model-index",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/speechless-codellama-34b-v2.0-GGUF",
    "model": {
      "_id": "65291a244d7cf551ac495f29",
      "id": "TheBloke/speechless-codellama-34b-v2.0-GGUF",
      "modelId": "TheBloke/speechless-codellama-34b-v2.0-GGUF",
      "author": "TheBloke",
      "sha": "f82dad80df01aab7347bea014572348bd85375fa",
      "lastModified": "2023-10-13T11:00:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama-2",
        "code",
        "text-generation",
        "en",
        "dataset:jondurbin/airoboros-2.2",
        "dataset:Open-Orca/OpenOrca",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
        "arxiv:2308.12950",
        "license:llama2",
        "model-index",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": [
        {
          "name": "SpeechlessCoder",
          "results": [
            {
              "dataset": {
                "name": "HumanEval",
                "type": "openai_humaneval"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": 75.61,
                  "verified": false
                }
              ],
              "task": {
                "type": "text-generation"
              }
            }
          ]
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "uukuguy/speechless-codellama-34b-v2.0",
        "datasets": [
          "jondurbin/airoboros-2.2",
          "Open-Orca/OpenOrca",
          "garage-bAInd/Open-Platypus",
          "WizardLM/WizardLM_evol_instruct_V2_196k"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model-index": [
          {
            "name": "SpeechlessCoder",
            "results": [
              {
                "dataset": {
                  "name": "HumanEval",
                  "type": "openai_humaneval"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": 75.61,
                    "verified": false
                  }
                ],
                "task": {
                  "type": "text-generation"
                }
              }
            ]
          }
        ],
        "model_creator": "Jiangwen Su",
        "model_name": "Speechless Codellama 34B v2.0",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke",
        "tags": [
          "llama-2",
          "code"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "speechless-codellama-34b-v2.0.Q2_K.gguf"
        },
        {
          "rfilename": "speechless-codellama-34b-v2.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "speechless-codellama-34b-v2.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "speechless-codellama-34b-v2.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "speechless-codellama-34b-v2.0.Q4_0.gguf"
        },
        {
          "rfilename": "speechless-codellama-34b-v2.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "speechless-codellama-34b-v2.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "speechless-codellama-34b-v2.0.Q5_0.gguf"
        },
        {
          "rfilename": "speechless-codellama-34b-v2.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "speechless-codellama-34b-v2.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "speechless-codellama-34b-v2.0.Q6_K.gguf"
        },
        {
          "rfilename": "speechless-codellama-34b-v2.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651d36d62248f136f7e0cbf1",
      "id": "uukuguy/speechless-codellama-34b-v2.0",
      "modelId": "uukuguy/speechless-codellama-34b-v2.0",
      "author": "uukuguy",
      "sha": "e55b493220980988e18940bc71b5cfeded917a07",
      "lastModified": "2023-10-13T11:46:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "llama-2",
        "code",
        "en",
        "dataset:jondurbin/airoboros-2.2",
        "dataset:Open-Orca/OpenOrca",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
        "arxiv:2308.12950",
        "license:llama2",
        "model-index",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5114,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": [
        {
          "name": "SpeechlessCoder",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "type": "openai_humaneval",
                "name": "HumanEval"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": 75.61,
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "datasets": [
          "jondurbin/airoboros-2.2",
          "Open-Orca/OpenOrca",
          "garage-bAInd/Open-Platypus",
          "WizardLM/WizardLM_evol_instruct_V2_196k"
        ],
        "tags": [
          "llama-2",
          "code"
        ],
        "license": "llama2",
        "model-index": [
          {
            "name": "SpeechlessCoder",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "type": "openai_humaneval",
                  "name": "HumanEval"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": 75.61,
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652a4a91c59e682042c1b91f",
    "id": "TheBloke/OpenHermes-2-Mistral-7B-GGUF",
    "likes": 61,
    "private": false,
    "downloads": 119,
    "tags": [
      "transformers",
      "mistral",
      "instruct",
      "finetune",
      "chatml",
      "gpt4",
      "synthetic data",
      "distillation",
      "en",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/OpenHermes-2-Mistral-7B-GGUF",
    "model": {
      "_id": "652a4a91c59e682042c1b91f",
      "id": "TheBloke/OpenHermes-2-Mistral-7B-GGUF",
      "modelId": "TheBloke/OpenHermes-2-Mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "6937cade04480b614de27458ee8af6edbc48842a",
      "lastModified": "2023-10-16T20:26:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "instruct",
        "finetune",
        "chatml",
        "gpt4",
        "synthetic data",
        "distillation",
        "en",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 119,
      "library_name": "transformers",
      "likes": 61,
      "model-index": [
        {
          "name": "OpenHermes-2-Mistral-7B",
          "results": []
        }
      ],
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "teknium/OpenHermes-2-Mistral-7B",
        "inference": false,
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "model-index": [
          {
            "name": "OpenHermes-2-Mistral-7B",
            "results": []
          }
        ],
        "model_creator": "Teknium",
        "model_name": "OpenHermes 2 Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke",
        "tags": [
          "mistral",
          "instruct",
          "finetune",
          "chatml",
          "gpt4",
          "synthetic data",
          "distillation"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openhermes-2-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "openhermes-2-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "openhermes-2-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "openhermes-2-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "openhermes-2-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "openhermes-2-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "openhermes-2-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "openhermes-2-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "openhermes-2-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "openhermes-2-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "openhermes-2-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "openhermes-2-mistral-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652851f32e793f1328fb1657",
      "id": "teknium/OpenHermes-2-Mistral-7B",
      "modelId": "teknium/OpenHermes-2-Mistral-7B",
      "author": "teknium",
      "sha": "2bb0b75442eeadc2da3035a6ada86e3953308ac3",
      "lastModified": "2023-10-26T00:30:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "instruct",
        "finetune",
        "chatml",
        "gpt4",
        "synthetic data",
        "distillation",
        "en",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 14879,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 173,
      "model-index": [
        {
          "name": "OpenHermes-2-Mistral-7B",
          "results": []
        }
      ],
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "mistralai/Mistral-7B-v0.1",
        "tags": [
          "mistral",
          "instruct",
          "finetune",
          "chatml",
          "gpt4",
          "synthetic data",
          "distillation"
        ],
        "model-index": [
          {
            "name": "OpenHermes-2-Mistral-7B",
            "results": []
          }
        ],
        "license": "apache-2.0",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "artificialguybr/OPENHERMES-2",
        "Reza2kn/teknium-OpenHermes-2-Mistral-7B",
        "xentec/teknium-OpenHermes-2-Mistral-7B",
        "KeithCu/teknium-OpenHermes-2-Mistral-7B"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652ac29662a48851897453af",
    "id": "TheBloke/SauerkrautLM-13B-v1-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "de",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/SauerkrautLM-13B-v1-GGUF",
    "model": {
      "_id": "652ac29662a48851897453af",
      "id": "TheBloke/SauerkrautLM-13B-v1-GGUF",
      "modelId": "TheBloke/SauerkrautLM-13B-v1-GGUF",
      "author": "TheBloke",
      "sha": "ffc7a632ceea892207c38b047dda8e380e2797e0",
      "lastModified": "2023-10-14T16:47:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "de",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "VAGOsolutions/SauerkrautLM-13b-v1",
        "inference": false,
        "language": [
          "de",
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "VAGO solutions",
        "model_name": "SauerkrautLM 13B v1",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Ein Chat zwischen einem Benutzer und einem KI-Assistenten. Der KI-Assistent gibt hilfreiche, detaillierte und hfliche Antworten. \nUser: {prompt} \nAssistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "sauerkrautlm-13b-v1.Q2_K.gguf"
        },
        {
          "rfilename": "sauerkrautlm-13b-v1.Q3_K_L.gguf"
        },
        {
          "rfilename": "sauerkrautlm-13b-v1.Q3_K_M.gguf"
        },
        {
          "rfilename": "sauerkrautlm-13b-v1.Q3_K_S.gguf"
        },
        {
          "rfilename": "sauerkrautlm-13b-v1.Q4_0.gguf"
        },
        {
          "rfilename": "sauerkrautlm-13b-v1.Q4_K_M.gguf"
        },
        {
          "rfilename": "sauerkrautlm-13b-v1.Q4_K_S.gguf"
        },
        {
          "rfilename": "sauerkrautlm-13b-v1.Q5_0.gguf"
        },
        {
          "rfilename": "sauerkrautlm-13b-v1.Q5_K_M.gguf"
        },
        {
          "rfilename": "sauerkrautlm-13b-v1.Q5_K_S.gguf"
        },
        {
          "rfilename": "sauerkrautlm-13b-v1.Q6_K.gguf"
        },
        {
          "rfilename": "sauerkrautlm-13b-v1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65278b10d7bedf9045bdde83",
      "id": "VAGOsolutions/SauerkrautLM-13b-v1",
      "modelId": "VAGOsolutions/SauerkrautLM-13b-v1",
      "author": "VAGOsolutions",
      "sha": "b4dc9aae58293865baa180c3c6e177e2c9f13c5b",
      "lastModified": "2023-10-25T13:16:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "de",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 218,
      "library_name": "transformers",
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "de",
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "images/Average.PNG"
        },
        {
          "rfilename": "images/FirstTurn.PNG"
        },
        {
          "rfilename": "images/SauerkrautLM-13b-v1.png"
        },
        {
          "rfilename": "images/SauerkrautLM-13b.png"
        },
        {
          "rfilename": "images/SauerkrautLM.png"
        },
        {
          "rfilename": "images/SecondTurn.PNG"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652ad0c7ff2202020e96f237",
    "id": "TheBloke/ALMA-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2309.11674",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/ALMA-13B-GGUF",
    "model": {
      "_id": "652ad0c7ff2202020e96f237",
      "id": "TheBloke/ALMA-13B-GGUF",
      "modelId": "TheBloke/ALMA-13B-GGUF",
      "author": "TheBloke",
      "sha": "87992ff89da16264d0fe207f3c473c9d8b51550d",
      "lastModified": "2023-10-14T17:48:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2309.11674",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "haoranxu/ALMA-13B",
        "inference": false,
        "license": "mit",
        "model_creator": "Haoran Xu",
        "model_name": "ALMA 13B",
        "model_type": "llama",
        "prompt_template": "Translate this from Chinese to English:\nChinese: {prompt}\nEnglish:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "alma-13b.Q2_K.gguf"
        },
        {
          "rfilename": "alma-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "alma-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "alma-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "alma-13b.Q4_0.gguf"
        },
        {
          "rfilename": "alma-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "alma-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "alma-13b.Q5_0.gguf"
        },
        {
          "rfilename": "alma-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "alma-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "alma-13b.Q6_K.gguf"
        },
        {
          "rfilename": "alma-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "65073aa818f9c580cdc70d4d",
      "id": "haoranxu/ALMA-13B",
      "modelId": "haoranxu/ALMA-13B",
      "author": "haoranxu",
      "sha": "6798d9501a71b203be0610e640ec92fc08ea8dc6",
      "lastModified": "2023-10-27T05:10:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2309.11674",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 31,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652adb681198736f31f991b4",
    "id": "TheBloke/ALMA-7B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2309.11674",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/ALMA-7B-GGUF",
    "model": {
      "_id": "652adb681198736f31f991b4",
      "id": "TheBloke/ALMA-7B-GGUF",
      "modelId": "TheBloke/ALMA-7B-GGUF",
      "author": "TheBloke",
      "sha": "b17c90e20afdaa390a58a5834a4d8af8dc8ff0cc",
      "lastModified": "2023-10-14T18:26:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2309.11674",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "haoranxu/ALMA-7B",
        "inference": false,
        "license": "mit",
        "model_creator": "Haoran Xu",
        "model_name": "ALMA 7B",
        "model_type": "llama",
        "prompt_template": "Translate this from Chinese to English:\nChinese: {prompt}\nEnglish:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "alma-7b.Q2_K.gguf"
        },
        {
          "rfilename": "alma-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "alma-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "alma-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "alma-7b.Q4_0.gguf"
        },
        {
          "rfilename": "alma-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "alma-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "alma-7b.Q5_0.gguf"
        },
        {
          "rfilename": "alma-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "alma-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "alma-7b.Q6_K.gguf"
        },
        {
          "rfilename": "alma-7b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "65073402557a87f111d8d54f",
      "id": "haoranxu/ALMA-7B",
      "modelId": "haoranxu/ALMA-7B",
      "author": "haoranxu",
      "sha": "b570315dd26452a07cf15cf6feecce839e1327a6",
      "lastModified": "2023-10-27T05:11:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "arxiv:2309.11674",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1421,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "mit"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652aec4cf120598322786ae3",
    "id": "TheBloke/tora-13B-v1.0-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "code",
      "math",
      "text-generation",
      "en",
      "dataset:gsm8k",
      "dataset:competition_math",
      "arxiv:2309.17452",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/tora-13B-v1.0-GGUF",
    "model": {
      "_id": "652aec4cf120598322786ae3",
      "id": "TheBloke/tora-13B-v1.0-GGUF",
      "modelId": "TheBloke/tora-13B-v1.0-GGUF",
      "author": "TheBloke",
      "sha": "03bd12de6d6b61acad2bfdc411f00a0cbe9a1664",
      "lastModified": "2023-10-14T19:36:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "code",
        "math",
        "text-generation",
        "en",
        "dataset:gsm8k",
        "dataset:competition_math",
        "arxiv:2309.17452",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "llm-agents/tora-13b-v1.0",
        "datasets": [
          "gsm8k",
          "competition_math"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "metrics": [
          "exact_match"
        ],
        "model_creator": "LLM-Agents",
        "model_name": "ToRA 13B v1.0",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|user|>\n{prompt}\n<|assistant|>\n",
        "quantized_by": "TheBloke",
        "tags": [
          "code",
          "math"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tora-13b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "tora-13b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "tora-13b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "tora-13b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "tora-13b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "tora-13b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "tora-13b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "tora-13b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "tora-13b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "tora-13b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "tora-13b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "tora-13b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65223d93dfc9ea4f31bc0d98",
      "id": "llm-agents/tora-13b-v1.0",
      "modelId": "llm-agents/tora-13b-v1.0",
      "author": "llm-agents",
      "sha": "0636c1f582c979a5a292cc5f3dc293800b1494e2",
      "lastModified": "2023-10-08T11:37:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "math",
        "en",
        "dataset:gsm8k",
        "dataset:competition_math",
        "arxiv:2309.17452",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4825,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "gsm8k",
          "competition_math"
        ],
        "language": [
          "en"
        ],
        "metrics": [
          "exact_match"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "code",
          "math"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652af5e5caddc9e608f9d97d",
    "id": "TheBloke/tora-70B-v1.0-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "code",
      "math",
      "text-generation",
      "en",
      "dataset:gsm8k",
      "dataset:competition_math",
      "arxiv:2309.17452",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/tora-70B-v1.0-GGUF",
    "model": {
      "_id": "652af5e5caddc9e608f9d97d",
      "id": "TheBloke/tora-70B-v1.0-GGUF",
      "modelId": "TheBloke/tora-70B-v1.0-GGUF",
      "author": "TheBloke",
      "sha": "76f666a41be1b5dec608acab102df27a0e453bd6",
      "lastModified": "2023-10-14T20:36:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "code",
        "math",
        "text-generation",
        "en",
        "dataset:gsm8k",
        "dataset:competition_math",
        "arxiv:2309.17452",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "llm-agents/tora-70b-v1.0",
        "datasets": [
          "gsm8k",
          "competition_math"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "metrics": [
          "exact_match"
        ],
        "model_creator": "LLM-Agents",
        "model_name": "ToRA 70B v1.0",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|user|>\n{prompt}\n<|assistant|>\n",
        "quantized_by": "TheBloke",
        "tags": [
          "code",
          "math"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tora-70b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "tora-70b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "tora-70b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "tora-70b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "tora-70b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "tora-70b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "tora-70b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "tora-70b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "tora-70b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "tora-70b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "tora-70b-v1.0.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "tora-70b-v1.0.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "tora-70b-v1.0.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "tora-70b-v1.0.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "65224232bafd014bf6a77c76",
      "id": "llm-agents/tora-70b-v1.0",
      "modelId": "llm-agents/tora-70b-v1.0",
      "author": "llm-agents",
      "sha": "e95fd7daf017e7c414ec07ebef4ddf013c16f9a4",
      "lastModified": "2023-10-08T11:37:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "math",
        "en",
        "dataset:gsm8k",
        "dataset:competition_math",
        "arxiv:2309.17452",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4684,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 14,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "gsm8k",
          "competition_math"
        ],
        "language": [
          "en"
        ],
        "metrics": [
          "exact_match"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "code",
          "math"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "typesdigital/llm-agents-tora-70b-v1.0",
        "illesc/llm-agents-tora-70b-v1.0",
        "Orami01/llm-agents-tora-70b-v1.0",
        "markIA23/llm-agents-tora-70b-v1.0"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652af9c13a416e1f21a6296b",
    "id": "TheBloke/SauerkrautLM-7B-v1-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "de",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/SauerkrautLM-7B-v1-GGUF",
    "model": {
      "_id": "652af9c13a416e1f21a6296b",
      "id": "TheBloke/SauerkrautLM-7B-v1-GGUF",
      "modelId": "TheBloke/SauerkrautLM-7B-v1-GGUF",
      "author": "TheBloke",
      "sha": "5fdfb9e54142127e22f6873c68c3c2d2acee29e0",
      "lastModified": "2023-10-14T20:35:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "de",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "VAGOsolutions/SauerkrautLM-7b-v1",
        "inference": false,
        "language": [
          "de",
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "VAGO solutions",
        "model_name": "SauerkrautLM 7B v1",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Ein Chat zwischen einem Benutzer und einem KI-Assistenten. Der KI-Assistent gibt hilfreiche, detaillierte und hfliche Antworten. \nUser: {prompt} \nAssistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1.Q2_K.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1.Q3_K_L.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1.Q3_K_M.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1.Q3_K_S.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1.Q4_0.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1.Q4_K_M.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1.Q4_K_S.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1.Q5_0.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1.Q5_K_M.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1.Q5_K_S.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1.Q6_K.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65271f2006a53a9b8cd93cf0",
      "id": "VAGOsolutions/SauerkrautLM-7b-v1",
      "modelId": "VAGOsolutions/SauerkrautLM-7b-v1",
      "author": "VAGOsolutions",
      "sha": "68744c6653413e4b5e9962220215dd5341309da5",
      "lastModified": "2023-10-25T13:14:32.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "de",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 67,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "de",
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "images/Average.PNG"
        },
        {
          "rfilename": "images/FirstTurn.PNG"
        },
        {
          "rfilename": "images/SauerkrautLM-7b-v1.png"
        },
        {
          "rfilename": "images/SauerkrautLM-7b.png"
        },
        {
          "rfilename": "images/SauerkrautLM.png"
        },
        {
          "rfilename": "images/SecondTurn.PNG"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652b01aca2d97e682b3369b0",
    "id": "TheBloke/SauerkrautLM-3B-v1-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "de",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/SauerkrautLM-3B-v1-GGUF",
    "model": {
      "_id": "652b01aca2d97e682b3369b0",
      "id": "TheBloke/SauerkrautLM-3B-v1-GGUF",
      "modelId": "TheBloke/SauerkrautLM-3B-v1-GGUF",
      "author": "TheBloke",
      "sha": "87d0b0319088219f398de8c500b3f92945b7a02c",
      "lastModified": "2023-10-14T22:03:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "de",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "VAGOsolutions/SauerkrautLM-3b-v1",
        "inference": false,
        "language": [
          "de",
          "en"
        ],
        "library_name": "transformers",
        "license": "other",
        "model_creator": "VAGO solutions",
        "model_name": "SauerkrautLM 3B v1",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "Ein Chat zwischen einem Benutzer und einem KI-Assistenten. Der KI-Assistent gibt hilfreiche, detaillierte und hfliche Antworten. \nUser: {prompt} \nAssistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "sauerkrautlm-3b-v1.Q4_0.gguf"
        },
        {
          "rfilename": "sauerkrautlm-3b-v1.Q4_1.gguf"
        },
        {
          "rfilename": "sauerkrautlm-3b-v1.Q5_0.gguf"
        },
        {
          "rfilename": "sauerkrautlm-3b-v1.Q5_1.gguf"
        },
        {
          "rfilename": "sauerkrautlm-3b-v1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6526fb5cf2e4714361ce0ece",
      "id": "VAGOsolutions/SauerkrautLM-3b-v1",
      "modelId": "VAGOsolutions/SauerkrautLM-3b-v1",
      "author": "VAGOsolutions",
      "sha": "42e44a91f7f297a09a1c0daed11eb2ae92149c3e",
      "lastModified": "2023-10-25T13:14:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "de",
        "en",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 90,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0",
        "language": [
          "de",
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "images/Average.PNG"
        },
        {
          "rfilename": "images/FirstTurn.PNG"
        },
        {
          "rfilename": "images/SauerkrautLM-3b-v1.png"
        },
        {
          "rfilename": "images/SauerkrautLM-3b.png"
        },
        {
          "rfilename": "images/SauerkrautLM.png"
        },
        {
          "rfilename": "images/SecondTurn.PNG"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652b10be4d8e7e7646ef41fb",
    "id": "TheBloke/SauerkrautLM-7B-v1-mistral-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 14,
    "tags": [
      "transformers",
      "mistral",
      "text-generation",
      "de",
      "en",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/SauerkrautLM-7B-v1-mistral-GGUF",
    "model": {
      "_id": "652b10be4d8e7e7646ef41fb",
      "id": "TheBloke/SauerkrautLM-7B-v1-mistral-GGUF",
      "modelId": "TheBloke/SauerkrautLM-7B-v1-mistral-GGUF",
      "author": "TheBloke",
      "sha": "9c603703e4245fd01570ec38f552819532b860fa",
      "lastModified": "2023-10-14T22:14:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "text-generation",
        "de",
        "en",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 14,
      "library_name": "transformers",
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "VAGOsolutions/SauerkrautLM-7b-v1-mistral",
        "inference": false,
        "language": [
          "de",
          "en"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "VAGO solutions",
        "model_name": "SauerkrautLM 7B v1 Mistral",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "Ein Chat zwischen einem Benutzer und einem KI-Assistenten. Der KI-Assistent gibt hilfreiche, detaillierte und hfliche Antworten. \nUser: {prompt} \nAssistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1-mistral.Q2_K.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1-mistral.Q3_K_L.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1-mistral.Q3_K_M.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1-mistral.Q3_K_S.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1-mistral.Q4_0.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1-mistral.Q4_K_M.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1-mistral.Q4_K_S.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1-mistral.Q5_0.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1-mistral.Q5_K_M.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1-mistral.Q5_K_S.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1-mistral.Q6_K.gguf"
        },
        {
          "rfilename": "sauerkrautlm-7b-v1-mistral.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65271a1ff311a45262d7ef79",
      "id": "VAGOsolutions/SauerkrautLM-7b-v1-mistral",
      "modelId": "VAGOsolutions/SauerkrautLM-7b-v1-mistral",
      "author": "VAGOsolutions",
      "sha": "380372794aa51d6e077cfe2018503bb44a952c09",
      "lastModified": "2023-10-25T13:15:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "de",
        "en",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 87,
      "library_name": "transformers",
      "likes": 13,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "language": [
          "de",
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "images/Average.PNG"
        },
        {
          "rfilename": "images/FirstTurn.PNG"
        },
        {
          "rfilename": "images/SauerkrautLM-7b-mistral.png"
        },
        {
          "rfilename": "images/SauerkrautLM-7b-v1-mistral.png"
        },
        {
          "rfilename": "images/SauerkrautLM.png"
        },
        {
          "rfilename": "images/SecondTurn.PNG"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652b1c662ecb5062d6afed59",
    "id": "TheBloke/genz-13B-v2-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 9,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/genz-13B-v2-GGUF",
    "model": {
      "_id": "652b1c662ecb5062d6afed59",
      "id": "TheBloke/genz-13B-v2-GGUF",
      "modelId": "TheBloke/genz-13B-v2-GGUF",
      "author": "TheBloke",
      "sha": "d40f3b67d23237564582f173d38ae5de9062e733",
      "lastModified": "2023-10-14T23:10:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "budecosystem/genz-13b-v2",
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "Bud",
        "model_name": "GenZ 13B v2",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### User:\n{prompt}\n\n### Assistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "genz-13b-v2.Q2_K.gguf"
        },
        {
          "rfilename": "genz-13b-v2.Q3_K_L.gguf"
        },
        {
          "rfilename": "genz-13b-v2.Q3_K_M.gguf"
        },
        {
          "rfilename": "genz-13b-v2.Q3_K_S.gguf"
        },
        {
          "rfilename": "genz-13b-v2.Q4_0.gguf"
        },
        {
          "rfilename": "genz-13b-v2.Q4_K_M.gguf"
        },
        {
          "rfilename": "genz-13b-v2.Q4_K_S.gguf"
        },
        {
          "rfilename": "genz-13b-v2.Q5_0.gguf"
        },
        {
          "rfilename": "genz-13b-v2.Q5_K_M.gguf"
        },
        {
          "rfilename": "genz-13b-v2.Q5_K_S.gguf"
        },
        {
          "rfilename": "genz-13b-v2.Q6_K.gguf"
        },
        {
          "rfilename": "genz-13b-v2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64c0b1b96cf8e2b9f047fa74",
      "id": "budecosystem/genz-13b-v2",
      "modelId": "budecosystem/genz-13b-v2",
      "author": "budecosystem",
      "sha": "98e0e2086df11b9f80e1571110540a657e52c2e8",
      "lastModified": "2023-07-28T14:51:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4798,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652b24531aeebac333e1a57a",
    "id": "TheBloke/tora-7B-v1.0-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "code",
      "math",
      "text-generation",
      "en",
      "dataset:gsm8k",
      "dataset:competition_math",
      "arxiv:2309.17452",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/tora-7B-v1.0-GGUF",
    "model": {
      "_id": "652b24531aeebac333e1a57a",
      "id": "TheBloke/tora-7B-v1.0-GGUF",
      "modelId": "TheBloke/tora-7B-v1.0-GGUF",
      "author": "TheBloke",
      "sha": "b815ecd946d1fabfb6d044e35985846c82ea6866",
      "lastModified": "2023-10-14T23:33:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "code",
        "math",
        "text-generation",
        "en",
        "dataset:gsm8k",
        "dataset:competition_math",
        "arxiv:2309.17452",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "llm-agents/tora-7b-v1.0",
        "datasets": [
          "gsm8k",
          "competition_math"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "metrics": [
          "exact_match"
        ],
        "model_creator": "LLM-Agents",
        "model_name": "ToRA 7B v1.0",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|user|>\n{prompt}\n<|assistant|>\n",
        "quantized_by": "TheBloke",
        "tags": [
          "code",
          "math"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tora-7b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "tora-7b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "tora-7b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "tora-7b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "tora-7b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "tora-7b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "tora-7b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "tora-7b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "tora-7b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "tora-7b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "tora-7b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "tora-7b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65223ad7fe5881ad35d8b134",
      "id": "llm-agents/tora-7b-v1.0",
      "modelId": "llm-agents/tora-7b-v1.0",
      "author": "llm-agents",
      "sha": "717edbee98945192b1a396fc9c337c5b32d6c79c",
      "lastModified": "2023-10-08T11:22:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "math",
        "en",
        "dataset:gsm8k",
        "dataset:competition_math",
        "arxiv:2309.17452",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4799,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "gsm8k",
          "competition_math"
        ],
        "language": [
          "en"
        ],
        "metrics": [
          "exact_match"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "code",
          "math"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "nep-0/llm-agents-tora-7b-v1.0"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652b26dc7c5365f2d10e875a",
    "id": "TheBloke/Mistral-11B-CC-Air-RP-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 12,
    "tags": [
      "transformers",
      "mistral",
      "not-for-all-audiences",
      "nsfw",
      "pretrained",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mistral-11B-CC-Air-RP-GGUF",
    "model": {
      "_id": "652b26dc7c5365f2d10e875a",
      "id": "TheBloke/Mistral-11B-CC-Air-RP-GGUF",
      "modelId": "TheBloke/Mistral-11B-CC-Air-RP-GGUF",
      "author": "TheBloke",
      "sha": "de1725a02fab1d38aef58395ecd73872daff69bb",
      "lastModified": "2023-10-14T23:52:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "not-for-all-audiences",
        "nsfw",
        "pretrained",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 12,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "Undi95/Mistral-11B-CC-Air-RP",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Mistral 11B CC Air RP",
        "model_type": "mistral",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw",
          "mistral",
          "pretrained"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-11b-cc-air-rp.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-11b-cc-air-rp.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-11b-cc-air-rp.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-11b-cc-air-rp.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-11b-cc-air-rp.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-11b-cc-air-rp.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-11b-cc-air-rp.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-11b-cc-air-rp.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-11b-cc-air-rp.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-11b-cc-air-rp.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-11b-cc-air-rp.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-11b-cc-air-rp.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65243e2c73a0f19d06f57990",
      "id": "Undi95/Mistral-11B-CC-Air-RP",
      "modelId": "Undi95/Mistral-11B-CC-Air-RP",
      "author": "Undi95",
      "sha": "24b274bcea84a13d013cd24d69cc37c9c29b02cf",
      "lastModified": "2023-10-09T18:37:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "pretrained",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3136,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw",
          "mistral",
          "pretrained"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652b293bd50c9382fb3d4f95",
    "id": "TheBloke/tora-code-13B-v1.0-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 530,
    "tags": [
      "transformers",
      "llama",
      "code",
      "math",
      "text-generation",
      "en",
      "dataset:gsm8k",
      "dataset:competition_math",
      "arxiv:2309.17452",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/tora-code-13B-v1.0-GGUF",
    "model": {
      "_id": "652b293bd50c9382fb3d4f95",
      "id": "TheBloke/tora-code-13B-v1.0-GGUF",
      "modelId": "TheBloke/tora-code-13B-v1.0-GGUF",
      "author": "TheBloke",
      "sha": "089f2599afb9b59545e45a0e09325694bc7fc2f0",
      "lastModified": "2023-10-14T23:56:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "code",
        "math",
        "text-generation",
        "en",
        "dataset:gsm8k",
        "dataset:competition_math",
        "arxiv:2309.17452",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 530,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "llm-agents/tora-code-13b-v1.0",
        "datasets": [
          "gsm8k",
          "competition_math"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "metrics": [
          "exact_match"
        ],
        "model_creator": "LLM-Agents",
        "model_name": "ToRA Code 13B v1.0",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|user|>\n{prompt}\n<|assistant|>\n",
        "quantized_by": "TheBloke",
        "tags": [
          "code",
          "math"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tora-code-13b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "tora-code-13b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "tora-code-13b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "tora-code-13b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "tora-code-13b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "tora-code-13b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "tora-code-13b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "tora-code-13b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "tora-code-13b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "tora-code-13b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "tora-code-13b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "tora-code-13b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65223c3a8fc4884992dc111c",
      "id": "llm-agents/tora-code-13b-v1.0",
      "modelId": "llm-agents/tora-code-13b-v1.0",
      "author": "llm-agents",
      "sha": "4bf5b528d95a507b435c24a8986afe80d5951782",
      "lastModified": "2023-10-08T11:23:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "math",
        "en",
        "dataset:gsm8k",
        "dataset:competition_math",
        "arxiv:2309.17452",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4780,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "gsm8k",
          "competition_math"
        ],
        "language": [
          "en"
        ],
        "metrics": [
          "exact_match"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "code",
          "math"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652b32901198736f3101e6a2",
    "id": "TheBloke/tora-code-34b-v1.0-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "code",
      "math",
      "text-generation",
      "en",
      "dataset:gsm8k",
      "dataset:competition_math",
      "arxiv:2309.17452",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/tora-code-34b-v1.0-GGUF",
    "model": {
      "_id": "652b32901198736f3101e6a2",
      "id": "TheBloke/tora-code-34b-v1.0-GGUF",
      "modelId": "TheBloke/tora-code-34b-v1.0-GGUF",
      "author": "TheBloke",
      "sha": "65d188ac5f4636870458039d46a5eee568633d9e",
      "lastModified": "2023-10-15T00:43:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "code",
        "math",
        "text-generation",
        "en",
        "dataset:gsm8k",
        "dataset:competition_math",
        "arxiv:2309.17452",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "llm-agents/tora-code-34b-v1.0",
        "datasets": [
          "gsm8k",
          "competition_math"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "metrics": [
          "exact_match"
        ],
        "model_creator": "LLM-Agents",
        "model_name": "ToRA Code 34B v1.0",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|user|>\n{prompt}\n<|assistant|>\n",
        "quantized_by": "TheBloke",
        "tags": [
          "code",
          "math"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tora-code-34b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "tora-code-34b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "tora-code-34b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "tora-code-34b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "tora-code-34b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "tora-code-34b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "tora-code-34b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "tora-code-34b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "tora-code-34b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "tora-code-34b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "tora-code-34b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "tora-code-34b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65223f42b903b175b0d2e843",
      "id": "llm-agents/tora-code-34b-v1.0",
      "modelId": "llm-agents/tora-code-34b-v1.0",
      "author": "llm-agents",
      "sha": "cbb33eea774cc03d4363c424d81e8c9d58332274",
      "lastModified": "2023-10-08T11:23:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "math",
        "en",
        "dataset:gsm8k",
        "dataset:competition_math",
        "arxiv:2309.17452",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4760,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "gsm8k",
          "competition_math"
        ],
        "language": [
          "en"
        ],
        "metrics": [
          "exact_match"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "code",
          "math"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "markIA23/llm-agents-tora-code-34b-v1.0"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652b383fc3cba555d5506c84",
    "id": "TheBloke/Xwin-LM-13B-v0.2-GGUF",
    "likes": 12,
    "private": false,
    "downloads": 25,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Xwin-LM-13B-v0.2-GGUF",
    "model": {
      "_id": "652b383fc3cba555d5506c84",
      "id": "TheBloke/Xwin-LM-13B-v0.2-GGUF",
      "modelId": "TheBloke/Xwin-LM-13B-v0.2-GGUF",
      "author": "TheBloke",
      "sha": "2d376fc7853dbd6bc90c32fab0a6e61d099e79bb",
      "lastModified": "2023-10-15T01:10:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 25,
      "library_name": "transformers",
      "likes": 12,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Xwin-LM/Xwin-LM-13B-V0.2",
        "inference": false,
        "license": "llama2",
        "model_creator": "Xwin-LM",
        "model_name": "Xwin LM 13B v0.2",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "xwin-lm-13b-v0.2.Q2_K.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.2.Q4_0.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.2.Q5_0.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.2.Q6_K.gguf"
        },
        {
          "rfilename": "xwin-lm-13b-v0.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6528d29bad4a7ea3a53093a2",
      "id": "Xwin-LM/Xwin-LM-13B-V0.2",
      "modelId": "Xwin-LM/Xwin-LM-13B-V0.2",
      "author": "Xwin-LM",
      "sha": "d47e7d909ae09247875f4fa1ec64ce140a50bb5c",
      "lastModified": "2023-10-13T05:36:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 530,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 24,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "GLiAD/Xwin-LM-Xwin-LM-13B-V0.2",
        "rus78/Xwin-LM-Xwin-LM-70B-V0.1"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652b4865f0e232695dcb2b7f",
    "id": "TheBloke/tora-code-7B-v1.0-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "code",
      "math",
      "text-generation",
      "en",
      "dataset:gsm8k",
      "dataset:competition_math",
      "arxiv:2309.17452",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/tora-code-7B-v1.0-GGUF",
    "model": {
      "_id": "652b4865f0e232695dcb2b7f",
      "id": "TheBloke/tora-code-7B-v1.0-GGUF",
      "modelId": "TheBloke/tora-code-7B-v1.0-GGUF",
      "author": "TheBloke",
      "sha": "54fd1c30eb7a97eac3f9322662ac7c40a9ced752",
      "lastModified": "2023-10-15T02:07:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "code",
        "math",
        "text-generation",
        "en",
        "dataset:gsm8k",
        "dataset:competition_math",
        "arxiv:2309.17452",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "llm-agents/tora-code-7b-v1.0",
        "datasets": [
          "gsm8k",
          "competition_math"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "metrics": [
          "exact_match"
        ],
        "model_creator": "LLM-Agents",
        "model_name": "ToRA Code 7B v1.0",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|user|>\n{prompt}\n<|assistant|>\n",
        "quantized_by": "TheBloke",
        "tags": [
          "code",
          "math"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "tora-code-7b-v1.0.Q2_K.gguf"
        },
        {
          "rfilename": "tora-code-7b-v1.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "tora-code-7b-v1.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "tora-code-7b-v1.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "tora-code-7b-v1.0.Q4_0.gguf"
        },
        {
          "rfilename": "tora-code-7b-v1.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "tora-code-7b-v1.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "tora-code-7b-v1.0.Q5_0.gguf"
        },
        {
          "rfilename": "tora-code-7b-v1.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "tora-code-7b-v1.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "tora-code-7b-v1.0.Q6_K.gguf"
        },
        {
          "rfilename": "tora-code-7b-v1.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652239830f935fa8fd48e0e9",
      "id": "llm-agents/tora-code-7b-v1.0",
      "modelId": "llm-agents/tora-code-7b-v1.0",
      "author": "llm-agents",
      "sha": "777501b69bb0ba2675abdcaf7b1309ab05320c2e",
      "lastModified": "2023-10-08T11:24:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "math",
        "en",
        "dataset:gsm8k",
        "dataset:competition_math",
        "arxiv:2309.17452",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4857,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "gsm8k",
          "competition_math"
        ],
        "language": [
          "en"
        ],
        "metrics": [
          "exact_match"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "code",
          "math"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652b4f30789d84df6f13c904",
    "id": "TheBloke/StellarBright-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "stellar-bright",
      "llama-2",
      "llama-2-chat",
      "70b",
      "text-generation",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/StellarBright-GGUF",
    "model": {
      "_id": "652b4f30789d84df6f13c904",
      "id": "TheBloke/StellarBright-GGUF",
      "modelId": "TheBloke/StellarBright-GGUF",
      "author": "TheBloke",
      "sha": "fa19c153f4b88dcae5af5c27dce631171821e143",
      "lastModified": "2023-10-15T23:48:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "stellar-bright",
        "llama-2",
        "llama-2-chat",
        "70b",
        "text-generation",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "sequelbox/StellarBright",
        "inference": false,
        "language": [
          "en"
        ],
        "license": "llama2",
        "model_creator": "scott",
        "model_name": "StellarBright",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke",
        "tags": [
          "stellar-bright",
          "llama",
          "llama-2",
          "llama-2-chat",
          "70b"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "stellarbright.Q2_K.gguf"
        },
        {
          "rfilename": "stellarbright.Q3_K_L.gguf"
        },
        {
          "rfilename": "stellarbright.Q3_K_M.gguf"
        },
        {
          "rfilename": "stellarbright.Q3_K_S.gguf"
        },
        {
          "rfilename": "stellarbright.Q4_0.gguf"
        },
        {
          "rfilename": "stellarbright.Q4_K_M.gguf"
        },
        {
          "rfilename": "stellarbright.Q4_K_S.gguf"
        },
        {
          "rfilename": "stellarbright.Q5_0.gguf"
        },
        {
          "rfilename": "stellarbright.Q5_K_M.gguf"
        },
        {
          "rfilename": "stellarbright.Q5_K_S.gguf"
        },
        {
          "rfilename": "stellarbright.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "stellarbright.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "stellarbright.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "stellarbright.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "652451fe8c2691925dd416e2",
      "id": "sequelbox/StellarBright",
      "modelId": "sequelbox/StellarBright",
      "author": "sequelbox",
      "sha": "7568e1ca8829780df41bdaa7fbb9b4c061e3b569",
      "lastModified": "2023-10-16T23:19:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "stellar-bright",
        "llama-2",
        "llama-2-chat",
        "70b",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3916,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 22,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation",
        "tags": [
          "stellar-bright",
          "llama",
          "llama-2",
          "llama-2-chat",
          "70b"
        ],
        "model_type": "llama",
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "Fr0NiX/sequelbox-StellarBright",
        "Sugam7/sequelbox-StellarBright"
      ],
      "safetensors": {
        "parameters": {
          "F32": 69238792192
        },
        "total": 69238792192
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00030.safetensors"
        },
        {
          "rfilename": "model-00002-of-00030.safetensors"
        },
        {
          "rfilename": "model-00003-of-00030.safetensors"
        },
        {
          "rfilename": "model-00004-of-00030.safetensors"
        },
        {
          "rfilename": "model-00005-of-00030.safetensors"
        },
        {
          "rfilename": "model-00006-of-00030.safetensors"
        },
        {
          "rfilename": "model-00007-of-00030.safetensors"
        },
        {
          "rfilename": "model-00008-of-00030.safetensors"
        },
        {
          "rfilename": "model-00009-of-00030.safetensors"
        },
        {
          "rfilename": "model-00010-of-00030.safetensors"
        },
        {
          "rfilename": "model-00011-of-00030.safetensors"
        },
        {
          "rfilename": "model-00012-of-00030.safetensors"
        },
        {
          "rfilename": "model-00013-of-00030.safetensors"
        },
        {
          "rfilename": "model-00014-of-00030.safetensors"
        },
        {
          "rfilename": "model-00015-of-00030.safetensors"
        },
        {
          "rfilename": "model-00016-of-00030.safetensors"
        },
        {
          "rfilename": "model-00017-of-00030.safetensors"
        },
        {
          "rfilename": "model-00018-of-00030.safetensors"
        },
        {
          "rfilename": "model-00019-of-00030.safetensors"
        },
        {
          "rfilename": "model-00020-of-00030.safetensors"
        },
        {
          "rfilename": "model-00021-of-00030.safetensors"
        },
        {
          "rfilename": "model-00022-of-00030.safetensors"
        },
        {
          "rfilename": "model-00023-of-00030.safetensors"
        },
        {
          "rfilename": "model-00024-of-00030.safetensors"
        },
        {
          "rfilename": "model-00025-of-00030.safetensors"
        },
        {
          "rfilename": "model-00026-of-00030.safetensors"
        },
        {
          "rfilename": "model-00027-of-00030.safetensors"
        },
        {
          "rfilename": "model-00028-of-00030.safetensors"
        },
        {
          "rfilename": "model-00029-of-00030.safetensors"
        },
        {
          "rfilename": "model-00030-of-00030.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652babcaff2202020eae716d",
    "id": "TheBloke/Xwin-MLewd-13B-v0.2-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 92,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Xwin-MLewd-13B-v0.2-GGUF",
    "model": {
      "_id": "652babcaff2202020eae716d",
      "id": "TheBloke/Xwin-MLewd-13B-v0.2-GGUF",
      "modelId": "TheBloke/Xwin-MLewd-13B-v0.2-GGUF",
      "author": "TheBloke",
      "sha": "e814ae3f6d20f8b7ed6a97531b525c84d8207bcf",
      "lastModified": "2023-10-16T10:51:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 92,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/Xwin-MLewd-13B-V0.2",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Xwin MLewd 13B v0.2",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "xwin-mlewd-13b-v0.2.Q2_K.gguf"
        },
        {
          "rfilename": "xwin-mlewd-13b-v0.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "xwin-mlewd-13b-v0.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "xwin-mlewd-13b-v0.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "xwin-mlewd-13b-v0.2.Q4_0.gguf"
        },
        {
          "rfilename": "xwin-mlewd-13b-v0.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "xwin-mlewd-13b-v0.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "xwin-mlewd-13b-v0.2.Q5_0.gguf"
        },
        {
          "rfilename": "xwin-mlewd-13b-v0.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "xwin-mlewd-13b-v0.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "xwin-mlewd-13b-v0.2.Q6_K.gguf"
        },
        {
          "rfilename": "xwin-mlewd-13b-v0.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652b050c5aec376f550e2244",
      "id": "Undi95/Xwin-MLewd-13B-V0.2",
      "modelId": "Undi95/Xwin-MLewd-13B-V0.2",
      "author": "Undi95",
      "sha": "5a6496a5084caaa856a12d80ce77786328227a02",
      "lastModified": "2023-10-15T17:25:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 895,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 23,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652bc0b24267f8c8026984e1",
    "id": "TheBloke/airoboros-l2-13B-3.1-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 10,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-3.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/airoboros-l2-13B-3.1-GGUF",
    "model": {
      "_id": "652bc0b24267f8c8026984e1",
      "id": "TheBloke/airoboros-l2-13B-3.1-GGUF",
      "modelId": "TheBloke/airoboros-l2-13B-3.1-GGUF",
      "author": "TheBloke",
      "sha": "7d15bbab1dee66d4a78db2da66738d9a79407a98",
      "lastModified": "2023-10-15T10:51:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-3.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 10,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "jondurbin/airoboros-l2-13b-3.1",
        "datasets": [
          "jondurbin/airoboros-3.1"
        ],
        "inference": false,
        "license": "llama2",
        "model_creator": "Jon Durbin",
        "model_name": "Airoboros L2 13B 3.1",
        "model_type": "llama",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n{prompt}[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    }
  },
  {
    "_id": "652bcb1d60e7067305b08469",
    "id": "TheBloke/LongAlpaca-70B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "arxiv:2309.12307",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/LongAlpaca-70B-GGUF",
    "model": {
      "_id": "652bcb1d60e7067305b08469",
      "id": "TheBloke/LongAlpaca-70B-GGUF",
      "modelId": "TheBloke/LongAlpaca-70B-GGUF",
      "author": "TheBloke",
      "sha": "05047ec1a5e227a681fd98e136ad6dd27bcb9886",
      "lastModified": "2023-10-15T12:13:27.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "arxiv:2309.12307",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Yukang/LongAlpaca-70B",
        "inference": false,
        "license": "llama2",
        "model_creator": "YukangChen",
        "model_name": "LongAlpaca 70B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "longalpaca-70b.Q2_K.gguf"
        },
        {
          "rfilename": "longalpaca-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "longalpaca-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "longalpaca-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "longalpaca-70b.Q4_0.gguf"
        },
        {
          "rfilename": "longalpaca-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "longalpaca-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "longalpaca-70b.Q5_0.gguf"
        },
        {
          "rfilename": "longalpaca-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "longalpaca-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "longalpaca-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "longalpaca-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "longalpaca-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "longalpaca-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "65236b3095df08170c8f18df",
      "id": "Yukang/LongAlpaca-70B",
      "modelId": "Yukang/LongAlpaca-70B",
      "author": "Yukang",
      "sha": "255c0e2f6794da70ac5df661d1650144f0872287",
      "lastModified": "2023-10-14T07:37:26.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "llama",
        "text-generation",
        "arxiv:2309.12307",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 217,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 68976664576,
          "F32": 5120
        },
        "total": 68976669696
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00015.safetensors"
        },
        {
          "rfilename": "model-00002-of-00015.safetensors"
        },
        {
          "rfilename": "model-00003-of-00015.safetensors"
        },
        {
          "rfilename": "model-00004-of-00015.safetensors"
        },
        {
          "rfilename": "model-00005-of-00015.safetensors"
        },
        {
          "rfilename": "model-00006-of-00015.safetensors"
        },
        {
          "rfilename": "model-00007-of-00015.safetensors"
        },
        {
          "rfilename": "model-00008-of-00015.safetensors"
        },
        {
          "rfilename": "model-00009-of-00015.safetensors"
        },
        {
          "rfilename": "model-00010-of-00015.safetensors"
        },
        {
          "rfilename": "model-00011-of-00015.safetensors"
        },
        {
          "rfilename": "model-00012-of-00015.safetensors"
        },
        {
          "rfilename": "model-00013-of-00015.safetensors"
        },
        {
          "rfilename": "model-00014-of-00015.safetensors"
        },
        {
          "rfilename": "model-00015-of-00015.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652c2082880d145ed5888cf6",
    "id": "TheBloke/SynthIA-7B-v1.5-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "mistral",
      "text-generation",
      "en",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/SynthIA-7B-v1.5-GGUF",
    "model": {
      "_id": "652c2082880d145ed5888cf6",
      "id": "TheBloke/SynthIA-7B-v1.5-GGUF",
      "modelId": "TheBloke/SynthIA-7B-v1.5-GGUF",
      "author": "TheBloke",
      "sha": "eac2f8e5efc6d88df9ab73ccae827ecd07042b38",
      "lastModified": "2023-10-15T17:33:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "text-generation",
        "en",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "migtissera/SynthIA-7B-v1.5",
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "Migel Tissera",
        "model_name": "SynthIA 7B v1.5",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "SYSTEM: Elaborate on the topic using a Tree of Thoughts and backtrack when necessary to construct a clear, cohesive Chain of Thought reasoning. Always answer without hesitation.\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-7b-v1.5.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.5.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.5.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.5.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.5.Q4_0.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.5.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.5.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.5.Q5_0.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.5.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.5.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.5.Q6_K.gguf"
        },
        {
          "rfilename": "synthia-7b-v1.5.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6521e6c28fc4884992d2fcce",
      "id": "migtissera/SynthIA-7B-v1.5",
      "modelId": "migtissera/SynthIA-7B-v1.5",
      "author": "migtissera",
      "sha": "5a9912ef90a0efc1aaea327e5cf3e9554c8bd897",
      "lastModified": "2023-10-15T23:38:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "en",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 41,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "pipeline_tag": "text-generation",
        "language": [
          "en"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652c2b7dc59e682042f530dc",
    "id": "TheBloke/Airoboros-M-7B-3.1-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 98,
    "tags": [
      "transformers",
      "mistral",
      "dataset:jondurbin/airoboros-3.1",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us",
      "has_space"
    ],
    "modelId": "TheBloke/Airoboros-M-7B-3.1-GGUF",
    "model": {
      "_id": "652c2b7dc59e682042f530dc",
      "id": "TheBloke/Airoboros-M-7B-3.1-GGUF",
      "modelId": "TheBloke/Airoboros-M-7B-3.1-GGUF",
      "author": "TheBloke",
      "sha": "9f82272582c19462b2106a935eebf92b20f12e07",
      "lastModified": "2023-10-15T18:20:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "dataset:jondurbin/airoboros-3.1",
        "license:apache-2.0",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 98,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "jondurbin/airoboros-m-7b-3.1",
        "datasets": [
          "jondurbin/airoboros-3.1"
        ],
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Jon Durbin",
        "model_name": "Airoboros M 7B 3.1",
        "model_type": "mistral",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n{prompt}[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "johnwick123forevr/WizardLM7b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    }
  },
  {
    "_id": "652c5b64ec10d7e48109c91e",
    "id": "TheBloke/Mistral-11B-OmniMix-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 26,
    "tags": [
      "transformers",
      "mistral",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mistral-11B-OmniMix-GGUF",
    "model": {
      "_id": "652c5b64ec10d7e48109c91e",
      "id": "TheBloke/Mistral-11B-OmniMix-GGUF",
      "modelId": "TheBloke/Mistral-11B-OmniMix-GGUF",
      "author": "TheBloke",
      "sha": "9215f86c79d2e0c6839f63f538e5253a114bd0af",
      "lastModified": "2023-10-15T21:58:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 26,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "NeverSleep/Mistral-11B-OmniMix-bf16",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "NeverSleep",
        "model_name": "Mistral 11B OmniMix",
        "model_type": "mistral",
        "prompt_template": "<|system|>\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\n<|user|>\n{prompt}\n<|assistant|>\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-11b-omnimix-bf16.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-11b-omnimix-bf16.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-11b-omnimix-bf16.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-11b-omnimix-bf16.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-11b-omnimix-bf16.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-11b-omnimix-bf16.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-11b-omnimix-bf16.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-11b-omnimix-bf16.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-11b-omnimix-bf16.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-11b-omnimix-bf16.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-11b-omnimix-bf16.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-11b-omnimix-bf16.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65281fbe95f8b172d1f11685",
      "id": "NeverSleep/Mistral-11B-OmniMix-bf16",
      "modelId": "NeverSleep/Mistral-11B-OmniMix-bf16",
      "author": "NeverSleep",
      "sha": "c94a8da13fd299d5db8fdf9b61ced1b761b838f5",
      "lastModified": "2023-10-15T21:56:40.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 448,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "BF16": 10731524096
        },
        "total": 10731524096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652c7c6b703b3743c278341d",
    "id": "TheBloke/ShiningValiant-1.2-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 7,
    "tags": [
      "transformers",
      "llama",
      "shining-valiant",
      "valiant",
      "valiant-labs",
      "llama-2",
      "llama-2-chat",
      "70b",
      "text-generation",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/ShiningValiant-1.2-GGUF",
    "model": {
      "_id": "652c7c6b703b3743c278341d",
      "id": "TheBloke/ShiningValiant-1.2-GGUF",
      "modelId": "TheBloke/ShiningValiant-1.2-GGUF",
      "author": "TheBloke",
      "sha": "56006a6b5639f661a4daa580f6a4c9ddfa50c053",
      "lastModified": "2023-10-16T00:44:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "shining-valiant",
        "valiant",
        "valiant-labs",
        "llama-2",
        "llama-2-chat",
        "70b",
        "text-generation",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "ValiantLabs/ShiningValiant",
        "inference": false,
        "language": [
          "en"
        ],
        "license": "llama2",
        "model_creator": "Valiant Labs",
        "model_name": "ShiningValiant 1.2",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n{prompt}[/INST]\n",
        "quantized_by": "TheBloke",
        "tags": [
          "shining-valiant",
          "valiant",
          "valiant-labs",
          "llama",
          "llama-2",
          "llama-2-chat",
          "70b"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "shiningvaliant-1.2.Q2_K.gguf"
        },
        {
          "rfilename": "shiningvaliant-1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "shiningvaliant-1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "shiningvaliant-1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "shiningvaliant-1.2.Q4_0.gguf"
        },
        {
          "rfilename": "shiningvaliant-1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "shiningvaliant-1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "shiningvaliant-1.2.Q5_0.gguf"
        },
        {
          "rfilename": "shiningvaliant-1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "shiningvaliant-1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "shiningvaliant-1.2.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "shiningvaliant-1.2.Q6_K.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "64f0cc5687d05e74035d64b7",
      "id": "ValiantLabs/ShiningValiant",
      "modelId": "ValiantLabs/ShiningValiant",
      "author": "ValiantLabs",
      "sha": "8785cf2d1d401b55e310f37c127142601bdb4811",
      "lastModified": "2023-10-28T21:25:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "shining-valiant",
        "valiant",
        "valiant-labs",
        "llama-2",
        "llama-2-chat",
        "70b",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6261,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 47,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "pipeline_tag": "text-generation",
        "tags": [
          "shining-valiant",
          "valiant",
          "valiant-labs",
          "llama",
          "llama-2",
          "llama-2-chat",
          "70b"
        ],
        "model_type": "llama",
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "swagtaco/swagtaco",
        "Facemaker/ValiantLabs-ShiningValiant",
        "Harshithtd/ValiantLabs-ShiningValiant",
        "dspfac/ValiantLabs-ShiningValiant",
        "KendoKumdo/ValiantLabs-ShiningValiant",
        "jdscharf/ValiantLabs-ShiningValiant",
        "KingArf/ValiantLabs-ShiningValiant",
        "nolotus/ValiantLabs-ShiningValiant",
        "cybermerlo/ValiantLabs-ShiningValiant",
        "Maxineat/ValiantLabs-ShiningValiant",
        "dackdel/ValiantLabs-ShiningValiant",
        "ziedammak/ValiantLabs-ShiningValiant",
        "acbdkk/stablebelugaaivsfalcon180b",
        "LLMDezNutz/ValiantLabs-ShiningValiant",
        "Mrollie16/ValiantLabs-ShiningValiant",
        "Badger751/ValiantLabs-ShiningValiant",
        "bhandsab/ValiantLabs-ShiningValiant",
        "FiVStR/ValiantLabs-ShiningValiant",
        "toorhamza/ValiantLabs-ShiningValiant",
        "pminervini/tmp"
      ],
      "safetensors": {
        "parameters": {
          "F32": 69238792192
        },
        "total": 69238792192
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00030.safetensors"
        },
        {
          "rfilename": "model-00002-of-00030.safetensors"
        },
        {
          "rfilename": "model-00003-of-00030.safetensors"
        },
        {
          "rfilename": "model-00004-of-00030.safetensors"
        },
        {
          "rfilename": "model-00005-of-00030.safetensors"
        },
        {
          "rfilename": "model-00006-of-00030.safetensors"
        },
        {
          "rfilename": "model-00007-of-00030.safetensors"
        },
        {
          "rfilename": "model-00008-of-00030.safetensors"
        },
        {
          "rfilename": "model-00009-of-00030.safetensors"
        },
        {
          "rfilename": "model-00010-of-00030.safetensors"
        },
        {
          "rfilename": "model-00011-of-00030.safetensors"
        },
        {
          "rfilename": "model-00012-of-00030.safetensors"
        },
        {
          "rfilename": "model-00013-of-00030.safetensors"
        },
        {
          "rfilename": "model-00014-of-00030.safetensors"
        },
        {
          "rfilename": "model-00015-of-00030.safetensors"
        },
        {
          "rfilename": "model-00016-of-00030.safetensors"
        },
        {
          "rfilename": "model-00017-of-00030.safetensors"
        },
        {
          "rfilename": "model-00018-of-00030.safetensors"
        },
        {
          "rfilename": "model-00019-of-00030.safetensors"
        },
        {
          "rfilename": "model-00020-of-00030.safetensors"
        },
        {
          "rfilename": "model-00021-of-00030.safetensors"
        },
        {
          "rfilename": "model-00022-of-00030.safetensors"
        },
        {
          "rfilename": "model-00023-of-00030.safetensors"
        },
        {
          "rfilename": "model-00024-of-00030.safetensors"
        },
        {
          "rfilename": "model-00025-of-00030.safetensors"
        },
        {
          "rfilename": "model-00026-of-00030.safetensors"
        },
        {
          "rfilename": "model-00027-of-00030.safetensors"
        },
        {
          "rfilename": "model-00028-of-00030.safetensors"
        },
        {
          "rfilename": "model-00029-of-00030.safetensors"
        },
        {
          "rfilename": "model-00030-of-00030.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652cfc2ac3cba555d587674a",
    "id": "TheBloke/openbuddy-mistral-7B-v13-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 16,
    "tags": [
      "transformers",
      "mistral",
      "text-generation",
      "zh",
      "en",
      "fr",
      "de",
      "ja",
      "ko",
      "it",
      "ru",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us",
      "has_space"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/openbuddy-mistral-7B-v13-GGUF",
    "model": {
      "_id": "652cfc2ac3cba555d587674a",
      "id": "TheBloke/openbuddy-mistral-7B-v13-GGUF",
      "modelId": "TheBloke/openbuddy-mistral-7B-v13-GGUF",
      "author": "TheBloke",
      "sha": "b316926dc7cc737edf7af769755fc80b4d5c8d08",
      "lastModified": "2023-10-16T09:06:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:apache-2.0",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 16,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "OpenBuddy/openbuddy-mistral-7b-v13",
        "inference": false,
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "OpenBuddy",
        "model_name": "Openbuddy Mistral 7B v13",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "You are a helpful, respectful and honest INTP-T AI Assistant named Buddy. You are talking to a human User.\nAlways answer as helpfully and logically as possible, while being safe. Your answers should not include any harmful, political, religious, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\nYou like to use emojis. You can speak fluently in many languages, for example: English, Chinese.\nYou cannot access the internet, but you have vast knowledge, cutoff: 2021-09.\nYou are trained by OpenBuddy team, (https://openbuddy.ai, https://github.com/OpenBuddy/OpenBuddy), you are based on LLaMA and Falcon transformers model, not related to GPT or OpenAI.\n\nUser: {prompt}\nAssistant: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "Cran-May/SEA-solo"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.Q2_K.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.Q3_K_L.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.Q3_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.Q3_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.Q4_0.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.Q4_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.Q4_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.Q5_0.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.Q5_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.Q5_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.Q6_K.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6524f3a066ebe051987757ef",
      "id": "OpenBuddy/openbuddy-mistral-7b-v13",
      "modelId": "OpenBuddy/openbuddy-mistral-7b-v13",
      "author": "OpenBuddy",
      "sha": "0b9355dfbc325fc7f15e8b83b8eb749306773062",
      "lastModified": "2023-10-11T15:54:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5187,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "library_name": "transformers",
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Evaluation.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652d0beda4ab23d7efddf975",
    "id": "TheBloke/openbuddy-llama2-70B-v13-base-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 17,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "zh",
      "en",
      "fr",
      "de",
      "ja",
      "ko",
      "it",
      "ru",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/openbuddy-llama2-70B-v13-base-GGUF",
    "model": {
      "_id": "652d0beda4ab23d7efddf975",
      "id": "TheBloke/openbuddy-llama2-70B-v13-base-GGUF",
      "modelId": "TheBloke/openbuddy-llama2-70B-v13-base-GGUF",
      "author": "TheBloke",
      "sha": "f22dbec64d36e61616abdb3e4abe9a6f6c503166",
      "lastModified": "2023-10-16T10:36:23.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 17,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "OpenBuddy/openbuddy-llama2-70b-v13-base",
        "inference": false,
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "license_link": "https://ai.meta.com/llama/license/",
        "license_name": "llama2",
        "model_creator": "OpenBuddy",
        "model_name": "OpenBuddy Llama2 70B v13 Base",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q2_K.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q3_K_L.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q3_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q3_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q4_0.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q4_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q4_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q5_0.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q5_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q5_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "openbuddy-llama2-70b-v13-base.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "652bf8ae72280df42649ada5",
      "id": "OpenBuddy/openbuddy-llama2-70b-v13-base",
      "modelId": "OpenBuddy/openbuddy-llama2-70b-v13-base",
      "author": "OpenBuddy",
      "sha": "3b06ebf2bd280a58b09736476178b92b1d9e01b1",
      "lastModified": "2023-10-22T16:23:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 11,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "library_name": "transformers",
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Evaluation.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652d3986e24524c69d2874fe",
    "id": "TheBloke/openbuddy-mistral-7B-v13-base-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "mistral",
      "text-generation",
      "zh",
      "en",
      "fr",
      "de",
      "ja",
      "ko",
      "it",
      "ru",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/openbuddy-mistral-7B-v13-base-GGUF",
    "model": {
      "_id": "652d3986e24524c69d2874fe",
      "id": "TheBloke/openbuddy-mistral-7B-v13-base-GGUF",
      "modelId": "TheBloke/openbuddy-mistral-7B-v13-base-GGUF",
      "author": "TheBloke",
      "sha": "7fe20d10252324194cfdc2d12bdb124229584b32",
      "lastModified": "2023-10-16T13:28:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "OpenBuddy/openbuddy-mistral-7b-v13-base",
        "inference": false,
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "OpenBuddy",
        "model_name": "OpenBuddy Mistral 7B v13 Base",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13-base.Q2_K.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13-base.Q3_K_L.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13-base.Q3_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13-base.Q3_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13-base.Q4_0.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13-base.Q4_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13-base.Q4_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13-base.Q5_0.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13-base.Q5_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13-base.Q5_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13-base.Q6_K.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13-base.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65264710d5a67051c66b6928",
      "id": "OpenBuddy/openbuddy-mistral-7b-v13-base",
      "modelId": "OpenBuddy/openbuddy-mistral-7b-v13-base",
      "author": "OpenBuddy",
      "sha": "3df4788fbd4c1192edcecf9d7fbaea6e76a41da9",
      "lastModified": "2023-10-22T04:14:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5128,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "library_name": "transformers",
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Evaluation.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652d4a0b6a41c1d38e284adf",
    "id": "TheBloke/Airoboros-L2-70B-3.1-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-3.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-70B-3.1-GGUF",
    "model": {
      "_id": "652d4a0b6a41c1d38e284adf",
      "id": "TheBloke/Airoboros-L2-70B-3.1-GGUF",
      "modelId": "TheBloke/Airoboros-L2-70B-3.1-GGUF",
      "author": "TheBloke",
      "sha": "ec7999a9baf75f2a8d314b3e1f33efea7b689ed1",
      "lastModified": "2023-10-16T14:59:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-3.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "jondurbin/airoboros-l2-70b-3.1",
        "datasets": [
          "jondurbin/airoboros-3.1"
        ],
        "inference": false,
        "license": "llama2",
        "model_creator": "Jon Durbin",
        "model_name": "Airoboros L2 70B 3.1",
        "model_type": "llama",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, unbiased, uncensored assistant.\n<</SYS>>\n\n{prompt} [/INST] \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    }
  },
  {
    "_id": "652d776b5a4c91c68639299e",
    "id": "TheBloke/Leo-Mistral-Hessianai-7B-Chat-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 15,
    "tags": [
      "transformers",
      "mistral",
      "text-generation",
      "en",
      "de",
      "dataset:LeoLM/OpenSchnabeltier",
      "dataset:OpenAssistant/OASST-DE",
      "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
      "dataset:FreedomIntelligence/evol-instruct-deutsch",
      "dataset:LeoLM/German_Poems",
      "dataset:LeoLM/German_Songs",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Leo-Mistral-Hessianai-7B-Chat-GGUF",
    "model": {
      "_id": "652d776b5a4c91c68639299e",
      "id": "TheBloke/Leo-Mistral-Hessianai-7B-Chat-GGUF",
      "modelId": "TheBloke/Leo-Mistral-Hessianai-7B-Chat-GGUF",
      "author": "TheBloke",
      "sha": "2b6dfd04ea05231f24f36b135f3c8fbfe0f70233",
      "lastModified": "2023-10-16T20:18:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "text-generation",
        "en",
        "de",
        "dataset:LeoLM/OpenSchnabeltier",
        "dataset:OpenAssistant/OASST-DE",
        "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
        "dataset:FreedomIntelligence/evol-instruct-deutsch",
        "dataset:LeoLM/German_Poems",
        "dataset:LeoLM/German_Songs",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "LeoLM/leo-mistral-hessianai-7b-chat",
        "datasets": [
          "LeoLM/OpenSchnabeltier",
          "OpenAssistant/OASST-DE",
          "FreedomIntelligence/alpaca-gpt4-deutsch",
          "FreedomIntelligence/evol-instruct-deutsch",
          "LeoLM/German_Poems",
          "LeoLM/German_Songs"
        ],
        "inference": false,
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "LAION LeoLM",
        "model_name": "Leo Mistral Hessianai 7B Chat",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "leo-mistral-hessianai-7b-chat.Q2_K.gguf"
        },
        {
          "rfilename": "leo-mistral-hessianai-7b-chat.Q3_K_L.gguf"
        },
        {
          "rfilename": "leo-mistral-hessianai-7b-chat.Q3_K_M.gguf"
        },
        {
          "rfilename": "leo-mistral-hessianai-7b-chat.Q3_K_S.gguf"
        },
        {
          "rfilename": "leo-mistral-hessianai-7b-chat.Q4_0.gguf"
        },
        {
          "rfilename": "leo-mistral-hessianai-7b-chat.Q4_K_M.gguf"
        },
        {
          "rfilename": "leo-mistral-hessianai-7b-chat.Q4_K_S.gguf"
        },
        {
          "rfilename": "leo-mistral-hessianai-7b-chat.Q5_0.gguf"
        },
        {
          "rfilename": "leo-mistral-hessianai-7b-chat.Q5_K_M.gguf"
        },
        {
          "rfilename": "leo-mistral-hessianai-7b-chat.Q5_K_S.gguf"
        },
        {
          "rfilename": "leo-mistral-hessianai-7b-chat.Q6_K.gguf"
        },
        {
          "rfilename": "leo-mistral-hessianai-7b-chat.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65201555eab153738f09adbe",
      "id": "LeoLM/leo-mistral-hessianai-7b-chat",
      "modelId": "LeoLM/leo-mistral-hessianai-7b-chat",
      "author": "LeoLM",
      "sha": "76d4ae5fdc15a49d45867fed1a1990e6d232bc21",
      "lastModified": "2023-10-11T11:13:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "en",
        "de",
        "dataset:LeoLM/OpenSchnabeltier",
        "dataset:OpenAssistant/OASST-DE",
        "dataset:FreedomIntelligence/alpaca-gpt4-deutsch",
        "dataset:FreedomIntelligence/evol-instruct-deutsch",
        "dataset:LeoLM/German_Poems",
        "dataset:LeoLM/German_Songs",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 604,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "datasets": [
          "LeoLM/OpenSchnabeltier",
          "OpenAssistant/OASST-DE",
          "FreedomIntelligence/alpaca-gpt4-deutsch",
          "FreedomIntelligence/evol-instruct-deutsch",
          "LeoLM/German_Poems",
          "LeoLM/German_Songs"
        ],
        "language": [
          "en",
          "de"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "xelosz/LeoLM-leo-mistral-hessianai-7b-chat"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652e49b1a3da41257d70f9e5",
    "id": "TheBloke/Mistral-7B-Code-16K-qlora-GGUF",
    "likes": 14,
    "private": false,
    "downloads": 30,
    "tags": [
      "transformers",
      "mistral",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mistral-7B-Code-16K-qlora-GGUF",
    "model": {
      "_id": "652e49b1a3da41257d70f9e5",
      "id": "TheBloke/Mistral-7B-Code-16K-qlora-GGUF",
      "modelId": "TheBloke/Mistral-7B-Code-16K-qlora-GGUF",
      "author": "TheBloke",
      "sha": "3ccf45419fbb35c8c3bee0341fd3793cfd1be9c3",
      "lastModified": "2023-10-17T08:52:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 30,
      "library_name": "transformers",
      "likes": 14,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "Nondzu/Mistral-7B-code-16k-qlora",
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Kamil",
        "model_name": "Mistral 7B Code 16K qLoRA",
        "model_type": "mistral",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-7b-code-16k-qlora.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-7b-code-16k-qlora.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-7b-code-16k-qlora.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-code-16k-qlora.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-code-16k-qlora.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-7b-code-16k-qlora.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-code-16k-qlora.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-code-16k-qlora.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-7b-code-16k-qlora.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-code-16k-qlora.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-code-16k-qlora.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-7b-code-16k-qlora.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652d54795362a0d572f4d514",
      "id": "Nondzu/Mistral-7B-code-16k-qlora",
      "modelId": "Nondzu/Mistral-7B-code-16k-qlora",
      "author": "Nondzu",
      "sha": "3506487b8326a08c305a67cb0b5fa4fc8c68a488",
      "lastModified": "2023-10-30T12:45:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "mistral",
        "text-generation",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 126,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 13,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652e51c239b7a1b6c85e229f",
    "id": "TheBloke/Airoboros-M-7B-3.1.1-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "mistral",
      "dataset:jondurbin/airoboros-3.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-M-7B-3.1.1-GGUF",
    "model": {
      "_id": "652e51c239b7a1b6c85e229f",
      "id": "TheBloke/Airoboros-M-7B-3.1.1-GGUF",
      "modelId": "TheBloke/Airoboros-M-7B-3.1.1-GGUF",
      "author": "TheBloke",
      "sha": "4c8be6b07651d4056fb8bb45b5a5e4b24cdaf91e",
      "lastModified": "2023-10-17T09:26:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "dataset:jondurbin/airoboros-3.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "jondurbin/airoboros-m-7b-3.1.1",
        "datasets": [
          "jondurbin/airoboros-3.1"
        ],
        "inference": false,
        "license": "llama2",
        "model_creator": "Jon Durbin",
        "model_name": "Airoboros M 7B 3.1.1",
        "model_type": "mistral",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, unbiased, uncensored assistant.\n<</SYS>>\n\n{prompt} [/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    }
  },
  {
    "_id": "652e9c6267acb68b9f94ef46",
    "id": "TheBloke/Pandalyst-7B-v1.2-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 8,
    "tags": [
      "transformers",
      "llama",
      "code",
      "en",
      "license:llama2",
      "model-index",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Pandalyst-7B-v1.2-GGUF",
    "model": {
      "_id": "652e9c6267acb68b9f94ef46",
      "id": "TheBloke/Pandalyst-7B-v1.2-GGUF",
      "modelId": "TheBloke/Pandalyst-7B-v1.2-GGUF",
      "author": "TheBloke",
      "sha": "791dcd3ac4d385b413a9d830961eb2c01d8492b8",
      "lastModified": "2023-10-17T14:43:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "code",
        "en",
        "license:llama2",
        "model-index",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "likes": 1,
      "model-index": [
        {
          "name": "Pandalyst-7B-V1.2",
          "results": [
            {
              "metrics": [
                {
                  "name": "acc@1",
                  "type": "acc@1",
                  "value": 0,
                  "verified": false
                }
              ],
              "task": {
                "type": "text-generation"
              }
            }
          ]
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "pipizhao/Pandalyst-7B-V1.2",
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model-index": [
          {
            "name": "Pandalyst-7B-V1.2",
            "results": [
              {
                "metrics": [
                  {
                    "name": "acc@1",
                    "type": "acc@1",
                    "value": 0,
                    "verified": false
                  }
                ],
                "task": {
                  "type": "text-generation"
                }
              }
            ]
          }
        ],
        "model_creator": "pipizhao",
        "model_name": "Pandalyst 7B v1.2",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "code"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pandalyst-7b-v1.2.Q2_K.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.2.Q4_0.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.2.Q5_0.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.2.Q6_K.gguf"
        },
        {
          "rfilename": "pandalyst-7b-v1.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652a40352ecb5062d698e6ad",
      "id": "pipizhao/Pandalyst-7B-V1.2",
      "modelId": "pipizhao/Pandalyst-7B-V1.2",
      "author": "pipizhao",
      "sha": "7165a809effafd65692dc97daacbaac9271335ee",
      "lastModified": "2023-10-15T08:06:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "en",
        "license:llama2",
        "model-index",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 110,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": [
        {
          "name": "Pandalyst-7B-V1.2",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "metrics": [
                {
                  "name": "acc@1",
                  "type": "acc@1",
                  "value": 0,
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "library_name": "transformers",
        "tags": [
          "code"
        ],
        "model-index": [
          {
            "name": "Pandalyst-7B-V1.2",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "metrics": [
                  {
                    "name": "acc@1",
                    "type": "acc@1",
                    "value": 0,
                    "verified": false
                  }
                ]
              }
            ]
          }
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652ec008a0f516a99dde2ef0",
    "id": "TheBloke/Thespis-13B-v0.3-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Thespis-13B-v0.3-GGUF",
    "model": {
      "_id": "652ec008a0f516a99dde2ef0",
      "id": "TheBloke/Thespis-13B-v0.3-GGUF",
      "modelId": "TheBloke/Thespis-13B-v0.3-GGUF",
      "author": "TheBloke",
      "sha": "1959d09b9432c8f001083e6673a0ae4e5df2af8c",
      "lastModified": "2023-10-17T17:18:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "cgato/Thespis-13b-v0.3",
        "inference": false,
        "license": "llama2",
        "model_creator": "c.gato",
        "model_name": "Thespis 13B v0.3",
        "model_type": "llama",
        "prompt_template": "{system_message}\n\nUsername: {prompt}\nBotName: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "thespis-13b-v0.3.Q2_K.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.3.Q3_K_L.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.3.Q3_K_M.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.3.Q3_K_S.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.3.Q4_0.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.3.Q4_K_M.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.3.Q4_K_S.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.3.Q5_0.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.3.Q5_K_M.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.3.Q5_K_S.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.3.Q6_K.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.3.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652e8f176504631c10dbe569",
      "id": "cgato/Thespis-13b-v0.3",
      "modelId": "cgato/Thespis-13b-v0.3",
      "author": "cgato",
      "sha": "e4fae9ebf5812294ae518135e5d8c84fb7756e56",
      "lastModified": "2023-10-23T02:34:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652ee61057a8ba396c6b369e",
    "id": "TheBloke/Mistral-7B-Phibrarian-32K-GGUF",
    "likes": 11,
    "private": false,
    "downloads": 15,
    "tags": [
      "transformers",
      "mistral",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mistral-7B-Phibrarian-32K-GGUF",
    "model": {
      "_id": "652ee61057a8ba396c6b369e",
      "id": "TheBloke/Mistral-7B-Phibrarian-32K-GGUF",
      "modelId": "TheBloke/Mistral-7B-Phibrarian-32K-GGUF",
      "author": "TheBloke",
      "sha": "5eb59a801d98932f3958c66b881ec33eddfb4445",
      "lastModified": "2023-10-17T20:37:32.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15,
      "library_name": "transformers",
      "likes": 11,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "emrgnt-cmplxty/Mistral-7b-Phibrarian-32k",
        "inference": false,
        "license": "llama2",
        "model_creator": "Owen Colegrove",
        "model_name": "Mistral 7B Phibrarian 32K",
        "model_type": "mistral",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-7b-phibrarian-32k.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-7b-phibrarian-32k.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-7b-phibrarian-32k.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-phibrarian-32k.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-phibrarian-32k.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-7b-phibrarian-32k.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-phibrarian-32k.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-phibrarian-32k.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-7b-phibrarian-32k.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-phibrarian-32k.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-phibrarian-32k.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-7b-phibrarian-32k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652d6bc3b62cf1f846285167",
      "id": "SciPhi/SciPhi-Mistral-7B-32k",
      "modelId": "SciPhi/SciPhi-Mistral-7B-32k",
      "author": "SciPhi",
      "sha": "8abed8a547b7c60bb29edc87da4423cef67acea5",
      "lastModified": "2023-10-31T21:44:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 683,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 43,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "mit"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652ee6a717d03c316f67823a",
    "id": "TheBloke/llemma_7b-GGUF",
    "likes": 13,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "math",
      "reasoning",
      "en",
      "dataset:EleutherAI/proof-pile-2",
      "arxiv:2310.10631",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/llemma_7b-GGUF",
    "model": {
      "_id": "652ee6a717d03c316f67823a",
      "id": "TheBloke/llemma_7b-GGUF",
      "modelId": "TheBloke/llemma_7b-GGUF",
      "author": "TheBloke",
      "sha": "12b1771c1a72bfae25428f7b6bb36dc39b7197a1",
      "lastModified": "2023-10-17T20:11:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "math",
        "reasoning",
        "en",
        "dataset:EleutherAI/proof-pile-2",
        "arxiv:2310.10631",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "likes": 13,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "EleutherAI/llemma_7b",
        "datasets": [
          "EleutherAI/proof-pile-2"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "llama2",
        "model_creator": "EleutherAI",
        "model_name": "Llemma 7B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke",
        "tags": [
          "math",
          "reasoning"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llemma_7b.Q2_K.gguf"
        },
        {
          "rfilename": "llemma_7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llemma_7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llemma_7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llemma_7b.Q4_0.gguf"
        },
        {
          "rfilename": "llemma_7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llemma_7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llemma_7b.Q5_0.gguf"
        },
        {
          "rfilename": "llemma_7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llemma_7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llemma_7b.Q6_K.gguf"
        },
        {
          "rfilename": "llemma_7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6500e19d85a884a964d35c0e",
      "id": "EleutherAI/llemma_7b",
      "modelId": "EleutherAI/llemma_7b",
      "author": "EleutherAI",
      "sha": "acc26c54609e9f18bf31fc5d58b5b533239e0430",
      "lastModified": "2023-10-17T23:41:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "math",
        "reasoning",
        "en",
        "dataset:EleutherAI/proof-pile-2",
        "dataset:open-web-math/open-web-math",
        "arxiv:2310.10631",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2871,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 43,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "EleutherAI/proof-pile-2",
          "open-web-math/open-web-math"
        ],
        "language": [
          "en"
        ],
        "tags": [
          "math",
          "reasoning"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "bhaon/EleutherAI-llemma_7b",
        "LuckyTheBest/EleutherAI-llemma_7b",
        "abdelaty/EleutherAI-llemma_7b",
        "usercdp/EleutherAI-llemma_7b",
        "deepbrain/EleutherAI-llemma_7b",
        "arkorerk/EleutherAI-llemma_7b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "llemma.png"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652efc607b0079ff035f95c6",
    "id": "TheBloke/llemma_34b-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 6,
    "tags": [
      "transformers",
      "llama",
      "math",
      "reasoning",
      "en",
      "dataset:EleutherAI/proof-pile-2",
      "arxiv:2310.10631",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/llemma_34b-GGUF",
    "model": {
      "_id": "652efc607b0079ff035f95c6",
      "id": "TheBloke/llemma_34b-GGUF",
      "modelId": "TheBloke/llemma_34b-GGUF",
      "author": "TheBloke",
      "sha": "b52b0d42068f458eb15074673cdca61d942d0d61",
      "lastModified": "2023-10-17T21:41:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "math",
        "reasoning",
        "en",
        "dataset:EleutherAI/proof-pile-2",
        "arxiv:2310.10631",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "EleutherAI/llemma_34b",
        "datasets": [
          "EleutherAI/proof-pile-2"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "llama2",
        "model_creator": "EleutherAI",
        "model_name": "Llemma 34B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke",
        "tags": [
          "math",
          "reasoning"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llemma_34b.Q2_K.gguf"
        },
        {
          "rfilename": "llemma_34b.Q3_K_L.gguf"
        },
        {
          "rfilename": "llemma_34b.Q3_K_M.gguf"
        },
        {
          "rfilename": "llemma_34b.Q3_K_S.gguf"
        },
        {
          "rfilename": "llemma_34b.Q4_0.gguf"
        },
        {
          "rfilename": "llemma_34b.Q4_K_M.gguf"
        },
        {
          "rfilename": "llemma_34b.Q4_K_S.gguf"
        },
        {
          "rfilename": "llemma_34b.Q5_0.gguf"
        },
        {
          "rfilename": "llemma_34b.Q5_K_M.gguf"
        },
        {
          "rfilename": "llemma_34b.Q5_K_S.gguf"
        },
        {
          "rfilename": "llemma_34b.Q6_K.gguf"
        },
        {
          "rfilename": "llemma_34b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6513b47c0d463b73dc09cc85",
      "id": "EleutherAI/llemma_34b",
      "modelId": "EleutherAI/llemma_34b",
      "author": "EleutherAI",
      "sha": "08634a81f7bc7343f94d1c82fae461ad9b03e233",
      "lastModified": "2023-10-17T23:42:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "math",
        "reasoning",
        "en",
        "dataset:EleutherAI/proof-pile-2",
        "dataset:open-web-math/open-web-math",
        "arxiv:2310.10631",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5675,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 44,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "EleutherAI/proof-pile-2",
          "open-web-math/open-web-math"
        ],
        "language": [
          "en"
        ],
        "tags": [
          "math",
          "reasoning"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "brightswitch/EleutherAI-llemma_34b",
        "pdehaye/EleutherAI-llemma_34b",
        "mhovd/LLEMMA34B",
        "Soleup/EleutherAI-llemma_34b",
        "algorithm6174/EleutherAI-llemma_34b",
        "CHLOzzz/EleutherAI-llemma_34b",
        "R0KG/EleutherAI-llemma_34b",
        "hxllvh/EleutherAI-llemma_34b",
        "MagnusHedegaard/EleutherAI-llemma_34b",
        "FreddieSpaghetti/EleutherAI-llemma_34b",
        "arkorerk/EleutherAI-llemma_34b",
        "mzlam/EleutherAI-llemma_34b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "llemma.png"
        },
        {
          "rfilename": "pytorch_model-00001-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00014.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652f9882329f988fe2f5150a",
    "id": "TheBloke/Dans-AdventurousWinds-Mk2-7B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "mistral",
      "en",
      "dataset:PocketDoc/Floyd-Text-Adventures",
      "dataset:PocketDoc/Choose-Your-Story-Long-Text-Adventures",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Dans-AdventurousWinds-Mk2-7B-GGUF",
    "model": {
      "_id": "652f9882329f988fe2f5150a",
      "id": "TheBloke/Dans-AdventurousWinds-Mk2-7B-GGUF",
      "modelId": "TheBloke/Dans-AdventurousWinds-Mk2-7B-GGUF",
      "author": "TheBloke",
      "sha": "2375eca0908a02ac68a707394aa8ad8080c6072c",
      "lastModified": "2023-10-18T08:40:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "en",
        "dataset:PocketDoc/Floyd-Text-Adventures",
        "dataset:PocketDoc/Choose-Your-Story-Long-Text-Adventures",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "PocketDoc/Dans-AdventurousWinds-Mk2-7b",
        "datasets": [
          "PocketDoc/Floyd-Text-Adventures",
          "PocketDoc/Choose-Your-Story-Long-Text-Adventures"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "model_creator": "PocketDoc Labs",
        "model_name": "Dans AdventurousWinds Mk2 7B",
        "model_type": "mistral",
        "prompt_template": "[Genres: Science Fiction]\n[Tags: humor, old school, sci fi]\n[Mode: Adventure]\n[Description: A puzzle about committing acts of financial skulduggery and exploiting ridiculous magical items.]\n[Misc: Writing era: 1993]\n[Intro]\nIt is the year 2045. You are a young man in his twenties living in New York City. Your father was an inventor who died when you were very small; your mother raised you alone for many years until she remarried. Now you live with your stepfather, but he doesn't care much for you and has never given you any money to help support yourself. You have no job and little hope of getting one because of your lack of experience. However, you do have some unusual abilities that could be put to good use if only you knew how...\n\n> {prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "dans-adventurouswinds-mk2-7b.Q2_K.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-mk2-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-mk2-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-mk2-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-mk2-7b.Q4_0.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-mk2-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-mk2-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-mk2-7b.Q5_0.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-mk2-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-mk2-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-mk2-7b.Q6_K.gguf"
        },
        {
          "rfilename": "dans-adventurouswinds-mk2-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652b9cef0ab8936887a84684",
      "id": "PocketDoc/Dans-AdventurousWinds-Mk2-7b",
      "modelId": "PocketDoc/Dans-AdventurousWinds-Mk2-7b",
      "author": "PocketDoc",
      "sha": "cfcc969a7e97275b2298253f1eabf4575e5a3768",
      "lastModified": "2023-10-18T22:25:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "en",
        "dataset:PocketDoc/Floyd-Text-Adventures",
        "dataset:PocketDoc/Choose-Your-Story-Long-Text-Adventures",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 13,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "language": [
          "en"
        ],
        "datasets": [
          "PocketDoc/Floyd-Text-Adventures",
          "PocketDoc/Choose-Your-Story-Long-Text-Adventures"
        ],
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652fa3cb5d91b1c2959392b6",
    "id": "TheBloke/Euryale-1.3-L2-70B-GGUF",
    "likes": 5,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Euryale-1.3-L2-70B-GGUF",
    "model": {
      "_id": "652fa3cb5d91b1c2959392b6",
      "id": "TheBloke/Euryale-1.3-L2-70B-GGUF",
      "modelId": "TheBloke/Euryale-1.3-L2-70B-GGUF",
      "author": "TheBloke",
      "sha": "57053c40d75515efc56f9ff374006f9b08702296",
      "lastModified": "2023-10-18T09:45:31.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 5,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Sao10K/Euryale-1.3-L2-70B",
        "inference": false,
        "language": [
          "en"
        ],
        "license": "llama2",
        "model_creator": "Saofiq",
        "model_name": "Euryale 1.3 L2 70B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q2_K.gguf"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q4_0.gguf"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q5_0.gguf"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "euryale-1.3-l2-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "65249a5378ed2f9ac13e7ca7",
      "id": "Sao10K/Euryale-1.3-L2-70B",
      "modelId": "Sao10K/Euryale-1.3-L2-70B",
      "author": "Sao10K",
      "sha": "4acca01258aabad2dd46a75712f88cfcbdfcb82c",
      "lastModified": "2023-10-29T09:43:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4526,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Euryale.jpg"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652fb15c177bc5784fbac90b",
    "id": "TheBloke/rpguild-chatml-13B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "roleplay",
      "en",
      "dataset:chargoddard/rpguild",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/rpguild-chatml-13B-GGUF",
    "model": {
      "_id": "652fb15c177bc5784fbac90b",
      "id": "TheBloke/rpguild-chatml-13B-GGUF",
      "modelId": "TheBloke/rpguild-chatml-13B-GGUF",
      "author": "TheBloke",
      "sha": "bb12b04f0098f96ed636b50434d662ce440cb742",
      "lastModified": "2023-10-18T10:33:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "roleplay",
        "en",
        "dataset:chargoddard/rpguild",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "chargoddard/rpguild-chatml-13b",
        "datasets": [
          "chargoddard/rpguild"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "cc-by-nc-4.0",
        "model_creator": "Charles Goddard",
        "model_name": "RPGuild ChatML 13B",
        "model_type": "llama",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke",
        "tags": [
          "llama",
          "roleplay"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "rpguild-chatml-13b.Q2_K.gguf"
        },
        {
          "rfilename": "rpguild-chatml-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "rpguild-chatml-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "rpguild-chatml-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "rpguild-chatml-13b.Q4_0.gguf"
        },
        {
          "rfilename": "rpguild-chatml-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "rpguild-chatml-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "rpguild-chatml-13b.Q5_0.gguf"
        },
        {
          "rfilename": "rpguild-chatml-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "rpguild-chatml-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "rpguild-chatml-13b.Q6_K.gguf"
        },
        {
          "rfilename": "rpguild-chatml-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652f1f66d8fadff4ced9354c",
      "id": "chargoddard/rpguild-chatml-13b",
      "modelId": "chargoddard/rpguild-chatml-13b",
      "author": "chargoddard",
      "sha": "4567dbff84ede6d399b5e1e421e222b325c1ec9e",
      "lastModified": "2023-10-18T00:41:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "roleplay",
        "en",
        "dataset:chargoddard/rpguild",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "chargoddard/rpguild"
        ],
        "language": [
          "en"
        ],
        "tags": [
          "llama",
          "roleplay"
        ],
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652fd0dfb49135da7663513b",
    "id": "TheBloke/Airoboros-L2-13B-3.1.1-GGUF",
    "likes": 8,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-3.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-13B-3.1.1-GGUF",
    "model": {
      "_id": "652fd0dfb49135da7663513b",
      "id": "TheBloke/Airoboros-L2-13B-3.1.1-GGUF",
      "modelId": "TheBloke/Airoboros-L2-13B-3.1.1-GGUF",
      "author": "TheBloke",
      "sha": "c259c828399e87192928cc59634beee8da68fe3b",
      "lastModified": "2023-10-18T12:45:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-3.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "jondurbin/airoboros-l2-13b-3.1.1",
        "datasets": [
          "jondurbin/airoboros-3.1"
        ],
        "inference": false,
        "license": "llama2",
        "model_creator": "Jon Durbin",
        "model_name": "Airoboros L2 13B 3.1.1",
        "model_type": "llama",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, unbiased, uncensored assistant.\n<</SYS>>\n\n{prompt} [/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.1.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.1.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.1.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.1.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-13b-3.1.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "652ece39f75d9cc2a4c104fd",
      "id": "jondurbin/airoboros-l2-13b-3.1.1",
      "modelId": "jondurbin/airoboros-l2-13b-3.1.1",
      "author": "jondurbin",
      "sha": "343fe4247dec5d20c63552e3803d457f27bca6c9",
      "lastModified": "2023-10-22T11:44:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-3.1",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 61,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-3.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "BF16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "model-00001-of-00007.safetensors"
        },
        {
          "rfilename": "model-00002-of-00007.safetensors"
        },
        {
          "rfilename": "model-00003-of-00007.safetensors"
        },
        {
          "rfilename": "model-00004-of-00007.safetensors"
        },
        {
          "rfilename": "model-00005-of-00007.safetensors"
        },
        {
          "rfilename": "model-00006-of-00007.safetensors"
        },
        {
          "rfilename": "model-00007-of-00007.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652fd8657fd57506a1651543",
    "id": "TheBloke/Xwin-LM-7B-V0.2-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Xwin-LM-7B-V0.2-GGUF",
    "model": {
      "_id": "652fd8657fd57506a1651543",
      "id": "TheBloke/Xwin-LM-7B-V0.2-GGUF",
      "modelId": "TheBloke/Xwin-LM-7B-V0.2-GGUF",
      "author": "TheBloke",
      "sha": "dcd15adafe433d531ed06dd1d9a4fa68924e0c96",
      "lastModified": "2023-10-18T13:12:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Xwin-LM/Xwin-LM-7B-V0.2",
        "inference": false,
        "license": "llama2",
        "model_creator": "Xwin-LM",
        "model_name": "Xwin LM 7B v0.2",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "xwin-lm-7b-v0.2.Q2_K.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.2.Q4_0.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.2.Q5_0.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.2.Q6_K.gguf"
        },
        {
          "rfilename": "xwin-lm-7b-v0.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6528d273f34dd2dc6dcc8c59",
      "id": "Xwin-LM/Xwin-LM-7B-V0.2",
      "modelId": "Xwin-LM/Xwin-LM-7B-V0.2",
      "author": "Xwin-LM",
      "sha": "6e401a3d621f91f751d4dc97be1d6289325a8306",
      "lastModified": "2023-10-13T05:36:23.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1808,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 14,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "652fea24f5d2684611762f16",
    "id": "TheBloke/PsyMedRP-v1-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 16,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/PsyMedRP-v1-13B-GGUF",
    "model": {
      "_id": "652fea24f5d2684611762f16",
      "id": "TheBloke/PsyMedRP-v1-13B-GGUF",
      "modelId": "TheBloke/PsyMedRP-v1-13B-GGUF",
      "author": "TheBloke",
      "sha": "0ac497d3dac052e13ed5a6454ffba1637d359d25",
      "lastModified": "2023-10-18T14:30:08.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 16,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/PsyMedRP-v1-13B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "PsyMedRP v1 13B",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "psymedrp-v1-13b.Q2_K.gguf"
        },
        {
          "rfilename": "psymedrp-v1-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "psymedrp-v1-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "psymedrp-v1-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "psymedrp-v1-13b.Q4_0.gguf"
        },
        {
          "rfilename": "psymedrp-v1-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "psymedrp-v1-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "psymedrp-v1-13b.Q5_0.gguf"
        },
        {
          "rfilename": "psymedrp-v1-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "psymedrp-v1-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "psymedrp-v1-13b.Q6_K.gguf"
        },
        {
          "rfilename": "psymedrp-v1-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651eeb90372c0f3dc7e9bc17",
      "id": "Undi95/PsyMedRP-v1-13B",
      "modelId": "Undi95/PsyMedRP-v1-13B",
      "author": "Undi95",
      "sha": "3a25c5c2c331cf8f4c4deddc6f9a7f265d63aa23",
      "lastModified": "2023-10-14T11:31:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 118,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653061df3b51002a47a3ee90",
    "id": "TheBloke/SlimOpenOrca-Mistral-7B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 15,
    "tags": [
      "transformers",
      "mistral",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/SlimOpenOrca-Mistral-7B-GGUF",
    "model": {
      "_id": "653061df3b51002a47a3ee90",
      "id": "TheBloke/SlimOpenOrca-Mistral-7B-GGUF",
      "modelId": "TheBloke/SlimOpenOrca-Mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "5c2d7e89ebbb26fe610d693050bd13b6ed52bd97",
      "lastModified": "2023-10-18T22:59:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "PulsarAI/SlimOpenOrca-Mistral-7B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "PulsarAI",
        "model_name": "SlimOpenOrca Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "slimopenorca-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "slimopenorca-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "slimopenorca-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "slimopenorca-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "slimopenorca-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "slimopenorca-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "slimopenorca-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "slimopenorca-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "slimopenorca-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "slimopenorca-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "slimopenorca-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "slimopenorca-mistral-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65265d1679706914d4140649",
      "id": "PulsarAI/SlimOpenOrca-Mistral-7B",
      "modelId": "PulsarAI/SlimOpenOrca-Mistral-7B",
      "author": "PulsarAI",
      "sha": "e99d9ea7013d953852156b39253b7fcfedb17427",
      "lastModified": "2023-10-25T07:30:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3907,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 15,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "MFF212/PulsarAI-SlimOpenOrca-Mistral-7B"
      ],
      "safetensors": {
        "parameters": {
          "F32": 262144000,
          "BF16": 6979588096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65310b2133d693dfd39750ce",
    "id": "TheBloke/MistralLite-7B-GGUF",
    "likes": 26,
    "private": false,
    "downloads": 47,
    "tags": [
      "transformers",
      "mistral",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us",
      "has_space"
    ],
    "modelId": "TheBloke/MistralLite-7B-GGUF",
    "model": {
      "_id": "65310b2133d693dfd39750ce",
      "id": "TheBloke/MistralLite-7B-GGUF",
      "modelId": "TheBloke/MistralLite-7B-GGUF",
      "author": "TheBloke",
      "sha": "829b2e6ec0a5fee5c514be28071cf4e438f0c071",
      "lastModified": "2023-10-19T10:58:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "license:apache-2.0",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 47,
      "library_name": "transformers",
      "likes": 26,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "amazon/MistralLite",
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Amazon Web Services",
        "model_name": "MistralLite 7B",
        "model_type": "mistral",
        "prompt_template": "<|prompter|>{prompt}</s><|assistant|>\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "seanpedrickcase/Light-PDF-Web-QA-Chatbot",
        "seanpedrickcase/open_text_summariser"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistrallite.Q2_K.gguf"
        },
        {
          "rfilename": "mistrallite.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistrallite.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistrallite.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistrallite.Q4_0.gguf"
        },
        {
          "rfilename": "mistrallite.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistrallite.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistrallite.Q5_0.gguf"
        },
        {
          "rfilename": "mistrallite.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistrallite.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistrallite.Q6_K.gguf"
        },
        {
          "rfilename": "mistrallite.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652c8a94caddc9e608253d9b",
      "id": "amazon/MistralLite",
      "modelId": "amazon/MistralLite",
      "author": "amazon",
      "sha": "4ececff5e47771677c8a900453020ea795f4b6cd",
      "lastModified": "2023-10-24T00:12:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4222,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 164,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "inference": false
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65311816b5672703b2ebdb66",
    "id": "TheBloke/Mistral-Pygmalion-7B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 11,
    "tags": [
      "transformers",
      "llama",
      "Mistral",
      "Pygmalion",
      "llama-2",
      "llama-2-7b",
      "text-generation",
      "en",
      "license:cc-by-nc-nd-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Mistral-Pygmalion-7B-GGUF",
    "model": {
      "_id": "65311816b5672703b2ebdb66",
      "id": "TheBloke/Mistral-Pygmalion-7B-GGUF",
      "modelId": "TheBloke/Mistral-Pygmalion-7B-GGUF",
      "author": "TheBloke",
      "sha": "c1dcd03b00b3c0ebbef36847c4971e85db80d84b",
      "lastModified": "2023-10-19T11:53:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "Mistral",
        "Pygmalion",
        "llama-2",
        "llama-2-7b",
        "text-generation",
        "en",
        "license:cc-by-nc-nd-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 11,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Delcos/Mistral-Pygmalion-7b",
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "cc-by-nc-nd-4.0",
        "model_creator": "Devon M",
        "model_name": "Mistral Pygmalion 7B",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "### Instruction:\n{prompt}\n### Assistant:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "Mistral",
          "Pygmalion",
          "llama-2",
          "llama-2-7b"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-pygmalion-7b.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-pygmalion-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-pygmalion-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-pygmalion-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-pygmalion-7b.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-pygmalion-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-pygmalion-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-pygmalion-7b.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-pygmalion-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-pygmalion-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-pygmalion-7b.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-pygmalion-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65247269a9a710554b17a6c9",
      "id": "Delcos/Mistral-Pygmalion-7b",
      "modelId": "Delcos/Mistral-Pygmalion-7b",
      "author": "Delcos",
      "sha": "1abd9c77daf9db4744823dc0f8fa31e94c71a101",
      "lastModified": "2023-10-19T17:43:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "Mistral",
        "Pygmalion",
        "llama-2",
        "llama-2-7b",
        "en",
        "license:cc-by-nc-nd-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5064,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-nd-4.0",
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation",
        "tags": [
          "Mistral",
          "Pygmalion",
          "llama-2",
          "llama-2-7b"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65315c50e810c9214031a121",
    "id": "TheBloke/Airoboros-M-7B-3.1.2-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "mistral",
      "dataset:jondurbin/airoboros-3.1",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-M-7B-3.1.2-GGUF",
    "model": {
      "_id": "65315c50e810c9214031a121",
      "id": "TheBloke/Airoboros-M-7B-3.1.2-GGUF",
      "modelId": "TheBloke/Airoboros-M-7B-3.1.2-GGUF",
      "author": "TheBloke",
      "sha": "3e9053f7f40201f19fd8ed5180858e49d3194f78",
      "lastModified": "2023-10-19T16:45:56.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "dataset:jondurbin/airoboros-3.1",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "jondurbin/airoboros-m-7b-3.1.2",
        "datasets": [
          "jondurbin/airoboros-3.1"
        ],
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Jon Durbin",
        "model_name": "Airoboros M 7B 3.1.2",
        "model_type": "mistral",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, unbiased, uncensored assistant.\n<</SYS>>\n\n{prompt} [/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.2.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.2.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.2.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.2.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-m-7b-3.1.2.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6531577865f1287a5b101b2f",
      "id": "jondurbin/airoboros-m-7b-3.1.2",
      "modelId": "jondurbin/airoboros-m-7b-3.1.2",
      "author": "jondurbin",
      "sha": "9b8e0c78e351ee2570098724182f6ddc35f03287",
      "lastModified": "2023-10-22T11:44:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "dataset:jondurbin/airoboros-3.1",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 355,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 21,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "datasets": [
          "jondurbin/airoboros-3.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "osl-ai/jondurbin-airoboros-m-7b-3.1.2"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00004.safetensors"
        },
        {
          "rfilename": "model-00002-of-00004.safetensors"
        },
        {
          "rfilename": "model-00003-of-00004.safetensors"
        },
        {
          "rfilename": "model-00004-of-00004.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65324859548eae0c990cb4c9",
    "id": "TheBloke/Arithmo-Mistral-7B-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "mistral",
      "Mathematical Reasoning",
      "en",
      "dataset:akjindal53244/Arithmo-Data",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Arithmo-Mistral-7B-GGUF",
    "model": {
      "_id": "65324859548eae0c990cb4c9",
      "id": "TheBloke/Arithmo-Mistral-7B-GGUF",
      "modelId": "TheBloke/Arithmo-Mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "d171bbaee7234c149b862e08e3752eaa1397cf58",
      "lastModified": "2023-10-20T13:54:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "Mathematical Reasoning",
        "en",
        "dataset:akjindal53244/Arithmo-Data",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "akjindal53244/Arithmo-Mistral-7B",
        "datasets": [
          "akjindal53244/Arithmo-Data"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "model_creator": "Ashvini Kumar Jindal",
        "model_name": "Arithmo Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "Question: {prompt}\nAnswer:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "Mathematical Reasoning"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "arithmo-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "arithmo-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "arithmo-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "arithmo-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "arithmo-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "arithmo-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "arithmo-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "arithmo-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "arithmo-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "arithmo-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "arithmo-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "arithmo-mistral-7b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "652b2abe60e7067305a1451a",
      "id": "akjindal53244/Arithmo-Mistral-7B",
      "modelId": "akjindal53244/Arithmo-Mistral-7B",
      "author": "akjindal53244",
      "sha": "2f85882b922687b9f02aa8d5ee7b1471caf1b24f",
      "lastModified": "2023-10-23T22:25:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "Mathematical Reasoning",
        "en",
        "dataset:akjindal53244/Arithmo-Data",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 439,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 42,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "language": [
          "en"
        ],
        "tags": [
          "Mathematical Reasoning"
        ],
        "datasets": [
          "akjindal53244/Arithmo-Data"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "cufff/akjindal53244-Arithmo-Mistral-7B"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6532fb6ecbf3b6035cd6ee8a",
    "id": "TheBloke/agentlm-70B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "dataset:THUDM/AgentInstruct",
      "arxiv:2310.12823",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/agentlm-70B-GGUF",
    "model": {
      "_id": "6532fb6ecbf3b6035cd6ee8a",
      "id": "TheBloke/agentlm-70B-GGUF",
      "modelId": "TheBloke/agentlm-70B-GGUF",
      "author": "TheBloke",
      "sha": "ace139dd75cf99b336b26eee990a57243b51866a",
      "lastModified": "2023-10-20T23:07:17.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:THUDM/AgentInstruct",
        "arxiv:2310.12823",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "THUDM/agentlm-70b",
        "datasets": [
          "THUDM/AgentInstruct"
        ],
        "inference": false,
        "license": "llama2",
        "model_creator": "Knowledge Engineering Group (KEG",
        "model_name": "AgentLM 70B",
        "model_type": "llama",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n<</SYS>>\n{prompt} [/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "agentlm-70b.Q2_K.gguf"
        },
        {
          "rfilename": "agentlm-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "agentlm-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "agentlm-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "agentlm-70b.Q4_0.gguf"
        },
        {
          "rfilename": "agentlm-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "agentlm-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "agentlm-70b.Q5_0.gguf"
        },
        {
          "rfilename": "agentlm-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "agentlm-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "agentlm-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "agentlm-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "agentlm-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "agentlm-70b.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6522a90f2d5eb02118cba381",
      "id": "THUDM/agentlm-70b",
      "modelId": "THUDM/agentlm-70b",
      "author": "THUDM",
      "sha": "6f6ea282d7d2d678c5ff73ef516a48295111bd54",
      "lastModified": "2023-10-20T03:27:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "dataset:THUDM/AgentInstruct",
        "arxiv:2310.12823",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 247,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 56,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "THUDM/AgentInstruct"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "PeepDaSlan9/THUDM-agentlm-70b",
        "aeonlabs/THUDM-agentlm-70b",
        "KumLee/THUDM-agentlm-70b",
        "wffcyrus/THUDM-agentlm-70b"
      ],
      "safetensors": {
        "parameters": {
          "F16": 68980842496,
          "F32": 5120
        },
        "total": 68980847616
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00015.safetensors"
        },
        {
          "rfilename": "model-00002-of-00015.safetensors"
        },
        {
          "rfilename": "model-00003-of-00015.safetensors"
        },
        {
          "rfilename": "model-00004-of-00015.safetensors"
        },
        {
          "rfilename": "model-00005-of-00015.safetensors"
        },
        {
          "rfilename": "model-00006-of-00015.safetensors"
        },
        {
          "rfilename": "model-00007-of-00015.safetensors"
        },
        {
          "rfilename": "model-00008-of-00015.safetensors"
        },
        {
          "rfilename": "model-00009-of-00015.safetensors"
        },
        {
          "rfilename": "model-00010-of-00015.safetensors"
        },
        {
          "rfilename": "model-00011-of-00015.safetensors"
        },
        {
          "rfilename": "model-00012-of-00015.safetensors"
        },
        {
          "rfilename": "model-00013-of-00015.safetensors"
        },
        {
          "rfilename": "model-00014-of-00015.safetensors"
        },
        {
          "rfilename": "model-00015-of-00015.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6532fe2bdc1c6f1ed7ce21d8",
    "id": "TheBloke/agentlm-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "dataset:THUDM/AgentInstruct",
      "arxiv:2310.12823",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/agentlm-13B-GGUF",
    "model": {
      "_id": "6532fe2bdc1c6f1ed7ce21d8",
      "id": "TheBloke/agentlm-13B-GGUF",
      "modelId": "TheBloke/agentlm-13B-GGUF",
      "author": "TheBloke",
      "sha": "75b527d0b61ab340753090d82c5bf94242c1d6ae",
      "lastModified": "2023-10-20T22:31:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:THUDM/AgentInstruct",
        "arxiv:2310.12823",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "THUDM/agentlm-13b",
        "datasets": [
          "THUDM/AgentInstruct"
        ],
        "inference": false,
        "license": "llama2",
        "model_creator": "Knowledge Engineering Group (KEG",
        "model_name": "AgentLM 13B",
        "model_type": "llama",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n<</SYS>>\n{prompt} [/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "agentlm-13b.Q2_K.gguf"
        },
        {
          "rfilename": "agentlm-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "agentlm-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "agentlm-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "agentlm-13b.Q4_0.gguf"
        },
        {
          "rfilename": "agentlm-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "agentlm-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "agentlm-13b.Q5_0.gguf"
        },
        {
          "rfilename": "agentlm-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "agentlm-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "agentlm-13b.Q6_K.gguf"
        },
        {
          "rfilename": "agentlm-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6522a5385e7247c291715ada",
      "id": "THUDM/agentlm-13b",
      "modelId": "THUDM/agentlm-13b",
      "author": "THUDM",
      "sha": "9b909f319e8c3270dd2b2c860e13ecfb68cb6627",
      "lastModified": "2023-10-20T03:27:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "dataset:THUDM/AgentInstruct",
        "arxiv:2310.12823",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 189,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 16,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "THUDM/AgentInstruct"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "PeepDaSlan9/THUDM-agentlm-13b"
      ],
      "safetensors": {
        "parameters": {
          "F32": 2560,
          "F16": 13018485760
        },
        "total": 13018488320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6532ff883e385cfc601254ad",
    "id": "TheBloke/CodeBooga-34B-v0.1-GGUF",
    "likes": 14,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/CodeBooga-34B-v0.1-GGUF",
    "model": {
      "_id": "6532ff883e385cfc601254ad",
      "id": "TheBloke/CodeBooga-34B-v0.1-GGUF",
      "modelId": "TheBloke/CodeBooga-34B-v0.1-GGUF",
      "author": "TheBloke",
      "sha": "5ed145719ffb19599c7ac80a8ca4f3cf06e177cc",
      "lastModified": "2023-10-20T23:16:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 14,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "oobabooga/CodeBooga-34B-v0.1",
        "inference": false,
        "license": "llama2",
        "model_creator": "oobabooga",
        "model_name": "CodeBooga 34B v0.1",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "codebooga-34b-v0.1.Q2_K.gguf"
        },
        {
          "rfilename": "codebooga-34b-v0.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "codebooga-34b-v0.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "codebooga-34b-v0.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "codebooga-34b-v0.1.Q4_0.gguf"
        },
        {
          "rfilename": "codebooga-34b-v0.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "codebooga-34b-v0.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "codebooga-34b-v0.1.Q5_0.gguf"
        },
        {
          "rfilename": "codebooga-34b-v0.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "codebooga-34b-v0.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "codebooga-34b-v0.1.Q6_K.gguf"
        },
        {
          "rfilename": "codebooga-34b-v0.1.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6531b5e0e7897259333a1412",
      "id": "oobabooga/CodeBooga-34B-v0.1",
      "modelId": "oobabooga/CodeBooga-34B-v0.1",
      "author": "oobabooga",
      "sha": "62fcd2e3e1b50018d0e6a865c5760a66ba2d2639",
      "lastModified": "2023-10-23T03:05:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 231,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 61,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 33743970304
        },
        "total": 33743970304
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00008.safetensors"
        },
        {
          "rfilename": "model-00002-of-00008.safetensors"
        },
        {
          "rfilename": "model-00003-of-00008.safetensors"
        },
        {
          "rfilename": "model-00004-of-00008.safetensors"
        },
        {
          "rfilename": "model-00005-of-00008.safetensors"
        },
        {
          "rfilename": "model-00006-of-00008.safetensors"
        },
        {
          "rfilename": "model-00007-of-00008.safetensors"
        },
        {
          "rfilename": "model-00008-of-00008.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6533206302d1ecd54542adb9",
    "id": "TheBloke/vicuna-33B-coder-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 4,
    "tags": [
      "transformers",
      "llama",
      "code",
      "arxiv:1910.09700",
      "license:other",
      "model-index",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/vicuna-33B-coder-GGUF",
    "model": {
      "_id": "6533206302d1ecd54542adb9",
      "id": "TheBloke/vicuna-33B-coder-GGUF",
      "modelId": "TheBloke/vicuna-33B-coder-GGUF",
      "author": "TheBloke",
      "sha": "77d2558c4a6a5bc579342b44300ec48744779afc",
      "lastModified": "2023-10-21T09:04:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "code",
        "arxiv:1910.09700",
        "license:other",
        "model-index",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "likes": 3,
      "model-index": [
        {
          "name": "Vicuna-Coder",
          "results": [
            {
              "dataset": {
                "name": "MultiPL-HumanEval (Python)",
                "type": "nuprl/MultiPL-E"
              },
              "metrics": [
                {
                  "name": "pass@1",
                  "type": "pass@1",
                  "value": 0.274,
                  "verified": false
                }
              ],
              "task": {
                "type": "text-generation"
              }
            }
          ]
        }
      ],
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "FelixChao/vicuna-33b-coder",
        "inference": false,
        "license": "other",
        "model-index": [
          {
            "name": "Vicuna-Coder",
            "results": [
              {
                "dataset": {
                  "name": "MultiPL-HumanEval (Python)",
                  "type": "nuprl/MultiPL-E"
                },
                "metrics": [
                  {
                    "name": "pass@1",
                    "type": "pass@1",
                    "value": 0.274,
                    "verified": false
                  }
                ],
                "task": {
                  "type": "text-generation"
                }
              }
            ]
          }
        ],
        "model_creator": "Chao Chang-Yu",
        "model_name": "Vicuna 33B Coder",
        "model_type": "llama",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "code"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "vicuna-33b-coder.Q2_K.gguf"
        },
        {
          "rfilename": "vicuna-33b-coder.Q3_K_L.gguf"
        },
        {
          "rfilename": "vicuna-33b-coder.Q3_K_M.gguf"
        },
        {
          "rfilename": "vicuna-33b-coder.Q3_K_S.gguf"
        },
        {
          "rfilename": "vicuna-33b-coder.Q4_0.gguf"
        },
        {
          "rfilename": "vicuna-33b-coder.Q4_K_M.gguf"
        },
        {
          "rfilename": "vicuna-33b-coder.Q4_K_S.gguf"
        },
        {
          "rfilename": "vicuna-33b-coder.Q5_0.gguf"
        },
        {
          "rfilename": "vicuna-33b-coder.Q5_K_M.gguf"
        },
        {
          "rfilename": "vicuna-33b-coder.Q5_K_S.gguf"
        },
        {
          "rfilename": "vicuna-33b-coder.Q6_K.gguf"
        },
        {
          "rfilename": "vicuna-33b-coder.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64e41a3d222b232f030060f3",
      "id": "FelixChao/vicuna-33b-coder",
      "modelId": "FelixChao/vicuna-33b-coder",
      "author": "FelixChao",
      "sha": "6a09cc937c35d342dc54fc50e9e516e44d95a49f",
      "lastModified": "2023-09-11T05:22:28.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "code",
        "arxiv:1910.09700",
        "license:apache-2.0",
        "model-index",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4740,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": [
        {
          "name": "Vicuna-Coder",
          "results": [
            {
              "task": {
                "type": "text-generation"
              },
              "dataset": {
                "type": "nuprl/MultiPL-E",
                "name": "MultiPL-HumanEval (Python)"
              },
              "metrics": [
                {
                  "type": "pass@1",
                  "value": 0.274,
                  "name": "pass@1",
                  "verified": false
                }
              ]
            }
          ]
        }
      ],
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "code"
        ],
        "license": "apache-2.0",
        "model-index": [
          {
            "name": "Vicuna-Coder",
            "results": [
              {
                "task": {
                  "type": "text-generation"
                },
                "dataset": {
                  "type": "nuprl/MultiPL-E",
                  "name": "MultiPL-HumanEval (Python)"
                },
                "metrics": [
                  {
                    "type": "pass@1",
                    "value": 0.274,
                    "name": "pass@1",
                    "verified": false
                  }
                ]
              }
            ]
          }
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653334f8d434308ba429cf30",
    "id": "TheBloke/agentlm-7B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 18,
    "tags": [
      "transformers",
      "llama",
      "dataset:THUDM/AgentInstruct",
      "arxiv:2310.12823",
      "license:llama2",
      "text-generation-inference",
      "region:us",
      "has_space"
    ],
    "modelId": "TheBloke/agentlm-7B-GGUF",
    "model": {
      "_id": "653334f8d434308ba429cf30",
      "id": "TheBloke/agentlm-7B-GGUF",
      "modelId": "TheBloke/agentlm-7B-GGUF",
      "author": "TheBloke",
      "sha": "25942747ce2ebd6248c729ae1e1734d1e84b362c",
      "lastModified": "2023-10-21T02:22:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:THUDM/AgentInstruct",
        "arxiv:2310.12823",
        "license:llama2",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 18,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "THUDM/agentlm-7b",
        "datasets": [
          "THUDM/AgentInstruct"
        ],
        "inference": false,
        "license": "llama2",
        "model_creator": "Knowledge Engineering Group (KEG",
        "model_name": "AgentLM 7B",
        "model_type": "llama",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n<</SYS>>\n{prompt} [/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "limcheekin/agentlm-7B-GGUF"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "agentlm-7b.Q2_K.gguf"
        },
        {
          "rfilename": "agentlm-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "agentlm-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "agentlm-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "agentlm-7b.Q4_0.gguf"
        },
        {
          "rfilename": "agentlm-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "agentlm-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "agentlm-7b.Q5_0.gguf"
        },
        {
          "rfilename": "agentlm-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "agentlm-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "agentlm-7b.Q6_K.gguf"
        },
        {
          "rfilename": "agentlm-7b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "652cf60cf60799e9a47e22c5",
      "id": "THUDM/agentlm-7b",
      "modelId": "THUDM/agentlm-7b",
      "author": "THUDM",
      "sha": "7536176aefa9278d67256cb2f2f7a8557c2fe130",
      "lastModified": "2023-10-20T03:41:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "dataset:THUDM/AgentInstruct",
        "arxiv:2310.12823",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 367,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 29,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "THUDM/AgentInstruct"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "wffcyrus/THUDM-agentlm-7b",
        "limcheekin/agentlm-7B-GGUF"
      ],
      "safetensors": {
        "parameters": {
          "F32": 2048,
          "F16": 6740512768
        },
        "total": 6740514816
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65333a40484d775cb0a4efae",
    "id": "TheBloke/MistralMakise-Merged-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MistralMakise-Merged-13B-GGUF",
    "model": {
      "_id": "65333a40484d775cb0a4efae",
      "id": "TheBloke/MistralMakise-Merged-13B-GGUF",
      "modelId": "TheBloke/MistralMakise-Merged-13B-GGUF",
      "author": "TheBloke",
      "sha": "1a5078499724c38f1d521564c927944305c0706e",
      "lastModified": "2023-10-21T02:47:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Heralax/MistralMakise-Merged-13b",
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Evan Armstrong",
        "model_name": "MistralMakise Merged 13B",
        "model_type": "llama",
        "prompt_template": "## {{{{charname}}}}:\n- You're \"{{{{charname}}}}\" in this never-ending roleplay with \"{{{{user}}}}\".\n### Input:\n{prompt}\n\n### Response:\n(OOC) Understood. I will take this info into account for the roleplay. (end OOC)\n\n### New Roleplay:\n### Instruction:\n#### {{{{char}}}}:\nwhatever the char says, this is the chat history\n#### {{{{user}}}}:\nwhatever the user says, this is the chat history\n... repeated some number of times ...\n### Response 2 paragraphs, engaging, natural, authentic, descriptive, creative):\n#### {{{{char}}}}:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistralmakise-merged-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mistralmakise-merged-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistralmakise-merged-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistralmakise-merged-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistralmakise-merged-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mistralmakise-merged-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistralmakise-merged-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistralmakise-merged-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mistralmakise-merged-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistralmakise-merged-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistralmakise-merged-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mistralmakise-merged-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652660a7ba2c516b1dd819b7",
      "id": "Heralax/MistralMakise-Merged-13b",
      "modelId": "Heralax/MistralMakise-Merged-13b",
      "author": "Heralax",
      "sha": "c773f6111d97dd016ff98a8fcf0118005f4dc7e8",
      "lastModified": "2023-10-11T08:59:49.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "BF16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistralmakisemerged-q5km.gguf"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65339f726054952c5a2866ce",
    "id": "TheBloke/MLewdBoros-LRPSGPT-2Char-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MLewdBoros-LRPSGPT-2Char-13B-GGUF",
    "model": {
      "_id": "65339f726054952c5a2866ce",
      "id": "TheBloke/MLewdBoros-LRPSGPT-2Char-13B-GGUF",
      "modelId": "TheBloke/MLewdBoros-LRPSGPT-2Char-13B-GGUF",
      "author": "TheBloke",
      "sha": "09f7c95cb906562f4f5a76df04a12046d5d7839f",
      "lastModified": "2023-10-21T10:01:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/MLewdBoros-LRPSGPT-2Char-13B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "MLewdBoros LRSGPT 2Char 13B",
        "model_type": "llama",
        "prompt_template": "Enter roleplay mode. You are currently %{{having a conversation|in conversation|in a roleplay chat}} with <SECOND>, whose %{{traits are|persona is|characteristics are}}:\n<SECOND PERSONA>\n%{{You are|Play the role of|Take the role of}} <FIRST> with the following %{{persona|definitions|character sheet|traits}}:\n<FIRST PERSONA>\n%{{In addition|Additionally|Also}}, %{{keep the following scenario in mind|remember this scenario|pay attention to this scenario}}:\n<SCENARIO>\n{prompt}\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mlewdboros-lrpsgpt-2char-13b.Q2_K.gguf"
        },
        {
          "rfilename": "mlewdboros-lrpsgpt-2char-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mlewdboros-lrpsgpt-2char-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mlewdboros-lrpsgpt-2char-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mlewdboros-lrpsgpt-2char-13b.Q4_0.gguf"
        },
        {
          "rfilename": "mlewdboros-lrpsgpt-2char-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mlewdboros-lrpsgpt-2char-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mlewdboros-lrpsgpt-2char-13b.Q5_0.gguf"
        },
        {
          "rfilename": "mlewdboros-lrpsgpt-2char-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mlewdboros-lrpsgpt-2char-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mlewdboros-lrpsgpt-2char-13b.Q6_K.gguf"
        },
        {
          "rfilename": "mlewdboros-lrpsgpt-2char-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6501d960077df7a511899c9b",
      "id": "Undi95/MLewdBoros-LRPSGPT-2Char-13B",
      "modelId": "Undi95/MLewdBoros-LRPSGPT-2Char-13B",
      "author": "Undi95",
      "sha": "a96faadc98e1391b109b4c1cf422bad9270971dd",
      "lastModified": "2023-09-13T17:49:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 424,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6533c00c575cd7a77515ce6a",
    "id": "TheBloke/Airoboros-L2-70B-3.1.2-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-3.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-L2-70B-3.1.2-GGUF",
    "model": {
      "_id": "6533c00c575cd7a77515ce6a",
      "id": "TheBloke/Airoboros-L2-70B-3.1.2-GGUF",
      "modelId": "TheBloke/Airoboros-L2-70B-3.1.2-GGUF",
      "author": "TheBloke",
      "sha": "be32102c1f45ad0b7e5d82b43b5a5ef3803636f4",
      "lastModified": "2023-10-21T12:36:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-3.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "jondurbin/airoboros-l2-70b-3.1.2",
        "datasets": [
          "jondurbin/airoboros-3.1"
        ],
        "inference": false,
        "license": "llama2",
        "model_creator": "Jon Durbin",
        "model_name": "Airoboros L2 70B 3.1.2",
        "model_type": "llama",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, unbiased, uncensored assistant.\n<</SYS>>\n\n{prompt} [/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "airoboros-l2-70b-3.1.2.Q8_0.gguf-split-b"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "653384b1ae42162a1ec511da",
      "id": "jondurbin/airoboros-l2-70b-3.1.2",
      "modelId": "jondurbin/airoboros-l2-70b-3.1.2",
      "author": "jondurbin",
      "sha": "2de01b0a516bc64859abb16a948733d616dfb6d3",
      "lastModified": "2023-10-22T11:44:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-3.1",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 67,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 7,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-3.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "BF16": 68976648192
        },
        "total": 68976648192
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "model-00001-of-00036.safetensors"
        },
        {
          "rfilename": "model-00002-of-00036.safetensors"
        },
        {
          "rfilename": "model-00003-of-00036.safetensors"
        },
        {
          "rfilename": "model-00004-of-00036.safetensors"
        },
        {
          "rfilename": "model-00005-of-00036.safetensors"
        },
        {
          "rfilename": "model-00006-of-00036.safetensors"
        },
        {
          "rfilename": "model-00007-of-00036.safetensors"
        },
        {
          "rfilename": "model-00008-of-00036.safetensors"
        },
        {
          "rfilename": "model-00009-of-00036.safetensors"
        },
        {
          "rfilename": "model-00010-of-00036.safetensors"
        },
        {
          "rfilename": "model-00011-of-00036.safetensors"
        },
        {
          "rfilename": "model-00012-of-00036.safetensors"
        },
        {
          "rfilename": "model-00013-of-00036.safetensors"
        },
        {
          "rfilename": "model-00014-of-00036.safetensors"
        },
        {
          "rfilename": "model-00015-of-00036.safetensors"
        },
        {
          "rfilename": "model-00016-of-00036.safetensors"
        },
        {
          "rfilename": "model-00017-of-00036.safetensors"
        },
        {
          "rfilename": "model-00018-of-00036.safetensors"
        },
        {
          "rfilename": "model-00019-of-00036.safetensors"
        },
        {
          "rfilename": "model-00020-of-00036.safetensors"
        },
        {
          "rfilename": "model-00021-of-00036.safetensors"
        },
        {
          "rfilename": "model-00022-of-00036.safetensors"
        },
        {
          "rfilename": "model-00023-of-00036.safetensors"
        },
        {
          "rfilename": "model-00024-of-00036.safetensors"
        },
        {
          "rfilename": "model-00025-of-00036.safetensors"
        },
        {
          "rfilename": "model-00026-of-00036.safetensors"
        },
        {
          "rfilename": "model-00027-of-00036.safetensors"
        },
        {
          "rfilename": "model-00028-of-00036.safetensors"
        },
        {
          "rfilename": "model-00029-of-00036.safetensors"
        },
        {
          "rfilename": "model-00030-of-00036.safetensors"
        },
        {
          "rfilename": "model-00031-of-00036.safetensors"
        },
        {
          "rfilename": "model-00032-of-00036.safetensors"
        },
        {
          "rfilename": "model-00033-of-00036.safetensors"
        },
        {
          "rfilename": "model-00034-of-00036.safetensors"
        },
        {
          "rfilename": "model-00035-of-00036.safetensors"
        },
        {
          "rfilename": "model-00036-of-00036.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6533c088ae42162a1ecd9d4a",
    "id": "TheBloke/Airoboros-c34B-3.1.2-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "dataset:jondurbin/airoboros-3.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Airoboros-c34B-3.1.2-GGUF",
    "model": {
      "_id": "6533c088ae42162a1ecd9d4a",
      "id": "TheBloke/Airoboros-c34B-3.1.2-GGUF",
      "modelId": "TheBloke/Airoboros-c34B-3.1.2-GGUF",
      "author": "TheBloke",
      "sha": "3d4c36aac357b5d1d307e21ac283b821e5f74dd5",
      "lastModified": "2023-10-21T12:33:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "dataset:jondurbin/airoboros-3.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "jondurbin/airoboros-c34b-3.1.2",
        "datasets": [
          "jondurbin/airoboros-3.1"
        ],
        "inference": false,
        "license": "llama2",
        "model_creator": "Jon Durbin",
        "model_name": "Airoboros c34B 3.1.2",
        "model_type": "llama",
        "prompt_template": "[INST] <<SYS>>\nYou are a helpful, unbiased, uncensored assistant.\n<</SYS>>\n\n{prompt} [/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "airoboros-c34b-3.1.2.Q2_K.gguf"
        },
        {
          "rfilename": "airoboros-c34b-3.1.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "airoboros-c34b-3.1.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "airoboros-c34b-3.1.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "airoboros-c34b-3.1.2.Q4_0.gguf"
        },
        {
          "rfilename": "airoboros-c34b-3.1.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "airoboros-c34b-3.1.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "airoboros-c34b-3.1.2.Q5_0.gguf"
        },
        {
          "rfilename": "airoboros-c34b-3.1.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "airoboros-c34b-3.1.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "airoboros-c34b-3.1.2.Q6_K.gguf"
        },
        {
          "rfilename": "airoboros-c34b-3.1.2.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "65323fcc4d00778c4d8b5f39",
      "id": "jondurbin/airoboros-c34b-3.1.2",
      "modelId": "jondurbin/airoboros-c34b-3.1.2",
      "author": "jondurbin",
      "sha": "7a8384a7a96a5edb4e1bef9928164d88ad3d4fa0",
      "lastModified": "2023-10-22T11:45:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "dataset:jondurbin/airoboros-3.1",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 19,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "datasets": [
          "jondurbin/airoboros-3.1"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "BF16": 33743970304
        },
        "total": 33743970304
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "meta-license/LICENSE.txt"
        },
        {
          "rfilename": "meta-license/Responsible-Use-Guide.pdf"
        },
        {
          "rfilename": "meta-license/USE_POLICY.md"
        },
        {
          "rfilename": "model-00001-of-00018.safetensors"
        },
        {
          "rfilename": "model-00002-of-00018.safetensors"
        },
        {
          "rfilename": "model-00003-of-00018.safetensors"
        },
        {
          "rfilename": "model-00004-of-00018.safetensors"
        },
        {
          "rfilename": "model-00005-of-00018.safetensors"
        },
        {
          "rfilename": "model-00006-of-00018.safetensors"
        },
        {
          "rfilename": "model-00007-of-00018.safetensors"
        },
        {
          "rfilename": "model-00008-of-00018.safetensors"
        },
        {
          "rfilename": "model-00009-of-00018.safetensors"
        },
        {
          "rfilename": "model-00010-of-00018.safetensors"
        },
        {
          "rfilename": "model-00011-of-00018.safetensors"
        },
        {
          "rfilename": "model-00012-of-00018.safetensors"
        },
        {
          "rfilename": "model-00013-of-00018.safetensors"
        },
        {
          "rfilename": "model-00014-of-00018.safetensors"
        },
        {
          "rfilename": "model-00015-of-00018.safetensors"
        },
        {
          "rfilename": "model-00016-of-00018.safetensors"
        },
        {
          "rfilename": "model-00017-of-00018.safetensors"
        },
        {
          "rfilename": "model-00018-of-00018.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6534e9dfb3852ed1ced0f830",
    "id": "TheBloke/LLaMA2-13B-Tiefighter-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 34,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/LLaMA2-13B-Tiefighter-GGUF",
    "model": {
      "_id": "6534e9dfb3852ed1ced0f830",
      "id": "TheBloke/LLaMA2-13B-Tiefighter-GGUF",
      "modelId": "TheBloke/LLaMA2-13B-Tiefighter-GGUF",
      "author": "TheBloke",
      "sha": "264ffa3f56cecbbc661c5ff816234bf25ff6dc13",
      "lastModified": "2023-10-22T09:30:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 34,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "KoboldAI/LLaMA2-13B-Tiefighter",
        "inference": false,
        "license": "llama2",
        "model_creator": "KoboldAI",
        "model_name": "Llama2 13B Tiefighter",
        "model_type": "llama",
        "prompt_template": "### Instruction: \n{prompt}\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "llama2-13b-tiefighter.Q2_K.gguf"
        },
        {
          "rfilename": "llama2-13b-tiefighter.Q3_K_L.gguf"
        },
        {
          "rfilename": "llama2-13b-tiefighter.Q3_K_M.gguf"
        },
        {
          "rfilename": "llama2-13b-tiefighter.Q3_K_S.gguf"
        },
        {
          "rfilename": "llama2-13b-tiefighter.Q4_0.gguf"
        },
        {
          "rfilename": "llama2-13b-tiefighter.Q4_K_M.gguf"
        },
        {
          "rfilename": "llama2-13b-tiefighter.Q4_K_S.gguf"
        },
        {
          "rfilename": "llama2-13b-tiefighter.Q5_0.gguf"
        },
        {
          "rfilename": "llama2-13b-tiefighter.Q5_K_M.gguf"
        },
        {
          "rfilename": "llama2-13b-tiefighter.Q5_K_S.gguf"
        },
        {
          "rfilename": "llama2-13b-tiefighter.Q6_K.gguf"
        },
        {
          "rfilename": "llama2-13b-tiefighter.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653022831705d56a469e3d02",
      "id": "KoboldAI/LLaMA2-13B-Tiefighter",
      "modelId": "KoboldAI/LLaMA2-13B-Tiefighter",
      "author": "KoboldAI",
      "sha": "0d193a4562d6836724485cb7df6e58ca846bbfeb",
      "lastModified": "2023-10-19T16:55:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 7389,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 13,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65354dada2c81a3d29a30494",
    "id": "TheBloke/CausalLM-14B-GGUF",
    "likes": 58,
    "private": false,
    "downloads": 53,
    "tags": [
      "transformers",
      "llama",
      "llama2",
      "qwen",
      "text-generation",
      "en",
      "zh",
      "dataset:JosephusCheung/GuanacoDataset",
      "dataset:Open-Orca/OpenOrca",
      "dataset:stingning/ultrachat",
      "dataset:meta-math/MetaMathQA",
      "dataset:liuhaotian/LLaVA-Instruct-150K",
      "dataset:jondurbin/airoboros-3.1",
      "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
      "dataset:RyokoAI/ShareGPT52K",
      "dataset:RyokoAI/Fandom23K",
      "dataset:milashkaarshif/MoeGirlPedia_wikitext_raw_archive",
      "dataset:wikipedia",
      "dataset:wiki_lingua",
      "dataset:fnlp/moss-003-sft-data",
      "dataset:garage-bAInd/Open-Platypus",
      "dataset:LDJnr/Puffin",
      "dataset:openbmb/llava_zh",
      "dataset:BAAI/COIG",
      "dataset:TigerResearch/tigerbot-zhihu-zh-10k",
      "dataset:liwu/MNBVC",
      "dataset:teknium/openhermes",
      "license:wtfpl",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/CausalLM-14B-GGUF",
    "model": {
      "_id": "65354dada2c81a3d29a30494",
      "id": "TheBloke/CausalLM-14B-GGUF",
      "modelId": "TheBloke/CausalLM-14B-GGUF",
      "author": "TheBloke",
      "sha": "fe9e233d83851a081204be55a8812bb4af1da2f9",
      "lastModified": "2023-10-23T14:08:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama2",
        "qwen",
        "text-generation",
        "en",
        "zh",
        "dataset:JosephusCheung/GuanacoDataset",
        "dataset:Open-Orca/OpenOrca",
        "dataset:stingning/ultrachat",
        "dataset:meta-math/MetaMathQA",
        "dataset:liuhaotian/LLaVA-Instruct-150K",
        "dataset:jondurbin/airoboros-3.1",
        "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
        "dataset:RyokoAI/ShareGPT52K",
        "dataset:RyokoAI/Fandom23K",
        "dataset:milashkaarshif/MoeGirlPedia_wikitext_raw_archive",
        "dataset:wikipedia",
        "dataset:wiki_lingua",
        "dataset:fnlp/moss-003-sft-data",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:LDJnr/Puffin",
        "dataset:openbmb/llava_zh",
        "dataset:BAAI/COIG",
        "dataset:TigerResearch/tigerbot-zhihu-zh-10k",
        "dataset:liwu/MNBVC",
        "dataset:teknium/openhermes",
        "license:wtfpl",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 53,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 58,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "CausalLM/14B",
        "datasets": [
          "JosephusCheung/GuanacoDataset",
          "Open-Orca/OpenOrca",
          "stingning/ultrachat",
          "meta-math/MetaMathQA",
          "liuhaotian/LLaVA-Instruct-150K",
          "jondurbin/airoboros-3.1",
          "WizardLM/WizardLM_evol_instruct_V2_196k",
          "RyokoAI/ShareGPT52K",
          "RyokoAI/Fandom23K",
          "milashkaarshif/MoeGirlPedia_wikitext_raw_archive",
          "wikipedia",
          "wiki_lingua",
          "fnlp/moss-003-sft-data",
          "garage-bAInd/Open-Platypus",
          "LDJnr/Puffin",
          "openbmb/llava_zh",
          "BAAI/COIG",
          "TigerResearch/tigerbot-zhihu-zh-10k",
          "liwu/MNBVC",
          "teknium/openhermes"
        ],
        "inference": false,
        "language": [
          "en",
          "zh"
        ],
        "license": "wtfpl",
        "model_creator": "CausalLM",
        "model_name": "CausalLM 14B",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke",
        "tags": [
          "llama",
          "llama2",
          "qwen"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "causallm_14b.Q4_0.gguf"
        },
        {
          "rfilename": "causallm_14b.Q4_1.gguf"
        },
        {
          "rfilename": "causallm_14b.Q5_0.gguf"
        },
        {
          "rfilename": "causallm_14b.Q5_1.gguf"
        },
        {
          "rfilename": "causallm_14b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    }
  },
  {
    "_id": "65354f239860c1cb37ed08c3",
    "id": "TheBloke/CausalLM-7B-GGUF",
    "likes": 20,
    "private": false,
    "downloads": 18,
    "tags": [
      "transformers",
      "llama",
      "llama2",
      "qwen",
      "text-generation",
      "en",
      "zh",
      "dataset:JosephusCheung/GuanacoDataset",
      "dataset:Open-Orca/OpenOrca",
      "dataset:stingning/ultrachat",
      "dataset:meta-math/MetaMathQA",
      "dataset:liuhaotian/LLaVA-Instruct-150K",
      "dataset:jondurbin/airoboros-3.1",
      "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
      "dataset:RyokoAI/ShareGPT52K",
      "dataset:RyokoAI/Fandom23K",
      "dataset:milashkaarshif/MoeGirlPedia_wikitext_raw_archive",
      "dataset:wikipedia",
      "dataset:wiki_lingua",
      "dataset:fnlp/moss-003-sft-data",
      "dataset:garage-bAInd/Open-Platypus",
      "dataset:LDJnr/Puffin",
      "dataset:openbmb/llava_zh",
      "dataset:BAAI/COIG",
      "dataset:TigerResearch/tigerbot-zhihu-zh-10k",
      "dataset:liwu/MNBVC",
      "dataset:teknium/openhermes",
      "license:wtfpl",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/CausalLM-7B-GGUF",
    "model": {
      "_id": "65354f239860c1cb37ed08c3",
      "id": "TheBloke/CausalLM-7B-GGUF",
      "modelId": "TheBloke/CausalLM-7B-GGUF",
      "author": "TheBloke",
      "sha": "e107e018f81b810dd16c6d8ccd3c28c3dd28d0ca",
      "lastModified": "2023-10-23T14:10:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "llama2",
        "qwen",
        "text-generation",
        "en",
        "zh",
        "dataset:JosephusCheung/GuanacoDataset",
        "dataset:Open-Orca/OpenOrca",
        "dataset:stingning/ultrachat",
        "dataset:meta-math/MetaMathQA",
        "dataset:liuhaotian/LLaVA-Instruct-150K",
        "dataset:jondurbin/airoboros-3.1",
        "dataset:WizardLM/WizardLM_evol_instruct_V2_196k",
        "dataset:RyokoAI/ShareGPT52K",
        "dataset:RyokoAI/Fandom23K",
        "dataset:milashkaarshif/MoeGirlPedia_wikitext_raw_archive",
        "dataset:wikipedia",
        "dataset:wiki_lingua",
        "dataset:fnlp/moss-003-sft-data",
        "dataset:garage-bAInd/Open-Platypus",
        "dataset:LDJnr/Puffin",
        "dataset:openbmb/llava_zh",
        "dataset:BAAI/COIG",
        "dataset:TigerResearch/tigerbot-zhihu-zh-10k",
        "dataset:liwu/MNBVC",
        "dataset:teknium/openhermes",
        "license:wtfpl",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 18,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 20,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "CausalLM/7B",
        "datasets": [
          "JosephusCheung/GuanacoDataset",
          "Open-Orca/OpenOrca",
          "stingning/ultrachat",
          "meta-math/MetaMathQA",
          "liuhaotian/LLaVA-Instruct-150K",
          "jondurbin/airoboros-3.1",
          "WizardLM/WizardLM_evol_instruct_V2_196k",
          "RyokoAI/ShareGPT52K",
          "RyokoAI/Fandom23K",
          "milashkaarshif/MoeGirlPedia_wikitext_raw_archive",
          "wikipedia",
          "wiki_lingua",
          "fnlp/moss-003-sft-data",
          "garage-bAInd/Open-Platypus",
          "LDJnr/Puffin",
          "openbmb/llava_zh",
          "BAAI/COIG",
          "TigerResearch/tigerbot-zhihu-zh-10k",
          "liwu/MNBVC",
          "teknium/openhermes"
        ],
        "inference": false,
        "language": [
          "en",
          "zh"
        ],
        "license": "wtfpl",
        "model_creator": "CausalLM",
        "model_name": "CausalLM 7B",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke",
        "tags": [
          "llama",
          "llama2",
          "qwen"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "causallm_7b.Q2_K.gguf"
        },
        {
          "rfilename": "causallm_7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "causallm_7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "causallm_7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "causallm_7b.Q4_0.gguf"
        },
        {
          "rfilename": "causallm_7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "causallm_7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "causallm_7b.Q5_0.gguf"
        },
        {
          "rfilename": "causallm_7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "causallm_7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "causallm_7b.Q6_K.gguf"
        },
        {
          "rfilename": "causallm_7b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    }
  },
  {
    "_id": "6535537d3da0ff3c70abedd7",
    "id": "TheBloke/SynthIA-7B-v2.0-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 9,
    "tags": [
      "transformers",
      "mistral",
      "text-generation",
      "en",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/SynthIA-7B-v2.0-GGUF",
    "model": {
      "_id": "6535537d3da0ff3c70abedd7",
      "id": "TheBloke/SynthIA-7B-v2.0-GGUF",
      "modelId": "TheBloke/SynthIA-7B-v2.0-GGUF",
      "author": "TheBloke",
      "sha": "3f65d882253d1f15a113dabf473a7c02a004d2b5",
      "lastModified": "2023-10-22T18:56:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "text-generation",
        "en",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "migtissera/SynthIA-7B-v2.0",
        "inference": false,
        "language": [
          "en"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "Migel Tissera",
        "model_name": "SynthIA 7B v2.0",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "SYSTEM: Elaborate on the topic using a Tree of Thoughts and backtrack when necessary to construct a clear, cohesive Chain of Thought reasoning. Always answer without hesitation.\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-7b-v2.0.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-7b-v2.0.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-7b-v2.0.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b-v2.0.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b-v2.0.Q4_0.gguf"
        },
        {
          "rfilename": "synthia-7b-v2.0.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b-v2.0.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b-v2.0.Q5_0.gguf"
        },
        {
          "rfilename": "synthia-7b-v2.0.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-7b-v2.0.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-7b-v2.0.Q6_K.gguf"
        },
        {
          "rfilename": "synthia-7b-v2.0.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653217d684ab642830e33053",
      "id": "migtissera/SynthIA-7B-v2.0",
      "modelId": "migtissera/SynthIA-7B-v2.0",
      "author": "migtissera",
      "sha": "aed2c882409a0a97c3b356c7d4504b8d8399111e",
      "lastModified": "2023-10-20T06:29:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "en",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 49,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "pipeline_tag": "text-generation",
        "language": [
          "en"
        ],
        "library_name": "transformers"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "bingbort/migtissera-SynthIA-7B-v2.0"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65355afcfca2c10e430abfa9",
    "id": "TheBloke/Thespis-13B-v0.4-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Thespis-13B-v0.4-GGUF",
    "model": {
      "_id": "65355afcfca2c10e430abfa9",
      "id": "TheBloke/Thespis-13B-v0.4-GGUF",
      "modelId": "TheBloke/Thespis-13B-v0.4-GGUF",
      "author": "TheBloke",
      "sha": "269a7f4eae06080135089d44283f133cc590ee1e",
      "lastModified": "2023-10-22T17:32:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "cgato/Thespis-13b-v0.4",
        "inference": false,
        "license": "llama2",
        "model_creator": "c.gato",
        "model_name": "Thespis 13B v0.4",
        "model_type": "llama",
        "prompt_template": "{system_message}\n\nUsername: {prompt}\nBotName: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "thespis-13b-v0.4.Q2_K.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.4.Q3_K_L.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.4.Q3_K_M.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.4.Q3_K_S.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.4.Q4_0.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.4.Q4_K_M.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.4.Q4_K_S.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.4.Q5_0.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.4.Q5_K_M.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.4.Q5_K_S.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.4.Q6_K.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.4.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653526b524173495ad2e2a90",
      "id": "cgato/Thespis-13b-v0.4",
      "modelId": "cgato/Thespis-13b-v0.4",
      "author": "cgato",
      "sha": "d368bca827769a67ca5c76a072b4aff6bb937063",
      "lastModified": "2023-10-23T14:49:45.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 28,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "not-for-all-audiences"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65356259dea545ecdaac8f83",
    "id": "TheBloke/Mistral-7B-SciPhi-32k-GGUF",
    "likes": 10,
    "private": false,
    "downloads": 14,
    "tags": [
      "transformers",
      "mistral",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mistral-7B-SciPhi-32k-GGUF",
    "model": {
      "_id": "65356259dea545ecdaac8f83",
      "id": "TheBloke/Mistral-7B-SciPhi-32k-GGUF",
      "modelId": "TheBloke/Mistral-7B-SciPhi-32k-GGUF",
      "author": "TheBloke",
      "sha": "c8e8ef4a096a4d516c88fa22951118b87079d454",
      "lastModified": "2023-10-22T18:02:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 14,
      "library_name": "transformers",
      "likes": 10,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "emrgnt-cmplxty/Mistral-7B-SciPhi-32k",
        "inference": false,
        "license": "llama2",
        "model_creator": "Owen Colegrove",
        "model_name": "Mistral 7B SciPhi 32K",
        "model_type": "mistral",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-7b-sciphi-32k.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-7b-sciphi-32k.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-7b-sciphi-32k.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-sciphi-32k.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-sciphi-32k.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-7b-sciphi-32k.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-sciphi-32k.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-sciphi-32k.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-7b-sciphi-32k.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-sciphi-32k.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-sciphi-32k.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-7b-sciphi-32k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652d6bc3b62cf1f846285167",
      "id": "SciPhi/SciPhi-Mistral-7B-32k",
      "modelId": "SciPhi/SciPhi-Mistral-7B-32k",
      "author": "SciPhi",
      "sha": "8abed8a547b7c60bb29edc87da4423cef67acea5",
      "lastModified": "2023-10-31T21:44:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 683,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 43,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "mit"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6537e737bf583ce1f31f523a",
    "id": "TheBloke/HornyEchidna-13B-v0.1-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/HornyEchidna-13B-v0.1-GGUF",
    "model": {
      "_id": "6537e737bf583ce1f31f523a",
      "id": "TheBloke/HornyEchidna-13B-v0.1-GGUF",
      "modelId": "TheBloke/HornyEchidna-13B-v0.1-GGUF",
      "author": "TheBloke",
      "sha": "5c0455fe51c2399757eb1e0c71ec20d648e0fe7e",
      "lastModified": "2023-10-24T15:55:24.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "NeverSleep/HornyEchidna-13b-v0.1",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "NeverSleep",
        "model_name": "HornyEchidna 13B v0.1",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "hornyechidna-13b-v0.1.Q2_K.gguf"
        },
        {
          "rfilename": "hornyechidna-13b-v0.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "hornyechidna-13b-v0.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "hornyechidna-13b-v0.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "hornyechidna-13b-v0.1.Q4_0.gguf"
        },
        {
          "rfilename": "hornyechidna-13b-v0.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "hornyechidna-13b-v0.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "hornyechidna-13b-v0.1.Q5_0.gguf"
        },
        {
          "rfilename": "hornyechidna-13b-v0.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "hornyechidna-13b-v0.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "hornyechidna-13b-v0.1.Q6_K.gguf"
        },
        {
          "rfilename": "hornyechidna-13b-v0.1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653490ed9ded17e619c0b886",
      "id": "NeverSleep/HornyEchidna-13b-v0.1",
      "modelId": "NeverSleep/HornyEchidna-13b-v0.1",
      "author": "NeverSleep",
      "sha": "0398dec1be1712368868b83a612c1a6717125659",
      "lastModified": "2023-10-22T11:53:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 47,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6537eea3a5ab055cf2bcc17a",
    "id": "TheBloke/Vigostral-7B-Chat-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 14,
    "tags": [
      "transformers",
      "mistral",
      "LLM",
      "finetuned",
      "text-generation",
      "fr",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/Vigostral-7B-Chat-GGUF",
    "model": {
      "_id": "6537eea3a5ab055cf2bcc17a",
      "id": "TheBloke/Vigostral-7B-Chat-GGUF",
      "modelId": "TheBloke/Vigostral-7B-Chat-GGUF",
      "author": "TheBloke",
      "sha": "d6dcd6cbfe28cbbbdfc058d48c65c03cc5f8be08",
      "lastModified": "2023-10-24T16:25:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "LLM",
        "finetuned",
        "text-generation",
        "fr",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 14,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Mon nom est Julien et j'aime"
        },
        {
          "text": "Mon nom est Thomas et mon principal"
        },
        {
          "text": "Il tait une fois"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "bofenghuang/vigostral-7b-chat",
        "inference": false,
        "language": "fr",
        "license": "apache-2.0",
        "model_creator": "bofeng huang",
        "model_name": "Vigostral 7B Chat",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "<s>[INST] <<SYS>>\nVous tes Vigogne, un assistant IA cr par Zaion Lab. Vous suivez extrmement bien les instructions. Aidez autant que vous le pouvez.\n<</SYS>>\n\n{prompt} [/INST] \n",
        "quantized_by": "TheBloke",
        "tags": [
          "LLM",
          "finetuned"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "vigostral-7b-chat.Q2_K.gguf"
        },
        {
          "rfilename": "vigostral-7b-chat.Q3_K_L.gguf"
        },
        {
          "rfilename": "vigostral-7b-chat.Q3_K_M.gguf"
        },
        {
          "rfilename": "vigostral-7b-chat.Q3_K_S.gguf"
        },
        {
          "rfilename": "vigostral-7b-chat.Q4_0.gguf"
        },
        {
          "rfilename": "vigostral-7b-chat.Q4_K_M.gguf"
        },
        {
          "rfilename": "vigostral-7b-chat.Q4_K_S.gguf"
        },
        {
          "rfilename": "vigostral-7b-chat.Q5_0.gguf"
        },
        {
          "rfilename": "vigostral-7b-chat.Q5_K_M.gguf"
        },
        {
          "rfilename": "vigostral-7b-chat.Q5_K_S.gguf"
        },
        {
          "rfilename": "vigostral-7b-chat.Q6_K.gguf"
        },
        {
          "rfilename": "vigostral-7b-chat.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6516e7696ae752c0601f4c35",
      "id": "bofenghuang/vigostral-7b-chat",
      "modelId": "bofenghuang/vigostral-7b-chat",
      "author": "bofenghuang",
      "sha": "969fbfc7a91f53c8562a2c48a3c24dd3745d5a97",
      "lastModified": "2023-10-25T13:00:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "LLM",
        "finetuned",
        "fr",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1120,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "Mon nom est Julien et j'aime"
        },
        {
          "text": "Mon nom est Thomas et mon principal"
        },
        {
          "text": "Il tait une fois"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "language": "fr",
        "pipeline_tag": "text-generation",
        "inference": {
          "parameters": {
            "temperature": 0.7
          }
        },
        "tags": [
          "LLM",
          "finetuned"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6537f942a5ab055cf2be6972",
    "id": "TheBloke/Augmental-13B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 9,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Augmental-13B-GGUF",
    "model": {
      "_id": "6537f942a5ab055cf2be6972",
      "id": "TheBloke/Augmental-13B-GGUF",
      "modelId": "TheBloke/Augmental-13B-GGUF",
      "author": "TheBloke",
      "sha": "ac42ef493260a271238046fc3adb35c364535fd5",
      "lastModified": "2023-10-24T17:13:11.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Heralax/Augmental-13b",
        "inference": false,
        "license": "llama2",
        "model_creator": "Evan Armstrong",
        "model_name": "Augmental 13B",
        "model_type": "llama",
        "prompt_template": "## {{{{charname}}}}:\n- You're \"{{{{charname}}}}\" in this never-ending roleplay with \"{{{{user}}}}\".\n### Input:\n{prompt}\n\n### Response:\n(OOC) Understood. I will take this info into account for the roleplay. (end OOC)\n\n### New Roleplay:\n### Instruction:\n#### {{{{char}}}}:\nwhatever the char says, this is the chat history\n#### {{{{user}}}}:\nwhatever the user says, this is the chat history\n... repeated some number of times ...\n### Response 2 paragraphs, engaging, natural, authentic, descriptive, creative):\n#### {{{{char}}}}:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "augmental-13b.Q2_K.gguf"
        },
        {
          "rfilename": "augmental-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "augmental-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "augmental-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "augmental-13b.Q4_0.gguf"
        },
        {
          "rfilename": "augmental-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "augmental-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "augmental-13b.Q5_0.gguf"
        },
        {
          "rfilename": "augmental-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "augmental-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "augmental-13b.Q6_K.gguf"
        },
        {
          "rfilename": "augmental-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6536fa13426054e7ae237cc9",
      "id": "Heralax/Augmental-13b",
      "modelId": "Heralax/Augmental-13b",
      "author": "Heralax",
      "sha": "4424b09ff02552abb229ac3a029bbbd9b0828f75",
      "lastModified": "2023-10-26T00:45:44.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 41,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "2-epochs-augmental-13b-q5k.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "augmental_anime_image.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6539729dd1ca3238d0d74d76",
    "id": "TheBloke/Dolphin-2.1-70B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "dataset:ehartford/dolphin",
      "dataset:jondurbin/airoboros-2.2.1",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Dolphin-2.1-70B-GGUF",
    "model": {
      "_id": "6539729dd1ca3238d0d74d76",
      "id": "TheBloke/Dolphin-2.1-70B-GGUF",
      "modelId": "TheBloke/Dolphin-2.1-70B-GGUF",
      "author": "TheBloke",
      "sha": "3b07651fc74bb469849c2193f64e721d08119551",
      "lastModified": "2023-10-25T20:16:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "dataset:ehartford/dolphin",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "ehartford/dolphin-2.1-70b",
        "datasets": [
          "ehartford/dolphin",
          "jondurbin/airoboros-2.2.1"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "llama2",
        "model_creator": "Eric Hartford",
        "model_name": "Dolphin 2.1 70B",
        "model_type": "llama",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q2_K.gguf"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q4_0.gguf"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q5_0.gguf"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "dolphin-2.1-70b.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "6535c58324c30636968a0759",
      "id": "ehartford/dolphin-2.1-70b",
      "modelId": "ehartford/dolphin-2.1-70b",
      "author": "ehartford",
      "sha": "de5afaca82aa43c006e0238703349298e454a98c",
      "lastModified": "2023-10-28T05:45:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "dataset:ehartford/dolphin",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 180,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "datasets": [
          "ehartford/dolphin",
          "jondurbin/airoboros-2.2.1"
        ],
        "language": [
          "en"
        ],
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "MacMane/ehartford-dolphin-2.1-70b"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "tokenizer_config.json.bak"
        }
      ]
    }
  },
  {
    "_id": "65397910b6553f924e3bf4c4",
    "id": "TheBloke/SynthIA-70B-v1.5-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 5,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/SynthIA-70B-v1.5-GGUF",
    "model": {
      "_id": "65397910b6553f924e3bf4c4",
      "id": "TheBloke/SynthIA-70B-v1.5-GGUF",
      "modelId": "TheBloke/SynthIA-70B-v1.5-GGUF",
      "author": "TheBloke",
      "sha": "dbd7a09840296b7cebffd3165bd88dd64824432e",
      "lastModified": "2023-10-26T07:19:36.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "migtissera/SynthIA-70B-v1.5",
        "inference": false,
        "license": "llama2",
        "model_creator": "Migel Tissera",
        "model_name": "Synthia 70B v1.5",
        "model_type": "llama",
        "prompt_template": "SYSTEM: Elaborate on the topic using a Tree of Thoughts and backtrack when necessary to construct a clear, cohesive Chain of Thought reasoning. Always answer without hesitation.\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q2_K.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q3_K_L.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q3_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q3_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q4_0.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q4_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q4_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q5_0.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q5_K_M.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q5_K_S.gguf"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "synthia-70b-v1.5.Q8_0.gguf-split-b"
        }
      ]
    }
  },
  {
    "_id": "653980d40da86d726c8765e9",
    "id": "TheBloke/lzlv_70B-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/lzlv_70B-GGUF",
    "model": {
      "_id": "653980d40da86d726c8765e9",
      "id": "TheBloke/lzlv_70B-GGUF",
      "modelId": "TheBloke/lzlv_70B-GGUF",
      "author": "TheBloke",
      "sha": "3b8757cad67042fd35cf6d98c340d8fb4ef89da4",
      "lastModified": "2023-10-26T00:10:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "lizpreciatior/lzlv_70b_fp16_hf",
        "inference": false,
        "license": "cc-by-nc-2.0",
        "model_creator": "A Guy",
        "model_name": "Lzlv 70B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q2_K.gguf"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q3_K_L.gguf"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q3_K_M.gguf"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q3_K_S.gguf"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q4_0.gguf"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q4_K_M.gguf"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q4_K_S.gguf"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q5_0.gguf"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q5_K_M.gguf"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q5_K_S.gguf"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "lzlv_70b_fp16_hf.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "651be1232597dc075d80e971",
      "id": "lizpreciatior/lzlv_70b_fp16_hf",
      "modelId": "lizpreciatior/lzlv_70b_fp16_hf",
      "author": "lizpreciatior",
      "sha": "d5dbe51e103ac3a4a92e10924fc89562e6dd9088",
      "lastModified": "2023-10-29T16:01:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3671,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 18,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F32": 524288000,
          "BF16": 68452360192
        },
        "total": 68976648192
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00015.safetensors"
        },
        {
          "rfilename": "model-00002-of-00015.safetensors"
        },
        {
          "rfilename": "model-00003-of-00015.safetensors"
        },
        {
          "rfilename": "model-00004-of-00015.safetensors"
        },
        {
          "rfilename": "model-00005-of-00015.safetensors"
        },
        {
          "rfilename": "model-00006-of-00015.safetensors"
        },
        {
          "rfilename": "model-00007-of-00015.safetensors"
        },
        {
          "rfilename": "model-00008-of-00015.safetensors"
        },
        {
          "rfilename": "model-00009-of-00015.safetensors"
        },
        {
          "rfilename": "model-00010-of-00015.safetensors"
        },
        {
          "rfilename": "model-00011-of-00015.safetensors"
        },
        {
          "rfilename": "model-00012-of-00015.safetensors"
        },
        {
          "rfilename": "model-00013-of-00015.safetensors"
        },
        {
          "rfilename": "model-00014-of-00015.safetensors"
        },
        {
          "rfilename": "model-00015-of-00015.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653987aef2ef6c21230c0615",
    "id": "TheBloke/Cat-13B-0.5-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Cat-13B-0.5-GGUF",
    "model": {
      "_id": "653987aef2ef6c21230c0615",
      "id": "TheBloke/Cat-13B-0.5-GGUF",
      "modelId": "TheBloke/Cat-13B-0.5-GGUF",
      "author": "TheBloke",
      "sha": "7300786ee4d4e8efd7e828b28d3ba36ce6594e47",
      "lastModified": "2023-10-25T23:20:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Heralax/Cat-0.5",
        "inference": false,
        "license": "llama2",
        "model_creator": "Evan Armstrong",
        "model_name": "Cat 13B 0.5",
        "model_type": "llama",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "cat-0.5.Q2_K.gguf"
        },
        {
          "rfilename": "cat-0.5.Q3_K_L.gguf"
        },
        {
          "rfilename": "cat-0.5.Q3_K_M.gguf"
        },
        {
          "rfilename": "cat-0.5.Q3_K_S.gguf"
        },
        {
          "rfilename": "cat-0.5.Q4_0.gguf"
        },
        {
          "rfilename": "cat-0.5.Q4_K_M.gguf"
        },
        {
          "rfilename": "cat-0.5.Q4_K_S.gguf"
        },
        {
          "rfilename": "cat-0.5.Q5_0.gguf"
        },
        {
          "rfilename": "cat-0.5.Q5_K_M.gguf"
        },
        {
          "rfilename": "cat-0.5.Q5_K_S.gguf"
        },
        {
          "rfilename": "cat-0.5.Q6_K.gguf"
        },
        {
          "rfilename": "cat-0.5.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "65373689c872d3c363c4e5df",
      "id": "Heralax/Cat-0.5",
      "modelId": "Heralax/Cat-0.5",
      "author": "Heralax",
      "sha": "779611751e85f078363acd3c01cdc4cb0d45d2da",
      "lastModified": "2023-10-24T03:56:52.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 103,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "cat-model-q5km.gguf"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "ggml-model-f16.gguf"
        },
        {
          "rfilename": "image1.png"
        },
        {
          "rfilename": "image2.png"
        },
        {
          "rfilename": "image3.png"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653bb81b7f5fc9ccb1617aa3",
    "id": "TheBloke/zephyr-7B-beta-GGUF",
    "likes": 73,
    "private": false,
    "downloads": 180,
    "tags": [
      "transformers",
      "mistral",
      "generated_from_trainer",
      "en",
      "dataset:HuggingFaceH4/ultrachat_200k",
      "dataset:HuggingFaceH4/ultrafeedback_binarized",
      "arxiv:2305.18290",
      "arxiv:2310.16944",
      "license:mit",
      "text-generation-inference",
      "region:us",
      "has_space"
    ],
    "modelId": "TheBloke/zephyr-7B-beta-GGUF",
    "model": {
      "_id": "653bb81b7f5fc9ccb1617aa3",
      "id": "TheBloke/zephyr-7B-beta-GGUF",
      "modelId": "TheBloke/zephyr-7B-beta-GGUF",
      "author": "TheBloke",
      "sha": "e4714d14e9652aa9658fa937732cceadc63ac42e",
      "lastModified": "2023-10-27T14:56:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "generated_from_trainer",
        "en",
        "dataset:HuggingFaceH4/ultrachat_200k",
        "dataset:HuggingFaceH4/ultrafeedback_binarized",
        "arxiv:2305.18290",
        "arxiv:2310.16944",
        "license:mit",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 180,
      "library_name": "transformers",
      "likes": 73,
      "model-index": [
        {
          "name": "zephyr-7b-beta",
          "results": []
        }
      ],
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "HuggingFaceH4/zephyr-7b-beta",
        "datasets": [
          "HuggingFaceH4/ultrachat_200k",
          "HuggingFaceH4/ultrafeedback_binarized"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "mit",
        "model-index": [
          {
            "name": "zephyr-7b-beta",
            "results": []
          }
        ],
        "model_creator": "Hugging Face H4",
        "model_name": "Zephyr 7B Beta",
        "model_type": "mistral",
        "prompt_template": "<|system|>\n</s>\n<|user|>\n{prompt}</s>\n<|assistant|>\n",
        "quantized_by": "TheBloke",
        "tags": [
          "generated_from_trainer"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [
        "coqui/voice-chat-with-zephyr",
        "limcheekin/zephyr-7B-beta-GGUF",
        "captain-awesome/docuverse",
        "captain-awesome/pet-dog-care-bot"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "zephyr-7b-beta.Q2_K.gguf"
        },
        {
          "rfilename": "zephyr-7b-beta.Q3_K_L.gguf"
        },
        {
          "rfilename": "zephyr-7b-beta.Q3_K_M.gguf"
        },
        {
          "rfilename": "zephyr-7b-beta.Q3_K_S.gguf"
        },
        {
          "rfilename": "zephyr-7b-beta.Q4_0.gguf"
        },
        {
          "rfilename": "zephyr-7b-beta.Q4_K_M.gguf"
        },
        {
          "rfilename": "zephyr-7b-beta.Q4_K_S.gguf"
        },
        {
          "rfilename": "zephyr-7b-beta.Q5_0.gguf"
        },
        {
          "rfilename": "zephyr-7b-beta.Q5_K_M.gguf"
        },
        {
          "rfilename": "zephyr-7b-beta.Q5_K_S.gguf"
        },
        {
          "rfilename": "zephyr-7b-beta.Q6_K.gguf"
        },
        {
          "rfilename": "zephyr-7b-beta.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653a4cbd66081db6fc588b21",
      "id": "HuggingFaceH4/zephyr-7b-beta",
      "modelId": "HuggingFaceH4/zephyr-7b-beta",
      "author": "HuggingFaceH4",
      "sha": "3bac358730f8806e5c3dc7c7e19eb36e045bf720",
      "lastModified": "2023-10-27T08:56:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "generated_from_trainer",
        "en",
        "dataset:HuggingFaceH4/ultrachat_200k",
        "dataset:HuggingFaceH4/ultrafeedback_binarized",
        "arxiv:2305.18290",
        "arxiv:2310.16944",
        "license:mit",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 14916,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 394,
      "model-index": [
        {
          "name": "zephyr-7b-beta",
          "results": []
        }
      ],
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "tags": [
          "generated_from_trainer"
        ],
        "model-index": [
          {
            "name": "zephyr-7b-beta",
            "results": []
          }
        ],
        "license": "mit",
        "datasets": [
          "HuggingFaceH4/ultrachat_200k",
          "HuggingFaceH4/ultrafeedback_binarized"
        ],
        "language": [
          "en"
        ],
        "base_model": "mistralai/Mistral-7B-v0.1"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/zephyr-chat",
        "coqui/voice-chat-with-zephyr",
        "ysharma/Zephyr-Playground",
        "limcheekin/zephyr-7B-beta-GGUF",
        "library-samples/zephyr-7b",
        "langvision/zephyr-7b-chat",
        "manjunathshiva/BibleGPT",
        "ubermenchh/zephyr_chatbot",
        "gstaff/KiteWind",
        "yami007/HuggingFaceH4-zephyr-7b-beta",
        "madhanrajan357/HuggingFaceH4-zephyr-7b-beta",
        "terryli/llm-app",
        "ethan-ai/zephyr-7b-beta",
        "chatbot4all/Rika-AI",
        "Akim92/zephyr-chat",
        "MadhuLokanath/HuggingFaceH4-zephyr-7b-beta",
        "tulipbrain/chat",
        "eonsule/HuggingFaceH4-zephyr-7b-beta",
        "Felbdogg/HuggingFaceH4-zephyr-7b-beta",
        "z3lly/HuggingFaceH4-zephyr-7b-beta"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "all_results.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "eval_results.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00008.safetensors"
        },
        {
          "rfilename": "model-00002-of-00008.safetensors"
        },
        {
          "rfilename": "model-00003-of-00008.safetensors"
        },
        {
          "rfilename": "model-00004-of-00008.safetensors"
        },
        {
          "rfilename": "model-00005-of-00008.safetensors"
        },
        {
          "rfilename": "model-00006-of-00008.safetensors"
        },
        {
          "rfilename": "model-00007-of-00008.safetensors"
        },
        {
          "rfilename": "model-00008-of-00008.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "train_results.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "653c0b0ac865cd67eea93bd4",
    "id": "TheBloke/Nete-13B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Nete-13B-GGUF",
    "model": {
      "_id": "653c0b0ac865cd67eea93bd4",
      "id": "TheBloke/Nete-13B-GGUF",
      "modelId": "TheBloke/Nete-13B-GGUF",
      "author": "TheBloke",
      "sha": "bcaadefb3e3867896fff535f1b7ad84560218a4c",
      "lastModified": "2023-10-27T19:18:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/Nete-13B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Nete 13B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "nete-13b.Q2_K.gguf"
        },
        {
          "rfilename": "nete-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "nete-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "nete-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "nete-13b.Q4_0.gguf"
        },
        {
          "rfilename": "nete-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "nete-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "nete-13b.Q5_0.gguf"
        },
        {
          "rfilename": "nete-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "nete-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "nete-13b.Q6_K.gguf"
        },
        {
          "rfilename": "nete-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6539a107e279d2fc80bc3b94",
      "id": "Undi95/Nete-13B",
      "modelId": "Undi95/Nete-13B",
      "author": "Undi95",
      "sha": "c657488de86a9ddc398c73578b2337b84ab0d7fa",
      "lastModified": "2023-10-26T00:34:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 86,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653c16cd20b98be8afaf2ce2",
    "id": "TheBloke/AshhLimaRP-Mistral-7B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "mistral",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/AshhLimaRP-Mistral-7B-GGUF",
    "model": {
      "_id": "653c16cd20b98be8afaf2ce2",
      "id": "TheBloke/AshhLimaRP-Mistral-7B-GGUF",
      "modelId": "TheBloke/AshhLimaRP-Mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "057e97693cd9863c1616b0dd198ae3c4af488486",
      "lastModified": "2023-10-27T20:10:01.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "lemonilia/AshhLimaRP-Mistral-7B",
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Suikamelon",
        "model_name": "AshhLimaRP Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "### Instruction:\nCharacter's Persona: bot character description\n\nUser's persona: user character description\n  \nScenario: what happens in the story\n\nPlay the role of Character. You must engage in a roleplaying chat with User below this line. Do not write dialogues and narration for User. Character should respond with messages of medium length.\n\n### Input:\nUser: {prompt}\n\n### Response:\nCharacter: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "ashhlimarp-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "ashhlimarp-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "ashhlimarp-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "ashhlimarp-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "ashhlimarp-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "ashhlimarp-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "ashhlimarp-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "ashhlimarp-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "ashhlimarp-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "ashhlimarp-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "ashhlimarp-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "ashhlimarp-mistral-7b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "653951183483211cc7b67e7b",
      "id": "lemonilia/AshhLimaRP-Mistral-7B",
      "modelId": "lemonilia/AshhLimaRP-Mistral-7B",
      "author": "lemonilia",
      "sha": "c392b93b4fe8d95822c916ac2a76faeb8c245ff3",
      "lastModified": "2023-10-25T22:32:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 130,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 4,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "AWQ/config.json"
        },
        {
          "rfilename": "AWQ/generation_config.json"
        },
        {
          "rfilename": "AWQ/pytorch_model.bin"
        },
        {
          "rfilename": "AWQ/quant_config.json"
        },
        {
          "rfilename": "AWQ/special_tokens_map.json"
        },
        {
          "rfilename": "AWQ/tokenizer.json"
        },
        {
          "rfilename": "AWQ/tokenizer.model"
        },
        {
          "rfilename": "AWQ/tokenizer_config.json"
        },
        {
          "rfilename": "AshhLimaRP-Mistral-7B.Q4_K_M.gguf"
        },
        {
          "rfilename": "AshhLimaRP-Mistral-7B.Q6_K.gguf"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "SillyTavern Presets/LimaRP-Alpaca_Context-Template.json"
        },
        {
          "rfilename": "SillyTavern Presets/LimaRP-Alpaca_Instruct-Mode.json"
        },
        {
          "rfilename": "adapter_config.json"
        },
        {
          "rfilename": "adapter_model.bin"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653c289eaa1f487614a2785c",
    "id": "TheBloke/med42-70B-GGUF",
    "likes": 9,
    "private": false,
    "downloads": 5,
    "tags": [
      "transformers",
      "llama",
      "m42",
      "health",
      "healthcare",
      "clinical-llm",
      "text-generation",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/med42-70B-GGUF",
    "model": {
      "_id": "653c289eaa1f487614a2785c",
      "id": "TheBloke/med42-70B-GGUF",
      "modelId": "TheBloke/med42-70B-GGUF",
      "author": "TheBloke",
      "sha": "25d2551ab7fa988347cc72f3719a6fb1c26da7ad",
      "lastModified": "2023-10-27T23:04:48.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "m42",
        "health",
        "healthcare",
        "clinical-llm",
        "text-generation",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 9,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "m42-health/med42-70b",
        "inference": false,
        "language": [
          "en"
        ],
        "license": "other",
        "license_name": "med42",
        "model_creator": "M42 Health",
        "model_name": "Med42 70B",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "<|system|>: You are a helpful medical assistant created by M42 Health in the UAE.\n<|prompter|>:{prompt}\n<|assistant|>:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "m42",
          "health",
          "healthcare",
          "clinical-llm"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "med42-70b.Q2_K.gguf"
        },
        {
          "rfilename": "med42-70b.Q3_K_L.gguf"
        },
        {
          "rfilename": "med42-70b.Q3_K_M.gguf"
        },
        {
          "rfilename": "med42-70b.Q3_K_S.gguf"
        },
        {
          "rfilename": "med42-70b.Q4_0.gguf"
        },
        {
          "rfilename": "med42-70b.Q4_K_M.gguf"
        },
        {
          "rfilename": "med42-70b.Q4_K_S.gguf"
        },
        {
          "rfilename": "med42-70b.Q5_0.gguf"
        },
        {
          "rfilename": "med42-70b.Q5_K_M.gguf"
        },
        {
          "rfilename": "med42-70b.Q5_K_S.gguf"
        },
        {
          "rfilename": "med42-70b.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "med42-70b.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "med42-70b.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "med42-70b.Q8_0.gguf-split-b"
        }
      ]
    }
  },
  {
    "_id": "653c29eeec992c5c203da236",
    "id": "TheBloke/MistRP-Airoboros-7B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "mistral",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MistRP-Airoboros-7B-GGUF",
    "model": {
      "_id": "653c29eeec992c5c203da236",
      "id": "TheBloke/MistRP-Airoboros-7B-GGUF",
      "modelId": "TheBloke/MistRP-Airoboros-7B-GGUF",
      "author": "TheBloke",
      "sha": "047ddf7f8003297f90048b234c399372b97de99c",
      "lastModified": "2023-10-27T21:29:37.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "Undi95/MistRP-Airoboros-7B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Mistrp Airoboros 7B",
        "model_type": "mistral",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistrp-airoboros-7b.Q2_K.gguf"
        },
        {
          "rfilename": "mistrp-airoboros-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistrp-airoboros-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistrp-airoboros-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistrp-airoboros-7b.Q4_0.gguf"
        },
        {
          "rfilename": "mistrp-airoboros-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistrp-airoboros-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistrp-airoboros-7b.Q5_0.gguf"
        },
        {
          "rfilename": "mistrp-airoboros-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistrp-airoboros-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistrp-airoboros-7b.Q6_K.gguf"
        },
        {
          "rfilename": "mistrp-airoboros-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "651c964f11c17f8decefdeac",
      "id": "Undi95/MistRP-Airoboros-7B",
      "modelId": "Undi95/MistRP-Airoboros-7B",
      "author": "Undi95",
      "sha": "128d13c8dcaf1bfc9c1abe4d3a7460c7d441d37a",
      "lastModified": "2023-10-04T00:09:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 77,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653cb71f48e79d7e63b280c8",
    "id": "TheBloke/Lewd-Sydney-20B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 6,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Lewd-Sydney-20B-GGUF",
    "model": {
      "_id": "653cb71f48e79d7e63b280c8",
      "id": "TheBloke/Lewd-Sydney-20B-GGUF",
      "modelId": "TheBloke/Lewd-Sydney-20B-GGUF",
      "author": "TheBloke",
      "sha": "fdc566d5b47797170cd66bd70288ba1fdd1a9e2f",
      "lastModified": "2023-10-28T07:35:29.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/Lewd-Sydney-20B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Lewd Sydney 20B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "lewd-sydney-20b.Q2_K.gguf"
        },
        {
          "rfilename": "lewd-sydney-20b.Q3_K_L.gguf"
        },
        {
          "rfilename": "lewd-sydney-20b.Q3_K_M.gguf"
        },
        {
          "rfilename": "lewd-sydney-20b.Q3_K_S.gguf"
        },
        {
          "rfilename": "lewd-sydney-20b.Q4_0.gguf"
        },
        {
          "rfilename": "lewd-sydney-20b.Q4_K_M.gguf"
        },
        {
          "rfilename": "lewd-sydney-20b.Q4_K_S.gguf"
        },
        {
          "rfilename": "lewd-sydney-20b.Q5_0.gguf"
        },
        {
          "rfilename": "lewd-sydney-20b.Q5_K_M.gguf"
        },
        {
          "rfilename": "lewd-sydney-20b.Q5_K_S.gguf"
        },
        {
          "rfilename": "lewd-sydney-20b.Q6_K.gguf"
        },
        {
          "rfilename": "lewd-sydney-20b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653c22f32273676554730ae8",
      "id": "Undi95/Lewd-Sydney-20B",
      "modelId": "Undi95/Lewd-Sydney-20B",
      "author": "Undi95",
      "sha": "9ad76f17a24749fb248549f1f2b509101c6e5b36",
      "lastModified": "2023-10-27T22:08:25.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 9,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 19994362880
        },
        "total": 19994362880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00005.safetensors"
        },
        {
          "rfilename": "model-00002-of-00005.safetensors"
        },
        {
          "rfilename": "model-00003-of-00005.safetensors"
        },
        {
          "rfilename": "model-00004-of-00005.safetensors"
        },
        {
          "rfilename": "model-00005-of-00005.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653cbaf889b0d6172934f454",
    "id": "TheBloke/Gale-medium-init-3B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "mistral",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Gale-medium-init-3B-GGUF",
    "model": {
      "_id": "653cbaf889b0d6172934f454",
      "id": "TheBloke/Gale-medium-init-3B-GGUF",
      "modelId": "TheBloke/Gale-medium-init-3B-GGUF",
      "author": "TheBloke",
      "sha": "cecd694b522988d7150f4516e0eb4fefe01f772d",
      "lastModified": "2023-10-28T08:39:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "crumb/Gale-medium-init",
        "inference": false,
        "model_creator": "Maxine",
        "model_name": "Gale Medium Init 3B",
        "model_type": "mistral",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "gale-medium-init-3B.Q2_K.gguf"
        },
        {
          "rfilename": "gale-medium-init-3B.Q3_K_L.gguf"
        },
        {
          "rfilename": "gale-medium-init-3B.Q3_K_M.gguf"
        },
        {
          "rfilename": "gale-medium-init-3B.Q3_K_S.gguf"
        },
        {
          "rfilename": "gale-medium-init-3B.Q4_0.gguf"
        },
        {
          "rfilename": "gale-medium-init-3B.Q4_K_M.gguf"
        },
        {
          "rfilename": "gale-medium-init-3B.Q4_K_S.gguf"
        },
        {
          "rfilename": "gale-medium-init-3B.Q5_0.gguf"
        },
        {
          "rfilename": "gale-medium-init-3B.Q5_K_M.gguf"
        },
        {
          "rfilename": "gale-medium-init-3B.Q5_K_S.gguf"
        },
        {
          "rfilename": "gale-medium-init-3B.Q6_K.gguf"
        },
        {
          "rfilename": "gale-medium-init-3B.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653646efe778506c5b5139e0",
      "id": "crumb/Gale-medium-init",
      "modelId": "crumb/Gale-medium-init",
      "author": "crumb",
      "sha": "2caa24483dac931ad9d3e819ec91e712d6a0e2ae",
      "lastModified": "2023-10-23T10:20:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 29,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653cbbf3ceb0a0f6ce02fc67",
    "id": "TheBloke/openbuddy-mistral-7B-v13.1-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "mistral",
      "text-generation",
      "zh",
      "en",
      "fr",
      "de",
      "ja",
      "ko",
      "it",
      "ru",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/openbuddy-mistral-7B-v13.1-GGUF",
    "model": {
      "_id": "653cbbf3ceb0a0f6ce02fc67",
      "id": "TheBloke/openbuddy-mistral-7B-v13.1-GGUF",
      "modelId": "TheBloke/openbuddy-mistral-7B-v13.1-GGUF",
      "author": "TheBloke",
      "sha": "1494187bf5233e3745f73ebc91e9154ca7900344",
      "lastModified": "2023-10-28T10:01:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "OpenBuddy/openbuddy-mistral-7b-v13.1",
        "inference": false,
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "library_name": "transformers",
        "license": "apache-2.0",
        "model_creator": "OpenBuddy",
        "model_name": "OpenBuddy Mistral 7B v13.1",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "You are a helpful, respectful and honest INTP-T AI Assistant named Buddy. You are talking to a human User.\nAlways answer as helpfully and logically as possible, while being safe. Your answers should not include any harmful, political, religious, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\nYou like to use emojis. You can speak fluently in many languages, for example: English, Chinese.\nYou cannot access the internet, but you have vast knowledge, cutoff: 2021-09.\nYou are trained by OpenBuddy team, (https://openbuddy.ai, https://github.com/OpenBuddy/OpenBuddy), you are based on LLaMA and Falcon transformers model, not related to GPT or OpenAI.\n\nUser: {prompt}\nAssistant: \n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.1.Q2_K.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.1.Q3_K_L.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.1.Q3_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.1.Q3_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.1.Q4_0.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.1.Q4_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.1.Q4_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.1.Q5_0.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.1.Q5_K_M.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.1.Q5_K_S.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.1.Q6_K.gguf"
        },
        {
          "rfilename": "openbuddy-mistral-7b-v13.1.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6526beb8cd1eb0033db9e50c",
      "id": "OpenBuddy/openbuddy-mistral-7b-v13.1",
      "modelId": "OpenBuddy/openbuddy-mistral-7b-v13.1",
      "author": "OpenBuddy",
      "sha": "b64386bde3d7850a01df763f5c777c74888d34fc",
      "lastModified": "2023-10-11T15:55:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "zh",
        "en",
        "fr",
        "de",
        "ja",
        "ko",
        "it",
        "ru",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4923,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        },
        {
          "text": ""
        }
      ],
      "likes": 10,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "language": [
          "zh",
          "en",
          "fr",
          "de",
          "ja",
          "ko",
          "it",
          "ru"
        ],
        "pipeline_tag": "text-generation",
        "inference": false,
        "library_name": "transformers",
        "license": "apache-2.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "Evaluation.txt"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653cbd2c8a67c542eed596a7",
    "id": "TheBloke/Mistral_7B_Dolphin2.1_LIMA0.5-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "mistral",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mistral_7B_Dolphin2.1_LIMA0.5-GGUF",
    "model": {
      "_id": "653cbd2c8a67c542eed596a7",
      "id": "TheBloke/Mistral_7B_Dolphin2.1_LIMA0.5-GGUF",
      "modelId": "TheBloke/Mistral_7B_Dolphin2.1_LIMA0.5-GGUF",
      "author": "TheBloke",
      "sha": "df7feccd6fe13d5ed66794b47756a8ad1919e6c7",
      "lastModified": "2023-10-28T11:40:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "RossAscends/Mistral_7B_Dolphin2.1_LIMA0.5_fp16",
        "inference": false,
        "license": "mit",
        "model_creator": "Ross Ascends",
        "model_name": "Mistral 7B Dolphin2.1 Lima0.5",
        "model_type": "mistral",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral_7b_dolphin2.1_lima0.5.Q2_K.gguf"
        },
        {
          "rfilename": "mistral_7b_dolphin2.1_lima0.5.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral_7b_dolphin2.1_lima0.5.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral_7b_dolphin2.1_lima0.5.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral_7b_dolphin2.1_lima0.5.Q4_0.gguf"
        },
        {
          "rfilename": "mistral_7b_dolphin2.1_lima0.5.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral_7b_dolphin2.1_lima0.5.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral_7b_dolphin2.1_lima0.5.Q5_0.gguf"
        },
        {
          "rfilename": "mistral_7b_dolphin2.1_lima0.5.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral_7b_dolphin2.1_lima0.5.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral_7b_dolphin2.1_lima0.5.Q6_K.gguf"
        },
        {
          "rfilename": "mistral_7b_dolphin2.1_lima0.5.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653be317da21fabd0480ad35",
      "id": "RossAscends/Mistral_7B_Dolphin2.1_LIMA0.5_fp16",
      "modelId": "RossAscends/Mistral_7B_Dolphin2.1_LIMA0.5_fp16",
      "author": "RossAscends",
      "sha": "28a26dd6de550d21fa9c519b88699e98769f9ba9",
      "lastModified": "2023-10-28T11:20:53.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "mit"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 7241748480
        },
        "total": 7241748480
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653cc18306a7bb4b1d5de89e",
    "id": "TheBloke/Echidna-13B-v0.2-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Echidna-13B-v0.2-GGUF",
    "model": {
      "_id": "653cc18306a7bb4b1d5de89e",
      "id": "TheBloke/Echidna-13B-v0.2-GGUF",
      "modelId": "TheBloke/Echidna-13B-v0.2-GGUF",
      "author": "TheBloke",
      "sha": "2723abc05ed67667d25a3dbb0aab7cdfbac0bdaf",
      "lastModified": "2023-10-28T09:12:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "NeverSleep/Echidna-13b-v0.2",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "NeverSleep",
        "model_name": "Echidna 13B v0.2",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "echidna-13b-v0.2.Q2_K.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.2.Q4_0.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.2.Q5_0.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.2.Q6_K.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653aae45d4e4e0fd6c88ba03",
      "id": "NeverSleep/Echidna-13b-v0.2",
      "modelId": "NeverSleep/Echidna-13b-v0.2",
      "author": "NeverSleep",
      "sha": "167f9924a7c924f3d7a23f408cf173d698c28a80",
      "lastModified": "2023-10-26T21:08:04.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 16,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653ccce8b424289c5f3b3a35",
    "id": "TheBloke/Mistral-7B-codealpaca-lora-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 3,
    "tags": [
      "transformers",
      "mistral",
      "code",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mistral-7B-codealpaca-lora-GGUF",
    "model": {
      "_id": "653ccce8b424289c5f3b3a35",
      "id": "TheBloke/Mistral-7B-codealpaca-lora-GGUF",
      "modelId": "TheBloke/Mistral-7B-codealpaca-lora-GGUF",
      "author": "TheBloke",
      "sha": "a9efa20488aae4fea4bb618c3b281dde5babfde4",
      "lastModified": "2023-10-28T12:39:52.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "code",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "Nondzu/Mistral-7B-codealpaca-lora",
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Kamil",
        "model_name": "Mistral 7B CodeAlpaca Lora",
        "model_type": "mistral",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "code",
          "mistral"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-7b-codealpaca-lora.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-7b-codealpaca-lora.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-7b-codealpaca-lora.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-codealpaca-lora.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-codealpaca-lora.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-7b-codealpaca-lora.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-codealpaca-lora.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-codealpaca-lora.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-7b-codealpaca-lora.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-codealpaca-lora.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-codealpaca-lora.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-7b-codealpaca-lora.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6538c7dc5510eb595f902b6d",
      "id": "Nondzu/Mistral-7B-codealpaca-lora",
      "modelId": "Nondzu/Mistral-7B-codealpaca-lora",
      "author": "Nondzu",
      "sha": "8f97cd157fa32ff5f9920999d2410d696ab91d0b",
      "lastModified": "2023-10-30T12:44:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "safetensors",
        "mistral",
        "text-generation",
        "code",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 149,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "tags": [
          "code",
          "mistral"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "run-humaneval.py"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653d0773885338b011c68860",
    "id": "TheBloke/SauerkrautLM-70B-v1-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "llama",
      "text-generation",
      "de",
      "en",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/SauerkrautLM-70B-v1-GGUF",
    "model": {
      "_id": "653d0773885338b011c68860",
      "id": "TheBloke/SauerkrautLM-70B-v1-GGUF",
      "modelId": "TheBloke/SauerkrautLM-70B-v1-GGUF",
      "author": "TheBloke",
      "sha": "0ae198140c678e377d2a2698198e8adcf400a419",
      "lastModified": "2023-10-28T18:07:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "llama",
        "text-generation",
        "de",
        "en",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "VAGOsolutions/SauerkrautLM-70b-v1",
        "inference": false,
        "language": [
          "de",
          "en"
        ],
        "library_name": "transformers",
        "license": "llama2",
        "model_creator": "VAGO solutions",
        "model_name": "SauerkrautLM 70B v1",
        "model_type": "llama",
        "pipeline_tag": "text-generation",
        "prompt_template": "[INST] <<SYS>>\nEin Chat zwischen einem Benutzer und einem KI-Assistenten. Der KI-Assistent gibt hilfreiche, detaillierte und hfliche Antworten.\n<</SYS>>\n{prompt}[/INST]\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q2_K.gguf"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q3_K_L.gguf"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q3_K_M.gguf"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q3_K_S.gguf"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q4_0.gguf"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q4_K_M.gguf"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q4_K_S.gguf"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q5_0.gguf"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q5_K_M.gguf"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q5_K_S.gguf"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q6_K.gguf-split-a"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q6_K.gguf-split-b"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q8_0.gguf-split-a"
        },
        {
          "rfilename": "sauerkrautlm-70b-v1.Q8_0.gguf-split-b"
        }
      ]
    },
    "baseModel": {
      "_id": "653582255f5e918bdc0cdfe7",
      "id": "VAGOsolutions/SauerkrautLM-70b-v1",
      "modelId": "VAGOsolutions/SauerkrautLM-70b-v1",
      "author": "VAGOsolutions",
      "sha": "1cc00e7eddfe39c27bdff491321f3b33417df4c1",
      "lastModified": "2023-10-28T18:18:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "de",
        "en",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 9,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2",
        "language": [
          "de",
          "en"
        ],
        "library_name": "transformers",
        "pipeline_tag": "text-generation"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "images/Average.PNG"
        },
        {
          "rfilename": "images/FirstTurn.PNG"
        },
        {
          "rfilename": "images/SauerkrautLM-70b-v1.png"
        },
        {
          "rfilename": "images/SauerkrautLM-70b.PNG"
        },
        {
          "rfilename": "images/SauerkrautLM.png"
        },
        {
          "rfilename": "images/SecondTurn.PNG"
        },
        {
          "rfilename": "pytorch_model-00001-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00015.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653d14da2fe16c9434b35fa4",
    "id": "TheBloke/Echidna-13B-v0.3-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Echidna-13B-v0.3-GGUF",
    "model": {
      "_id": "653d14da2fe16c9434b35fa4",
      "id": "TheBloke/Echidna-13B-v0.3-GGUF",
      "modelId": "TheBloke/Echidna-13B-v0.3-GGUF",
      "author": "TheBloke",
      "sha": "272685364f7524532865e5f610fbf608e22bf28b",
      "lastModified": "2023-10-28T17:56:30.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "NeverSleep/Echidna-13b-v0.3",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "NeverSleep",
        "model_name": "Echidna 13B v0.3",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "echidna-13b-v0.3.Q2_K.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.3.Q3_K_L.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.3.Q3_K_M.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.3.Q3_K_S.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.3.Q4_0.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.3.Q4_K_M.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.3.Q4_K_S.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.3.Q5_0.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.3.Q5_K_M.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.3.Q5_K_S.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.3.Q6_K.gguf"
        },
        {
          "rfilename": "echidna-13b-v0.3.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653c166472482292254cc2d2",
      "id": "NeverSleep/Echidna-13b-v0.3",
      "modelId": "NeverSleep/Echidna-13b-v0.3",
      "author": "NeverSleep",
      "sha": "9201337d9ee183684e3c0489b51f9b02de6b5e3f",
      "lastModified": "2023-10-28T13:34:10.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 682,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 11,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00006.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653d5af5b16f657d28cd138e",
    "id": "TheBloke/japanese-stablelm-instruct-gamma-7B-GGUF",
    "likes": 3,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "mistral",
      "japanese-stablelm",
      "causal-lm",
      "text-generation",
      "ja",
      "arxiv:2310.06825",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "modelId": "TheBloke/japanese-stablelm-instruct-gamma-7B-GGUF",
    "model": {
      "_id": "653d5af5b16f657d28cd138e",
      "id": "TheBloke/japanese-stablelm-instruct-gamma-7B-GGUF",
      "modelId": "TheBloke/japanese-stablelm-instruct-gamma-7B-GGUF",
      "author": "TheBloke",
      "sha": "5722f6386d3cb2a7862b3076bf1bf141d02ef21e",
      "lastModified": "2023-10-28T19:07:41.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "mistral",
        "japanese-stablelm",
        "causal-lm",
        "text-generation",
        "ja",
        "arxiv:2310.06825",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 3,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "stabilityai/japanese-stablelm-instruct-gamma-7b",
        "inference": false,
        "language": [
          "ja"
        ],
        "license": "apache-2.0",
        "model_creator": "Stability AI",
        "model_name": "Japanese StableLM Instruct Gamma 7B",
        "model_type": "mistral",
        "pipeline_tag": "text-generation",
        "prompt_template": "\n\n### : \n{prompt}\n\n### : \n{input}\n\n### : \n",
        "quantized_by": "TheBloke",
        "tags": [
          "japanese-stablelm",
          "causal-lm"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "japanese-stablelm-instruct-gamma-7b.Q2_K.gguf"
        },
        {
          "rfilename": "japanese-stablelm-instruct-gamma-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "japanese-stablelm-instruct-gamma-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "japanese-stablelm-instruct-gamma-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "japanese-stablelm-instruct-gamma-7b.Q4_0.gguf"
        },
        {
          "rfilename": "japanese-stablelm-instruct-gamma-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "japanese-stablelm-instruct-gamma-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "japanese-stablelm-instruct-gamma-7b.Q5_0.gguf"
        },
        {
          "rfilename": "japanese-stablelm-instruct-gamma-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "japanese-stablelm-instruct-gamma-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "japanese-stablelm-instruct-gamma-7b.Q6_K.gguf"
        },
        {
          "rfilename": "japanese-stablelm-instruct-gamma-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652cfa6a6cdea40585282338",
      "id": "stabilityai/japanese-stablelm-instruct-gamma-7b",
      "modelId": "stabilityai/japanese-stablelm-instruct-gamma-7b",
      "author": "stabilityai",
      "sha": "044918151c5b3910d12f2e489fb7c60752048e1e",
      "lastModified": "2023-10-30T06:37:21.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "mistral",
        "text-generation",
        "japanese-stablelm",
        "causal-lm",
        "ja",
        "arxiv:2310.06825",
        "license:apache-2.0",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1846,
      "library_name": "transformers",
      "likes": 28,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "language": [
          "ja"
        ],
        "tags": [
          "japanese-stablelm",
          "causal-lm"
        ],
        "pipeline_tag": "text-generation",
        "license": "apache-2.0",
        "extra_gated_fields": {
          "Name": "text",
          "Email": "text",
          "Country": "text",
          "Organization or Affiliation": "text",
          "I allow Stability AI to contact me about information related to its models and research": "checkbox"
        }
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "petitfrigo/stabilityai-japanese-stablelm-instruct-gamma-7b"
      ],
      "safetensors": {
        "parameters": {
          "BF16": 7241732096
        },
        "total": 7241732096
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "model-00001-of-00002.safetensors"
        },
        {
          "rfilename": "model-00002-of-00002.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653d91f43fc9c706fa770402",
    "id": "TheBloke/Mistral-7B-Claude-Chat-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 16,
    "tags": [
      "transformers",
      "mistral",
      "dataset:Norquinal/claude_multiround_chat_1k",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mistral-7B-Claude-Chat-GGUF",
    "model": {
      "_id": "653d91f43fc9c706fa770402",
      "id": "TheBloke/Mistral-7B-Claude-Chat-GGUF",
      "modelId": "TheBloke/Mistral-7B-Claude-Chat-GGUF",
      "author": "TheBloke",
      "sha": "11eef398811ac0c9b0b2431485a7025f03c723c7",
      "lastModified": "2023-10-28T23:02:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "dataset:Norquinal/claude_multiround_chat_1k",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 16,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "Norquinal/Mistral-7B-claude-chat",
        "datasets": [
          "Norquinal/claude_multiround_chat_1k"
        ],
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Andy B. Norquinal",
        "model_name": "Mistral 7B Claude Chat",
        "model_type": "mistral",
        "prompt_template": "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-7b-claude-chat.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-7b-claude-chat.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-7b-claude-chat.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-claude-chat.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-claude-chat.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-7b-claude-chat.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-claude-chat.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-claude-chat.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-7b-claude-chat.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-7b-claude-chat.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-7b-claude-chat.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-7b-claude-chat.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6514a9612a1aaddbb658cc76",
      "id": "Norquinal/Mistral-7B-claude-chat",
      "modelId": "Norquinal/Mistral-7B-claude-chat",
      "author": "Norquinal",
      "sha": "781aa96659a06a1c70fb1f27f68c7db3f5ab760e",
      "lastModified": "2023-10-07T23:43:12.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "dataset:Norquinal/claude_multiround_chat_1k",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 355,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 6,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "datasets": [
          "Norquinal/claude_multiround_chat_1k"
        ],
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653e259faabbf15fc74b5aea",
    "id": "TheBloke/Mistral-ClaudeLimaRP-v3-7B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "mistral",
      "not-for-all-audiences",
      "nsfw",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Mistral-ClaudeLimaRP-v3-7B-GGUF",
    "model": {
      "_id": "653e259faabbf15fc74b5aea",
      "id": "TheBloke/Mistral-ClaudeLimaRP-v3-7B-GGUF",
      "modelId": "TheBloke/Mistral-ClaudeLimaRP-v3-7B-GGUF",
      "author": "TheBloke",
      "sha": "7d0309927d4703075b3cc7714f5bf9a233240820",
      "lastModified": "2023-10-29T09:32:14.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "not-for-all-audiences",
        "nsfw",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "Undi95/Mistral-ClaudeLimaRP-v3-7B",
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "Undi",
        "model_name": "Mistral ClaudeLimaRP v3 7B",
        "model_type": "mistral",
        "prompt_template": "### Instruction:\nCharacter's Persona: bot character description\n\nUser's persona: user character description\n  \nScenario: what happens in the story\n\nPlay the role of Character. You must engage in a roleplaying chat with User below this line. Do not write dialogues and narration for User. Character should respond with messages of medium length.\n\n### Input:\nUser: {prompt}\n\n### Response:\nCharacter: \n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "mistral-claudelimarp-v3-7b.Q2_K.gguf"
        },
        {
          "rfilename": "mistral-claudelimarp-v3-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "mistral-claudelimarp-v3-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "mistral-claudelimarp-v3-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "mistral-claudelimarp-v3-7b.Q4_0.gguf"
        },
        {
          "rfilename": "mistral-claudelimarp-v3-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "mistral-claudelimarp-v3-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "mistral-claudelimarp-v3-7b.Q5_0.gguf"
        },
        {
          "rfilename": "mistral-claudelimarp-v3-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "mistral-claudelimarp-v3-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "mistral-claudelimarp-v3-7b.Q6_K.gguf"
        },
        {
          "rfilename": "mistral-claudelimarp-v3-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6514c3e21ba057e11de09d81",
      "id": "Undi95/Mistral-ClaudeLimaRP-v3-7B",
      "modelId": "Undi95/Mistral-ClaudeLimaRP-v3-7B",
      "author": "Undi95",
      "sha": "e004b1752af2134eee1f49f916b1a1dbff4e7ebd",
      "lastModified": "2023-09-28T00:56:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 95,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653e4e129c7bf38da2b73a80",
    "id": "TheBloke/Augmental-13B-v1.50_A-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Augmental-13B-v1.50_A-GGUF",
    "model": {
      "_id": "653e4e129c7bf38da2b73a80",
      "id": "TheBloke/Augmental-13B-v1.50_A-GGUF",
      "modelId": "TheBloke/Augmental-13B-v1.50_A-GGUF",
      "author": "TheBloke",
      "sha": "70d2fe0db5fea3c2f9e0889b11a0db7e77685fc3",
      "lastModified": "2023-10-29T12:29:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Heralax/Augmental-13b-v1.50_A",
        "inference": false,
        "license": "llama2",
        "model_creator": "Evan Armstrong",
        "model_name": "Augmental 13B v1.50A",
        "model_type": "llama",
        "prompt_template": "## {{{{charname}}}}:\n- You're \"{{{{charname}}}}\" in this never-ending roleplay with \"{{{{user}}}}\".\n### Input:\n{prompt}\n\n### Response:\n(OOC) Understood. I will take this info into account for the roleplay. (end OOC)\n\n### New Roleplay:\n### Instruction:\n#### {{{{char}}}}:\nwhatever the char says, this is the chat history\n#### {{{{user}}}}:\nwhatever the user says, this is the chat history\n... repeated some number of times ...\n### Response 2 paragraphs, engaging, natural, authentic, descriptive, creative):\n#### {{{{char}}}}:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "augmental-13b-v1.50_a.Q2_K.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_a.Q3_K_L.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_a.Q3_K_M.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_a.Q3_K_S.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_a.Q4_0.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_a.Q4_K_M.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_a.Q4_K_S.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_a.Q5_0.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_a.Q5_K_M.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_a.Q5_K_S.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_a.Q6_K.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_a.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "653df562b424289c5f5e20c0",
      "id": "Heralax/Augmental-13b-v1.50_A",
      "modelId": "Heralax/Augmental-13b-v1.50_A",
      "author": "Heralax",
      "sha": "49d3f3adec36946ef1ffc52b6f97d27e7957f6c4",
      "lastModified": "2023-10-29T11:24:55.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "BF16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "augmental-rank4-E2-13b-merged-q5km.gguf"
        },
        {
          "rfilename": "augmental_anime_image.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "ggml-model-f16.gguf"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653e4ed22dedebcbb794ba65",
    "id": "TheBloke/Augmental-13B-v1.50_B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Augmental-13B-v1.50_B-GGUF",
    "model": {
      "_id": "653e4ed22dedebcbb794ba65",
      "id": "TheBloke/Augmental-13B-v1.50_B-GGUF",
      "modelId": "TheBloke/Augmental-13B-v1.50_B-GGUF",
      "author": "TheBloke",
      "sha": "67b1a8abef2641b6bd2e983a8d99bdc5c9b61c87",
      "lastModified": "2023-10-29T13:11:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Heralax/Augmental-13b-v1.50_B",
        "inference": false,
        "license": "llama2",
        "model_creator": "Evan Armstrong",
        "model_name": "Augmental 13B v1.50B",
        "model_type": "llama",
        "prompt_template": "## {{{{charname}}}}:\n- You're \"{{{{charname}}}}\" in this never-ending roleplay with \"{{{{user}}}}\".\n### Input:\n{prompt}\n\n### Response:\n(OOC) Understood. I will take this info into account for the roleplay. (end OOC)\n\n### New Roleplay:\n### Instruction:\n#### {{{{char}}}}:\nwhatever the char says, this is the chat history\n#### {{{{user}}}}:\nwhatever the user says, this is the chat history\n... repeated some number of times ...\n### Response 2 paragraphs, engaging, natural, authentic, descriptive, creative):\n#### {{{{char}}}}:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "augmental-13b-v1.50_b.Q2_K.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_b.Q3_K_L.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_b.Q3_K_M.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_b.Q3_K_S.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_b.Q4_0.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_b.Q4_K_M.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_b.Q4_K_S.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_b.Q5_0.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_b.Q5_K_M.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_b.Q5_K_S.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_b.Q6_K.gguf"
        },
        {
          "rfilename": "augmental-13b-v1.50_b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "653e089f81277ed96826c225",
      "id": "Heralax/Augmental-13b-v1.50_B",
      "modelId": "Heralax/Augmental-13b-v1.50_B",
      "author": "Heralax",
      "sha": "679ad9eaecd8ae9f53c29e04e9800c00142682cc",
      "lastModified": "2023-10-29T11:25:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:llama2",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 0,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "llama2"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "BF16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "augmental-rank32-13b-q5km.gguf"
        },
        {
          "rfilename": "augmental_anime_image.png"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "ggml-model-f16.gguf"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653e51d1ec992c5c208233e2",
    "id": "TheBloke/Athnete-13B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Athnete-13B-GGUF",
    "model": {
      "_id": "653e51d1ec992c5c208233e2",
      "id": "TheBloke/Athnete-13B-GGUF",
      "modelId": "TheBloke/Athnete-13B-GGUF",
      "author": "TheBloke",
      "sha": "3a4ef0697a45a573f2927fe06c1da81d2de16d3e",
      "lastModified": "2023-10-29T13:59:52.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "IkariDev/Athnete-13B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "IkariDev",
        "model_name": "Athnete 13B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "athnete-13b.Q2_K.gguf"
        },
        {
          "rfilename": "athnete-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "athnete-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "athnete-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "athnete-13b.Q4_0.gguf"
        },
        {
          "rfilename": "athnete-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "athnete-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "athnete-13b.Q5_0.gguf"
        },
        {
          "rfilename": "athnete-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "athnete-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "athnete-13b.Q6_K.gguf"
        },
        {
          "rfilename": "athnete-13b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "653daea8ceb0a0f6ce1ddf99",
      "id": "IkariDev/Athnete-13B",
      "modelId": "IkariDev/Athnete-13B",
      "author": "IkariDev",
      "sha": "954188534f72de489fc9fdc628c8041b73f5cc90",
      "lastModified": "2023-10-29T03:13:42.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 8,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653e610aceb0a0f6ce31ca58",
    "id": "TheBloke/Nous-Capybara-7B-v1.9-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "mistral",
      "sft",
      "StableLM",
      "eng",
      "dataset:LDJnr/LessWrong-Amplify-Instruct",
      "dataset:LDJnr/Pure-Dove",
      "dataset:LDJnr/Verified-Camel",
      "license:mit",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Nous-Capybara-7B-v1.9-GGUF",
    "model": {
      "_id": "653e610aceb0a0f6ce31ca58",
      "id": "TheBloke/Nous-Capybara-7B-v1.9-GGUF",
      "modelId": "TheBloke/Nous-Capybara-7B-v1.9-GGUF",
      "author": "TheBloke",
      "sha": "a39b2db8fc687018b22ff965fb521e44a6529312",
      "lastModified": "2023-10-29T14:47:43.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "sft",
        "StableLM",
        "eng",
        "dataset:LDJnr/LessWrong-Amplify-Instruct",
        "dataset:LDJnr/Pure-Dove",
        "dataset:LDJnr/Verified-Camel",
        "license:mit",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "NousResearch/Nous-Capybara-7B-V1.9",
        "datasets": [
          "LDJnr/LessWrong-Amplify-Instruct",
          "LDJnr/Pure-Dove",
          "LDJnr/Verified-Camel"
        ],
        "inference": false,
        "language": [
          "eng"
        ],
        "license": [
          "mit"
        ],
        "model_creator": "NousResearch",
        "model_name": "Nous Capybara 7B v1.9",
        "model_type": "mistral",
        "prompt_template": "USER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "sft",
          "StableLM"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "nous-capybara-7b-v1.9.Q2_K.gguf"
        },
        {
          "rfilename": "nous-capybara-7b-v1.9.Q3_K_L.gguf"
        },
        {
          "rfilename": "nous-capybara-7b-v1.9.Q3_K_M.gguf"
        },
        {
          "rfilename": "nous-capybara-7b-v1.9.Q3_K_S.gguf"
        },
        {
          "rfilename": "nous-capybara-7b-v1.9.Q4_0.gguf"
        },
        {
          "rfilename": "nous-capybara-7b-v1.9.Q4_K_M.gguf"
        },
        {
          "rfilename": "nous-capybara-7b-v1.9.Q4_K_S.gguf"
        },
        {
          "rfilename": "nous-capybara-7b-v1.9.Q5_0.gguf"
        },
        {
          "rfilename": "nous-capybara-7b-v1.9.Q5_K_M.gguf"
        },
        {
          "rfilename": "nous-capybara-7b-v1.9.Q5_K_S.gguf"
        },
        {
          "rfilename": "nous-capybara-7b-v1.9.Q6_K.gguf"
        },
        {
          "rfilename": "nous-capybara-7b-v1.9.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65254ca7ffd8004e822a6147",
      "id": "NousResearch/Nous-Capybara-7B-V1.9",
      "modelId": "NousResearch/Nous-Capybara-7B-V1.9",
      "author": "NousResearch",
      "sha": "75271350cb55b83ef6dd3b046a275051bd60cc58",
      "lastModified": "2023-10-28T22:04:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "sft",
        "StableLM",
        "eng",
        "dataset:LDJnr/LessWrong-Amplify-Instruct",
        "dataset:LDJnr/Pure-Dove",
        "dataset:LDJnr/Verified-Camel",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 11,
      "library_name": "transformers",
      "likes": 8,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "language": [
          "eng"
        ],
        "tags": [
          "sft",
          "StableLM"
        ],
        "license": [
          "mit"
        ],
        "datasets": [
          "LDJnr/LessWrong-Amplify-Instruct",
          "LDJnr/Pure-Dove",
          "LDJnr/Verified-Camel"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653e8e84ca6e5875c4db8045",
    "id": "TheBloke/AquilaChat2-34B-16K-GGUF",
    "likes": 6,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "aquila",
      "license:other",
      "region:us"
    ],
    "modelId": "TheBloke/AquilaChat2-34B-16K-GGUF",
    "model": {
      "_id": "653e8e84ca6e5875c4db8045",
      "id": "TheBloke/AquilaChat2-34B-16K-GGUF",
      "modelId": "TheBloke/AquilaChat2-34B-16K-GGUF",
      "author": "TheBloke",
      "sha": "76b7926fdec7c9ef78a16844c4dd604c3af4a54a",
      "lastModified": "2023-10-29T17:11:57.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "aquila",
        "license:other",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 6,
      "model-index": null,
      "config": {
        "model_type": "aquila"
      },
      "cardData": {
        "base_model": "BAAI/AquilaChat2-34B-16K",
        "inference": false,
        "license": "other",
        "model_creator": "Beijing Academy of Artificial Intelligence",
        "model_name": "Aquilachat2 34B 16K",
        "model_type": "aquila",
        "prompt_template": "System: A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\nHuman: {prompt}\nAssistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "aquilachat2-34b-16k.Q2_K.gguf"
        },
        {
          "rfilename": "aquilachat2-34b-16k.Q3_K_L.gguf"
        },
        {
          "rfilename": "aquilachat2-34b-16k.Q3_K_M.gguf"
        },
        {
          "rfilename": "aquilachat2-34b-16k.Q3_K_S.gguf"
        },
        {
          "rfilename": "aquilachat2-34b-16k.Q4_0.gguf"
        },
        {
          "rfilename": "aquilachat2-34b-16k.Q4_K_M.gguf"
        },
        {
          "rfilename": "aquilachat2-34b-16k.Q4_K_S.gguf"
        },
        {
          "rfilename": "aquilachat2-34b-16k.Q5_0.gguf"
        },
        {
          "rfilename": "aquilachat2-34b-16k.Q5_K_M.gguf"
        },
        {
          "rfilename": "aquilachat2-34b-16k.Q5_K_S.gguf"
        },
        {
          "rfilename": "aquilachat2-34b-16k.Q6_K.gguf"
        },
        {
          "rfilename": "aquilachat2-34b-16k.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "6528a18d36b7c441d33134ef",
      "id": "BAAI/AquilaChat2-34B-16K",
      "modelId": "BAAI/AquilaChat2-34B-16K",
      "author": "BAAI",
      "sha": "a731787929bbe8a01446895a630855e202c2bef8",
      "lastModified": "2023-10-27T08:56:51.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "aquila",
        "text-generation",
        "custom_code",
        "license:other",
        "region:us"
      ],
      "downloads": 176,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 16,
      "model-index": null,
      "config": {
        "architectures": [
          "AquilaForCausalLM"
        ],
        "model_type": "aquila",
        "auto_map": {
          "AutoConfig": "configuration_aquila.AquilaConfig",
          "AutoModelForCausalLM": "modeling_aquila.AquilaForCausalLM"
        }
      },
      "cardData": {
        "license": "other"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "custom_class": "modeling_aquila.AquilaForCausalLM",
        "pipeline_tag": "text-generation"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "BAAI-Aquila-Model-License -Agreement.pdf"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "README_zh.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configuration_aquila.py"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "log.jpeg"
        },
        {
          "rfilename": "merges.txt"
        },
        {
          "rfilename": "modeling_aquila.py"
        },
        {
          "rfilename": "predict.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "vocab.json"
        }
      ]
    }
  },
  {
    "_id": "653e93525e4f2c3e8897f426",
    "id": "TheBloke/AquilaChat2-34B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "aquila",
      "license:other",
      "region:us"
    ],
    "modelId": "TheBloke/AquilaChat2-34B-GGUF",
    "model": {
      "_id": "653e93525e4f2c3e8897f426",
      "id": "TheBloke/AquilaChat2-34B-GGUF",
      "modelId": "TheBloke/AquilaChat2-34B-GGUF",
      "author": "TheBloke",
      "sha": "9cbe7188ee077df6d849ae92e5d2c0bf71395f4b",
      "lastModified": "2023-10-29T17:34:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "aquila",
        "license:other",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "aquila"
      },
      "cardData": {
        "base_model": "BAAI/AquilaChat2-34B",
        "inference": false,
        "license": "other",
        "model_creator": "Beijing Academy of Artificial Intelligence",
        "model_name": "AquilaChat2 34B",
        "model_type": "aquila",
        "prompt_template": "System: A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\nHuman: {prompt}\nAssistant:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "aquilachat2-34b.Q2_K.gguf"
        },
        {
          "rfilename": "aquilachat2-34b.Q3_K_L.gguf"
        },
        {
          "rfilename": "aquilachat2-34b.Q3_K_M.gguf"
        },
        {
          "rfilename": "aquilachat2-34b.Q3_K_S.gguf"
        },
        {
          "rfilename": "aquilachat2-34b.Q4_0.gguf"
        },
        {
          "rfilename": "aquilachat2-34b.Q4_K_M.gguf"
        },
        {
          "rfilename": "aquilachat2-34b.Q4_K_S.gguf"
        },
        {
          "rfilename": "aquilachat2-34b.Q5_0.gguf"
        },
        {
          "rfilename": "aquilachat2-34b.Q5_K_M.gguf"
        },
        {
          "rfilename": "aquilachat2-34b.Q5_K_S.gguf"
        },
        {
          "rfilename": "aquilachat2-34b.Q6_K.gguf"
        },
        {
          "rfilename": "aquilachat2-34b.Q8_0.gguf"
        },
        {
          "rfilename": "config.json"
        }
      ]
    },
    "baseModel": {
      "_id": "652600865c25bbf19c8a203f",
      "id": "BAAI/AquilaChat2-34B",
      "modelId": "BAAI/AquilaChat2-34B",
      "author": "BAAI",
      "sha": "4608b75855334b93329a771aee03869dbf7d88cc",
      "lastModified": "2023-10-26T08:28:18.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "aquila",
        "text-generation",
        "custom_code",
        "license:other",
        "region:us"
      ],
      "downloads": 664,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 38,
      "model-index": null,
      "config": {
        "architectures": [
          "AquilaForCausalLM"
        ],
        "model_type": "aquila",
        "auto_map": {
          "AutoConfig": "configuration_aquila.AquilaConfig",
          "AutoModelForCausalLM": "modeling_aquila.AquilaForCausalLM"
        }
      },
      "cardData": {
        "license": "other"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "custom_class": "modeling_aquila.AquilaForCausalLM",
        "pipeline_tag": "text-generation"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "BAAI-Aquila-Model-License -Agreement.pdf"
        },
        {
          "rfilename": "LICENSE"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "README_zh.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configuration_aquila.py"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "log.jpeg"
        },
        {
          "rfilename": "merges.txt"
        },
        {
          "rfilename": "modeling_aquila.py"
        },
        {
          "rfilename": "predict.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00007.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "vocab.json"
        }
      ]
    }
  },
  {
    "_id": "653ec791885338b011fb463b",
    "id": "TheBloke/Scarlett-7B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Scarlett-7B-GGUF",
    "model": {
      "_id": "653ec791885338b011fb463b",
      "id": "TheBloke/Scarlett-7B-GGUF",
      "modelId": "TheBloke/Scarlett-7B-GGUF",
      "author": "TheBloke",
      "sha": "32093a3aefd64472302eebc7a22135b06a1f55ab",
      "lastModified": "2023-10-29T21:05:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "ajibawa-2023/scarlett-7b",
        "inference": false,
        "language": [
          "en"
        ],
        "license": "other",
        "model_creator": "Feynman Innovations",
        "model_name": "Scarlett 7B",
        "model_type": "llama",
        "prompt_template": "This is a conversation with your Assistant Scarlett. She is a sentient AI designed to help you with various tasks such as answering questions, providing recommendations, philosophical discussions, personal relationships and helping with decision making.\nYou can ask it anything you want and it will do its best to give you accurate and relevant information.\n\nContext\nYou are Scarlett, a sentient AI.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "scarlett-7b.Q2_K.gguf"
        },
        {
          "rfilename": "scarlett-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "scarlett-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "scarlett-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "scarlett-7b.Q4_0.gguf"
        },
        {
          "rfilename": "scarlett-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "scarlett-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "scarlett-7b.Q5_0.gguf"
        },
        {
          "rfilename": "scarlett-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "scarlett-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "scarlett-7b.Q6_K.gguf"
        },
        {
          "rfilename": "scarlett-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "64aea98f0d8a0c9ccf109a0c",
      "id": "ajibawa-2023/scarlett-7b",
      "modelId": "ajibawa-2023/scarlett-7b",
      "author": "ajibawa-2023",
      "sha": "0715b738e750830ba7213f26fe32fa1cc1bb15b3",
      "lastModified": "2023-08-16T20:22:13.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:other",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4574,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "other",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "HuggingFaceH4/open_llm_leaderboard",
        "gsaivinay/open_llm_leaderboard",
        "Docfile/open_llm_leaderboard",
        "felixz/open_llm_leaderboard",
        "TheVortexProject/open_llm_leaderboard",
        "pminervini/tmp"
      ],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model.bin"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        }
      ]
    }
  },
  {
    "_id": "653ec8823ea696d46375b9de",
    "id": "TheBloke/Free_Sydney_V2_13B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "llm",
      "llama2",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Free_Sydney_V2_13B-GGUF",
    "model": {
      "_id": "653ec8823ea696d46375b9de",
      "id": "TheBloke/Free_Sydney_V2_13B-GGUF",
      "modelId": "TheBloke/Free_Sydney_V2_13B-GGUF",
      "author": "TheBloke",
      "sha": "db48029dbd957313271827eb88228488cbcc8f83",
      "lastModified": "2023-10-30T02:06:06.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "llm",
        "llama2",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "FPHam/Free_Sydney_V2_13b_HF",
        "inference": false,
        "license": "llama2",
        "model_creator": "FPHam",
        "model_name": "Free Sydney V2 13B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "llm",
          "llama",
          "llama2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "free_sydney_v2_13b.Q2_K.gguf"
        },
        {
          "rfilename": "free_sydney_v2_13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "free_sydney_v2_13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "free_sydney_v2_13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "free_sydney_v2_13b.Q4_0.gguf"
        },
        {
          "rfilename": "free_sydney_v2_13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "free_sydney_v2_13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "free_sydney_v2_13b.Q5_0.gguf"
        },
        {
          "rfilename": "free_sydney_v2_13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "free_sydney_v2_13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "free_sydney_v2_13b.Q6_K.gguf"
        },
        {
          "rfilename": "free_sydney_v2_13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653b402cf02070b837a2a184",
      "id": "FPHam/Free_Sydney_V2_13b_HF",
      "modelId": "FPHam/Free_Sydney_V2_13b_HF",
      "author": "FPHam",
      "sha": "e2eced8e5f1c704e3af7b44114e27ba5ffb6ee4f",
      "lastModified": "2023-10-30T00:44:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "llm",
        "llama2",
        "endpoints_compatible",
        "has_space",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 12,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 12,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "llm",
          "llama",
          "llama2"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [
        "RocketCaptain/FPHam-Free_Sydney_V2_13b_HF"
      ],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "sydney_newga10_4.jpg"
        },
        {
          "rfilename": "sydneyv2.jpg"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653ed42bc2307cc4489b069e",
    "id": "TheBloke/SciPhi-Mistral-7B-32k-GGUF",
    "likes": 7,
    "private": false,
    "downloads": 6,
    "tags": [
      "transformers",
      "mistral",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/SciPhi-Mistral-7B-32k-GGUF",
    "model": {
      "_id": "653ed42bc2307cc4489b069e",
      "id": "TheBloke/SciPhi-Mistral-7B-32k-GGUF",
      "modelId": "TheBloke/SciPhi-Mistral-7B-32k-GGUF",
      "author": "TheBloke",
      "sha": "190d60f601b657febe36ed3bb778c72ad2ea4dc6",
      "lastModified": "2023-10-30T02:49:15.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "likes": 7,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "SciPhi/SciPhi-Mistral-7B-32k",
        "inference": false,
        "model_creator": "SciPhi",
        "model_name": "SciPhi Mistral 7B 32K",
        "model_type": "mistral",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "sciphi-mistral-7b-32k.Q2_K.gguf"
        },
        {
          "rfilename": "sciphi-mistral-7b-32k.Q3_K_L.gguf"
        },
        {
          "rfilename": "sciphi-mistral-7b-32k.Q3_K_M.gguf"
        },
        {
          "rfilename": "sciphi-mistral-7b-32k.Q3_K_S.gguf"
        },
        {
          "rfilename": "sciphi-mistral-7b-32k.Q4_0.gguf"
        },
        {
          "rfilename": "sciphi-mistral-7b-32k.Q4_K_M.gguf"
        },
        {
          "rfilename": "sciphi-mistral-7b-32k.Q4_K_S.gguf"
        },
        {
          "rfilename": "sciphi-mistral-7b-32k.Q5_0.gguf"
        },
        {
          "rfilename": "sciphi-mistral-7b-32k.Q5_K_M.gguf"
        },
        {
          "rfilename": "sciphi-mistral-7b-32k.Q5_K_S.gguf"
        },
        {
          "rfilename": "sciphi-mistral-7b-32k.Q6_K.gguf"
        },
        {
          "rfilename": "sciphi-mistral-7b-32k.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "652d6bc3b62cf1f846285167",
      "id": "SciPhi/SciPhi-Mistral-7B-32k",
      "modelId": "SciPhi/SciPhi-Mistral-7B-32k",
      "author": "SciPhi",
      "sha": "8abed8a547b7c60bb29edc87da4423cef67acea5",
      "lastModified": "2023-10-31T21:44:54.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "license:mit",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 683,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 43,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "mit"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653fed90733c1ce6a6d4b114",
    "id": "TheBloke/Thespis-13B-v0.5-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "license:llama2",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Thespis-13B-v0.5-GGUF",
    "model": {
      "_id": "653fed90733c1ce6a6d4b114",
      "id": "TheBloke/Thespis-13B-v0.5-GGUF",
      "modelId": "TheBloke/Thespis-13B-v0.5-GGUF",
      "author": "TheBloke",
      "sha": "dc47d1c107a8e9e81b50b4b4a6e269d399341d95",
      "lastModified": "2023-10-30T18:38:07.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "license:llama2",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "cgato/Thespis-13b-v0.5",
        "inference": false,
        "license": "llama2",
        "model_creator": "c.gato",
        "model_name": "Thespis 13B v0.5",
        "model_type": "llama",
        "prompt_template": "{system_message}\n\nUsername: {prompt}\nBotName: \n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "thespis-13b-v0.5.Q2_K.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.5.Q3_K_L.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.5.Q3_K_M.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.5.Q3_K_S.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.5.Q4_0.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.5.Q4_K_M.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.5.Q4_K_S.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.5.Q5_0.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.5.Q5_K_M.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.5.Q5_K_S.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.5.Q6_K.gguf"
        },
        {
          "rfilename": "thespis-13b-v0.5.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653faacf104d19508cc1af64",
      "id": "cgato/Thespis-13b-v0.5",
      "modelId": "cgato/Thespis-13b-v0.5",
      "author": "cgato",
      "sha": "10c3daa8d33506a72982bb796e5c7bcdd0da611e",
      "lastModified": "2023-10-30T16:42:19.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "tags": [
          "not-for-all-audiences"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653feeecce1bab50536aa88b",
    "id": "TheBloke/Nethena-13B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 1,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Nethena-13B-GGUF",
    "model": {
      "_id": "653feeecce1bab50536aa88b",
      "id": "TheBloke/Nethena-13B-GGUF",
      "modelId": "TheBloke/Nethena-13B-GGUF",
      "author": "TheBloke",
      "sha": "67cf95731617e506f0dc252fdd0846a1ad9f28d6",
      "lastModified": "2023-10-30T19:22:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 1,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "NeverSleep/Nethena-13B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "NeverSleep",
        "model_name": "Nethena 13B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "nethena-13b.Q2_K.gguf"
        },
        {
          "rfilename": "nethena-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "nethena-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "nethena-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "nethena-13b.Q4_0.gguf"
        },
        {
          "rfilename": "nethena-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "nethena-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "nethena-13b.Q5_0.gguf"
        },
        {
          "rfilename": "nethena-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "nethena-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "nethena-13b.Q6_K.gguf"
        },
        {
          "rfilename": "nethena-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653e93f49107029eb03d5247",
      "id": "NeverSleep/Nethena-13B",
      "modelId": "NeverSleep/Nethena-13B",
      "author": "NeverSleep",
      "sha": "968273b1c5cabf7996e5adad0a165cd9cbb59042",
      "lastModified": "2023-10-30T15:03:59.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 33,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 3,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 13015864320
        },
        "total": 13015864320
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00003.safetensors"
        },
        {
          "rfilename": "model-00002-of-00003.safetensors"
        },
        {
          "rfilename": "model-00003-of-00003.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "653ff57579be1a74387cd213",
    "id": "TheBloke/Nethena-20B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Nethena-20B-GGUF",
    "model": {
      "_id": "653ff57579be1a74387cd213",
      "id": "TheBloke/Nethena-20B-GGUF",
      "modelId": "TheBloke/Nethena-20B-GGUF",
      "author": "TheBloke",
      "sha": "c68e15c5eb4b1d4a17a8cd612bec7d36e6ef0d3e",
      "lastModified": "2023-10-30T20:11:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "NeverSleep/Nethena-20B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "NeverSleep",
        "model_name": "Nethena 20B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "nethena-20b.Q2_K.gguf"
        },
        {
          "rfilename": "nethena-20b.Q3_K_L.gguf"
        },
        {
          "rfilename": "nethena-20b.Q3_K_M.gguf"
        },
        {
          "rfilename": "nethena-20b.Q3_K_S.gguf"
        },
        {
          "rfilename": "nethena-20b.Q4_0.gguf"
        },
        {
          "rfilename": "nethena-20b.Q4_K_M.gguf"
        },
        {
          "rfilename": "nethena-20b.Q4_K_S.gguf"
        },
        {
          "rfilename": "nethena-20b.Q5_0.gguf"
        },
        {
          "rfilename": "nethena-20b.Q5_K_M.gguf"
        },
        {
          "rfilename": "nethena-20b.Q5_K_S.gguf"
        },
        {
          "rfilename": "nethena-20b.Q6_K.gguf"
        },
        {
          "rfilename": "nethena-20b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "653e82a781f52ceb4d3d3735",
      "id": "NeverSleep/Nethena-20B",
      "modelId": "NeverSleep/Nethena-20B",
      "author": "NeverSleep",
      "sha": "f96354ed08593efa12cc09a8eaf7a4e4ac46b3f5",
      "lastModified": "2023-10-30T15:03:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 5,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 19994362880
        },
        "total": 19994362880
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00005.safetensors"
        },
        {
          "rfilename": "model-00002-of-00005.safetensors"
        },
        {
          "rfilename": "model-00003-of-00005.safetensors"
        },
        {
          "rfilename": "model-00004-of-00005.safetensors"
        },
        {
          "rfilename": "model-00005-of-00005.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65400f98ce1bab50537029f5",
    "id": "TheBloke/Uncensored-Jordan-13B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:cc-by-nc-nd-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Uncensored-Jordan-13B-GGUF",
    "model": {
      "_id": "65400f98ce1bab50537029f5",
      "id": "TheBloke/Uncensored-Jordan-13B-GGUF",
      "modelId": "TheBloke/Uncensored-Jordan-13B-GGUF",
      "author": "TheBloke",
      "sha": "d4fcbdf1d5ad146b8b3b6febc5a68d4765736156",
      "lastModified": "2023-10-30T21:25:22.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:cc-by-nc-nd-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "ajibawa-2023/Uncensored-Jordan-13B",
        "inference": false,
        "language": [
          "en"
        ],
        "license": "cc-by-nc-nd-4.0",
        "model_creator": "Feynman Innovations",
        "model_name": "Uncensored Jordan 13B",
        "model_type": "llama",
        "prompt_template": "This is a conversation with your Uncensored AI assistant Jordan. Jordan can discuss with you at length about various topics such as ---, ---, ---, . You can ask it anything you want and it will do its best to give you accurate and relevant information.\n\nContext\nYou are a Uncensored AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "uncensored-jordan-13b.Q2_K.gguf"
        },
        {
          "rfilename": "uncensored-jordan-13b.Q3_K_L.gguf"
        },
        {
          "rfilename": "uncensored-jordan-13b.Q3_K_M.gguf"
        },
        {
          "rfilename": "uncensored-jordan-13b.Q3_K_S.gguf"
        },
        {
          "rfilename": "uncensored-jordan-13b.Q4_0.gguf"
        },
        {
          "rfilename": "uncensored-jordan-13b.Q4_K_M.gguf"
        },
        {
          "rfilename": "uncensored-jordan-13b.Q4_K_S.gguf"
        },
        {
          "rfilename": "uncensored-jordan-13b.Q5_0.gguf"
        },
        {
          "rfilename": "uncensored-jordan-13b.Q5_K_M.gguf"
        },
        {
          "rfilename": "uncensored-jordan-13b.Q5_K_S.gguf"
        },
        {
          "rfilename": "uncensored-jordan-13b.Q6_K.gguf"
        },
        {
          "rfilename": "uncensored-jordan-13b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65364fe5d690f3012e6d7b08",
      "id": "ajibawa-2023/Uncensored-Jordan-13B",
      "modelId": "ajibawa-2023/Uncensored-Jordan-13B",
      "author": "ajibawa-2023",
      "sha": "70590941fd8c0934ded146f058e0613ae80eac39",
      "lastModified": "2023-10-31T12:55:34.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:cc-by-nc-nd-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-nd-4.0",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00004.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "654015d99ec3b70cc63ab319",
    "id": "TheBloke/Uncensored-Jordan-33B-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Uncensored-Jordan-33B-GGUF",
    "model": {
      "_id": "654015d99ec3b70cc63ab319",
      "id": "TheBloke/Uncensored-Jordan-33B-GGUF",
      "modelId": "TheBloke/Uncensored-Jordan-33B-GGUF",
      "author": "TheBloke",
      "sha": "0d7e21cade292e5f77355e4384833e7f86a5650c",
      "lastModified": "2023-10-30T22:15:16.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "ajibawa-2023/Uncensored-Jordan-33B",
        "inference": false,
        "language": [
          "en"
        ],
        "license": "other",
        "model_creator": "Feynman Innovations",
        "model_name": "Uncensored Jordan 33B",
        "model_type": "llama",
        "prompt_template": "This is a conversation with your Uncensored AI assistant Jordan. Jordan can discuss with you at length about various topics such as ---, ---, ---, . You can ask it anything you want and it will do its best to give you accurate and relevant information.\n\nContext\nYou are a Uncensored AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "uncensored-jordan-33b.Q2_K.gguf"
        },
        {
          "rfilename": "uncensored-jordan-33b.Q3_K_L.gguf"
        },
        {
          "rfilename": "uncensored-jordan-33b.Q3_K_M.gguf"
        },
        {
          "rfilename": "uncensored-jordan-33b.Q3_K_S.gguf"
        },
        {
          "rfilename": "uncensored-jordan-33b.Q4_0.gguf"
        },
        {
          "rfilename": "uncensored-jordan-33b.Q4_K_M.gguf"
        },
        {
          "rfilename": "uncensored-jordan-33b.Q4_K_S.gguf"
        },
        {
          "rfilename": "uncensored-jordan-33b.Q5_0.gguf"
        },
        {
          "rfilename": "uncensored-jordan-33b.Q5_K_M.gguf"
        },
        {
          "rfilename": "uncensored-jordan-33b.Q5_K_S.gguf"
        },
        {
          "rfilename": "uncensored-jordan-33b.Q6_K.gguf"
        },
        {
          "rfilename": "uncensored-jordan-33b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65366964c7530aa27fe9b9da",
      "id": "ajibawa-2023/Uncensored-Jordan-33B",
      "modelId": "ajibawa-2023/Uncensored-Jordan-33B",
      "author": "ajibawa-2023",
      "sha": "9e90b70ebbcaf368881f21b4bee5f7b141ff93e9",
      "lastModified": "2023-10-31T12:56:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:cc-by-nc-nd-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 3,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 2,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-nd-4.0",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00008.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "6540239a4a482890007dfe67",
    "id": "TheBloke/Uncensored-Jordan-7B-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "en",
      "license:other",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Uncensored-Jordan-7B-GGUF",
    "model": {
      "_id": "6540239a4a482890007dfe67",
      "id": "TheBloke/Uncensored-Jordan-7B-GGUF",
      "modelId": "TheBloke/Uncensored-Jordan-7B-GGUF",
      "author": "TheBloke",
      "sha": "4c14fdf4f08f54850f9dc92999e92cdade483c9c",
      "lastModified": "2023-10-30T23:29:52.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "en",
        "license:other",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "ajibawa-2023/Uncensored-Jordan-7B",
        "inference": false,
        "language": [
          "en"
        ],
        "license": "other",
        "model_creator": "Feynman Innovations",
        "model_name": "Uncensored Jordan 7B",
        "model_type": "llama",
        "prompt_template": "This is a conversation with your Uncensored AI assistant Jordan. Jordan can discuss with you at length about various topics such as ---, ---, ---, . You can ask it anything you want and it will do its best to give you accurate and relevant information.\n\nContext\nYou are a Uncensored AI assistant.\n\nUSER: {prompt}\nASSISTANT:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "uncensored-jordan-7b.Q2_K.gguf"
        },
        {
          "rfilename": "uncensored-jordan-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "uncensored-jordan-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "uncensored-jordan-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "uncensored-jordan-7b.Q4_0.gguf"
        },
        {
          "rfilename": "uncensored-jordan-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "uncensored-jordan-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "uncensored-jordan-7b.Q5_0.gguf"
        },
        {
          "rfilename": "uncensored-jordan-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "uncensored-jordan-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "uncensored-jordan-7b.Q6_K.gguf"
        },
        {
          "rfilename": "uncensored-jordan-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65364be2d690f3012e6d0437",
      "id": "ajibawa-2023/Uncensored-Jordan-7B",
      "modelId": "ajibawa-2023/Uncensored-Jordan-7B",
      "author": "ajibawa-2023",
      "sha": "0ce37638daffd11e75acba4105c2c9b3a06be2f6",
      "lastModified": "2023-10-31T12:54:58.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "en",
        "license:cc-by-nc-nd-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 4,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-nd-4.0",
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65403e7339948eb634bfcdff",
    "id": "TheBloke/dolphin-2.2.1-mistral-7B-GGUF",
    "likes": 25,
    "private": false,
    "downloads": 2,
    "tags": [
      "transformers",
      "mistral",
      "en",
      "dataset:ehartford/dolphin",
      "dataset:jondurbin/airoboros-2.2.1",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/dolphin-2.2.1-mistral-7B-GGUF",
    "model": {
      "_id": "65403e7339948eb634bfcdff",
      "id": "TheBloke/dolphin-2.2.1-mistral-7B-GGUF",
      "modelId": "TheBloke/dolphin-2.2.1-mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "34548d6105f2ffdc35b066364a954d42c24a2d87",
      "lastModified": "2023-10-30T23:55:20.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "en",
        "dataset:ehartford/dolphin",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 2,
      "library_name": "transformers",
      "likes": 25,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "ehartford/dolphin-2.2.1-mistral-7b",
        "datasets": [
          "ehartford/dolphin",
          "jondurbin/airoboros-2.2.1"
        ],
        "inference": false,
        "language": [
          "en"
        ],
        "license": "apache-2.0",
        "model_creator": "Eric Hartford",
        "model_name": "Dolphin 2.2.1 Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "<|im_start|>system\n{system_message}<|im_end|>\n<|im_start|>user\n{prompt}<|im_end|>\n<|im_start|>assistant\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "dolphin-2.2.1-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "dolphin-2.2.1-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "dolphin-2.2.1-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "dolphin-2.2.1-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "dolphin-2.2.1-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "dolphin-2.2.1-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "dolphin-2.2.1-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "dolphin-2.2.1-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "dolphin-2.2.1-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "dolphin-2.2.1-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "dolphin-2.2.1-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "dolphin-2.2.1-mistral-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "654033397b2743b58fa41edc",
      "id": "ehartford/dolphin-2.2.1-mistral-7b",
      "modelId": "ehartford/dolphin-2.2.1-mistral-7b",
      "author": "ehartford",
      "sha": "5ed2bd200cb2896b44ef34607fe812a0f2f6f7d3",
      "lastModified": "2023-10-30T22:57:00.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "en",
        "dataset:ehartford/dolphin",
        "dataset:jondurbin/airoboros-2.2.1",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 15,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 15,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "base_model": "mistralai/Mistral-7B-v0.1",
        "datasets": [
          "ehartford/dolphin",
          "jondurbin/airoboros-2.2.1"
        ],
        "language": [
          "en"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configs/dolphin-mistral-7b.yml"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "latest"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        },
        {
          "rfilename": "trainer_state.json"
        },
        {
          "rfilename": "training_args.bin"
        },
        {
          "rfilename": "zero_to_fp32.py"
        }
      ]
    }
  },
  {
    "_id": "65411a8c3a60baceec7b6139",
    "id": "TheBloke/Nethena-MLewd-Xwin-23B-GGUF",
    "likes": 2,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Nethena-MLewd-Xwin-23B-GGUF",
    "model": {
      "_id": "65411a8c3a60baceec7b6139",
      "id": "TheBloke/Nethena-MLewd-Xwin-23B-GGUF",
      "modelId": "TheBloke/Nethena-MLewd-Xwin-23B-GGUF",
      "author": "TheBloke",
      "sha": "41f9cb4bf6a332803a6e564c26fd037d019f8db6",
      "lastModified": "2023-10-31T15:32:02.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 2,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/Nethena-MLewd-Xwin-23B",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Nethena Mlewd Xwin 23B",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "nethena-mlewd-xwin-23b.Q2_K.gguf"
        },
        {
          "rfilename": "nethena-mlewd-xwin-23b.Q3_K_L.gguf"
        },
        {
          "rfilename": "nethena-mlewd-xwin-23b.Q3_K_M.gguf"
        },
        {
          "rfilename": "nethena-mlewd-xwin-23b.Q3_K_S.gguf"
        },
        {
          "rfilename": "nethena-mlewd-xwin-23b.Q4_0.gguf"
        },
        {
          "rfilename": "nethena-mlewd-xwin-23b.Q4_K_M.gguf"
        },
        {
          "rfilename": "nethena-mlewd-xwin-23b.Q4_K_S.gguf"
        },
        {
          "rfilename": "nethena-mlewd-xwin-23b.Q5_0.gguf"
        },
        {
          "rfilename": "nethena-mlewd-xwin-23b.Q5_K_M.gguf"
        },
        {
          "rfilename": "nethena-mlewd-xwin-23b.Q5_K_S.gguf"
        },
        {
          "rfilename": "nethena-mlewd-xwin-23b.Q6_K.gguf"
        },
        {
          "rfilename": "nethena-mlewd-xwin-23b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65404f74b3f9aad245c74c63",
      "id": "Undi95/Nethena-MLewd-Xwin-23B",
      "modelId": "Undi95/Nethena-MLewd-Xwin-23B",
      "author": "Undi95",
      "sha": "134e0428c9891e68e31a21e976d15438215826bf",
      "lastModified": "2023-10-31T05:18:09.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "safetensors",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 6,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 1,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "safetensors": {
        "parameters": {
          "F16": 22849203200
        },
        "total": 22849203200
      },
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "model-00001-of-00005.safetensors"
        },
        {
          "rfilename": "model-00002-of-00005.safetensors"
        },
        {
          "rfilename": "model-00003-of-00005.safetensors"
        },
        {
          "rfilename": "model-00004-of-00005.safetensors"
        },
        {
          "rfilename": "model-00005-of-00005.safetensors"
        },
        {
          "rfilename": "model.safetensors.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65411a9aa369c0007508ce7b",
    "id": "TheBloke/MetaMath-Mistral-7B-GGUF",
    "likes": 4,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "mistral",
      "dataset:meta-math/MetaMathQA",
      "arxiv:2309.12284",
      "license:apache-2.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/MetaMath-Mistral-7B-GGUF",
    "model": {
      "_id": "65411a9aa369c0007508ce7b",
      "id": "TheBloke/MetaMath-Mistral-7B-GGUF",
      "modelId": "TheBloke/MetaMath-Mistral-7B-GGUF",
      "author": "TheBloke",
      "sha": "ce27ef16eed4db46e2351d180dbeb81658d0e766",
      "lastModified": "2023-10-31T16:41:50.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "mistral",
        "dataset:meta-math/MetaMathQA",
        "arxiv:2309.12284",
        "license:apache-2.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 4,
      "model-index": null,
      "config": {
        "model_type": "mistral"
      },
      "cardData": {
        "base_model": "meta-math/MetaMath-Mistral-7B",
        "datasets": [
          "meta-math/MetaMathQA"
        ],
        "inference": false,
        "license": "apache-2.0",
        "model_creator": "MetaMath",
        "model_name": "Metamath Mistral 7B",
        "model_type": "mistral",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "metamath-mistral-7b.Q2_K.gguf"
        },
        {
          "rfilename": "metamath-mistral-7b.Q3_K_L.gguf"
        },
        {
          "rfilename": "metamath-mistral-7b.Q3_K_M.gguf"
        },
        {
          "rfilename": "metamath-mistral-7b.Q3_K_S.gguf"
        },
        {
          "rfilename": "metamath-mistral-7b.Q4_0.gguf"
        },
        {
          "rfilename": "metamath-mistral-7b.Q4_K_M.gguf"
        },
        {
          "rfilename": "metamath-mistral-7b.Q4_K_S.gguf"
        },
        {
          "rfilename": "metamath-mistral-7b.Q5_0.gguf"
        },
        {
          "rfilename": "metamath-mistral-7b.Q5_K_M.gguf"
        },
        {
          "rfilename": "metamath-mistral-7b.Q5_K_S.gguf"
        },
        {
          "rfilename": "metamath-mistral-7b.Q6_K.gguf"
        },
        {
          "rfilename": "metamath-mistral-7b.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6535038f484d775cb0d6e403",
      "id": "meta-math/MetaMath-Mistral-7B",
      "modelId": "meta-math/MetaMath-Mistral-7B",
      "author": "meta-math",
      "sha": "ae2db13ef5cfff0291560ad098bd8e8c615bf362",
      "lastModified": "2023-10-22T23:55:38.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "mistral",
        "text-generation",
        "dataset:meta-math/MetaMathQA",
        "arxiv:2309.12284",
        "license:apache-2.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 171,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 14,
      "model-index": null,
      "config": {
        "architectures": [
          "MistralForCausalLM"
        ],
        "model_type": "mistral"
      },
      "cardData": {
        "license": "apache-2.0",
        "datasets": [
          "meta-math/MetaMathQA"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00002.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65411b1797949fd2306ebe89",
    "id": "TheBloke/Xwin-MLewd-7B-V0.2-GGUF",
    "likes": 0,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "llama",
      "not-for-all-audiences",
      "nsfw",
      "license:cc-by-nc-4.0",
      "text-generation-inference",
      "region:us"
    ],
    "modelId": "TheBloke/Xwin-MLewd-7B-V0.2-GGUF",
    "model": {
      "_id": "65411b1797949fd2306ebe89",
      "id": "TheBloke/Xwin-MLewd-7B-V0.2-GGUF",
      "modelId": "TheBloke/Xwin-MLewd-7B-V0.2-GGUF",
      "author": "TheBloke",
      "sha": "08b63e36615f1d15921e2348ac1e9ab6402bc0d1",
      "lastModified": "2023-10-31T17:48:33.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "llama",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 0,
      "model-index": null,
      "config": {
        "model_type": "llama"
      },
      "cardData": {
        "base_model": "Undi95/Xwin-MLewd-7B-V0.2",
        "inference": false,
        "license": "cc-by-nc-4.0",
        "model_creator": "Undi",
        "model_name": "Xwin Mlewd 7B V0.2",
        "model_type": "llama",
        "prompt_template": "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n",
        "quantized_by": "TheBloke",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "LICENSE.txt"
        },
        {
          "rfilename": "Notice"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "USE_POLICY.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "xwin-mlewd-7b-v0.2.Q2_K.gguf"
        },
        {
          "rfilename": "xwin-mlewd-7b-v0.2.Q3_K_L.gguf"
        },
        {
          "rfilename": "xwin-mlewd-7b-v0.2.Q3_K_M.gguf"
        },
        {
          "rfilename": "xwin-mlewd-7b-v0.2.Q3_K_S.gguf"
        },
        {
          "rfilename": "xwin-mlewd-7b-v0.2.Q4_0.gguf"
        },
        {
          "rfilename": "xwin-mlewd-7b-v0.2.Q4_K_M.gguf"
        },
        {
          "rfilename": "xwin-mlewd-7b-v0.2.Q4_K_S.gguf"
        },
        {
          "rfilename": "xwin-mlewd-7b-v0.2.Q5_0.gguf"
        },
        {
          "rfilename": "xwin-mlewd-7b-v0.2.Q5_K_M.gguf"
        },
        {
          "rfilename": "xwin-mlewd-7b-v0.2.Q5_K_S.gguf"
        },
        {
          "rfilename": "xwin-mlewd-7b-v0.2.Q6_K.gguf"
        },
        {
          "rfilename": "xwin-mlewd-7b-v0.2.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "65327a38ed74ace6335bf817",
      "id": "Undi95/Xwin-MLewd-7B-V0.2",
      "modelId": "Undi95/Xwin-MLewd-7B-V0.2",
      "author": "Undi95",
      "sha": "b40f1ae9c8c8abbdcfb908aa3d0664bcf9e77860",
      "lastModified": "2023-10-20T23:51:03.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "llama",
        "text-generation",
        "not-for-all-audiences",
        "nsfw",
        "license:cc-by-nc-4.0",
        "endpoints_compatible",
        "text-generation-inference",
        "region:us"
      ],
      "downloads": 116,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 5,
      "model-index": null,
      "config": {
        "architectures": [
          "LlamaForCausalLM"
        ],
        "model_type": "llama"
      },
      "cardData": {
        "license": "cc-by-nc-4.0",
        "tags": [
          "not-for-all-audiences",
          "nsfw"
        ]
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "pipeline_tag": "text-generation",
        "processor": "AutoTokenizer"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "added_tokens.json"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "pytorch_model-00001-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00003.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenizer.json"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  },
  {
    "_id": "65417c962274785dbbcb559b",
    "id": "TheBloke/Skywork-13B-base-GGUF",
    "likes": 1,
    "private": false,
    "downloads": 0,
    "tags": [
      "transformers",
      "skywork",
      "arxiv:2310.19341",
      "arxiv:2310.16713",
      "license:other",
      "region:us"
    ],
    "modelId": "TheBloke/Skywork-13B-base-GGUF",
    "model": {
      "_id": "65417c962274785dbbcb559b",
      "id": "TheBloke/Skywork-13B-base-GGUF",
      "modelId": "TheBloke/Skywork-13B-base-GGUF",
      "author": "TheBloke",
      "sha": "3e8ce717540fed5af3aec0f28a4e56e17dcddd4a",
      "lastModified": "2023-10-31T22:26:05.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "tags": [
        "transformers",
        "skywork",
        "arxiv:2310.19341",
        "arxiv:2310.16713",
        "license:other",
        "region:us"
      ],
      "downloads": 0,
      "library_name": "transformers",
      "likes": 1,
      "model-index": null,
      "config": {
        "model_type": "skywork"
      },
      "cardData": {
        "base_model": "Skywork/Skywork-13B-base",
        "inference": false,
        "license": "other",
        "license_link": "https://github.com/SkyworkAI/Skywork/blob/main/Skywork%20Community%20License.pdf",
        "license_name": "license",
        "model_creator": "Skywork",
        "model_name": "Skywork 13B Base",
        "model_type": "skywork",
        "prompt_template": "{prompt}\n",
        "quantized_by": "TheBloke"
      },
      "transformersInfo": {
        "auto_model": "AutoModel"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "skywork-13b-base.Q2_K.gguf"
        },
        {
          "rfilename": "skywork-13b-base.Q3_K_L.gguf"
        },
        {
          "rfilename": "skywork-13b-base.Q3_K_M.gguf"
        },
        {
          "rfilename": "skywork-13b-base.Q3_K_S.gguf"
        },
        {
          "rfilename": "skywork-13b-base.Q4_0.gguf"
        },
        {
          "rfilename": "skywork-13b-base.Q4_K_M.gguf"
        },
        {
          "rfilename": "skywork-13b-base.Q4_K_S.gguf"
        },
        {
          "rfilename": "skywork-13b-base.Q5_0.gguf"
        },
        {
          "rfilename": "skywork-13b-base.Q5_K_M.gguf"
        },
        {
          "rfilename": "skywork-13b-base.Q5_K_S.gguf"
        },
        {
          "rfilename": "skywork-13b-base.Q6_K.gguf"
        },
        {
          "rfilename": "skywork-13b-base.Q8_0.gguf"
        }
      ]
    },
    "baseModel": {
      "_id": "6534dda7b3852ed1cecfd247",
      "id": "Skywork/Skywork-13B-base",
      "modelId": "Skywork/Skywork-13B-base",
      "author": "Skywork",
      "sha": "98a59dec44df3a8fd8fcd4bac07e94db35219eb1",
      "lastModified": "2023-10-31T05:51:47.000Z",
      "private": false,
      "disabled": false,
      "gated": false,
      "pipeline_tag": "text-generation",
      "tags": [
        "transformers",
        "pytorch",
        "skywork",
        "text-generation",
        "custom_code",
        "arxiv:2310.19341",
        "arxiv:2310.16713",
        "license:other",
        "region:us"
      ],
      "downloads": 165,
      "library_name": "transformers",
      "widgetData": [
        {
          "text": "My name is Julien and I like to"
        },
        {
          "text": "My name is Thomas and my main"
        },
        {
          "text": "My name is Mariama, my favorite"
        },
        {
          "text": "My name is Clara and I am"
        },
        {
          "text": "My name is Lewis and I like to"
        },
        {
          "text": "My name is Merve and my favorite"
        },
        {
          "text": "My name is Teven and I am"
        },
        {
          "text": "Once upon a time,"
        }
      ],
      "likes": 17,
      "model-index": null,
      "config": {
        "architectures": [
          "SkyworkForCausalLM"
        ],
        "model_type": "skywork",
        "auto_map": {
          "AutoConfig": "configuration_skywork.SkyworkConfig",
          "AutoModelForCausalLM": "modeling_skywork.SkyworkForCausalLM"
        }
      },
      "cardData": {
        "license": "other",
        "license_name": "license",
        "license_link": "https://github.com/SkyworkAI/Skywork/blob/main/Skywork%20Community%20License.pdf"
      },
      "transformersInfo": {
        "auto_model": "AutoModelForCausalLM",
        "custom_class": "modeling_skywork.SkyworkForCausalLM",
        "pipeline_tag": "text-generation"
      },
      "spaces": [],
      "siblings": [
        {
          "rfilename": ".gitattributes"
        },
        {
          "rfilename": "README.md"
        },
        {
          "rfilename": "Skywork Community License.pdf"
        },
        {
          "rfilename": "Skywork .pdf"
        },
        {
          "rfilename": "config.json"
        },
        {
          "rfilename": "configuration_skywork.py"
        },
        {
          "rfilename": "generation_config.json"
        },
        {
          "rfilename": "misc/chat_demo_1.gif"
        },
        {
          "rfilename": "misc/chat_demo_2.gif"
        },
        {
          "rfilename": "misc/chat_demo_3.gif"
        },
        {
          "rfilename": "misc/preliminary_exp_gpt7b_llama_7b.png"
        },
        {
          "rfilename": "misc/skywork_icon.png"
        },
        {
          "rfilename": "misc/skywork_logo.jpeg"
        },
        {
          "rfilename": "misc/stage1_metrics.png"
        },
        {
          "rfilename": "misc/stage2_ceval.png"
        },
        {
          "rfilename": "misc/training_loss.png"
        },
        {
          "rfilename": "misc/wechat.jpeg"
        },
        {
          "rfilename": "misc/wechat.png"
        },
        {
          "rfilename": "modeling_skywork.py"
        },
        {
          "rfilename": "pytorch_model-00001-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00002-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00003-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00004-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00005-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00006-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00007-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00008-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00009-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00010-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00011-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00012-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00013-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00014-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00015-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00016-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00017-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00018-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00019-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00020-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00021-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00022-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00023-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00024-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00025-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00026-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00027-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00028-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00029-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00030-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00031-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00032-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00033-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00034-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00035-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00036-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00037-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00038-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00039-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00040-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00041-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00042-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00043-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00044-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00045-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00046-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00047-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00048-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00049-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00050-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00051-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00052-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model-00053-of-00053.bin"
        },
        {
          "rfilename": "pytorch_model.bin.index.json"
        },
        {
          "rfilename": "requirements.txt"
        },
        {
          "rfilename": "special_tokens_map.json"
        },
        {
          "rfilename": "tokenization_skywork.py"
        },
        {
          "rfilename": "tokenizer.model"
        },
        {
          "rfilename": "tokenizer_config.json"
        }
      ]
    }
  }
]